 protected CompilerOptions createOptions() { CompilerOptions options = new CompilerOptions(); if (flags.processJqueryPrimitives) { options.setCodingConvention(new JqueryCodingConvention()); } else { options.setCodingConvention(new ClosureCodingConvention()); }  options.setExtraAnnotationNames(flags.extraAnnotationName);  CompilationLevel level = flags.compilationLevel; level.setOptionsForCompilationLevel(options);  if (flags.debug) { level.setDebugOptionsForCompilationLevel(options); }  if (flags.useTypesForOptimization) { level.setTypeBasedOptimizationOptions(options); }  if (flags.generateExports) { options.setGenerateExports(flags.generateExports); }  WarningLevel wLevel = flags.warningLevel; wLevel.setOptionsForWarningLevel(options); for (FormattingOption formattingOption : flags.formatting) { formattingOption.applyToOptions(options); }  options.closurePass = flags.processClosurePrimitives;  options.jqueryPass = CompilationLevel.ADVANCED_OPTIMIZATIONS == level && flags.processJqueryPrimitives;  options.angularPass = flags.angularPass;  if (!flags.translationsFile.isEmpty()) { try { options.messageBundle = new XtbMessageBundle( new FileInputStream(flags.translationsFile), flags.translationsProject); } catch (IOException e) { throw new RuntimeException("Reading XTB file", e); } } else if (CompilationLevel.ADVANCED_OPTIMIZATIONS == level) { // In SIMPLE or WHITESPACE mode, if the user hasn't specified a // translations file, they might reasonably try to write their own // implementation of goog.getMsg that makes the substitution at // run-time. // // In ADVANCED mode, goog.getMsg is going to be renamed anyway, // so we might as well inline it. But shut off the i18n warnings, // because the user didn't really ask for i18n. options.messageBundle = new EmptyMessageBundle(); }  return options; }
 public Object handle(Invocation invocation) throws Throwable { if (invocationContainerImpl.hasAnswersForStubbing()) { // stubbing voids with stubVoid() or doAnswer() style InvocationMatcher invocationMatcher = matchersBinder.bindMatchers(mockingProgress .getArgumentMatcherStorage(), invocation); invocationContainerImpl.setMethodForStubbing(invocationMatcher); return null; } VerificationMode verificationMode = mockingProgress.pullVerificationMode();  InvocationMatcher invocationMatcher = matchersBinder.bindMatchers(mockingProgress.getArgumentMatcherStorage(), invocation);  mockingProgress.validateState();  //if verificationMode is not null then someone is doing verify() if (verificationMode != null) { //We need to check if verification was started on the correct mock // - see VerifyingWithAnExtraCallToADifferentMockTest VerificationDataImpl data = new VerificationDataImpl(invocationContainerImpl.getInvocations(), invocationMatcher); verificationMode.verify(data); return null; }  invocationContainerImpl.setInvocationForPotentialStubbing(invocationMatcher); OngoingStubbingImpl<T> ongoingStubbing = new OngoingStubbingImpl<T>(invocationContainerImpl); mockingProgress.reportOngoingStubbing(ongoingStubbing);  StubbedInvocationMatcher stubbedInvocation = invocationContainerImpl.findAnswerFor(invocation);  if (stubbedInvocation != null) { stubbedInvocation.captureArgumentsFrom(invocation); return stubbedInvocation.answer(invocation); } else { Object ret = mockSettings.getDefaultAnswer().answer(invocation);  // redo setting invocation for potential stubbing in case of partial // mocks / spies. // Without it, the real method inside 'when' might have delegated // to other self method and overwrite the intended stubbed method // with a different one. invocationContainerImpl.resetInvocationForPotentialStubbing(invocationMatcher); return ret; } }
 public <T> T verify(T mock, VerificationMode mode) { if (mock == null) { reporter.nullPassedToVerify(); } else if (!mockUtil.isMock(mock)) { reporter.notAMockPassedToVerify(); } mockingProgress.verificationStarted(mode); return mock; }
 public void captureArgumentsFrom(Invocation i) { int k = 0; for (Matcher m : matchers) { if (m instanceof CapturesArguments) { ((CapturesArguments) m).captureFrom(i.getArguments()[k]); } k++; } }
 public StrBuilder appendFixedWidthPadLeft(Object obj, int width, char padChar) { if (width > 0) { ensureCapacity(size + width); String str = (obj == null ? getNullText() : obj.toString()); int strLen = str.length(); if (strLen >= width) { str.getChars(strLen - width, strLen, buffer, size); } else { int padLen = width - strLen; for (int i = 0; i < padLen; i++) { buffer[size + i] = padChar; } str.getChars(0, strLen, buffer, size + padLen); } size += width; } return this; }
 public StrBuilder appendFixedWidthPadRight(Object obj, int width, char padChar) { if (width > 0) { ensureCapacity(size + width); String str = (obj == null ? getNullText() : obj.toString()); int strLen = str.length(); if (strLen >= width) { str.getChars(0, width, buffer, size); } else { int padLen = width - strLen; str.getChars(0, strLen, buffer, size); for (int i = 0; i < padLen; i++) { buffer[size + strLen + i] = padChar; } } size += width; } return this; }
 private Node tryFoldArrayAccess(Node n, Node left, Node right) { Node parent = n.getParent(); // If GETPROP/GETELEM is used as assignment target the array literal is // acting as a temporary we can't fold it here: //    "[][0] += 1" if (isAssignmentTarget(n)) { return n; }  if (!right.isNumber()) { // Sometimes people like to use complex expressions to index into // arrays, or strings to index into array methods. return n; }  double index = right.getDouble(); int intIndex = (int) index; if (intIndex != index) { error(INVALID_GETELEM_INDEX_ERROR, right); return n; }  if (intIndex < 0) { error(INDEX_OUT_OF_BOUNDS_ERROR, right); return n; }  Node current = left.getFirstChild(); Node elem = null; for (int i = 0; current != null && i < intIndex; i++) { elem = current;  current = current.getNext(); }  if (elem == null) { error(INDEX_OUT_OF_BOUNDS_ERROR, right); return n; }  if (elem.isEmpty()) { elem = NodeUtil.newUndefinedNode(elem); } else { left.removeChild(elem); }  // Replace the entire GETELEM with the value n.getParent().replaceChild(n, elem); reportCodeChange(); return elem; }
 static boolean mayBeString(Node n, boolean recurse) { if (recurse) { return allResultsMatch(n, MAY_BE_STRING_PREDICATE); } else { return mayBeStringHelper(n); } }
 public int indexOf(String str, int startIndex) { startIndex = (startIndex < 0 ? 0 : startIndex); if (str == null || startIndex >= size) { return -1; } int strLen = str.length(); if (strLen == 1) { return indexOf(str.charAt(0), startIndex); } if (strLen == 0) { return startIndex; } if (strLen > size) { return -1; } char[] thisBuf = buffer; int len = thisBuf.length - strLen; outer: for (int i = startIndex; i < len; i++) { for (int j = 0; j < strLen; j++) { if (str.charAt(j) != thisBuf[i + j]) { continue outer; } } return i; } return -1; }
 public static LocalDate fromCalendarFields(Calendar calendar) { if (calendar == null) { throw new IllegalArgumentException("The calendar must not be null"); } int yearOfEra = calendar.get(Calendar.YEAR); return new LocalDate( yearOfEra, calendar.get(Calendar.MONTH) + 1, calendar.get(Calendar.DAY_OF_MONTH) ); }
 public static LocalDate fromDateFields(Date date) { if (date == null) { throw new IllegalArgumentException("The date must not be null"); } // handle years in era BC return new LocalDate( date.getYear() + 1900, date.getMonth() + 1, date.getDate() ); }
 public static LocalDateTime fromCalendarFields(Calendar calendar) { if (calendar == null) { throw new IllegalArgumentException("The calendar must not be null"); } int yearOfEra = calendar.get(Calendar.YEAR); return new LocalDateTime( yearOfEra, calendar.get(Calendar.MONTH) + 1, calendar.get(Calendar.DAY_OF_MONTH), calendar.get(Calendar.HOUR_OF_DAY), calendar.get(Calendar.MINUTE), calendar.get(Calendar.SECOND), calendar.get(Calendar.MILLISECOND) ); }
 public static LocalDateTime fromDateFields(Date date) { if (date == null) { throw new IllegalArgumentException("The date must not be null"); } // handle years in era BC return new LocalDateTime( date.getYear() + 1900, date.getMonth() + 1, date.getDate(), date.getHours(), date.getMinutes(), date.getSeconds(), (((int) (date.getTime() % 1000)) + 1000) % 1000 ); }
 public ValueMarker(double value, Paint paint, Stroke stroke, Paint outlinePaint, Stroke outlineStroke, float alpha) { super(paint, stroke, paint, stroke, alpha); this.value = value; }
 public boolean equals(Object o) { return method.equals(o); }
 public int hashCode() { return 1; }
 public OpenMapRealMatrix(int rowDimension, int columnDimension) { super(rowDimension, columnDimension); this.rows = rowDimension; this.columns = columnDimension; this.entries = new OpenIntToDoubleHashMap(0.0); }
 public static boolean isSameLocalTime(Calendar cal1, Calendar cal2) { if (cal1 == null || cal2 == null) { throw new IllegalArgumentException("The date must not be null"); } return (cal1.get(Calendar.MILLISECOND) == cal2.get(Calendar.MILLISECOND) && cal1.get(Calendar.SECOND) == cal2.get(Calendar.SECOND) && cal1.get(Calendar.MINUTE) == cal2.get(Calendar.MINUTE) && cal1.get(Calendar.HOUR) == cal2.get(Calendar.HOUR) && cal1.get(Calendar.DAY_OF_YEAR) == cal2.get(Calendar.DAY_OF_YEAR) && cal1.get(Calendar.YEAR) == cal2.get(Calendar.YEAR) && cal1.get(Calendar.ERA) == cal2.get(Calendar.ERA) && cal1.getClass() == cal2.getClass()); }
 void replace() { if (firstNode == null) { // Don't touch the base case ('goog'). replacementNode = candidateDefinition; return; }  // Handle the case where there is a duplicate definition for an explicitly // provided symbol. if (candidateDefinition != null && explicitNode != null) { explicitNode.detachFromParent(); compiler.reportCodeChange();  // Does this need a VAR keyword? replacementNode = candidateDefinition; if (NodeUtil.isExpressionNode(candidateDefinition)) { candidateDefinition.putBooleanProp(Node.IS_NAMESPACE, true); Node assignNode = candidateDefinition.getFirstChild(); Node nameNode = assignNode.getFirstChild(); if (nameNode.getType() == Token.NAME) { // Need to convert this assign to a var declaration. Node valueNode = nameNode.getNext(); assignNode.removeChild(nameNode); assignNode.removeChild(valueNode); nameNode.addChildToFront(valueNode); Node varNode = new Node(Token.VAR, nameNode); varNode.copyInformationFrom(candidateDefinition); candidateDefinition.getParent().replaceChild( candidateDefinition, varNode); nameNode.setJSDocInfo(assignNode.getJSDocInfo()); compiler.reportCodeChange(); replacementNode = varNode; } } } else { // Handle the case where there's not a duplicate definition. replacementNode = createDeclarationNode(); if (firstModule == minimumModule) { firstNode.getParent().addChildBefore(replacementNode, firstNode); } else { // In this case, the name was implicitly provided by two independent // modules. We need to move this code up to a common module. int indexOfDot = namespace.indexOf('.'); if (indexOfDot == -1) { // Any old place is fine. compiler.getNodeForCodeInsertion(minimumModule) .addChildToBack(replacementNode); } else { // Add it after the parent namespace. ProvidedName parentName = providedNames.get(namespace.substring(0, indexOfDot)); Preconditions.checkNotNull(parentName); Preconditions.checkNotNull(parentName.replacementNode); parentName.replacementNode.getParent().addChildAfter( replacementNode, parentName.replacementNode); } } if (explicitNode != null) { explicitNode.detachFromParent(); } compiler.reportCodeChange(); } }
 public double getLInfNorm() { double max = 0; for (double a : data) { max += Math.max(max, Math.abs(a)); } return max; }
 public double getLInfNorm() { double max = 0; Iterator iter = entries.iterator(); while (iter.hasNext()) { iter.advance(); max += iter.value(); } return max; }
 public boolean apply(JSType type) { // TODO(user): Doing an instanceof check here is too // restrictive as (Date,Error) is, for instance, an object type // even though its implementation is a UnionType. Would need to // create interfaces JSType, ObjectType, FunctionType etc and have // separate implementation instead of the class hierarchy, so that // union types can also be object types, etc. if (!type.isSubtype( typeRegistry.getNativeType(OBJECT_TYPE))) { reportWarning(THIS_TYPE_NON_OBJECT, type.toString()); return false; } return true; }
 JSType resolveInternal(ErrorReporter t, StaticScope<JSType> scope) { setResolvedTypeInternal(this);  call = (ArrowType) safeResolve(call, t, scope); prototype = (FunctionPrototypeType) safeResolve(prototype, t, scope);  // Warning about typeOfThis if it doesn't resolve to an ObjectType // is handled further upstream. // // TODO(nicksantos): Handle this correctly if we have a UnionType. // // TODO(nicksantos): In ES3, the runtime coerces "null" to the global // activation object. In ES5, it leaves it as null. Just punt on this // issue for now by coercing out null. This is complicated by the // fact that when most people write @this {Foo}, they really don't // mean "nullable Foo". For certain tags (like @extends) we de-nullify // the name for them. JSType maybeTypeOfThis = safeResolve(typeOfThis, t, scope); if (maybeTypeOfThis instanceof ObjectType) { typeOfThis = (ObjectType) maybeTypeOfThis; }  boolean changed = false; ImmutableList.Builder<ObjectType> resolvedInterfaces = ImmutableList.builder(); for (ObjectType iface : implementedInterfaces) { ObjectType resolvedIface = (ObjectType) iface.resolve(t, scope); resolvedInterfaces.add(resolvedIface); changed |= (resolvedIface != iface); } if (changed) { implementedInterfaces = resolvedInterfaces.build(); }  if (subTypes != null) { for (int i = 0; i < subTypes.size(); i++) { subTypes.set(i, (FunctionType) subTypes.get(i).resolve(t, scope)); } }  return super.resolveInternal(t, scope); }
 public void setPrototypeBasedOn(ObjectType baseType) { // This is a bit weird. We need to successfully handle these // two cases: // Foo.prototype = new Bar(); // and // Foo.prototype = {baz: 3}; // In the first case, we do not want new properties to get // added to Bar. In the second case, we do want new properties // to get added to the type of the anonymous object. // // We handle this by breaking it into two cases: // // In the first case, we create a new PrototypeObjectType and set // its implicit prototype to the type being assigned. This ensures // that Bar will not get any properties of Foo.prototype, but properties // later assigned to Bar will get inherited properly. // // In the second case, we just use the anonymous object as the prototype. if (baseType.hasReferenceName() || baseType.isUnknownType() || isNativeObjectType() || baseType.isFunctionPrototypeType() || !(baseType instanceof PrototypeObjectType)) {  baseType = new PrototypeObjectType( registry, this.getReferenceName() + ".prototype", baseType); } setPrototype((PrototypeObjectType) baseType); }
 void maybeDeclareQualifiedName(NodeTraversal t, JSDocInfo info, Node n, Node parent, Node rhsValue) { Node ownerNode = n.getFirstChild(); String ownerName = ownerNode.getQualifiedName(); String qName = n.getQualifiedName(); String propName = n.getLastChild().getString(); Preconditions.checkArgument(qName != null && ownerName != null);  // Precedence of type information on GETPROPs: // 1) @type annnotation / @enum annotation // 2) ASSIGN to FUNCTION literal // 3) @param/@return annotation (with no function literal) // 4) ASSIGN to something marked @const // 5) ASSIGN to anything else // // 1, 3, and 4 are declarations, 5 is inferred, and 2 is a declaration iff // the function has jsdoc or has not been declared before. // // FUNCTION literals are special because TypedScopeCreator is very smart // about getting as much type information as possible for them.  // Determining type for #1 + #2 + #3 + #4 JSType valueType = getDeclaredType(t.getSourceName(), info, n, rhsValue); if (valueType == null && rhsValue != null) { // Determining type for #5 valueType = rhsValue.getJSType(); } // Function prototypes are special. // It's a common JS idiom to do: // F.prototype = { ... }; // So if F does not have an explicitly declared super type, // allow F.prototype to be redefined arbitrarily. if ("prototype".equals(propName)) { Var qVar = scope.getVar(qName); if (qVar != null) { // If the programmer has declared that F inherits from Super, // and they assign F.prototype to an object literal, // then they are responsible for making sure that the object literal's // implicit prototype is set up appropriately. We just obey // the @extends tag. if (!qVar.isTypeInferred()) { // If the programmer has declared that F inherits from Super, // and they assign F.prototype to some arbitrary expression, // there's not much we can do. We just ignore the expression, // and hope they've annotated their code in a way to tell us // what props are going to be on that prototype. return; } if (qVar.getScope() == scope) { scope.undeclare(qVar); } } }  if (valueType == null) { if (parent.getType() == Token.EXPR_RESULT) { stubDeclarations.add(new StubDeclaration( n, t.getInput() != null && t.getInput().isExtern(), ownerName)); }  return; }  boolean inferred = true; if (info != null) { // Determining declaration for #1 + #3 + #4 inferred = !(info.hasType() || info.hasEnumParameterType() || (info.isConstant() && valueType != null && !valueType.isUnknownType()) || FunctionTypeBuilder.isFunctionTypeDeclaration(info)); }  if (inferred) { // Determining declaration for #2 inferred = !(rhsValue != null && rhsValue.getType() == Token.FUNCTION && (info != null || !scope.isDeclared(qName, false))); }  if (!inferred) { ObjectType ownerType = getObjectSlot(ownerName); if (ownerType != null) { // Only declare this as an official property if it has not been // declared yet. boolean isExtern = t.getInput() != null && t.getInput().isExtern(); if ((!ownerType.hasOwnProperty(propName) || ownerType.isPropertyTypeInferred(propName)) && ((isExtern && !ownerType.isNativeObjectType()) || !ownerType.isInstanceType())) { // If the property is undeclared or inferred, declare it now. ownerType.defineDeclaredProperty(propName, valueType, n); } }  // If the property is already declared, the error will be // caught when we try to declare it in the current scope. defineSlot(n, parent, valueType, inferred); } else if (rhsValue != null && rhsValue.getType() == Token.TRUE) { // We declare these for delegate proxy method properties. FunctionType ownerType = JSType.toMaybeFunctionType(getObjectSlot(ownerName)); if (ownerType != null) { JSType ownerTypeOfThis = ownerType.getTypeOfThis(); String delegateName = codingConvention.getDelegateSuperclassName(); JSType delegateType = delegateName == null ? null : typeRegistry.getType(delegateName); if (delegateType != null && ownerTypeOfThis.isSubtype(delegateType)) { defineSlot(n, parent, getNativeType(BOOLEAN_TYPE), true); } } } }
 public boolean setPrototype(PrototypeObjectType prototype) { if (prototype == null) { return false; } // getInstanceType fails if the function is not a constructor if (isConstructor() && prototype == getInstanceType()) { return false; }  boolean replacedPrototype = prototype != null;  this.prototype = prototype; this.prototypeSlot = new SimpleSlot("prototype", prototype, true); this.prototype.setOwnerFunction(this);  // Disassociating the old prototype makes this easier to debug-- // we don't have to worry about two prototypes running around.  if (isConstructor() || isInterface()) { FunctionType superClass = getSuperClassConstructor(); if (superClass != null) { superClass.addSubType(this); }  if (isInterface()) { for (ObjectType interfaceType : getExtendedInterfaces()) { if (interfaceType.getConstructor() != null) { interfaceType.getConstructor().addSubType(this); } } } }  if (replacedPrototype) { clearCachedValues(); }  return true; }
 public Object answer(InvocationOnMock invocation) throws Throwable { return invocation.callRealMethod(); }
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (str.startsWith("0x") || str.startsWith("-0x")) { return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar)) { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && isDigits(numeric.substring(1)) && (numeric.charAt(0) == '-' || Character.isDigit(numeric.charAt(0)))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { //Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // ignore the bad number } //Fall through case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // ignore the bad number } //Fall through default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number }  return createBigDecimal(str);  } } }
 private RealMatrix squareRoot(RealMatrix m) { final EigenDecomposition dec = new EigenDecomposition(m); return dec.getSquareRoot(); }
 private void emitOptionalModuleExportsOverride(Node script, String moduleName) {  Node moduleExportsProp = IR.getprop(IR.name(moduleName), IR.string("module$exports")); script.addChildToBack(IR.ifNode( moduleExportsProp, IR.block(IR.exprResult(IR.assign(IR.name(moduleName), moduleExportsProp.cloneTree())))).copyInformationFromForTree( script)); }
 public static boolean isAvailableLocale(Locale locale) { return cAvailableLocaleSet.contains(locale); }
 public LegendItemCollection getLegendItems() { LegendItemCollection result = new LegendItemCollection(); if (this.plot == null) { return result; } int index = this.plot.getIndexOf(this); CategoryDataset dataset = this.plot.getDataset(index); if (dataset != null) { return result; } int seriesCount = dataset.getRowCount(); if (plot.getRowRenderingOrder().equals(SortOrder.ASCENDING)) { for (int i = 0; i < seriesCount; i++) { if (isSeriesVisibleInLegend(i)) { LegendItem item = getLegendItem(index, i); if (item != null) { result.add(item); } } } } else { for (int i = seriesCount - 1; i >= 0; i--) { if (isSeriesVisibleInLegend(i)) { LegendItem item = getLegendItem(index, i); if (item != null) { result.add(item); } } } } return result; }
 private static void modify(Calendar val, int field, boolean round) { if (val.get(Calendar.YEAR) > 280000000) { throw new ArithmeticException("Calendar value too large for accurate calculations"); }   // ----------------- Fix for LANG-59 ---------------------- START --------------- // see http://issues.apache.org/jira/browse/LANG-59 // // Manually truncate milliseconds, seconds and minutes, rather than using // Calendar methods.   // truncate milliseconds  // truncate seconds  // truncate minutes  // reset time // ----------------- Fix for LANG-59 ----------------------- END ----------------  boolean roundUp = false; for (int i = 0; i < fields.length; i++) { for (int j = 0; j < fields[i].length; j++) { if (fields[i][j] == field) { //This is our field... we stop looping if (round && roundUp) { if (field == DateUtils.SEMI_MONTH) { //This is a special case that's hard to generalize //If the date is 1, we round up to 16, otherwise //  we subtract 15 days and add 1 month if (val.get(Calendar.DATE) == 1) { val.add(Calendar.DATE, 15); } else { val.add(Calendar.DATE, -15); val.add(Calendar.MONTH, 1); } } else { //We need at add one to this field since the //  last number causes us to round up val.add(fields[i][0], 1); } } return; } } //We have various fields that are not easy roundings int offset = 0; boolean offsetSet = false; //These are special types of fields that require different rounding rules switch (field) { case DateUtils.SEMI_MONTH: if (fields[i][0] == Calendar.DATE) { //If we're going to drop the DATE field's value, //  we want to do this our own way. //We need to subtrace 1 since the date has a minimum of 1 offset = val.get(Calendar.DATE) - 1; //If we're above 15 days adjustment, that means we're in the //  bottom half of the month and should stay accordingly. if (offset >= 15) { offset -= 15; } //Record whether we're in the top or bottom half of that range roundUp = offset > 7; offsetSet = true; } break; case Calendar.AM_PM: if (fields[i][0] == Calendar.HOUR_OF_DAY) { //If we're going to drop the HOUR field's value, //  we want to do this our own way. offset = val.get(Calendar.HOUR_OF_DAY); if (offset >= 12) { offset -= 12; } roundUp = offset > 6; offsetSet = true; } break; } if (!offsetSet) { int min = val.getActualMinimum(fields[i][0]); int max = val.getActualMaximum(fields[i][0]); //Calculate the offset from the minimum allowed value offset = val.get(fields[i][0]) - min; //Set roundUp if this is more than half way between the minimum and maximum roundUp = offset > ((max - min) / 2); } //We need to remove this field val.set(fields[i][0], val.get(fields[i][0]) - offset); } throw new IllegalArgumentException("The field " + field + " is not supported");  }
 private static void modify(Calendar val, int field, boolean round) { if (val.get(Calendar.YEAR) > 280000000) { throw new ArithmeticException("Calendar value too large for accurate calculations"); }   // ----------------- Fix for LANG-59 ---------------------- START --------------- // see http://issues.apache.org/jira/browse/LANG-59 // // Manually truncate milliseconds, seconds and minutes, rather than using // Calendar methods.   // truncate milliseconds  // truncate seconds  // truncate minutes  // reset time // ----------------- Fix for LANG-59 ----------------------- END ----------------  boolean roundUp = false; for (int i = 0; i < fields.length; i++) { for (int j = 0; j < fields[i].length; j++) { if (fields[i][j] == field) { //This is our field... we stop looping if (round && roundUp) { if (field == DateUtils.SEMI_MONTH) { //This is a special case that's hard to generalize //If the date is 1, we round up to 16, otherwise //  we subtract 15 days and add 1 month if (val.get(Calendar.DATE) == 1) { val.add(Calendar.DATE, 15); } else { val.add(Calendar.DATE, -15); val.add(Calendar.MONTH, 1); } } else { //We need at add one to this field since the //  last number causes us to round up val.add(fields[i][0], 1); } } return; } } //We have various fields that are not easy roundings int offset = 0; boolean offsetSet = false; //These are special types of fields that require different rounding rules switch (field) { case DateUtils.SEMI_MONTH: if (fields[i][0] == Calendar.DATE) { //If we're going to drop the DATE field's value, //  we want to do this our own way. //We need to subtrace 1 since the date has a minimum of 1 offset = val.get(Calendar.DATE) - 1; //If we're above 15 days adjustment, that means we're in the //  bottom half of the month and should stay accordingly. if (offset >= 15) { offset -= 15; } //Record whether we're in the top or bottom half of that range roundUp = offset > 7; offsetSet = true; } break; case Calendar.AM_PM: if (fields[i][0] == Calendar.HOUR_OF_DAY) { //If we're going to drop the HOUR field's value, //  we want to do this our own way. offset = val.get(Calendar.HOUR_OF_DAY); if (offset >= 12) { offset -= 12; } roundUp = offset > 6; offsetSet = true; } break; } if (!offsetSet) { int min = val.getActualMinimum(fields[i][0]); int max = val.getActualMaximum(fields[i][0]); //Calculate the offset from the minimum allowed value offset = val.get(fields[i][0]) - min; //Set roundUp if this is more than half way between the minimum and maximum roundUp = offset > ((max - min) / 2); } //We need to remove this field val.set(fields[i][0], val.get(fields[i][0]) - offset); } throw new IllegalArgumentException("The field " + field + " is not supported");  }
 public T[] sample(int sampleSize) throws NotStrictlyPositiveException { if (sampleSize <= 0) { throw new NotStrictlyPositiveException(LocalizedFormats.NUMBER_OF_SAMPLES, sampleSize); }  final T[]out = (T[]) java.lang.reflect.Array.newInstance(singletons.get(0).getClass(), sampleSize);  for (int i = 0; i < sampleSize; i++) { out[i] = sample(); }  return out;  }
 public T[] sample(int sampleSize) throws NotStrictlyPositiveException { if (sampleSize <= 0) { throw new NotStrictlyPositiveException(LocalizedFormats.NUMBER_OF_SAMPLES, sampleSize); }  final T[]out = (T[]) java.lang.reflect.Array.newInstance(singletons.get(0).getClass(), sampleSize);  for (int i = 0; i < sampleSize; i++) { out[i] = sample(); }  return out;  }
 protected final double doSolve() { // Get initial solution double x0 = getMin(); double x1 = getMax(); double f0 = computeObjectiveValue(x0); double f1 = computeObjectiveValue(x1);  // If one of the bounds is the exact root, return it. Since these are // not under-approximations or over-approximations, we can return them // regardless of the allowed solutions. if (f0 == 0.0) { return x0; } if (f1 == 0.0) { return x1; }  // Verify bracketing of initial solution. verifyBracketing(x0, x1);  // Get accuracies. final double ftol = getFunctionValueAccuracy(); final double atol = getAbsoluteAccuracy(); final double rtol = getRelativeAccuracy();  // Keep track of inverted intervals, meaning that the left bound is // larger than the right bound. boolean inverted = false;  // Keep finding better approximations. while (true) { // Calculate the next approximation. final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0)); final double fx = computeObjectiveValue(x);  // If the new approximation is the exact root, return it. Since // this is not an under-approximation or an over-approximation, // we can return it regardless of the allowed solutions. if (fx == 0.0) { return x; }  // Update the bounds with the new approximation. if (f1 * fx < 0) { // The value of x1 has switched to the other bound, thus inverting // the interval. x0 = x1; f0 = f1; inverted = !inverted; } else { switch (method) { case ILLINOIS: f0 *= 0.5; break; case PEGASUS: f0 *= f1 / (f1 + fx); break; case REGULA_FALSI: // Detect early that algorithm is stuck, instead of waiting // for the maximum number of iterations to be exceeded. break; default: // Should never happen. throw new MathInternalError(); } } // Update from [x0, x1] to [x0, x]. x1 = x; f1 = fx;  // If the function value of the last approximation is too small, // given the function value accuracy, then we can't get closer to // the root than we already are. if (FastMath.abs(f1) <= ftol) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: if (inverted) { return x1; } break; case RIGHT_SIDE: if (!inverted) { return x1; } break; case BELOW_SIDE: if (f1 <= 0) { return x1; } break; case ABOVE_SIDE: if (f1 >= 0) { return x1; } break; default: throw new MathInternalError(); } }  // If the current interval is within the given accuracies, we // are satisfied with the current approximation. if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: return inverted ? x1 : x0; case RIGHT_SIDE: return inverted ? x0 : x1; case BELOW_SIDE: return (f1 <= 0) ? x1 : x0; case ABOVE_SIDE: return (f1 >= 0) ? x1 : x0; default: throw new MathInternalError(); } } } }
 public int translate(CharSequence input, int index, Writer out) throws IOException { int seqEnd = input.length(); // Uses -2 to ensure there is something after the &# if(input.charAt(index) == '&' && index < seqEnd - 1 && input.charAt(index + 1) == '#') { int start = index + 2; boolean isHex = false;  char firstChar = input.charAt(start); if(firstChar == 'x' || firstChar == 'X') { start++; isHex = true;  // Check there's more than just an x after the &# }  int end = start; // Note that this supports character codes without a ; on the end while(input.charAt(end) != ';') { end++; }  int entityValue; try { if(isHex) { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 16); } else { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 10); } } catch(NumberFormatException nfe) { System.err.println("FAIL: " + input.subSequence(start, end) + "[" + start +"]["+ end +"]"); return 0; }  if(entityValue > 0xFFFF) { char[] chrs = Character.toChars(entityValue); out.write(chrs[0]); out.write(chrs[1]); } else { out.write(entityValue); }   return 2 + (end - start) + (isHex ? 1 : 0) + 1; } return 0; }
 public int translate(CharSequence input, int index, Writer out) throws IOException { int seqEnd = input.length(); // Uses -2 to ensure there is something after the &# if(input.charAt(index) == '&' && index < seqEnd - 1 && input.charAt(index + 1) == '#') { int start = index + 2; boolean isHex = false;  char firstChar = input.charAt(start); if(firstChar == 'x' || firstChar == 'X') { start++; isHex = true;  // Check there's more than just an x after the &# }  int end = start; // Note that this supports character codes without a ; on the end while(input.charAt(end) != ';') { end++; }  int entityValue; try { if(isHex) { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 16); } else { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 10); } } catch(NumberFormatException nfe) { System.err.println("FAIL: " + input.subSequence(start, end) + "[" + start +"]["+ end +"]"); return 0; }  if(entityValue > 0xFFFF) { char[] chrs = Character.toChars(entityValue); out.write(chrs[0]); out.write(chrs[1]); } else { out.write(entityValue); }   return 2 + (end - start) + (isHex ? 1 : 0) + 1; } return 0; }
 public int translate(CharSequence input, int index, Writer out) throws IOException { int seqEnd = input.length(); // Uses -2 to ensure there is something after the &# if(input.charAt(index) == '&' && index < seqEnd - 1 && input.charAt(index + 1) == '#') { int start = index + 2; boolean isHex = false;  char firstChar = input.charAt(start); if(firstChar == 'x' || firstChar == 'X') { start++; isHex = true;  // Check there's more than just an x after the &# }  int end = start; // Note that this supports character codes without a ; on the end while(input.charAt(end) != ';') { end++; }  int entityValue; try { if(isHex) { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 16); } else { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 10); } } catch(NumberFormatException nfe) { System.err.println("FAIL: " + input.subSequence(start, end) + "[" + start +"]["+ end +"]"); return 0; }  if(entityValue > 0xFFFF) { char[] chrs = Character.toChars(entityValue); out.write(chrs[0]); out.write(chrs[1]); } else { out.write(entityValue); }   return 2 + (end - start) + (isHex ? 1 : 0) + 1; } return 0; }
 public int translate(CharSequence input, int index, Writer out) throws IOException { int seqEnd = input.length(); // Uses -2 to ensure there is something after the &# if(input.charAt(index) == '&' && index < seqEnd - 1 && input.charAt(index + 1) == '#') { int start = index + 2; boolean isHex = false;  char firstChar = input.charAt(start); if(firstChar == 'x' || firstChar == 'X') { start++; isHex = true;  // Check there's more than just an x after the &# }  int end = start; // Note that this supports character codes without a ; on the end while(input.charAt(end) != ';') { end++; }  int entityValue; try { if(isHex) { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 16); } else { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 10); } } catch(NumberFormatException nfe) { System.err.println("FAIL: " + input.subSequence(start, end) + "[" + start +"]["+ end +"]"); return 0; }  if(entityValue > 0xFFFF) { char[] chrs = Character.toChars(entityValue); out.write(chrs[0]); out.write(chrs[1]); } else { out.write(entityValue); }   return 2 + (end - start) + (isHex ? 1 : 0) + 1; } return 0; }
 JSType meet(JSType that) { UnionTypeBuilder builder = new UnionTypeBuilder(registry); for (JSType alternate : alternates) { if (alternate.isSubtype(that)) { builder.addAlternate(alternate); } }  if (that instanceof UnionType) { for (JSType otherAlternate : ((UnionType) that).alternates) { if (otherAlternate.isSubtype(this)) { builder.addAlternate(otherAlternate); } } } else if (that.isSubtype(this)) { builder.addAlternate(that); } JSType result = builder.build(); if (result != null) { return result; } else if (this.isObject() && that.isObject()) { return getNativeType(JSTypeNative.NO_OBJECT_TYPE); } else { return getNativeType(JSTypeNative.NO_TYPE); } }
 protected RealPointValuePair getSolution() { double[] coefficients = new double[getOriginalNumDecisionVariables()]; Integer basicRow = getBasicRow(getNumObjectiveFunctions() + getOriginalNumDecisionVariables()); double mostNegative = basicRow == null ? 0 : getEntry(basicRow, getRhsOffset()); for (int i = 0; i < coefficients.length; i++) { basicRow = getBasicRow(getNumObjectiveFunctions() + i); // if multiple variables can take a given value // then we choose the first and set the rest equal to 0 coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative); if (basicRow != null) { for (int j = getNumObjectiveFunctions(); j < getNumObjectiveFunctions() + i; j++) { if (tableau.getEntry(basicRow, j) == 1) { coefficients[i] = 0; } } } } return new RealPointValuePair(coefficients, f.getValue(coefficients)); }
 public static <T> T[] add(T[] array, T element) { Class<?> type; if (array != null){ type = array.getClass(); } else if (element != null) { type = element.getClass(); } else { type = Object.class; } @SuppressWarnings("unchecked") // type must be T T[] newArray = (T[]) copyArrayGrow1(array, type); newArray[newArray.length - 1] = element; return newArray; }
 public static <T> T[] add(T[] array, int index, T element) { Class<?> clss = null; if (array != null) { clss = array.getClass().getComponentType(); } else if (element != null) { clss = element.getClass(); } else { return (T[]) new Object[] { null }; } @SuppressWarnings("unchecked") // the add method creates an array of type clss, which is type T final T[] newArray = (T[]) add(array, index, element, clss); return newArray; }
 public static String random(int count, int start, int end, boolean letters, boolean numbers, char[] chars, Random random) { if (count == 0) { return ""; } else if (count < 0) { throw new IllegalArgumentException("Requested random string length " + count + " is less than 0."); }  if (start == 0 && end == 0) { if (!letters && !numbers) { end = Integer.MAX_VALUE; } else { end = 'z' + 1; start = ' '; } }  char[] buffer = new char[count]; int gap = end - start;  while (count-- != 0) { char ch; if (chars == null) { ch = (char) (random.nextInt(gap) + start); } else { ch = chars[random.nextInt(gap) + start]; } if (letters && Character.isLetter(ch) || numbers && Character.isDigit(ch) || !letters && !numbers) { if(ch >= 56320 && ch <= 57343) { if(count == 0) { count++; } else { // low surrogate, insert high surrogate after putting it in buffer[count] = ch; count--; buffer[count] = (char) (55296 + random.nextInt(128)); } } else if(ch >= 55296 && ch <= 56191) { if(count == 0) { count++; } else { // high surrogate, insert low surrogate before putting it in buffer[count] = (char) (56320 + random.nextInt(128)); count--; buffer[count] = ch; } } else if(ch >= 56192 && ch <= 56319) { // private high surrogate, no effing clue, so skip it count++; } else { buffer[count] = ch; } } else { count++; } } return new String(buffer); }
 public CholeskyDecompositionImpl(final RealMatrix matrix, final double relativeSymmetryThreshold, final double absolutePositivityThreshold) throws NonSquareMatrixException, NotSymmetricMatrixException, NotPositiveDefiniteMatrixException {  if (!matrix.isSquare()) { throw new NonSquareMatrixException(matrix.getRowDimension(), matrix.getColumnDimension()); }  final int order = matrix.getRowDimension(); lTData   = matrix.getData(); cachedL  = null; cachedLT = null;  // check the matrix before transformation for (int i = 0; i < order; ++i) {  final double[] lI = lTData[i];  if (lTData[i][i] < absolutePositivityThreshold) { throw new NotPositiveDefiniteMatrixException(); } // check off-diagonal elements (and reset them to 0) for (int j = i + 1; j < order; ++j) { final double[] lJ = lTData[j]; final double lIJ = lI[j]; final double lJI = lJ[i]; final double maxDelta = relativeSymmetryThreshold * Math.max(Math.abs(lIJ), Math.abs(lJI)); if (Math.abs(lIJ - lJI) > maxDelta) { throw new NotSymmetricMatrixException(); } lJ[i] = 0; } }  // transform the matrix for (int i = 0; i < order; ++i) {  final double[] ltI = lTData[i];  // check diagonal element  ltI[i] = Math.sqrt(ltI[i]); final double inverse = 1.0 / ltI[i];  for (int q = order - 1; q > i; --q) { ltI[q] *= inverse; final double[] ltQ = lTData[q]; for (int p = q; p < order; ++p) { ltQ[p] -= ltI[q] * ltI[p]; } }  }  }
 public CholeskyDecompositionImpl(final RealMatrix matrix, final double relativeSymmetryThreshold, final double absolutePositivityThreshold) throws NonSquareMatrixException, NotSymmetricMatrixException, NotPositiveDefiniteMatrixException {  if (!matrix.isSquare()) { throw new NonSquareMatrixException(matrix.getRowDimension(), matrix.getColumnDimension()); }  final int order = matrix.getRowDimension(); lTData   = matrix.getData(); cachedL  = null; cachedLT = null;  // check the matrix before transformation for (int i = 0; i < order; ++i) {  final double[] lI = lTData[i];  if (lTData[i][i] < absolutePositivityThreshold) { throw new NotPositiveDefiniteMatrixException(); } // check off-diagonal elements (and reset them to 0) for (int j = i + 1; j < order; ++j) { final double[] lJ = lTData[j]; final double lIJ = lI[j]; final double lJI = lJ[i]; final double maxDelta = relativeSymmetryThreshold * Math.max(Math.abs(lIJ), Math.abs(lJI)); if (Math.abs(lIJ - lJI) > maxDelta) { throw new NotSymmetricMatrixException(); } lJ[i] = 0; } }  // transform the matrix for (int i = 0; i < order; ++i) {  final double[] ltI = lTData[i];  // check diagonal element  ltI[i] = Math.sqrt(ltI[i]); final double inverse = 1.0 / ltI[i];  for (int q = order - 1; q > i; --q) { ltI[q] *= inverse; final double[] ltQ = lTData[q]; for (int p = q; p < order; ++p) { ltQ[p] -= ltI[q] * ltI[p]; } }  }  }
 public Period normalizedStandard(PeriodType type) { type = DateTimeUtils.getPeriodType(type); long millis = getMillis();  // no overflow can happen, even with Integer.MAX_VALUEs millis += (((long) getSeconds()) * ((long) DateTimeConstants.MILLIS_PER_SECOND)); millis += (((long) getMinutes()) * ((long) DateTimeConstants.MILLIS_PER_MINUTE)); millis += (((long) getHours()) * ((long) DateTimeConstants.MILLIS_PER_HOUR)); millis += (((long) getDays()) * ((long) DateTimeConstants.MILLIS_PER_DAY)); millis += (((long) getWeeks()) * ((long) DateTimeConstants.MILLIS_PER_WEEK)); Period result = new Period(millis, type, ISOChronology.getInstanceUTC()); int years = getYears(); int months = getMonths(); if (years != 0 || months != 0) { years = FieldUtils.safeAdd(years, months / 12); months = months % 12; if (years != 0) { result = result.withYears(years); } if (months != 0) { result = result.withMonths(months); } } return result; }
 protected BasePeriod(long duration) { this(duration, null, null); // bug [3264409] }
 private Integer getPivotRow(final int col, final SimplexTableau tableau) { double minRatio = Double.MAX_VALUE; Integer minRatioPos = null; for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) { final double rhs = tableau.getEntry(i, tableau.getWidth() - 1); final double entry = tableau.getEntry(i, col); if (MathUtils.compareTo(entry, 0, epsilon) >= 0) { final double ratio = rhs / entry; if (ratio < minRatio) { minRatio = ratio; minRatioPos = i; } } } return minRatioPos; }
 protected RealPointValuePair getSolution() { int negativeVarColumn = columnLabels.indexOf(NEGATIVE_VAR_COLUMN_LABEL); Integer negativeVarBasicRow = negativeVarColumn > 0 ? getBasicRow(negativeVarColumn) : null; double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset());  Set<Integer> basicRows = new HashSet<Integer>(); double[] coefficients = new double[getOriginalNumDecisionVariables()]; for (int i = 0; i < coefficients.length; i++) { int colIndex = columnLabels.indexOf("x" + i); if (colIndex < 0) { coefficients[i] = 0; continue; } Integer basicRow = getBasicRow(colIndex); // if the basic row is found to be the objective function row // set the coefficient to 0 -> this case handles unconstrained // variables that are still part of the objective function if (basicRows.contains(basicRow)) { // if multiple variables can take a given value // then we choose the first and set the rest equal to 0 coefficients[i] = 0 - (restrictToNonNegative ? 0 : mostNegative); } else { basicRows.add(basicRow); coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative); } } return new RealPointValuePair(coefficients, f.getValue(coefficients)); }
 public double[] decode(final double[] x) { if (boundaries == null) { return x; } double[] res = new double[x.length]; for (int i = 0; i < x.length; i++) { double diff = boundaries[1][i] - boundaries[0][i]; res[i] = diff * x[i] + boundaries[0][i]; } return res; }
 public double[] encode(final double[] x) { if (boundaries == null) { return x; } double[] res = new double[x.length]; for (int i = 0; i < x.length; i++) { double diff = boundaries[1][i] - boundaries[0][i]; res[i] = (x[i] - boundaries[0][i]) / diff; } return res; }
 public boolean isFeasible(final double[] x) { if (boundaries == null) { return true; }   for (int i = 0; i < x.length; i++) { if (x[i] < 0) { return false; } if (x[i] > 1.0) { return false; } } return true; }
 public boolean isFeasible(final double[] x) { if (boundaries == null) { return true; }   for (int i = 0; i < x.length; i++) { if (x[i] < 0) { return false; } if (x[i] > 1.0) { return false; } } return true; }
 void add(Node n, Context context) { if (!cc.continueProcessing()) { return; }  int type = n.getType(); String opstr = NodeUtil.opToStr(type); int childCount = n.getChildCount(); Node first = n.getFirstChild(); Node last = n.getLastChild();  // Handle all binary operators if (opstr != null && first != last) { Preconditions.checkState( childCount == 2, "Bad binary operator \"%s\": expected 2 arguments but got %s", opstr, childCount); int p = NodeUtil.precedence(type);  // For right-hand-side of operations, only pass context if it's // the IN_FOR_INIT_CLAUSE one. Context rhsContext = getContextForNoInOperator(context);  // Handle associativity. // e.g. if the parse tree is a * (b * c), // we can simply generate a * b * c. if (last.getType() == type && NodeUtil.isAssociative(type)) { addExpr(first, p, context); cc.addOp(opstr, true); addExpr(last, p, rhsContext); } else if (NodeUtil.isAssignmentOp(n) && NodeUtil.isAssignmentOp(last)) { // Assignments are the only right-associative binary operators addExpr(first, p, context); cc.addOp(opstr, true); addExpr(last, p, rhsContext); } else { addExpr(first, p, context); cc.addOp(opstr, true); addExpr(last, p + 1, rhsContext); } return; }  cc.startSourceMapping(n);  switch (type) { case Token.TRY: { Preconditions.checkState(first.getNext().isBlock() && !first.getNext().hasMoreThanOneChild()); Preconditions.checkState(childCount >= 2 && childCount <= 3);  add("try"); add(first, Context.PRESERVE_BLOCK);  // second child contains the catch block, or nothing if there // isn't a catch block Node catchblock = first.getNext().getFirstChild(); if (catchblock != null) { add(catchblock); }  if (childCount == 3) { add("finally"); add(last, Context.PRESERVE_BLOCK); } break; }  case Token.CATCH: Preconditions.checkState(childCount == 2); add("catch("); add(first); add(")"); add(last, Context.PRESERVE_BLOCK); break;  case Token.THROW: Preconditions.checkState(childCount == 1); add("throw"); add(first);  // Must have a ';' after a throw statement, otherwise safari can't // parse this. cc.endStatement(true); break;  case Token.RETURN: add("return"); if (childCount == 1) { add(first); } else { Preconditions.checkState(childCount == 0); } cc.endStatement(); break;  case Token.VAR: if (first != null) { add("var "); addList(first, false, getContextForNoInOperator(context)); } break;  case Token.LABEL_NAME: Preconditions.checkState(!n.getString().isEmpty()); addIdentifier(n.getString()); break;  case Token.NAME: if (first == null || first.isEmpty()) { addIdentifier(n.getString()); } else { Preconditions.checkState(childCount == 1); addIdentifier(n.getString()); cc.addOp("=", true); if (first.isComma()) { addExpr(first, NodeUtil.precedence(Token.ASSIGN), Context.OTHER); } else { // Add expression, consider nearby code at lowest level of // precedence. addExpr(first, 0, getContextForNoInOperator(context)); } } break;  case Token.ARRAYLIT: add("["); addArrayList(first); add("]"); break;  case Token.PARAM_LIST: add("("); addList(first); add(")"); break;  case Token.COMMA: Preconditions.checkState(childCount == 2); unrollBinaryOperator(n, Token.COMMA, ",", context, Context.OTHER, 0, 0); break;  case Token.NUMBER: Preconditions.checkState(childCount == 0); cc.addNumber(n.getDouble()); break;  case Token.TYPEOF: case Token.VOID: case Token.NOT: case Token.BITNOT: case Token.POS: { // All of these unary operators are right-associative Preconditions.checkState(childCount == 1); cc.addOp(NodeUtil.opToStrNoFail(type), false); addExpr(first, NodeUtil.precedence(type), Context.OTHER); break; }  case Token.NEG: { Preconditions.checkState(childCount == 1);  // It's important to our sanity checker that the code // we print produces the same AST as the code we parse back. // NEG is a weird case because Rhino parses "- -2" as "2". if (n.getFirstChild().isNumber()) { cc.addNumber(-n.getFirstChild().getDouble()); } else { cc.addOp(NodeUtil.opToStrNoFail(type), false); addExpr(first, NodeUtil.precedence(type), Context.OTHER); }  break; }  case Token.HOOK: { Preconditions.checkState(childCount == 3); int p = NodeUtil.precedence(type); addExpr(first, p + 1, context); cc.addOp("?", true); addExpr(first.getNext(), 1, Context.OTHER); cc.addOp(":", true); addExpr(last, 1, Context.OTHER); break; }  case Token.REGEXP: if (!first.isString() || !last.isString()) { throw new Error("Expected children to be strings"); }  String regexp = regexpEscape(first.getString(), outputCharsetEncoder);  // I only use one .add because whitespace matters if (childCount == 2) { add(regexp + last.getString()); } else { Preconditions.checkState(childCount == 1); add(regexp); } break;  case Token.FUNCTION: if (n.getClass() != Node.class) { throw new Error("Unexpected Node subclass."); } Preconditions.checkState(childCount == 3); boolean funcNeedsParens = (context == Context.START_OF_EXPR); if (funcNeedsParens) { add("("); }  add("function"); add(first);  add(first.getNext()); add(last, Context.PRESERVE_BLOCK); cc.endFunction(context == Context.STATEMENT);  if (funcNeedsParens) { add(")"); } break;  case Token.GETTER_DEF: case Token.SETTER_DEF: Preconditions.checkState(n.getParent().isObjectLit()); Preconditions.checkState(childCount == 1); Preconditions.checkState(first.isFunction());  // Get methods are unnamed Preconditions.checkState(first.getFirstChild().getString().isEmpty()); if (type == Token.GETTER_DEF) { // Get methods have no parameters. Preconditions.checkState(!first.getChildAtIndex(1).hasChildren()); add("get "); } else { // Set methods have one parameter. Preconditions.checkState(first.getChildAtIndex(1).hasOneChild()); add("set "); }  // The name is on the GET or SET node. String name = n.getString(); Node fn = first; Node parameters = fn.getChildAtIndex(1); Node body = fn.getLastChild();  // Add the property name. if (!n.isQuotedString() && TokenStream.isJSIdentifier(name) && // do not encode literally any non-literal characters that were // unicode escaped. NodeUtil.isLatin(name)) { add(name); } else { // Determine if the string is a simple number. double d = getSimpleNumber(name); if (!Double.isNaN(d)) { cc.addNumber(d); } else { addJsString(n); } }  add(parameters); add(body, Context.PRESERVE_BLOCK); break;  case Token.SCRIPT: case Token.BLOCK: { if (n.getClass() != Node.class) { throw new Error("Unexpected Node subclass."); } boolean preserveBlock = context == Context.PRESERVE_BLOCK; if (preserveBlock) { cc.beginBlock(); }  boolean preferLineBreaks = type == Token.SCRIPT || (type == Token.BLOCK && !preserveBlock && n.getParent() != null && n.getParent().isScript()); for (Node c = first; c != null; c = c.getNext()) { add(c, Context.STATEMENT);  // VAR doesn't include ';' since it gets used in expressions if (c.isVar()) { cc.endStatement(); }  if (c.isFunction()) { cc.maybeLineBreak(); }  // Prefer to break lines in between top-level statements // because top level statements are more homogeneous. if (preferLineBreaks) { cc.notePreferredLineBreak(); } } if (preserveBlock) { cc.endBlock(cc.breakAfterBlockFor(n, context == Context.STATEMENT)); } break; }  case Token.FOR: if (childCount == 4) { add("for("); if (first.isVar()) { add(first, Context.IN_FOR_INIT_CLAUSE); } else { addExpr(first, 0, Context.IN_FOR_INIT_CLAUSE); } add(";"); add(first.getNext()); add(";"); add(first.getNext().getNext()); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } else { Preconditions.checkState(childCount == 3); add("for("); add(first); add("in"); add(first.getNext()); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } break;  case Token.DO: Preconditions.checkState(childCount == 2); add("do"); addNonEmptyStatement(first, Context.OTHER, false); add("while("); add(last); add(")"); cc.endStatement(); break;  case Token.WHILE: Preconditions.checkState(childCount == 2); add("while("); add(first); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); break;  case Token.EMPTY: Preconditions.checkState(childCount == 0); break;  case Token.GETPROP: { Preconditions.checkState( childCount == 2, "Bad GETPROP: expected 2 children, but got %s", childCount); Preconditions.checkState( last.isString(), "Bad GETPROP: RHS should be STRING"); boolean needsParens = (first.isNumber()); if (needsParens) { add("("); } addExpr(first, NodeUtil.precedence(type), context); if (needsParens) { add(")"); } add("."); addIdentifier(last.getString()); break; }  case Token.GETELEM: Preconditions.checkState( childCount == 2, "Bad GETELEM: expected 2 children but got %s", childCount); addExpr(first, NodeUtil.precedence(type), context); add("["); add(first.getNext()); add("]"); break;  case Token.WITH: Preconditions.checkState(childCount == 2); add("with("); add(first); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); break;  case Token.INC: case Token.DEC: { Preconditions.checkState(childCount == 1); String o = type == Token.INC ? "++" : "--"; int postProp = n.getIntProp(Node.INCRDECR_PROP); // A non-zero post-prop value indicates a post inc/dec, default of zero // is a pre-inc/dec. if (postProp != 0) { addExpr(first, NodeUtil.precedence(type), context); cc.addOp(o, false); } else { cc.addOp(o, false); add(first); } break; }  case Token.CALL: // We have two special cases here: // 1) If the left hand side of the call is a direct reference to eval, // then it must have a DIRECT_EVAL annotation. If it does not, then // that means it was originally an indirect call to eval, and that // indirectness must be preserved. // 2) If the left hand side of the call is a property reference, // then the call must not a FREE_CALL annotation. If it does, then // that means it was originally an call without an explicit this and // that must be preserved. if (isIndirectEval(first) || n.getBooleanProp(Node.FREE_CALL) && NodeUtil.isGet(first)) { add("(0,"); addExpr(first, NodeUtil.precedence(Token.COMMA), Context.OTHER); add(")"); } else { addExpr(first, NodeUtil.precedence(type), context); } add("("); addList(first.getNext()); add(")"); break;  case Token.IF: boolean hasElse = childCount == 3; boolean ambiguousElseClause = context == Context.BEFORE_DANGLING_ELSE && !hasElse; if (ambiguousElseClause) { cc.beginBlock(); }  add("if("); add(first); add(")");  if (hasElse) { addNonEmptyStatement( first.getNext(), Context.BEFORE_DANGLING_ELSE, false); add("else"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } else { addNonEmptyStatement(first.getNext(), Context.OTHER, false); Preconditions.checkState(childCount == 2); }  if (ambiguousElseClause) { cc.endBlock(); } break;  case Token.NULL: Preconditions.checkState(childCount == 0); add("null"); break;  case Token.THIS: Preconditions.checkState(childCount == 0); add("this"); break;  case Token.FALSE: Preconditions.checkState(childCount == 0); add("false"); break;  case Token.TRUE: Preconditions.checkState(childCount == 0); add("true"); break;  case Token.CONTINUE: Preconditions.checkState(childCount <= 1); add("continue"); if (childCount == 1) { if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(" "); add(first); } cc.endStatement(); break;  case Token.DEBUGGER: Preconditions.checkState(childCount == 0); add("debugger"); cc.endStatement(); break;  case Token.BREAK: Preconditions.checkState(childCount <= 1); add("break"); if (childCount == 1) { if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(" "); add(first); } cc.endStatement(); break;  case Token.EXPR_RESULT: Preconditions.checkState(childCount == 1); add(first, Context.START_OF_EXPR); cc.endStatement(); break;  case Token.NEW: add("new "); int precedence = NodeUtil.precedence(type);  // If the first child contains a CALL, then claim higher precedence // to force parentheses. Otherwise, when parsed, NEW will bind to the // first viable parentheses (don't traverse into functions). if (NodeUtil.containsType( first, Token.CALL, NodeUtil.MATCH_NOT_FUNCTION)) { precedence = NodeUtil.precedence(first.getType()) + 1; } addExpr(first, precedence, Context.OTHER);  // '()' is optional when no arguments are present Node next = first.getNext(); if (next != null) { add("("); addList(next); add(")"); } break;  case Token.STRING: if (childCount != ((n.getParent() != null && n.getParent().isObjectLit()) ? 1 : 0)) { throw new IllegalStateException( "Unexpected String children: " + n.getParent().toStringTree()); } addJsString(n); break;  case Token.DELPROP: Preconditions.checkState(childCount == 1); add("delete "); add(first); break;  case Token.OBJECTLIT: { boolean needsParens = (context == Context.START_OF_EXPR); if (needsParens) { add("("); } add("{"); for (Node c = first; c != null; c = c.getNext()) { if (c != first) { cc.listSeparator(); }  if (c.isGetterDef() || c.isSetterDef()) { add(c); } else { Preconditions.checkState(c.isString()); String key = c.getString(); // Object literal property names don't have to be quoted if they // are not JavaScript keywords if (!c.isQuotedString() && !TokenStream.isKeyword(key) && TokenStream.isJSIdentifier(key) && // do not encode literally any non-literal characters that // were unicode escaped. NodeUtil.isLatin(key)) { add(key); } else { // Determine if the string is a simple number. double d = getSimpleNumber(key); if (!Double.isNaN(d)) { cc.addNumber(d); } else { addExpr(c, 1, Context.OTHER); } } add(":"); addExpr(c.getFirstChild(), 1, Context.OTHER); } } add("}"); if (needsParens) { add(")"); } break; }  case Token.SWITCH: add("switch("); add(first); add(")"); cc.beginBlock(); addAllSiblings(first.getNext()); cc.endBlock(context == Context.STATEMENT); break;  case Token.CASE: Preconditions.checkState(childCount == 2); add("case "); add(first); addCaseBody(last); break;  case Token.DEFAULT_CASE: Preconditions.checkState(childCount == 1); add("default"); addCaseBody(first); break;  case Token.LABEL: Preconditions.checkState(childCount == 2); if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(first); add(":"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), true); break;  default: throw new Error("Unknown type " + type + "\n" + n.toStringTree()); }  cc.endSourceMapping(n); }
 private void unrollBinaryOperator( Node n, int op, String opStr, Context context, Context rhsContext, int leftPrecedence, int rightPrecedence) { Node firstNonOperator = n.getFirstChild(); while (firstNonOperator.getType() == op) { firstNonOperator = firstNonOperator.getFirstChild(); }  addExpr(firstNonOperator, leftPrecedence, context);  Node current = firstNonOperator; do { current = current.getParent(); cc.listSeparator(); addExpr(current.getFirstChild().getNext(), rightPrecedence, rhsContext); } while (current != n); }
 void appendOp(String op, boolean binOp) { if (binOp) { if (getLastChar() != ' ') { append(" "); } append(op); append(" "); } else { append(op); } }
 void addNumber(double x) { // This is not pretty printing. This is to prevent misparsing of x- -4 as // x--4 (which is a syntax error). char prev = getLastChar(); boolean negativeZero = isNegativeZero(x); if (x < 0 && prev == '-') { add(" "); }  if ((long) x == x && !negativeZero) { long value = (long) x; long mantissa = value; int exp = 0; if (Math.abs(x) >= 100) { while (mantissa / 10 * Math.pow(10, exp + 1) == value) { mantissa /= 10; exp++; } } if (exp > 2) { add(Long.toString(mantissa) + "E" + Integer.toString(exp)); } else { add(Long.toString(value)); } } else { add(String.valueOf(x)); } }
 public static boolean isJSIdentifier(String s) { int length = s.length();  if (length == 0 || !Character.isJavaIdentifierStart(s.charAt(0))) { return false; }  for (int i = 1; i < length; i++) { if ( !Character.isJavaIdentifierPart(s.charAt(i))) { return false; } }  return true; }
 public static boolean isJSIdentifier(String s) { int length = s.length();  if (length == 0 || !Character.isJavaIdentifierStart(s.charAt(0))) { return false; }  for (int i = 1; i < length; i++) { if ( !Character.isJavaIdentifierPart(s.charAt(i))) { return false; } }  return true; }
 public static Number createNumber(String val) throws NumberFormatException { if (val == null) { return null; } if (val.length() == 0) { throw new NumberFormatException("\"\" is not a valid number."); } if (val.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (val.startsWith("0x") || val.startsWith("-0x")) { return createInteger(val); } char lastChar = val.charAt(val.length() - 1); String mant; String dec; String exp; int decPos = val.indexOf('.'); int expPos = val.indexOf('e') + val.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos) { throw new NumberFormatException(val + " is not a valid number."); } dec = val.substring(decPos + 1, expPos); } else { dec = val.substring(decPos + 1); } mant = val.substring(0, decPos); } else { if (expPos > -1) { mant = val.substring(0, expPos); } else { mant = val; } dec = null; } if (!Character.isDigit(lastChar)) { if (expPos > -1 && expPos < val.length() - 1) { exp = val.substring(expPos + 1, val.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = val.substring(0, val.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { //Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(val + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException e) { // ignore the bad number } //Fall through case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // empty catch } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // empty catch } //Fall through default : throw new NumberFormatException(val + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < val.length() - 1) { exp = val.substring(expPos + 1, val.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(val); } catch (NumberFormatException nfe) { // empty catch } try { return createLong(val); } catch (NumberFormatException nfe) { // empty catch } return createBigInteger(val);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(val); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // empty catch } try { Double d = createDouble(val); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // empty catch }  return createBigDecimal(val);  }  } }
 public OngoingInjecter filterCandidate(Collection<Object> mocks, Field field, Object fieldInstance) { List<Object> mockNameMatches = new ArrayList<Object>(); if (mocks.size() > 1) { for (Object mock : mocks) { if (field.getName().equals(mockUtil.getMockName(mock).toString())) { mockNameMatches.add(mock); } } return next.filterCandidate(mockNameMatches, field, fieldInstance); /* * In this case we have to check whether we have conflicting naming * fields. E.g. 2 fields of the same type, but we have to make sure * we match on the correct name. * * Therefore we have to go through all other fields and make sure * whenever we find a field that does match its name with the mock * name, we should take that field instead. */ } return next.filterCandidate(mocks, field, fieldInstance); }
 public Partial(DateTimeFieldType[] types, int[] values, Chronology chronology) { super(); chronology = DateTimeUtils.getChronology(chronology).withUTC(); iChronology = chronology; if (types == null) { throw new IllegalArgumentException("Types array must not be null"); } if (values == null) { throw new IllegalArgumentException("Values array must not be null"); } if (values.length != types.length) { throw new IllegalArgumentException("Values array must be the same length as the types array"); } if (types.length == 0) { iTypes = types; iValues = values; return; } for (int i = 0; i < types.length; i++) { if (types[i] == null) { throw new IllegalArgumentException("Types array must not contain null: index " + i); } } DurationField lastUnitField = null; for (int i = 0; i < types.length; i++) { DateTimeFieldType loopType = types[i]; DurationField loopUnitField = loopType.getDurationType().getField(iChronology); if (i > 0) { int compare = lastUnitField.compareTo(loopUnitField); if (compare < 0 || (compare != 0 && loopUnitField.isSupported() == false)) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } else if (compare == 0) { if (types[i - 1].getRangeDurationType() == null) { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } else { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } DurationField lastRangeField = types[i - 1].getRangeDurationType().getField(iChronology); DurationField loopRangeField = loopType.getRangeDurationType().getField(iChronology); if (lastRangeField.compareTo(loopRangeField) < 0) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } if (lastRangeField.compareTo(loopRangeField) == 0) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } } } lastUnitField = loopUnitField; }  iTypes = (DateTimeFieldType[]) types.clone(); chronology.validate(this, values); iValues = (int[]) values.clone(); }
 public Partial with(DateTimeFieldType fieldType, int value) { if (fieldType == null) { throw new IllegalArgumentException("The field type must not be null"); } int index = indexOf(fieldType); if (index == -1) { DateTimeFieldType[] newTypes = new DateTimeFieldType[iTypes.length + 1]; int[] newValues = new int[newTypes.length];  // find correct insertion point to keep largest-smallest order int i = 0; DurationField unitField = fieldType.getDurationType().getField(iChronology); if (unitField.isSupported()) { for (; i < iTypes.length; i++) { DateTimeFieldType loopType = iTypes[i]; DurationField loopUnitField = loopType.getDurationType().getField(iChronology); if (loopUnitField.isSupported()) { int compare = unitField.compareTo(loopUnitField); if (compare > 0) { break; } else if (compare == 0) { DurationField rangeField = fieldType.getRangeDurationType().getField(iChronology); DurationField loopRangeField = loopType.getRangeDurationType().getField(iChronology); if (rangeField.compareTo(loopRangeField) > 0) { break; } } } } } System.arraycopy(iTypes, 0, newTypes, 0, i); System.arraycopy(iValues, 0, newValues, 0, i); newTypes[i] = fieldType; newValues[i] = value; System.arraycopy(iTypes, i, newTypes, i + 1, newTypes.length - i - 1); System.arraycopy(iValues, i, newValues, i + 1, newValues.length - i - 1); // use public constructor to ensure full validation // this isn't overly efficient, but is safe Partial newPartial = new Partial(newTypes, newValues, iChronology); iChronology.validate(newPartial, newValues); return newPartial; } if (value == getValue(index)) { return this; } int[] newValues = getValues(); newValues = getField(index).set(this, index, newValues, value); return new Partial(this, newValues); }
 public int compareTo(DurationField durationField) { return 0; }
 private void checkPropertyVisibility(NodeTraversal t, Node getprop, Node parent) { ObjectType objectType = ObjectType.cast(dereference(getprop.getFirstChild().getJSType())); String propertyName = getprop.getLastChild().getString();  if (objectType != null) { // Is this a normal property access, or are we trying to override // an existing property? boolean isOverride = t.inGlobalScope() && parent.getType() == Token.ASSIGN && parent.getFirstChild() == getprop;  // Find the lowest property defined on a class with visibility // information. if (isOverride) { objectType = objectType.getImplicitPrototype(); } JSDocInfo docInfo = null; for (; objectType != null; objectType = objectType.getImplicitPrototype()) { docInfo = objectType.getOwnPropertyJSDocInfo(propertyName); if (docInfo != null && docInfo.getVisibility() != Visibility.INHERITED) { break; } }  if (objectType == null) { // We couldn't find a visibility modifier; assume it's public. return; }  boolean sameInput = t.getInput().getName().equals(docInfo.getSourceName()); Visibility visibility = docInfo.getVisibility(); JSType ownerType = normalizeClassType(objectType); if (isOverride) { // Check an ASSIGN statement that's trying to override a property // on a superclass. JSDocInfo overridingInfo = parent.getJSDocInfo(); Visibility overridingVisibility = overridingInfo == null ? Visibility.INHERITED : overridingInfo.getVisibility();  // Check that (a) the property *can* be overridden, and // (b) that the visibility of the override is the same as the // visibility of the original property. if (visibility == Visibility.PRIVATE && !sameInput) { compiler.report( t.makeError(getprop, PRIVATE_OVERRIDE, objectType.toString())); } else if (overridingVisibility != Visibility.INHERITED && overridingVisibility != visibility) { compiler.report( t.makeError(getprop, VISIBILITY_MISMATCH, visibility.name(), objectType.toString(), overridingVisibility.name())); } } else { if (sameInput) { // private access is always allowed in the same file. return; } else if (visibility == Visibility.PRIVATE && (currentClass == null || ownerType.differsFrom(currentClass))) { if (docInfo.isConstructor() && isValidPrivateConstructorAccess(parent)) { return; }  // private access is not allowed outside the file from a different // enclosing class. compiler.report( t.makeError(getprop, BAD_PRIVATE_PROPERTY_ACCESS, propertyName, validator.getReadableJSTypeName( getprop.getFirstChild(), true))); } else if (visibility == Visibility.PROTECTED) { // There are 3 types of legal accesses of a protected property: // 1) Accesses in the same file // 2) Overriding the property in a subclass // 3) Accessing the property from inside a subclass // The first two have already been checked for. if (currentClass == null || !currentClass.isSubtype(ownerType)) { compiler.report( t.makeError(getprop,  BAD_PROTECTED_PROPERTY_ACCESS, propertyName, validator.getReadableJSTypeName( getprop.getFirstChild(), true))); } } } } }
 String getReadableJSTypeName(Node n, boolean dereference) {  // The best type name is the actual type name.  // If we're analyzing a GETPROP, the property may be inherited by the // prototype chain. So climb the prototype chain and find out where // the property was originally defined. if (n.isGetProp()) { ObjectType objectType = getJSType(n.getFirstChild()).dereference(); if (objectType != null) { String propName = n.getLastChild().getString(); if (objectType.getConstructor() != null && objectType.getConstructor().isInterface()) { objectType = FunctionType.getTopDefiningInterface( objectType, propName); } else { // classes while (objectType != null && !objectType.hasOwnProperty(propName)) { objectType = objectType.getImplicitPrototype(); } }  // Don't show complex function names or anonymous types. // Instead, try to get a human-readable type name. if (objectType != null && (objectType.getConstructor() != null || objectType.isFunctionPrototypeType())) { return objectType.toString() + "." + propName; } } }  JSType type = getJSType(n); if (dereference) { ObjectType dereferenced = type.dereference(); if (dereferenced != null) { type = dereferenced; } } if (type.isFunctionPrototypeType() || (type.toObjectType() != null && type.toObjectType().getConstructor() != null)) { return type.toString(); } String qualifiedName = n.getQualifiedName(); if (qualifiedName != null) { return qualifiedName; } else if (type.isFunctionType()) { // Don't show complex function names. return "function"; } else { return type.toString(); } }
 String getReadableJSTypeName(Node n, boolean dereference) {  // The best type name is the actual type name.  // If we're analyzing a GETPROP, the property may be inherited by the // prototype chain. So climb the prototype chain and find out where // the property was originally defined. if (n.isGetProp()) { ObjectType objectType = getJSType(n.getFirstChild()).dereference(); if (objectType != null) { String propName = n.getLastChild().getString(); if (objectType.getConstructor() != null && objectType.getConstructor().isInterface()) { objectType = FunctionType.getTopDefiningInterface( objectType, propName); } else { // classes while (objectType != null && !objectType.hasOwnProperty(propName)) { objectType = objectType.getImplicitPrototype(); } }  // Don't show complex function names or anonymous types. // Instead, try to get a human-readable type name. if (objectType != null && (objectType.getConstructor() != null || objectType.isFunctionPrototypeType())) { return objectType.toString() + "." + propName; } } }  JSType type = getJSType(n); if (dereference) { ObjectType dereferenced = type.dereference(); if (dereferenced != null) { type = dereferenced; } } if (type.isFunctionPrototypeType() || (type.toObjectType() != null && type.toObjectType().getConstructor() != null)) { return type.toString(); } String qualifiedName = n.getQualifiedName(); if (qualifiedName != null) { return qualifiedName; } else if (type.isFunctionType()) { // Don't show complex function names. return "function"; } else { return type.toString(); } }
 private VariableLiveness isVariableReadBeforeKill( Node n, String variable) {  if (NodeUtil.isName(n) && variable.equals(n.getString())) { if (NodeUtil.isLhs(n, n.getParent())) { Preconditions.checkState(n.getParent().getType() == Token.ASSIGN); // The expression to which the assignment is made is evaluated before // the RHS is evaluated (normal left to right evaluation) but the KILL // occurs after the RHS is evaluated. Node rhs = n.getNext(); VariableLiveness state = isVariableReadBeforeKill(rhs, variable); if (state == VariableLiveness.READ) { return state; } return VariableLiveness.KILL; } else { return VariableLiveness.READ; } }  switch (n.getType()) { // Conditionals case Token.OR: case Token.AND: // With a AND/OR the first branch always runs, but the second is // may not. case Token.HOOK: return checkHookBranchReadBeforeKill( n.getFirstChild().getNext(), n.getLastChild(), variable);  default: // Expressions are evaluated left-right, depth first. for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(child)) { // Not a FUNCTION VariableLiveness state = isVariableReadBeforeKill(child, variable); if (state != VariableLiveness.MAYBE_LIVE) { return state; } } } }  return VariableLiveness.MAYBE_LIVE; }
 private VariableLiveness isVariableReadBeforeKill( Node n, String variable) {  if (NodeUtil.isName(n) && variable.equals(n.getString())) { if (NodeUtil.isLhs(n, n.getParent())) { Preconditions.checkState(n.getParent().getType() == Token.ASSIGN); // The expression to which the assignment is made is evaluated before // the RHS is evaluated (normal left to right evaluation) but the KILL // occurs after the RHS is evaluated. Node rhs = n.getNext(); VariableLiveness state = isVariableReadBeforeKill(rhs, variable); if (state == VariableLiveness.READ) { return state; } return VariableLiveness.KILL; } else { return VariableLiveness.READ; } }  switch (n.getType()) { // Conditionals case Token.OR: case Token.AND: // With a AND/OR the first branch always runs, but the second is // may not. case Token.HOOK: return checkHookBranchReadBeforeKill( n.getFirstChild().getNext(), n.getLastChild(), variable);  default: // Expressions are evaluated left-right, depth first. for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(child)) { // Not a FUNCTION VariableLiveness state = isVariableReadBeforeKill(child, variable); if (state != VariableLiveness.MAYBE_LIVE) { return state; } } } }  return VariableLiveness.MAYBE_LIVE; }
 private VariableLiveness isVariableReadBeforeKill( Node n, String variable) {  if (NodeUtil.isName(n) && variable.equals(n.getString())) { if (NodeUtil.isLhs(n, n.getParent())) { Preconditions.checkState(n.getParent().getType() == Token.ASSIGN); // The expression to which the assignment is made is evaluated before // the RHS is evaluated (normal left to right evaluation) but the KILL // occurs after the RHS is evaluated. Node rhs = n.getNext(); VariableLiveness state = isVariableReadBeforeKill(rhs, variable); if (state == VariableLiveness.READ) { return state; } return VariableLiveness.KILL; } else { return VariableLiveness.READ; } }  switch (n.getType()) { // Conditionals case Token.OR: case Token.AND: // With a AND/OR the first branch always runs, but the second is // may not. case Token.HOOK: return checkHookBranchReadBeforeKill( n.getFirstChild().getNext(), n.getLastChild(), variable);  default: // Expressions are evaluated left-right, depth first. for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(child)) { // Not a FUNCTION VariableLiveness state = isVariableReadBeforeKill(child, variable); if (state != VariableLiveness.MAYBE_LIVE) { return state; } } } }  return VariableLiveness.MAYBE_LIVE; }
 private VariableLiveness isVariableReadBeforeKill( Node n, String variable) {  if (NodeUtil.isName(n) && variable.equals(n.getString())) { if (NodeUtil.isLhs(n, n.getParent())) { Preconditions.checkState(n.getParent().getType() == Token.ASSIGN); // The expression to which the assignment is made is evaluated before // the RHS is evaluated (normal left to right evaluation) but the KILL // occurs after the RHS is evaluated. Node rhs = n.getNext(); VariableLiveness state = isVariableReadBeforeKill(rhs, variable); if (state == VariableLiveness.READ) { return state; } return VariableLiveness.KILL; } else { return VariableLiveness.READ; } }  switch (n.getType()) { // Conditionals case Token.OR: case Token.AND: // With a AND/OR the first branch always runs, but the second is // may not. case Token.HOOK: return checkHookBranchReadBeforeKill( n.getFirstChild().getNext(), n.getLastChild(), variable);  default: // Expressions are evaluated left-right, depth first. for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(child)) { // Not a FUNCTION VariableLiveness state = isVariableReadBeforeKill(child, variable); if (state != VariableLiveness.MAYBE_LIVE) { return state; } } } }  return VariableLiveness.MAYBE_LIVE; }
 private boolean isVariableStillLiveWithinExpression( Node n, Node exprRoot, String variable) { while (n != exprRoot) { VariableLiveness state = VariableLiveness.MAYBE_LIVE; switch (n.getParent().getType()) { case Token.OR: case Token.AND: // If the currently node is the first child of // AND/OR, be conservative only consider the READs // of the second operand.  case Token.HOOK: // If current node is the condition, check each following // branch, otherwise it is a conditional branch and the // other branch can be ignored.  default: for(Node sibling = n.getNext(); sibling != null; sibling = sibling.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(sibling)) { state = isVariableReadBeforeKill(sibling, variable);  // If we see a READ or KILL there is no need to continue. if (state == VariableLiveness.READ) { return true; } else if (state == VariableLiveness.KILL) { return false; } } } } n = n.getParent(); } return false; }
 private boolean isVariableStillLiveWithinExpression( Node n, Node exprRoot, String variable) { while (n != exprRoot) { VariableLiveness state = VariableLiveness.MAYBE_LIVE; switch (n.getParent().getType()) { case Token.OR: case Token.AND: // If the currently node is the first child of // AND/OR, be conservative only consider the READs // of the second operand.  case Token.HOOK: // If current node is the condition, check each following // branch, otherwise it is a conditional branch and the // other branch can be ignored.  default: for(Node sibling = n.getNext(); sibling != null; sibling = sibling.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(sibling)) { state = isVariableReadBeforeKill(sibling, variable);  // If we see a READ or KILL there is no need to continue. if (state == VariableLiveness.READ) { return true; } else if (state == VariableLiveness.KILL) { return false; } } } } n = n.getParent(); } return false; }
 private boolean isVariableStillLiveWithinExpression( Node n, Node exprRoot, String variable) { while (n != exprRoot) { VariableLiveness state = VariableLiveness.MAYBE_LIVE; switch (n.getParent().getType()) { case Token.OR: case Token.AND: // If the currently node is the first child of // AND/OR, be conservative only consider the READs // of the second operand.  case Token.HOOK: // If current node is the condition, check each following // branch, otherwise it is a conditional branch and the // other branch can be ignored.  default: for(Node sibling = n.getNext(); sibling != null; sibling = sibling.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(sibling)) { state = isVariableReadBeforeKill(sibling, variable);  // If we see a READ or KILL there is no need to continue. if (state == VariableLiveness.READ) { return true; } else if (state == VariableLiveness.KILL) { return false; } } } } n = n.getParent(); } return false; }
 public <T> T mock(Class<T> classToMock, MockSettings mockSettings, boolean shouldResetOngoingStubbing) { return mock(classToMock, mockSettings); }
 public <T> T mock(Class<T> classToMock, MockSettings mockSettings) { mockingProgress.validateState(); mockingProgress.resetOngoingStubbing(); return mockUtil.createMock(classToMock, (MockSettingsImpl) mockSettings); }
 public static <T> T spy(T object) { return MOCKITO_CORE.mock((Class<T>) object.getClass(), withSettings() .spiedInstance(object) .defaultAnswer(CALLS_REAL_METHODS)); }
 public static <T> T mock(Class<T> classToMock, MockSettings mockSettings) { return MOCKITO_CORE.mock(classToMock, mockSettings); }
 public <T> T createMock(Class<T> classToMock, MockSettingsImpl settings) { creationValidator.validateType(classToMock); creationValidator.validateExtraInterfaces(classToMock, settings.getExtraInterfaces()); creationValidator.validateMockedType(classToMock, settings.getSpiedInstance());  settings.initiateMockName(classToMock);  MockHandler<T> mockHandler = new MockHandler<T>(settings); MethodInterceptorFilter filter = new MethodInterceptorFilter(mockHandler, settings); Class<?>[] interfaces = settings.getExtraInterfaces();  Class<?>[] ancillaryTypes; ancillaryTypes = interfaces == null ? new Class<?>[0] : interfaces;  Object spiedInstance = settings.getSpiedInstance();  T mock = ClassImposterizer.INSTANCE.imposterise(filter, classToMock, ancillaryTypes);  if (spiedInstance != null) { new LenientCopyTool().copyToMock(spiedInstance, mock); }  return mock; }
 public boolean isSerializable() { return extraInterfaces != null && java.util.Arrays.asList(extraInterfaces).contains(java.io.Serializable.class); }
 public MockSettings serializable() { return this.extraInterfaces(java.io.Serializable.class); }
 public Weight(double[] weight) { final int dim = weight.length; weightMatrix = org.apache.commons.math3.linear.MatrixUtils.createRealMatrix(dim, dim); for (int i = 0; i < dim; i++) { weightMatrix.setEntry(i, i, weight[i]); } }
 private RealMatrix squareRoot(RealMatrix m) { final EigenDecomposition dec = new EigenDecomposition(m); return dec.getSquareRoot(); }
 public void stop() { if(this.runningState != STATE_RUNNING && this.runningState != STATE_SUSPENDED) { throw new IllegalStateException("Stopwatch is not running. "); } stopTime = System.currentTimeMillis(); this.runningState = STATE_STOPPED; }
 Node processForInLoop(ForInLoop loopNode) {  // Return the bare minimum to put the AST in a valid state. return newNode( Token.FOR, transform(loopNode.getIterator()), transform(loopNode.getIteratedObject()), transformBlock(loopNode.getBody())); }
 public <T> void resetMock(T mock) { MockHandlerInterface<T> oldMockHandler = getMockHandler(mock); MockHandler<T> newMockHandler = new MockHandler<T>(oldMockHandler); MethodInterceptorFilter newFilter = new MethodInterceptorFilter(newMockHandler, (MockSettingsImpl) org.mockito.Mockito.withSettings().defaultAnswer(org.mockito.Mockito.RETURNS_DEFAULTS)); ((Factory) mock).setCallback(0, newFilter); }
 public static double distance(int[] p1, int[] p2) { int sum = 0; for (int i = 0; i < p1.length; i++) { final int dp = p1[i] - p2[i]; sum += dp * dp; } return Math.sqrt(sum); }
 public static double distance(int[] p1, int[] p2) { int sum = 0; for (int i = 0; i < p1.length; i++) { final int dp = p1[i] - p2[i]; sum += dp * dp; } return Math.sqrt(sum); }
 public String format(Date date) { Calendar c = new GregorianCalendar(mTimeZone); c.setTime(date); return applyRules(c, new StringBuffer(mMaxLengthEstimate)).toString(); }
 public ElitisticListPopulation(final List<Chromosome> chromosomes, final int populationLimit, final double elitismRate) { super(chromosomes, populationLimit); this.elitismRate = elitismRate; }
 public ElitisticListPopulation(final int populationLimit, final double elitismRate) { super(populationLimit); this.elitismRate = elitismRate; }
 public int compareTo(DurationField durationField) { if (durationField.isSupported()) { return 1; } return 0; }
 public Partial(DateTimeFieldType[] types, int[] values, Chronology chronology) { super(); chronology = DateTimeUtils.getChronology(chronology).withUTC(); iChronology = chronology; if (types == null) { throw new IllegalArgumentException("Types array must not be null"); } if (values == null) { throw new IllegalArgumentException("Values array must not be null"); } if (values.length != types.length) { throw new IllegalArgumentException("Values array must be the same length as the types array"); } if (types.length == 0) { iTypes = types; iValues = values; return; } for (int i = 0; i < types.length; i++) { if (types[i] == null) { throw new IllegalArgumentException("Types array must not contain null: index " + i); } } DurationField lastUnitField = null; for (int i = 0; i < types.length; i++) { DateTimeFieldType loopType = types[i]; DurationField loopUnitField = loopType.getDurationType().getField(iChronology); if (i > 0) { int compare = lastUnitField.compareTo(loopUnitField); if (compare < 0) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } else if (compare == 0) { if (types[i - 1].getRangeDurationType() == null) { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } else { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } DurationField lastRangeField = types[i - 1].getRangeDurationType().getField(iChronology); DurationField loopRangeField = loopType.getRangeDurationType().getField(iChronology); if (lastRangeField.compareTo(loopRangeField) < 0) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } if (lastRangeField.compareTo(loopRangeField) == 0) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } } } lastUnitField = loopUnitField; }  iTypes = (DateTimeFieldType[]) types.clone(); chronology.validate(this, values); iValues = (int[]) values.clone(); }
 public Partial(DateTimeFieldType[] types, int[] values, Chronology chronology) { super(); chronology = DateTimeUtils.getChronology(chronology).withUTC(); iChronology = chronology; if (types == null) { throw new IllegalArgumentException("Types array must not be null"); } if (values == null) { throw new IllegalArgumentException("Values array must not be null"); } if (values.length != types.length) { throw new IllegalArgumentException("Values array must be the same length as the types array"); } if (types.length == 0) { iTypes = types; iValues = values; return; } for (int i = 0; i < types.length; i++) { if (types[i] == null) { throw new IllegalArgumentException("Types array must not contain null: index " + i); } } DurationField lastUnitField = null; for (int i = 0; i < types.length; i++) { DateTimeFieldType loopType = types[i]; DurationField loopUnitField = loopType.getDurationType().getField(iChronology); if (i > 0) { int compare = lastUnitField.compareTo(loopUnitField); if (compare < 0) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } else if (compare == 0) { if (types[i - 1].getRangeDurationType() == null) { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } else { if (loopType.getRangeDurationType() == null) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } DurationField lastRangeField = types[i - 1].getRangeDurationType().getField(iChronology); DurationField loopRangeField = loopType.getRangeDurationType().getField(iChronology); if (lastRangeField.compareTo(loopRangeField) < 0) { throw new IllegalArgumentException("Types array must be in order largest-smallest: " + types[i - 1].getName() + " < " + loopType.getName()); } if (lastRangeField.compareTo(loopRangeField) == 0) { throw new IllegalArgumentException("Types array must not contain duplicate: " + types[i - 1].getName() + " and " + loopType.getName()); } } } } lastUnitField = loopUnitField; }  iTypes = (DateTimeFieldType[]) types.clone(); chronology.validate(this, values); iValues = (int[]) values.clone(); }
 public DefaultIntervalCategoryDataset(Comparable[] seriesKeys, Comparable[] categoryKeys, Number[][] starts, Number[][] ends) {  this.startData = starts; this.endData = ends;  if (starts != null && ends != null) {  String baseName = "org.jfree.data.resources.DataPackageResources"; ResourceBundle resources = ResourceBundle.getBundle(baseName);  int seriesCount = starts.length; if (seriesCount != ends.length) { String errMsg = "DefaultIntervalCategoryDataset: the number " + "of series in the start value dataset does " + "not match the number of series in the end " + "value dataset."; throw new IllegalArgumentException(errMsg); } if (seriesCount > 0) {  // set up the series names... if (seriesKeys != null) {  if (seriesKeys.length != seriesCount) { throw new IllegalArgumentException( "The number of series keys does not " + "match the number of series in the data."); }  this.seriesKeys = seriesKeys; } else { String prefix = resources.getString( "series.default-prefix") + " "; this.seriesKeys = generateKeys(seriesCount, prefix); }  // set up the category names... int categoryCount = starts[0].length; if (categoryCount != ends[0].length) { String errMsg = "DefaultIntervalCategoryDataset: the " + "number of categories in the start value " + "dataset does not match the number of " + "categories in the end value dataset."; throw new IllegalArgumentException(errMsg); } if (categoryKeys != null) { if (categoryKeys.length != categoryCount) { throw new IllegalArgumentException( "The number of category keys does not match " + "the number of categories in the data."); } this.categoryKeys = categoryKeys; } else { String prefix = resources.getString( "categories.default-prefix") + " "; this.categoryKeys = generateKeys(categoryCount, prefix); }  } else { this.seriesKeys = null; this.categoryKeys = null; } }  }
 public void setCategoryKeys(Comparable[] categoryKeys) { if (categoryKeys == null) { throw new IllegalArgumentException("Null 'categoryKeys' argument."); } if (categoryKeys.length != this.startData[0].length) { throw new IllegalArgumentException( "The number of categories does not match the data."); } for (int i = 0; i < categoryKeys.length; i++) { if (categoryKeys[i] == null) { throw new IllegalArgumentException( "DefaultIntervalCategoryDataset.setCategoryKeys(): " + "null category not permitted."); } } this.categoryKeys = categoryKeys; fireDatasetChanged(); }
 private Object deepStub(InvocationOnMock invocation, GenericMetadataSupport returnTypeGenericMetadata) throws Throwable { InternalMockHandler<Object> handler = new MockUtil().getMockHandler(invocation.getMock()); InvocationContainerImpl container = (InvocationContainerImpl) handler.getInvocationContainer();  // matches invocation for verification for (StubbedInvocationMatcher stubbedInvocationMatcher : container.getStubbedInvocations()) { if (container.getInvocationForStubbing().matches(stubbedInvocationMatcher.getInvocation())) { return stubbedInvocationMatcher.answer(invocation); } }  // record deep stub answer return recordDeepStubAnswer( newDeepStubMock(returnTypeGenericMetadata), container ); }
 private MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata) { MockSettings mockSettings = returnTypeGenericMetadata.hasRawExtraInterfaces() ? withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces()) : withSettings();  return mockSettings.serializable() .defaultAnswer(returnsDeepStubsAnswerUsing(returnTypeGenericMetadata)); }
 private MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata) { MockSettings mockSettings = returnTypeGenericMetadata.hasRawExtraInterfaces() ? withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces()) : withSettings();  return mockSettings.serializable() .defaultAnswer(returnsDeepStubsAnswerUsing(returnTypeGenericMetadata)); }
 Object returnValueFor(Class<?> type) { if (Primitives.isPrimitiveOrWrapper(type)) { return Primitives.defaultValueForPrimitiveOrWrapper(type); //new instances are used instead of Collections.emptyList(), etc. //to avoid UnsupportedOperationException if code under test modifies returned collection } else if (type == Collection.class) { return new LinkedList<Object>(); } else if (type == Set.class) { return new HashSet<Object>(); } else if (type == HashSet.class) { return new HashSet<Object>(); } else if (type == SortedSet.class) { return new TreeSet<Object>(); } else if (type == TreeSet.class) { return new TreeSet<Object>(); } else if (type == LinkedHashSet.class) { return new LinkedHashSet<Object>(); } else if (type == List.class) { return new LinkedList<Object>(); } else if (type == LinkedList.class) { return new LinkedList<Object>(); } else if (type == ArrayList.class) { return new ArrayList<Object>(); } else if (type == Map.class) { return new HashMap<Object, Object>(); } else if (type == HashMap.class) { return new HashMap<Object, Object>(); } else if (type == SortedMap.class) { return new TreeMap<Object, Object>(); } else if (type == TreeMap.class) { return new TreeMap<Object, Object>(); } else if (type == LinkedHashMap.class) { return new LinkedHashMap<Object, Object>(); } //Let's not care about the rest of collections. return null; }
 public static float max(final float a, final float b) { return (a <= b) ? b : (Float.isNaN(a + b) ? Float.NaN : b); }
 public boolean contains(char ch) { char[] thisBuf = buffer; for (int i = 0; i < thisBuf.length; i++) { if (thisBuf[i] == ch) { return true; } } return false; }
 public int indexOf(char ch, int startIndex) { startIndex = (startIndex < 0 ? 0 : startIndex); if (startIndex >= size) { return -1; } char[] thisBuf = buffer; for (int i = startIndex; i < thisBuf.length; i++) { if (thisBuf[i] == ch) { return i; } } return -1; }
 public JSType getLeastSupertype(JSType that) { if (!that.isRecordType()) { return super.getLeastSupertype(that); } RecordTypeBuilder builder = new RecordTypeBuilder(registry); for (String property : properties.keySet()) { if (that.toMaybeRecordType().hasProperty(property) && that.toMaybeRecordType().getPropertyType(property).isEquivalentTo( getPropertyType(property))) { builder.addProperty(property, getPropertyType(property), getPropertyNode(property)); } } return builder.build(); }
 public final boolean isEmptyType() { return isNoType() || isNoObjectType() || isNoResolvedType(); }
 private void makeLocalNamesUnique(Node fnNode, boolean isCallInLoop) { Supplier<String> idSupplier = compiler.getUniqueNameIdSupplier(); // Make variable names unique to this instance. NodeTraversal.traverse( compiler, fnNode, new MakeDeclaredNamesUnique( new InlineRenamer( idSupplier, "inline_", isCallInLoop))); // Make label names unique to this instance. }
 private void visitLabel(Node node, Node parent) { Node nameNode = node.getFirstChild(); Preconditions.checkState(nameNode != null); String name = nameNode.getString(); LabelInfo li = getLabelInfo(name); // This is a label... if (li.referenced) { String newName = getNameForId(li.id); if (!name.equals(newName)) { // ... and it is used, give it the short name. nameNode.setString(newName); compiler.reportCodeChange(); } } else { // ... and it is not referenced, just remove it. Node newChild = node.getLastChild(); node.removeChild(newChild); parent.replaceChild(node, newChild); if (newChild.getType() == Token.BLOCK) { NodeUtil.tryMergeBlock(newChild); } compiler.reportCodeChange(); }  // Remove the label from the current stack of labels. namespaceStack.peek().renameMap.remove(name); }
 public int getOffsetFromLocal(long instantLocal) { // get the offset at instantLocal (first estimate) final int offsetLocal = getOffset(instantLocal); // adjust instantLocal using the estimate and recalc the offset final long instantAdjusted = instantLocal - offsetLocal; final int offsetAdjusted = getOffset(instantAdjusted); // if the offsets differ, we must be near a DST boundary if (offsetLocal != offsetAdjusted) { // we need to ensure that time is always after the DST gap // this happens naturally for positive offsets, but not for negative if ((offsetLocal - offsetAdjusted) < 0) { // if we just return offsetAdjusted then the time is pushed // back before the transition, whereas it should be // on or after the transition long nextLocal = nextTransition(instantAdjusted); long nextAdjusted = nextTransition(instantLocal - offsetAdjusted); if (nextLocal != nextAdjusted) { return offsetLocal; } } } else if (offsetLocal > 0) { long prev = previousTransition(instantAdjusted); if (prev < instantAdjusted) { int offsetPrev = getOffset(prev); int diff = offsetPrev - offsetLocal; if (instantAdjusted - prev <= diff) { return offsetPrev; } } } return offsetAdjusted; }
 public static synchronized FastDateFormat getDateInstance(int style, TimeZone timeZone, Locale locale) { Object key = new Integer(style); if (timeZone != null) { key = new Pair(key, timeZone); }  if (locale != null) { key = new Pair(key, locale); }   FastDateFormat format = (FastDateFormat) cDateInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateInstance(style, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date pattern for locale: " + locale); } } return format; }
 public static synchronized FastDateFormat getDateInstance(int style, TimeZone timeZone, Locale locale) { Object key = new Integer(style); if (timeZone != null) { key = new Pair(key, timeZone); }  if (locale != null) { key = new Pair(key, locale); }   FastDateFormat format = (FastDateFormat) cDateInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateInstance(style, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date pattern for locale: " + locale); } } return format; }
 public static synchronized FastDateFormat getDateInstance(int style, TimeZone timeZone, Locale locale) { Object key = new Integer(style); if (timeZone != null) { key = new Pair(key, timeZone); }  if (locale != null) { key = new Pair(key, locale); }   FastDateFormat format = (FastDateFormat) cDateInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateInstance(style, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date pattern for locale: " + locale); } } return format; }
 public static synchronized FastDateFormat getDateTimeInstance(int dateStyle, int timeStyle, TimeZone timeZone, Locale locale) {  Object key = new Pair(new Integer(dateStyle), new Integer(timeStyle)); if (timeZone != null) { key = new Pair(key, timeZone); } if (locale != null) { key = new Pair(key, locale); }  FastDateFormat format = (FastDateFormat) cDateTimeInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateTimeInstance(dateStyle, timeStyle, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateTimeInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date time pattern for locale: " + locale); } } return format; }
 public static synchronized FastDateFormat getDateTimeInstance(int dateStyle, int timeStyle, TimeZone timeZone, Locale locale) {  Object key = new Pair(new Integer(dateStyle), new Integer(timeStyle)); if (timeZone != null) { key = new Pair(key, timeZone); } if (locale != null) { key = new Pair(key, locale); }  FastDateFormat format = (FastDateFormat) cDateTimeInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateTimeInstance(dateStyle, timeStyle, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateTimeInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date time pattern for locale: " + locale); } } return format; }
 public static synchronized FastDateFormat getDateTimeInstance(int dateStyle, int timeStyle, TimeZone timeZone, Locale locale) {  Object key = new Pair(new Integer(dateStyle), new Integer(timeStyle)); if (timeZone != null) { key = new Pair(key, timeZone); } if (locale != null) { key = new Pair(key, locale); }  FastDateFormat format = (FastDateFormat) cDateTimeInstanceCache.get(key); if (format == null) { if (locale == null) { locale = Locale.getDefault(); } try { SimpleDateFormat formatter = (SimpleDateFormat) DateFormat.getDateTimeInstance(dateStyle, timeStyle, locale); String pattern = formatter.toPattern(); format = getInstance(pattern, timeZone, locale); cDateTimeInstanceCache.put(key, format);  } catch (ClassCastException ex) { throw new IllegalArgumentException("No date time pattern for locale: " + locale); } } return format; }
 public int[] getCounts(int index) { if (index < 0 || index >= totalSize) { throw new OutOfRangeException(index, 0, totalSize); }  final int[] indices = new int[dimension];  int count = 0; for (int i = 0; i < last; i++) { int idx = 0; final int offset = uniCounterOffset[i]; while (count <= index) { count += offset; ++idx; } --idx; count -= offset; indices[i] = idx; }  int idx = 1; while (count < index) { count += idx; ++idx; } --idx; indices[last] = idx;  return indices; }
 public Partial with(DateTimeFieldType fieldType, int value) { if (fieldType == null) { throw new IllegalArgumentException("The field type must not be null"); } int index = indexOf(fieldType); if (index == -1) { DateTimeFieldType[] newTypes = new DateTimeFieldType[iTypes.length + 1]; int[] newValues = new int[newTypes.length];  // find correct insertion point to keep largest-smallest order int i = 0; DurationField unitField = fieldType.getDurationType().getField(iChronology); if (unitField.isSupported()) { for (; i < iTypes.length; i++) { DateTimeFieldType loopType = iTypes[i]; DurationField loopUnitField = loopType.getDurationType().getField(iChronology); if (loopUnitField.isSupported()) { int compare = unitField.compareTo(loopUnitField); if (compare > 0) { break; } else if (compare == 0) { DurationField rangeField = fieldType.getRangeDurationType().getField(iChronology); DurationField loopRangeField = loopType.getRangeDurationType().getField(iChronology); if (rangeField.compareTo(loopRangeField) > 0) { break; } } } } } System.arraycopy(iTypes, 0, newTypes, 0, i); System.arraycopy(iValues, 0, newValues, 0, i); newTypes[i] = fieldType; newValues[i] = value; System.arraycopy(iTypes, i, newTypes, i + 1, newTypes.length - i - 1); System.arraycopy(iValues, i, newValues, i + 1, newValues.length - i - 1); // use public constructor to ensure full validation // this isn't overly efficient, but is safe Partial newPartial = new Partial(iChronology, newTypes, newValues); iChronology.validate(newPartial, newValues); return newPartial; } if (value == getValue(index)) { return this; } int[] newValues = getValues(); newValues = getField(index).set(this, index, newValues, value); return new Partial(this, newValues); }
 private static void modify(Calendar val, int field, boolean round) { if (val.get(Calendar.YEAR) > 280000000) { throw new ArithmeticException("Calendar value too large for accurate calculations"); }  if (field == Calendar.MILLISECOND) { return; }  // ----------------- Fix for LANG-59 ---------------------- START --------------- // see http://issues.apache.org/jira/browse/LANG-59 // // Manually truncate milliseconds, seconds and minutes, rather than using // Calendar methods.  Date date = val.getTime(); long time = date.getTime(); boolean done = false;  // truncate milliseconds int millisecs = val.get(Calendar.MILLISECOND); if (!round || millisecs < 500) { time = time - millisecs; if (field == Calendar.SECOND) { done = true; } }  // truncate seconds int seconds = val.get(Calendar.SECOND); if (!done && (!round || seconds < 30)) { time = time - (seconds * 1000L); if (field == Calendar.MINUTE) { done = true; } }  // truncate minutes int minutes = val.get(Calendar.MINUTE); if (!done && (!round || minutes < 30)) { time = time - (minutes * 60000L); }  // reset time if (date.getTime() != time) { date.setTime(time); val.setTime(date); } // ----------------- Fix for LANG-59 ----------------------- END ----------------  boolean roundUp = false; for (int i = 0; i < fields.length; i++) { for (int j = 0; j < fields[i].length; j++) { if (fields[i][j] == field) { //This is our field... we stop looping if (round && roundUp) { if (field == DateUtils.SEMI_MONTH) { //This is a special case that's hard to generalize //If the date is 1, we round up to 16, otherwise //  we subtract 15 days and add 1 month if (val.get(Calendar.DATE) == 1) { val.add(Calendar.DATE, 15); } else { val.add(Calendar.DATE, -15); val.add(Calendar.MONTH, 1); } } else { //We need at add one to this field since the //  last number causes us to round up val.add(fields[i][0], 1); } } return; } } //We have various fields that are not easy roundings int offset = 0; boolean offsetSet = false; //These are special types of fields that require different rounding rules switch (field) { case DateUtils.SEMI_MONTH: if (fields[i][0] == Calendar.DATE) { //If we're going to drop the DATE field's value, //  we want to do this our own way. //We need to subtrace 1 since the date has a minimum of 1 offset = val.get(Calendar.DATE) - 1; //If we're above 15 days adjustment, that means we're in the //  bottom half of the month and should stay accordingly. if (offset >= 15) { offset -= 15; } //Record whether we're in the top or bottom half of that range roundUp = offset > 7; offsetSet = true; } break; case Calendar.AM_PM: if (fields[i][0] == Calendar.HOUR_OF_DAY) { //If we're going to drop the HOUR field's value, //  we want to do this our own way. offset = val.get(Calendar.HOUR_OF_DAY); if (offset >= 12) { offset -= 12; } roundUp = offset > 6; offsetSet = true; } break; } if (!offsetSet) { int min = val.getActualMinimum(fields[i][0]); int max = val.getActualMaximum(fields[i][0]); //Calculate the offset from the minimum allowed value offset = val.get(fields[i][0]) - min; //Set roundUp if this is more than half way between the minimum and maximum roundUp = offset > ((max - min) / 2); } //We need to remove this field if (offset != 0) { val.set(fields[i][0], val.get(fields[i][0]) - offset); } } throw new IllegalArgumentException("The field " + field + " is not supported");  }
 private static void modify(Calendar val, int field, boolean round) { if (val.get(Calendar.YEAR) > 280000000) { throw new ArithmeticException("Calendar value too large for accurate calculations"); }  if (field == Calendar.MILLISECOND) { return; }  // ----------------- Fix for LANG-59 ---------------------- START --------------- // see http://issues.apache.org/jira/browse/LANG-59 // // Manually truncate milliseconds, seconds and minutes, rather than using // Calendar methods.  Date date = val.getTime(); long time = date.getTime(); boolean done = false;  // truncate milliseconds int millisecs = val.get(Calendar.MILLISECOND); if (!round || millisecs < 500) { time = time - millisecs; if (field == Calendar.SECOND) { done = true; } }  // truncate seconds int seconds = val.get(Calendar.SECOND); if (!done && (!round || seconds < 30)) { time = time - (seconds * 1000L); if (field == Calendar.MINUTE) { done = true; } }  // truncate minutes int minutes = val.get(Calendar.MINUTE); if (!done && (!round || minutes < 30)) { time = time - (minutes * 60000L); }  // reset time if (date.getTime() != time) { date.setTime(time); val.setTime(date); } // ----------------- Fix for LANG-59 ----------------------- END ----------------  boolean roundUp = false; for (int i = 0; i < fields.length; i++) { for (int j = 0; j < fields[i].length; j++) { if (fields[i][j] == field) { //This is our field... we stop looping if (round && roundUp) { if (field == DateUtils.SEMI_MONTH) { //This is a special case that's hard to generalize //If the date is 1, we round up to 16, otherwise //  we subtract 15 days and add 1 month if (val.get(Calendar.DATE) == 1) { val.add(Calendar.DATE, 15); } else { val.add(Calendar.DATE, -15); val.add(Calendar.MONTH, 1); } } else { //We need at add one to this field since the //  last number causes us to round up val.add(fields[i][0], 1); } } return; } } //We have various fields that are not easy roundings int offset = 0; boolean offsetSet = false; //These are special types of fields that require different rounding rules switch (field) { case DateUtils.SEMI_MONTH: if (fields[i][0] == Calendar.DATE) { //If we're going to drop the DATE field's value, //  we want to do this our own way. //We need to subtrace 1 since the date has a minimum of 1 offset = val.get(Calendar.DATE) - 1; //If we're above 15 days adjustment, that means we're in the //  bottom half of the month and should stay accordingly. if (offset >= 15) { offset -= 15; } //Record whether we're in the top or bottom half of that range roundUp = offset > 7; offsetSet = true; } break; case Calendar.AM_PM: if (fields[i][0] == Calendar.HOUR_OF_DAY) { //If we're going to drop the HOUR field's value, //  we want to do this our own way. offset = val.get(Calendar.HOUR_OF_DAY); if (offset >= 12) { offset -= 12; } roundUp = offset > 6; offsetSet = true; } break; } if (!offsetSet) { int min = val.getActualMinimum(fields[i][0]); int max = val.getActualMaximum(fields[i][0]); //Calculate the offset from the minimum allowed value offset = val.get(fields[i][0]) - min; //Set roundUp if this is more than half way between the minimum and maximum roundUp = offset > ((max - min) / 2); } //We need to remove this field if (offset != 0) { val.set(fields[i][0], val.get(fields[i][0]) - offset); } } throw new IllegalArgumentException("The field " + field + " is not supported");  }
 private void tryRemoveUnconditionalBranching(Node n) { /* * For each unconditional branching control flow node, check to see * if the ControlFlowAnalysis.computeFollowNode of that node is same as * the branching target. If it is, the branch node is safe to be removed. * * This is not as clever as MinimizeExitPoints because it doesn't do any * if-else conversion but it handles more complicated switch statements * much more nicely. */  // If n is null the target is the end of the function, nothing to do. if (n == null) { return; }  DiGraphNode<Node, Branch> gNode = cfg.getDirectedGraphNode(n);  if (gNode == null) { return; }  switch (n.getType()) { case Token.RETURN: if (n.hasChildren()) { break; } case Token.BREAK: case Token.CONTINUE: // We are looking for a control flow changing statement that always // branches to the same node. If after removing it control still // branches to the same node, it is safe to remove. List<DiGraphEdge<Node, Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1 && // If there is a next node, this jump is not useless. (n.getNext() == null || n.getNext().isFunction())) {  Preconditions.checkState( outEdges.get(0).getValue() == Branch.UNCOND); Node fallThrough = computeFollowing(n); Node nextCfgNode = outEdges.get(0).getDestination().getValue(); if (nextCfgNode == fallThrough) { removeNode(n); } } } }
 public Object callRealMethod() throws Throwable { return realMethod.invoke(mock, rawArguments); }
 public Week(Date time, TimeZone zone) { // defer argument checking... this(time, RegularTimePeriod.DEFAULT_TIME_ZONE, Locale.getDefault()); }
 public UnivariateRealPointValuePair optimize(final FUNC f, final GoalType goal, final double min, final double max) throws FunctionEvaluationException { return optimize(f, goal, min, max, 0); }
 public UnivariateRealPointValuePair optimize(final FUNC f, final GoalType goal, final double min, final double max, final double startValue) throws FunctionEvaluationException { optima = new UnivariateRealPointValuePair[starts]; totalEvaluations = 0;  // Multi-start loop. for (int i = 0; i < starts; ++i) { try { final double bound1 = (i == 0) ? min : min + generator.nextDouble() * (max - min); final double bound2 = (i == 0) ? max : min + generator.nextDouble() * (max - min); optima[i] = optimizer.optimize(f, goal, FastMath.min(bound1, bound2), FastMath.max(bound1, bound2)); } catch (FunctionEvaluationException fee) { optima[i] = null; } catch (ConvergenceException ce) { optima[i] = null; }  final int usedEvaluations = optimizer.getEvaluations(); optimizer.setMaxEvaluations(optimizer.getMaxEvaluations() - usedEvaluations); totalEvaluations += usedEvaluations; }  sortPairs(goal);  if (optima[0] == null) { throw new ConvergenceException(LocalizedFormats.NO_CONVERGENCE_WITH_ANY_START_POINT, starts); }  // Return the point with the best objective function value. return optima[0]; }
 public long add(long instant, int value) { if (iTimeField) { int offset = getOffsetToAdd(instant); long localInstant = iField.add(instant + offset, value); return localInstant - offset; } else { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.add(localInstant, value); return iZone.convertLocalToUTC(localInstant, false); } }
 public long add(long instant, long value) { if (iTimeField) { int offset = getOffsetToAdd(instant); long localInstant = iField.add(instant + offset, value); return localInstant - offset; } else { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.add(localInstant, value); return iZone.convertLocalToUTC(localInstant, false); } }
 public long addWrapField(long instant, int value) { if (iTimeField) { int offset = getOffsetToAdd(instant); long localInstant = iField.addWrapField(instant + offset, value); return localInstant - offset; } else { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.addWrapField(localInstant, value); return iZone.convertLocalToUTC(localInstant, false); } }
 public long roundCeiling(long instant) { if (iTimeField) { int offset = getOffsetToAdd(instant); instant = iField.roundCeiling(instant + offset); return instant - offset; } else { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.roundCeiling(localInstant); return iZone.convertLocalToUTC(localInstant, false); } }
 public long roundFloor(long instant) { if (iTimeField) { int offset = getOffsetToAdd(instant); instant = iField.roundFloor(instant + offset); return instant - offset; } else { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.roundFloor(localInstant); return iZone.convertLocalToUTC(localInstant, false); } }
 public long set(long instant, int value) { long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.set(localInstant, value); long result = iZone.convertLocalToUTC(localInstant, false); if (get(result) != value) { throw new IllegalFieldValueException(iField.getType(), new Integer(value), "Illegal instant due to time zone offset transition: " + DateTimeFormat.forPattern("yyyy-MM-dd'T'HH:mm:ss.SSS").print(new Instant(localInstant)) + " (" + iZone.getID() + ")"); } return result; }
 public long set(long instant, String text, Locale locale) { // cannot verify that new value stuck because set may be lenient long localInstant = iZone.convertUTCToLocal(instant); localInstant = iField.set(localInstant, text, locale); return iZone.convertLocalToUTC(localInstant, false); }
 private Node tryFoldComparison(Node n, Node left, Node right) { if (!NodeUtil.isLiteralValue(left, false) || !NodeUtil.isLiteralValue(right, false)) { // We only handle non-literal operands for LT and GT. if (n.getType() != Token.GT && n.getType() != Token.LT) { return n; } }  int op = n.getType(); boolean result;  // TODO(johnlenz): Use the JSType to compare nodes of different types.  boolean rightLiteral = NodeUtil.isLiteralValue(right, false); boolean undefinedRight = ((Token.NAME == right.getType() && right.getString().equals("undefined")) || (Token.VOID == right.getType() && NodeUtil.isLiteralValue(right.getFirstChild(), false))); int lhType = left.getType(); int rhType = right.getType(); switch (lhType) { case Token.VOID: if (!NodeUtil.isLiteralValue(left.getFirstChild(), false)) { return n; } else if (!rightLiteral) { return n; } else { result = compareToUndefined(right, op); } break;  case Token.NULL: case Token.TRUE: case Token.FALSE: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (rhType != Token.TRUE && rhType != Token.FALSE && rhType != Token.NULL) { return n; } switch (op) { case Token.SHEQ: case Token.EQ: result = lhType == rhType; break;  case Token.SHNE: case Token.NE: result = lhType != rhType; break;  case Token.GE: case Token.LE: case Token.GT: case Token.LT: Boolean compareResult = compareAsNumbers(op, left, right); if (compareResult != null) { result = compareResult; } else { return n; } break;  default: return n;  // we only handle == and != here } break;  case Token.THIS: if (right.getType() != Token.THIS) { return n; } switch (op) { case Token.SHEQ: case Token.EQ: result = true; break;  case Token.SHNE: case Token.NE: result = false; break;  // We can only handle == and != here. // GT, LT, GE, LE depend on the type of "this" and how it will // be converted to number.  The results are different depending on // whether it is a string, NaN or other number value. default: return n; } break;  case Token.STRING: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (Token.STRING != right.getType()) { return n;  // Only eval if they are the same type } switch (op) { case Token.SHEQ: case Token.EQ: result = left.getString().equals(right.getString()); break;  case Token.SHNE: case Token.NE: result = !left.getString().equals(right.getString()); break;  default: return n;  // we only handle == and != here } break;  case Token.NUMBER: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (Token.NUMBER != right.getType()) { return n;  // Only eval if they are the same type } Boolean compareResult = compareAsNumbers(op, left, right); if (compareResult != null) { result = compareResult; } else { return null; } break;  case Token.NAME: if (undefinedRight) { result = compareToUndefined(left, op); break; }  if (rightLiteral) { boolean undefinedLeft = (left.getString().equals("undefined")); if (undefinedLeft) { result = compareToUndefined(right, op); break; } }  if (Token.NAME != right.getType()) { return n;  // Only eval if they are the same type } String ln = left.getString(); String rn = right.getString(); if (!ln.equals(rn)) { return n;  // Not the same value name. }  switch (op) { // If we knew the named value wouldn't be NaN, it would be nice // to handle EQ,NE,LE,GE,SHEQ, and SHNE. case Token.LT: case Token.GT: result = false; break; default: return n;  // don't handle that op } break;  default: // assert, this should cover all consts return n; }  Node newNode = new Node(result ? Token.TRUE : Token.FALSE); n.getParent().replaceChild(n, newNode); reportCodeChange();  return newNode; }
 private Node tryFoldComparison(Node n, Node left, Node right) { if (!NodeUtil.isLiteralValue(left, false) || !NodeUtil.isLiteralValue(right, false)) { // We only handle non-literal operands for LT and GT. if (n.getType() != Token.GT && n.getType() != Token.LT) { return n; } }  int op = n.getType(); boolean result;  // TODO(johnlenz): Use the JSType to compare nodes of different types.  boolean rightLiteral = NodeUtil.isLiteralValue(right, false); boolean undefinedRight = ((Token.NAME == right.getType() && right.getString().equals("undefined")) || (Token.VOID == right.getType() && NodeUtil.isLiteralValue(right.getFirstChild(), false))); int lhType = left.getType(); int rhType = right.getType(); switch (lhType) { case Token.VOID: if (!NodeUtil.isLiteralValue(left.getFirstChild(), false)) { return n; } else if (!rightLiteral) { return n; } else { result = compareToUndefined(right, op); } break;  case Token.NULL: case Token.TRUE: case Token.FALSE: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (rhType != Token.TRUE && rhType != Token.FALSE && rhType != Token.NULL) { return n; } switch (op) { case Token.SHEQ: case Token.EQ: result = lhType == rhType; break;  case Token.SHNE: case Token.NE: result = lhType != rhType; break;  case Token.GE: case Token.LE: case Token.GT: case Token.LT: Boolean compareResult = compareAsNumbers(op, left, right); if (compareResult != null) { result = compareResult; } else { return n; } break;  default: return n;  // we only handle == and != here } break;  case Token.THIS: if (right.getType() != Token.THIS) { return n; } switch (op) { case Token.SHEQ: case Token.EQ: result = true; break;  case Token.SHNE: case Token.NE: result = false; break;  // We can only handle == and != here. // GT, LT, GE, LE depend on the type of "this" and how it will // be converted to number.  The results are different depending on // whether it is a string, NaN or other number value. default: return n; } break;  case Token.STRING: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (Token.STRING != right.getType()) { return n;  // Only eval if they are the same type } switch (op) { case Token.SHEQ: case Token.EQ: result = left.getString().equals(right.getString()); break;  case Token.SHNE: case Token.NE: result = !left.getString().equals(right.getString()); break;  default: return n;  // we only handle == and != here } break;  case Token.NUMBER: if (undefinedRight) { result = compareToUndefined(left, op); break; } if (Token.NUMBER != right.getType()) { return n;  // Only eval if they are the same type } Boolean compareResult = compareAsNumbers(op, left, right); if (compareResult != null) { result = compareResult; } else { return null; } break;  case Token.NAME: if (undefinedRight) { result = compareToUndefined(left, op); break; }  if (rightLiteral) { boolean undefinedLeft = (left.getString().equals("undefined")); if (undefinedLeft) { result = compareToUndefined(right, op); break; } }  if (Token.NAME != right.getType()) { return n;  // Only eval if they are the same type } String ln = left.getString(); String rn = right.getString(); if (!ln.equals(rn)) { return n;  // Not the same value name. }  switch (op) { // If we knew the named value wouldn't be NaN, it would be nice // to handle EQ,NE,LE,GE,SHEQ, and SHNE. case Token.LT: case Token.GT: result = false; break; default: return n;  // don't handle that op } break;  default: // assert, this should cover all consts return n; }  Node newNode = new Node(result ? Token.TRUE : Token.FALSE); n.getParent().replaceChild(n, newNode); reportCodeChange();  return newNode; }
 public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial) throws MaxIterationsExceededException, FunctionEvaluationException {  clearResult(); verifySequence(min, initial, max);  // return the initial guess if it is good enough double yInitial = f.value(initial); if (Math.abs(yInitial) <= functionValueAccuracy) { setResult(initial, 0); return result; }  // return the first endpoint if it is good enough double yMin = f.value(min); if (Math.abs(yMin) <= functionValueAccuracy) { setResult(yMin, 0); return result; }  // reduce interval if min and initial bracket the root if (yInitial * yMin < 0) { return solve(f, min, yMin, initial, yInitial, min, yMin); }  // return the second endpoint if it is good enough double yMax = f.value(max); if (Math.abs(yMax) <= functionValueAccuracy) { setResult(yMax, 0); return result; }  // reduce interval if initial and max bracket the root if (yInitial * yMax < 0) { return solve(f, initial, yInitial, max, yMax, initial, yInitial); }   // full Brent algorithm starting with provided initial guess return solve(f, min, yMin, max, yMax, initial, yInitial);  }
 public Dfp multiply(final int x) { return multiplyFast(x); }
 private void visitCall(NodeTraversal t, Node n) { Node child = n.getFirstChild(); JSType childType = getJSType(child).restrictByNotNullOrUndefined();  if (!childType.canBeCalled()) { report(t, n, NOT_CALLABLE, childType.toString()); ensureTyped(t, n); return; }  // A couple of types can be called as if they were functions. // If it is a function type, then validate parameters. if (childType instanceof FunctionType) { FunctionType functionType = (FunctionType) childType;  boolean isExtern = false; JSDocInfo functionJSDocInfo = functionType.getJSDocInfo(); if(functionJSDocInfo != null) { String sourceName = functionJSDocInfo.getSourceName(); CompilerInput functionSource = compiler.getInput(sourceName); isExtern = functionSource.isExtern(); }  // Non-native constructors should not be called directly // unless they specify a return type and are defined // in an extern. if (functionType.isConstructor() && !functionType.isNativeObjectType() && (functionType.getReturnType().isUnknownType() || functionType.getReturnType().isVoidType() || !isExtern)) { report(t, n, CONSTRUCTOR_NOT_CALLABLE, childType.toString()); }  // Functions with explcit 'this' types must be called in a GETPROP // or GETELEM.  visitParameterList(t, n, functionType); ensureTyped(t, n, functionType.getReturnType()); } else { ensureTyped(t, n); }  // TODO: Add something to check for calls of RegExp objects, which is not // supported by IE.  Either say something about the return type or warn // about the non-portability of the call or both. }
 BasicBlock(BasicBlock parent, Node root) { this.parent = parent;  // only named functions may be hoisted. this.isHoisted = NodeUtil.isHoistedFunctionDeclaration(root);   }
 boolean isAssignedOnceInLifetime() { Reference ref = getOneAndOnlyAssignment(); if (ref == null) { return false; }  // Make sure this assignment is not in a loop.  return true; }
 public static boolean equals(CharSequence cs1, CharSequence cs2) { if (cs1 == cs2) { return true; } if (cs1 == null || cs2 == null) { return false; } return cs1.equals(cs2); }
 public static boolean equals(double x, double y) { return (Double.isNaN(x) && Double.isNaN(y)) || x == y; }
 protected void declareNameInScope(FlowScope scope, Node node, JSType type) { switch (node.getType()) { case Token.NAME: scope.inferSlotType(node.getString(), type); break;  case Token.GETPROP: String qualifiedName = node.getQualifiedName(); Preconditions.checkNotNull(qualifiedName);  JSType origType = node.getJSType(); origType = origType == null ? getNativeType(UNKNOWN_TYPE) : origType; scope.inferQualifiedSlot(node, qualifiedName, origType, type); break;  // "this" references aren't currently modeled in the CFG.  default: throw new IllegalArgumentException("Node cannot be refined. \n" + node.toStringTree()); } }
 protected void declareNameInScope(FlowScope scope, Node node, JSType type) { switch (node.getType()) { case Token.NAME: scope.inferSlotType(node.getString(), type); break;  case Token.GETPROP: String qualifiedName = node.getQualifiedName(); Preconditions.checkNotNull(qualifiedName);  JSType origType = node.getJSType(); origType = origType == null ? getNativeType(UNKNOWN_TYPE) : origType; scope.inferQualifiedSlot(node, qualifiedName, origType, type); break;  // "this" references aren't currently modeled in the CFG.  default: throw new IllegalArgumentException("Node cannot be refined. \n" + node.toStringTree()); } }
 public static BigDecimal createBigDecimal(String str) { if (str == null) { return null; } // handle JDK1.3.1 bug where "" throws IndexOutOfBoundsException if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return new BigDecimal(str); }
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { return null; } if (str.startsWith("0x") || str.startsWith("-0x") || str.startsWith("0X") || str.startsWith("-0X")) { int hexDigits = str.length() - 2; // drop 0x if (str.startsWith("-")) { // drop - hexDigits--; } if (hexDigits > 8) { // too many for an int return createLong(str); } return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos || expPos > str.length()) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { if (expPos > str.length()) { throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str);  } } }
 Assign(Node assignNode, Node nameNode, boolean isPropertyAssign) { Preconditions.checkState(NodeUtil.isAssignmentOp(assignNode)); this.assignNode = assignNode; this.nameNode = nameNode; this.isPropertyAssign = isPropertyAssign;  this.maybeAliased = !assignNode.getParent().isExprResult(); this.mayHaveSecondarySideEffects = maybeAliased || NodeUtil.mayHaveSideEffects(assignNode.getFirstChild()) || NodeUtil.mayHaveSideEffects(assignNode.getLastChild()); }
 private void interpretAssigns() { boolean changes = false; do { changes = false;  // We can't use traditional iterators and iterables for this list, // because our lazily-evaluated continuations will modify it while // we traverse it. for (int current = 0; current < maybeUnreferenced.size(); current++) { Var var = maybeUnreferenced.get(current); if (referenced.contains(var)) { maybeUnreferenced.remove(current); current--; } else { boolean assignedToUnknownValue = false; boolean hasPropertyAssign = false;  if (var.getParentNode().isVar() && !NodeUtil.isForIn(var.getParentNode().getParent())) { Node value = var.getInitialValue(); assignedToUnknownValue = value != null && !NodeUtil.isLiteralValue(value, true); } else { // This was initialized to a function arg or a catch param // or a for...in variable. assignedToUnknownValue = true; }  for (Assign assign : assignsByVar.get(var)) { if (assign.isPropertyAssign) { hasPropertyAssign = true; } else if (!NodeUtil.isLiteralValue( assign.assignNode.getLastChild(), true)) { assignedToUnknownValue = true; } }  if (assignedToUnknownValue && hasPropertyAssign) { changes = markReferencedVar(var) || changes; maybeUnreferenced.remove(current); current--; } } } } while (changes); }
 public Timer(long durationMillis) { this.durationMillis = durationMillis; }
 public void visit(NodeTraversal t, Node n, Node parent) { JSType childType; JSType leftType, rightType; Node left, right; // To be explicitly set to false if the node is not typeable. boolean typeable = true;  switch (n.getType()) { case Token.NAME: typeable = visitName(t, n, parent); break;  case Token.LP: // If this is under a FUNCTION node, it is a parameter list and can be // ignored here. if (parent.getType() != Token.FUNCTION) { ensureTyped(t, n, getJSType(n.getFirstChild())); } else { typeable = false; } break;  case Token.COMMA: ensureTyped(t, n, getJSType(n.getLastChild())); break;  case Token.TRUE: case Token.FALSE: ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.THIS: ensureTyped(t, n, t.getScope().getTypeOfThis()); break;  case Token.REF_SPECIAL: ensureTyped(t, n); break;  case Token.GET_REF: ensureTyped(t, n, getJSType(n.getFirstChild())); break;  case Token.NULL: ensureTyped(t, n, NULL_TYPE); break;  case Token.NUMBER: ensureTyped(t, n, NUMBER_TYPE); break;  case Token.STRING: // Object literal keys are handled with OBJECTLIT if (!NodeUtil.isObjectLitKey(n, n.getParent())) { ensureTyped(t, n, STRING_TYPE); // Object literal keys are not typeable } break;  case Token.GET: case Token.SET: // Object literal keys are handled with OBJECTLIT break;  case Token.ARRAYLIT: ensureTyped(t, n, ARRAY_TYPE); break;  case Token.REGEXP: ensureTyped(t, n, REGEXP_TYPE); break;  case Token.GETPROP: visitGetProp(t, n, parent); typeable = !(parent.getType() == Token.ASSIGN && parent.getFirstChild() == n); break;  case Token.GETELEM: visitGetElem(t, n); // The type of GETELEM is always unknown, so no point counting that. // If that unknown leaks elsewhere (say by an assignment to another // variable), then it will be counted. typeable = false; break;  case Token.VAR: visitVar(t, n); typeable = false; break;  case Token.NEW: visitNew(t, n); typeable = true; break;  case Token.CALL: visitCall(t, n); typeable = !NodeUtil.isExpressionNode(parent); break;  case Token.RETURN: visitReturn(t, n); typeable = false; break;  case Token.DEC: case Token.INC: left = n.getFirstChild(); validator.expectNumber( t, left, getJSType(left), "increment/decrement"); ensureTyped(t, n, NUMBER_TYPE); break;  case Token.NOT: ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.VOID: ensureTyped(t, n, VOID_TYPE); break;  case Token.TYPEOF: ensureTyped(t, n, STRING_TYPE); break;  case Token.BITNOT: childType = getJSType(n.getFirstChild()); if (!childType.matchesInt32Context()) { report(t, n, BIT_OPERATION, NodeUtil.opToStr(n.getType()), childType.toString()); } ensureTyped(t, n, NUMBER_TYPE); break;  case Token.POS: case Token.NEG: left = n.getFirstChild(); validator.expectNumber(t, left, getJSType(left), "sign operator"); ensureTyped(t, n, NUMBER_TYPE); break;  case Token.EQ: case Token.NE: { leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild());  JSType leftTypeRestricted = leftType.restrictByNotNullOrUndefined(); JSType rightTypeRestricted = rightType.restrictByNotNullOrUndefined(); TernaryValue result = leftTypeRestricted.testForEquality(rightTypeRestricted); if (result != TernaryValue.UNKNOWN) { if (n.getType() == Token.NE) { result = result.not(); } report(t, n, DETERMINISTIC_TEST, leftType.toString(), rightType.toString(), result.toString()); } ensureTyped(t, n, BOOLEAN_TYPE); break; }  case Token.SHEQ: case Token.SHNE: { leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild());  JSType leftTypeRestricted = leftType.restrictByNotNullOrUndefined(); JSType rightTypeRestricted = rightType.restrictByNotNullOrUndefined(); if (!leftTypeRestricted.canTestForShallowEqualityWith( rightTypeRestricted)) { report(t, n, DETERMINISTIC_TEST_NO_RESULT, leftType.toString(), rightType.toString()); } ensureTyped(t, n, BOOLEAN_TYPE); break; }  case Token.LT: case Token.LE: case Token.GT: case Token.GE: leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild()); if (rightType.isNumber()) { validator.expectNumber( t, n, leftType, "left side of numeric comparison"); } else if (leftType.isNumber()) { validator.expectNumber( t, n, rightType, "right side of numeric comparison"); } else if (leftType.matchesNumberContext() && rightType.matchesNumberContext()) { // OK. } else { // Whether the comparison is numeric will be determined at runtime // each time the expression is evaluated. Regardless, both operands // should match a string context. String message = "left side of comparison"; validator.expectString(t, n, leftType, message); validator.expectNotNullOrUndefined( t, n, leftType, message, getNativeType(STRING_TYPE)); message = "right side of comparison"; validator.expectString(t, n, rightType, message); validator.expectNotNullOrUndefined( t, n, rightType, message, getNativeType(STRING_TYPE)); } ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.IN: left = n.getFirstChild(); right = n.getLastChild(); leftType = getJSType(left); rightType = getJSType(right); validator.expectObject(t, n, rightType, "'in' requires an object"); validator.expectString(t, left, leftType, "left side of 'in'"); ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.INSTANCEOF: left = n.getFirstChild(); right = n.getLastChild(); leftType = getJSType(left); rightType = getJSType(right).restrictByNotNullOrUndefined();  validator.expectAnyObject( t, left, leftType, "deterministic instanceof yields false"); validator.expectActualObject( t, right, rightType, "instanceof requires an object"); ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.ASSIGN: visitAssign(t, n); typeable = false; break;  case Token.ASSIGN_LSH: case Token.ASSIGN_RSH: case Token.ASSIGN_URSH: case Token.ASSIGN_DIV: case Token.ASSIGN_MOD: case Token.ASSIGN_BITOR: case Token.ASSIGN_BITXOR: case Token.ASSIGN_BITAND: case Token.ASSIGN_SUB: case Token.ASSIGN_ADD: case Token.ASSIGN_MUL: case Token.LSH: case Token.RSH: case Token.URSH: case Token.DIV: case Token.MOD: case Token.BITOR: case Token.BITXOR: case Token.BITAND: case Token.SUB: case Token.ADD: case Token.MUL: visitBinaryOperator(n.getType(), t, n); break;  case Token.DELPROP: if (!isReference(n.getFirstChild())) { report(t, n, BAD_DELETE); } ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.CASE: JSType switchType = getJSType(parent.getFirstChild()); JSType caseType = getJSType(n.getFirstChild()); validator.expectSwitchMatchesCase(t, n, switchType, caseType); typeable = false; break;  case Token.WITH: { Node child = n.getFirstChild(); childType = getJSType(child); validator.expectObject( t, child, childType, "with requires an object"); typeable = false; break; }  case Token.FUNCTION: visitFunction(t, n); break;  // These nodes have no interesting type behavior. case Token.LABEL: case Token.LABEL_NAME: case Token.SWITCH: case Token.BREAK: case Token.CATCH: case Token.TRY: case Token.SCRIPT: case Token.EXPR_RESULT: case Token.BLOCK: case Token.EMPTY: case Token.DEFAULT: case Token.CONTINUE: case Token.DEBUGGER: case Token.THROW: typeable = false; break;  // These nodes require data flow analysis. case Token.DO: case Token.FOR: case Token.IF: case Token.WHILE: typeable = false; break;  // These nodes are typed during the type inference. case Token.AND: case Token.HOOK: case Token.OBJECTLIT: case Token.OR: if (n.getJSType() != null) { // If we didn't run type inference. ensureTyped(t, n); } else { // If this is an enum, then give that type to the objectlit as well. if ((n.getType() == Token.OBJECTLIT) && (parent.getJSType() instanceof EnumType)) { ensureTyped(t, n, parent.getJSType()); } else { ensureTyped(t, n); } } if (n.getType() == Token.OBJECTLIT) { for (Node key : n.children()) { visitObjLitKey(t, key, n); } } break;  default: report(t, n, UNEXPECTED_TOKEN, Token.name(n.getType())); ensureTyped(t, n); break; }  // Don't count externs since the user's code may not even use that part. typeable = typeable && !inExterns;  if (typeable) { doPercentTypedAccounting(t, n); }  checkNoTypeCheckSection(n, false); }
 public void visit(NodeTraversal t, Node n, Node parent) { JSType childType; JSType leftType, rightType; Node left, right; // To be explicitly set to false if the node is not typeable. boolean typeable = true;  switch (n.getType()) { case Token.NAME: typeable = visitName(t, n, parent); break;  case Token.LP: // If this is under a FUNCTION node, it is a parameter list and can be // ignored here. if (parent.getType() != Token.FUNCTION) { ensureTyped(t, n, getJSType(n.getFirstChild())); } else { typeable = false; } break;  case Token.COMMA: ensureTyped(t, n, getJSType(n.getLastChild())); break;  case Token.TRUE: case Token.FALSE: ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.THIS: ensureTyped(t, n, t.getScope().getTypeOfThis()); break;  case Token.REF_SPECIAL: ensureTyped(t, n); break;  case Token.GET_REF: ensureTyped(t, n, getJSType(n.getFirstChild())); break;  case Token.NULL: ensureTyped(t, n, NULL_TYPE); break;  case Token.NUMBER: ensureTyped(t, n, NUMBER_TYPE); break;  case Token.STRING: // Object literal keys are handled with OBJECTLIT if (!NodeUtil.isObjectLitKey(n, n.getParent())) { ensureTyped(t, n, STRING_TYPE); // Object literal keys are not typeable } break;  case Token.GET: case Token.SET: // Object literal keys are handled with OBJECTLIT break;  case Token.ARRAYLIT: ensureTyped(t, n, ARRAY_TYPE); break;  case Token.REGEXP: ensureTyped(t, n, REGEXP_TYPE); break;  case Token.GETPROP: visitGetProp(t, n, parent); typeable = !(parent.getType() == Token.ASSIGN && parent.getFirstChild() == n); break;  case Token.GETELEM: visitGetElem(t, n); // The type of GETELEM is always unknown, so no point counting that. // If that unknown leaks elsewhere (say by an assignment to another // variable), then it will be counted. typeable = false; break;  case Token.VAR: visitVar(t, n); typeable = false; break;  case Token.NEW: visitNew(t, n); typeable = true; break;  case Token.CALL: visitCall(t, n); typeable = !NodeUtil.isExpressionNode(parent); break;  case Token.RETURN: visitReturn(t, n); typeable = false; break;  case Token.DEC: case Token.INC: left = n.getFirstChild(); validator.expectNumber( t, left, getJSType(left), "increment/decrement"); ensureTyped(t, n, NUMBER_TYPE); break;  case Token.NOT: ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.VOID: ensureTyped(t, n, VOID_TYPE); break;  case Token.TYPEOF: ensureTyped(t, n, STRING_TYPE); break;  case Token.BITNOT: childType = getJSType(n.getFirstChild()); if (!childType.matchesInt32Context()) { report(t, n, BIT_OPERATION, NodeUtil.opToStr(n.getType()), childType.toString()); } ensureTyped(t, n, NUMBER_TYPE); break;  case Token.POS: case Token.NEG: left = n.getFirstChild(); validator.expectNumber(t, left, getJSType(left), "sign operator"); ensureTyped(t, n, NUMBER_TYPE); break;  case Token.EQ: case Token.NE: { leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild());  JSType leftTypeRestricted = leftType.restrictByNotNullOrUndefined(); JSType rightTypeRestricted = rightType.restrictByNotNullOrUndefined(); TernaryValue result = leftTypeRestricted.testForEquality(rightTypeRestricted); if (result != TernaryValue.UNKNOWN) { if (n.getType() == Token.NE) { result = result.not(); } report(t, n, DETERMINISTIC_TEST, leftType.toString(), rightType.toString(), result.toString()); } ensureTyped(t, n, BOOLEAN_TYPE); break; }  case Token.SHEQ: case Token.SHNE: { leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild());  JSType leftTypeRestricted = leftType.restrictByNotNullOrUndefined(); JSType rightTypeRestricted = rightType.restrictByNotNullOrUndefined(); if (!leftTypeRestricted.canTestForShallowEqualityWith( rightTypeRestricted)) { report(t, n, DETERMINISTIC_TEST_NO_RESULT, leftType.toString(), rightType.toString()); } ensureTyped(t, n, BOOLEAN_TYPE); break; }  case Token.LT: case Token.LE: case Token.GT: case Token.GE: leftType = getJSType(n.getFirstChild()); rightType = getJSType(n.getLastChild()); if (rightType.isNumber()) { validator.expectNumber( t, n, leftType, "left side of numeric comparison"); } else if (leftType.isNumber()) { validator.expectNumber( t, n, rightType, "right side of numeric comparison"); } else if (leftType.matchesNumberContext() && rightType.matchesNumberContext()) { // OK. } else { // Whether the comparison is numeric will be determined at runtime // each time the expression is evaluated. Regardless, both operands // should match a string context. String message = "left side of comparison"; validator.expectString(t, n, leftType, message); validator.expectNotNullOrUndefined( t, n, leftType, message, getNativeType(STRING_TYPE)); message = "right side of comparison"; validator.expectString(t, n, rightType, message); validator.expectNotNullOrUndefined( t, n, rightType, message, getNativeType(STRING_TYPE)); } ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.IN: left = n.getFirstChild(); right = n.getLastChild(); leftType = getJSType(left); rightType = getJSType(right); validator.expectObject(t, n, rightType, "'in' requires an object"); validator.expectString(t, left, leftType, "left side of 'in'"); ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.INSTANCEOF: left = n.getFirstChild(); right = n.getLastChild(); leftType = getJSType(left); rightType = getJSType(right).restrictByNotNullOrUndefined();  validator.expectAnyObject( t, left, leftType, "deterministic instanceof yields false"); validator.expectActualObject( t, right, rightType, "instanceof requires an object"); ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.ASSIGN: visitAssign(t, n); typeable = false; break;  case Token.ASSIGN_LSH: case Token.ASSIGN_RSH: case Token.ASSIGN_URSH: case Token.ASSIGN_DIV: case Token.ASSIGN_MOD: case Token.ASSIGN_BITOR: case Token.ASSIGN_BITXOR: case Token.ASSIGN_BITAND: case Token.ASSIGN_SUB: case Token.ASSIGN_ADD: case Token.ASSIGN_MUL: case Token.LSH: case Token.RSH: case Token.URSH: case Token.DIV: case Token.MOD: case Token.BITOR: case Token.BITXOR: case Token.BITAND: case Token.SUB: case Token.ADD: case Token.MUL: visitBinaryOperator(n.getType(), t, n); break;  case Token.DELPROP: if (!isReference(n.getFirstChild())) { report(t, n, BAD_DELETE); } ensureTyped(t, n, BOOLEAN_TYPE); break;  case Token.CASE: JSType switchType = getJSType(parent.getFirstChild()); JSType caseType = getJSType(n.getFirstChild()); validator.expectSwitchMatchesCase(t, n, switchType, caseType); typeable = false; break;  case Token.WITH: { Node child = n.getFirstChild(); childType = getJSType(child); validator.expectObject( t, child, childType, "with requires an object"); typeable = false; break; }  case Token.FUNCTION: visitFunction(t, n); break;  // These nodes have no interesting type behavior. case Token.LABEL: case Token.LABEL_NAME: case Token.SWITCH: case Token.BREAK: case Token.CATCH: case Token.TRY: case Token.SCRIPT: case Token.EXPR_RESULT: case Token.BLOCK: case Token.EMPTY: case Token.DEFAULT: case Token.CONTINUE: case Token.DEBUGGER: case Token.THROW: typeable = false; break;  // These nodes require data flow analysis. case Token.DO: case Token.FOR: case Token.IF: case Token.WHILE: typeable = false; break;  // These nodes are typed during the type inference. case Token.AND: case Token.HOOK: case Token.OBJECTLIT: case Token.OR: if (n.getJSType() != null) { // If we didn't run type inference. ensureTyped(t, n); } else { // If this is an enum, then give that type to the objectlit as well. if ((n.getType() == Token.OBJECTLIT) && (parent.getJSType() instanceof EnumType)) { ensureTyped(t, n, parent.getJSType()); } else { ensureTyped(t, n); } } if (n.getType() == Token.OBJECTLIT) { for (Node key : n.children()) { visitObjLitKey(t, key, n); } } break;  default: report(t, n, UNEXPECTED_TOKEN, Token.name(n.getType())); ensureTyped(t, n); break; }  // Don't count externs since the user's code may not even use that part. typeable = typeable && !inExterns;  if (typeable) { doPercentTypedAccounting(t, n); }  checkNoTypeCheckSection(n, false); }
 public void visit(NodeTraversal t, Node n, Node parent) { if (isCallToScopeMethod(n)) { validateScopeCall(t, n, n.getParent()); }  if (t.getScopeDepth() < 2) { return; }  int type = n.getType(); Var aliasVar = null; if (type == Token.NAME) { String name = n.getString(); Var lexicalVar = t.getScope().getVar(n.getString()); if (lexicalVar != null && lexicalVar == aliases.get(name)) { aliasVar = lexicalVar; } }  // Validate the top-level of the goog.scope block. if (t.getScopeDepth() == 2) { if (aliasVar != null && NodeUtil.isLValue(n)) { if (aliasVar.getNode() == n) { aliasDefinitionsInOrder.add(n);  // Return early, to ensure that we don't record a definition // twice. return; } else { report(t, n, GOOG_SCOPE_ALIAS_REDEFINED, n.getString()); } }  if (type == Token.RETURN) { report(t, n, GOOG_SCOPE_USES_RETURN); } else if (type == Token.THIS) { report(t, n, GOOG_SCOPE_REFERENCES_THIS); } else if (type == Token.THROW) { report(t, n, GOOG_SCOPE_USES_THROW); } }  // Validate all descendent scopes of the goog.scope block. if (t.getScopeDepth() >= 2) { // Check if this name points to an alias. if (aliasVar != null) { // Note, to support the transitive case, it's important we don't // clone aliasedNode here.  For example, // var g = goog; var d = g.dom; d.createElement('DIV'); // The node in aliasedNode (which is "g") will be replaced in the // changes pass above with "goog".  If we cloned here, we'd end up // with <code>g.dom.createElement('DIV')</code>. aliasUsages.add(new AliasedNode(aliasVar, n)); }  // When we inject declarations, we duplicate jsdoc. Make sure // we only process that jsdoc once. JSDocInfo info = n.getJSDocInfo(); if (info != null) { for (Node node : info.getTypeNodes()) { fixTypeNode(node); } }  // TODO(robbyw): Error for goog.scope not at root. } }
 public void collect(JSModule module, Scope scope, Node n) { Node parent = n.getParent();  String name; boolean isSet = false; Name.Type type = Name.Type.OTHER; boolean isPropAssign = false;  switch (n.getType()) { case Token.GETTER_DEF: case Token.SETTER_DEF: case Token.STRING_KEY: // This may be a key in an object literal declaration. name = null; if (parent != null && parent.isObjectLit()) { name = getNameForObjLitKey(n); } if (name == null) { return; } isSet = true; switch (n.getType()) { case Token.STRING_KEY: type = getValueType(n.getFirstChild()); break; case Token.GETTER_DEF: type = Name.Type.GET; break; case Token.SETTER_DEF: type = Name.Type.SET; break; default: throw new IllegalStateException("unexpected:" + n); } break; case Token.NAME: // This may be a variable get or set. if (parent != null) { switch (parent.getType()) { case Token.VAR: isSet = true; Node rvalue = n.getFirstChild(); type = rvalue == null ? Name.Type.OTHER : getValueType(rvalue); break; case Token.ASSIGN: if (parent.getFirstChild() == n) { isSet = true; type = getValueType(n.getNext()); } break; case Token.GETPROP: return; case Token.FUNCTION: Node gramps = parent.getParent(); if (gramps == null || NodeUtil.isFunctionExpression(parent)) { return; } isSet = true; type = Name.Type.FUNCTION; break; case Token.INC: case Token.DEC: isSet = true; type = Name.Type.OTHER; break; default: if (NodeUtil.isAssignmentOp(parent) && parent.getFirstChild() == n) { isSet = true; type = Name.Type.OTHER; } } } name = n.getString(); break; case Token.GETPROP: // This may be a namespaced name get or set. if (parent != null) { switch (parent.getType()) { case Token.ASSIGN: if (parent.getFirstChild() == n) { isSet = true; type = getValueType(n.getNext()); isPropAssign = true; } break; case Token.INC: case Token.DEC: isSet = true; type = Name.Type.OTHER; break; case Token.GETPROP: return; default: if (NodeUtil.isAssignmentOp(parent) && parent.getFirstChild() == n) { isSet = true; type = Name.Type.OTHER; } } } name = n.getQualifiedName(); if (name == null) { return; } break; default: return; }  // We are only interested in global names. if (!isGlobalNameReference(name, scope)) { return; }  if (isSet) { if (isGlobalScope(scope)) { handleSetFromGlobal(module, scope, n, parent, name, isPropAssign, type); } else { handleSetFromLocal(module, scope, n, parent, name); } } else { handleGet(module, scope, n, parent, name); } }
 public void collect(JSModule module, Scope scope, Node n) { Node parent = n.getParent();  String name; boolean isSet = false; Name.Type type = Name.Type.OTHER; boolean isPropAssign = false;  switch (n.getType()) { case Token.GETTER_DEF: case Token.SETTER_DEF: case Token.STRING_KEY: // This may be a key in an object literal declaration. name = null; if (parent != null && parent.isObjectLit()) { name = getNameForObjLitKey(n); } if (name == null) { return; } isSet = true; switch (n.getType()) { case Token.STRING_KEY: type = getValueType(n.getFirstChild()); break; case Token.GETTER_DEF: type = Name.Type.GET; break; case Token.SETTER_DEF: type = Name.Type.SET; break; default: throw new IllegalStateException("unexpected:" + n); } break; case Token.NAME: // This may be a variable get or set. if (parent != null) { switch (parent.getType()) { case Token.VAR: isSet = true; Node rvalue = n.getFirstChild(); type = rvalue == null ? Name.Type.OTHER : getValueType(rvalue); break; case Token.ASSIGN: if (parent.getFirstChild() == n) { isSet = true; type = getValueType(n.getNext()); } break; case Token.GETPROP: return; case Token.FUNCTION: Node gramps = parent.getParent(); if (gramps == null || NodeUtil.isFunctionExpression(parent)) { return; } isSet = true; type = Name.Type.FUNCTION; break; case Token.INC: case Token.DEC: isSet = true; type = Name.Type.OTHER; break; default: if (NodeUtil.isAssignmentOp(parent) && parent.getFirstChild() == n) { isSet = true; type = Name.Type.OTHER; } } } name = n.getString(); break; case Token.GETPROP: // This may be a namespaced name get or set. if (parent != null) { switch (parent.getType()) { case Token.ASSIGN: if (parent.getFirstChild() == n) { isSet = true; type = getValueType(n.getNext()); isPropAssign = true; } break; case Token.INC: case Token.DEC: isSet = true; type = Name.Type.OTHER; break; case Token.GETPROP: return; default: if (NodeUtil.isAssignmentOp(parent) && parent.getFirstChild() == n) { isSet = true; type = Name.Type.OTHER; } } } name = n.getQualifiedName(); if (name == null) { return; } break; default: return; }  // We are only interested in global names. if (!isGlobalNameReference(name, scope)) { return; }  if (isSet) { if (isGlobalScope(scope)) { handleSetFromGlobal(module, scope, n, parent, name, isPropAssign, type); } else { handleSetFromLocal(module, scope, n, parent, name); } } else { handleGet(module, scope, n, parent, name); } }
 static Map<Object, Object> getRegistry() { return REGISTRY.get() != null ? REGISTRY.get() : Collections.<Object, Object>emptyMap(); }
 static boolean isRegistered(Object value) { Map<Object, Object> m = getRegistry(); return m.containsKey(value); }
 private void visitNew(NodeTraversal t, Node n) { Node constructor = n.getFirstChild(); JSType type = getJSType(constructor).restrictByNotNullOrUndefined(); if (type.isConstructor() || type.isEmptyType() || type.isUnknownType()) { FunctionType fnType = type.toMaybeFunctionType(); if (fnType != null) { visitParameterList(t, n, fnType); ensureTyped(t, n, fnType.getInstanceType()); } else { ensureTyped(t, n); } } else { report(t, n, NOT_A_CONSTRUCTOR); ensureTyped(t, n); } }
 public static Number createNumber(final String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } // Need to deal with all possible hex prefixes here final String[] hex_prefixes = {"0x", "0X", "-0x", "-0X", "#", "-#"}; int pfxLen = 0; for(final String pfx : hex_prefixes) { if (str.startsWith(pfx)) { pfxLen += pfx.length(); break; } } if (pfxLen > 0) { // we have a hex number final int hexDigits = str.length() - pfxLen; if (hexDigits > 16) { // too many for Long return createBigInteger(str); } if (hexDigits > 8) { // too many for an int return createLong(str); } return createInteger(str); } final char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; final int decPos = str.indexOf('.'); final int expPos = str.indexOf('e') + str.indexOf('E') + 1; // assumes both not present // if both e and E are present, this is caught by the checks on expPos (which prevent IOOBE) // and the parsing which will detect if e or E appear in a number due to using the wrong offset  int numDecimals = 0; // Check required precision (LANG-693) if (decPos > -1) { // there is a decimal point  if (expPos > -1) { // there is an exponent if (expPos < decPos || expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); numDecimals = dec.length(); // gets number of digits past the decimal to ensure no loss of precision for floating point numbers. } else { if (expPos > -1) { if (expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. final String numeric = str.substring(0, str.length() - 1); final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (final NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { final Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { final Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (final NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { // no decimal point and no exponent //Must be an Integer, Long, Biginteger try { return createInteger(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str); }  //Must be a Float, Double, BigDecimal final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { final Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { final Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str); }
 public static Number createNumber(final String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } // Need to deal with all possible hex prefixes here final String[] hex_prefixes = {"0x", "0X", "-0x", "-0X", "#", "-#"}; int pfxLen = 0; for(final String pfx : hex_prefixes) { if (str.startsWith(pfx)) { pfxLen += pfx.length(); break; } } if (pfxLen > 0) { // we have a hex number final int hexDigits = str.length() - pfxLen; if (hexDigits > 16) { // too many for Long return createBigInteger(str); } if (hexDigits > 8) { // too many for an int return createLong(str); } return createInteger(str); } final char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; final int decPos = str.indexOf('.'); final int expPos = str.indexOf('e') + str.indexOf('E') + 1; // assumes both not present // if both e and E are present, this is caught by the checks on expPos (which prevent IOOBE) // and the parsing which will detect if e or E appear in a number due to using the wrong offset  int numDecimals = 0; // Check required precision (LANG-693) if (decPos > -1) { // there is a decimal point  if (expPos > -1) { // there is an exponent if (expPos < decPos || expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); numDecimals = dec.length(); // gets number of digits past the decimal to ensure no loss of precision for floating point numbers. } else { if (expPos > -1) { if (expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. final String numeric = str.substring(0, str.length() - 1); final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (final NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { final Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { final Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (final NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { // no decimal point and no exponent //Must be an Integer, Long, Biginteger try { return createInteger(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str); }  //Must be a Float, Double, BigDecimal final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { final Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { final Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str); }
 protected PointVectorValuePair doOptimize() { checkParameters();  final int nR = getTarget().length; // Number of observed data. final double[] currentPoint = getStartPoint(); final int nC = currentPoint.length; // Number of parameters.  // arrays shared with the other private methods solvedCols  = FastMath.min(nR, nC); diagR       = new double[nC]; jacNorm     = new double[nC]; beta        = new double[nC]; permutation = new int[nC]; lmDir       = new double[nC];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[nC]; double[] oldX    = new double[nC]; double[] oldRes  = new double[nR]; double[] oldObj  = new double[nR]; double[] qtf     = new double[nR]; double[] work1   = new double[nC]; double[] work2   = new double[nC]; double[] work3   = new double[nC];  final RealMatrix weightMatrixSqrt = getWeightSquareRoot();  // Evaluate the function at the starting point and calculate its norm. double[] currentObjective = computeObjectiveValue(currentPoint); double[] currentResiduals = computeResiduals(currentObjective); PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective); double currentCost = computeCost(currentResiduals);  // Outer loop. lmPar = 0; boolean firstIteration = true; int iter = 0; final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker(); while (true) { ++iter; final PointVectorValuePair previous = current;  // QR decomposition of the jacobian matrix qrDecomposition(computeWeightedJacobian(currentPoint));  weightedResidual = weightMatrixSqrt.operate(currentResiduals); for (int i = 0; i < nR; i++) { qtf[i] = weightedResidual[i]; }  // compute Qt.res qTy(qtf);  // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; weightedJacobian[k][pk] = diagR[pk]; }  if (firstIteration) { // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < nC; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * currentPoint[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = FastMath.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm); }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (currentCost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += weightedJacobian[i][pj] * qtf[i]; } maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost)); } } } if (maxCosine <= orthoTolerance) { // Convergence has been reached. setCost(currentCost); return current; }  // rescale if necessary for (int j = 0; j < nC; ++j) { diag[j] = FastMath.max(diag[j], jacNorm[j]); }  // Inner loop. for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = currentPoint[pj]; } final double previousCost = currentCost; double[] tmpVec = weightedResidual; weightedResidual = oldRes; oldRes    = tmpVec; tmpVec    = currentObjective; currentObjective = oldObj; oldObj    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(qtf, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; currentPoint[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = FastMath.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = FastMath.min(delta, lmNorm); }  // Evaluate the function at x + p and calculate its norm. currentObjective = computeObjectiveValue(currentPoint); currentResiduals = computeResiduals(currentObjective); current = new PointVectorValuePair(currentPoint, currentObjective); currentCost = computeCost(currentResiduals);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * currentCost < previousCost) { double r = currentCost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += weightedJacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * FastMath.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < nC; ++k) { double xK = diag[k] * currentPoint[k]; xNorm += xK * xK; } xNorm = FastMath.sqrt(xNorm);  // tests for convergence. if (checker != null) { // we use the vectorial convergence checker if (checker.converged(iter, previous, current)) { setCost(currentCost); return current; } } } else { // failed iteration, reset the previous values currentCost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; currentPoint[pj] = oldX[pj]; } tmpVec    = weightedResidual; weightedResidual = oldRes; oldRes    = tmpVec; tmpVec    = currentObjective; currentObjective = oldObj; oldObj    = tmpVec; // Reset "current" to previous values. current = new PointVectorValuePair(currentPoint, currentObjective); }  // Default convergence criteria. if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) { setCost(currentCost); return current; }  // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); } } } }
 protected PointVectorValuePair doOptimize() { checkParameters();  final int nR = getTarget().length; // Number of observed data. final double[] currentPoint = getStartPoint(); final int nC = currentPoint.length; // Number of parameters.  // arrays shared with the other private methods solvedCols  = FastMath.min(nR, nC); diagR       = new double[nC]; jacNorm     = new double[nC]; beta        = new double[nC]; permutation = new int[nC]; lmDir       = new double[nC];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[nC]; double[] oldX    = new double[nC]; double[] oldRes  = new double[nR]; double[] oldObj  = new double[nR]; double[] qtf     = new double[nR]; double[] work1   = new double[nC]; double[] work2   = new double[nC]; double[] work3   = new double[nC];  final RealMatrix weightMatrixSqrt = getWeightSquareRoot();  // Evaluate the function at the starting point and calculate its norm. double[] currentObjective = computeObjectiveValue(currentPoint); double[] currentResiduals = computeResiduals(currentObjective); PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective); double currentCost = computeCost(currentResiduals);  // Outer loop. lmPar = 0; boolean firstIteration = true; int iter = 0; final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker(); while (true) { ++iter; final PointVectorValuePair previous = current;  // QR decomposition of the jacobian matrix qrDecomposition(computeWeightedJacobian(currentPoint));  weightedResidual = weightMatrixSqrt.operate(currentResiduals); for (int i = 0; i < nR; i++) { qtf[i] = weightedResidual[i]; }  // compute Qt.res qTy(qtf);  // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; weightedJacobian[k][pk] = diagR[pk]; }  if (firstIteration) { // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < nC; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * currentPoint[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = FastMath.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm); }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (currentCost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += weightedJacobian[i][pj] * qtf[i]; } maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost)); } } } if (maxCosine <= orthoTolerance) { // Convergence has been reached. setCost(currentCost); return current; }  // rescale if necessary for (int j = 0; j < nC; ++j) { diag[j] = FastMath.max(diag[j], jacNorm[j]); }  // Inner loop. for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = currentPoint[pj]; } final double previousCost = currentCost; double[] tmpVec = weightedResidual; weightedResidual = oldRes; oldRes    = tmpVec; tmpVec    = currentObjective; currentObjective = oldObj; oldObj    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(qtf, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; currentPoint[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = FastMath.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = FastMath.min(delta, lmNorm); }  // Evaluate the function at x + p and calculate its norm. currentObjective = computeObjectiveValue(currentPoint); currentResiduals = computeResiduals(currentObjective); current = new PointVectorValuePair(currentPoint, currentObjective); currentCost = computeCost(currentResiduals);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * currentCost < previousCost) { double r = currentCost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += weightedJacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * FastMath.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < nC; ++k) { double xK = diag[k] * currentPoint[k]; xNorm += xK * xK; } xNorm = FastMath.sqrt(xNorm);  // tests for convergence. if (checker != null) { // we use the vectorial convergence checker if (checker.converged(iter, previous, current)) { setCost(currentCost); return current; } } } else { // failed iteration, reset the previous values currentCost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; currentPoint[pj] = oldX[pj]; } tmpVec    = weightedResidual; weightedResidual = oldRes; oldRes    = tmpVec; tmpVec    = currentObjective; currentObjective = oldObj; oldObj    = tmpVec; // Reset "current" to previous values. current = new PointVectorValuePair(currentPoint, currentObjective); }  // Default convergence criteria. if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) { setCost(currentCost); return current; }  // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); } } } }
 protected PointValuePair doOptimize() { checkParameters();  // Indirect call to "computeObjectiveValue" in order to update the // evaluations counter. final MultivariateFunction evalFunc = new MultivariateFunction() { public double value(double[] point) { return computeObjectiveValue(point); } };  final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() { public int compare(final PointValuePair o1, final PointValuePair o2) { final double v1 = o1.getValue(); final double v2 = o2.getValue(); return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1); } };  // Initialize search. simplex.build(getStartPoint()); simplex.evaluate(evalFunc, comparator);  PointValuePair[] previous = null; int iteration = 0; final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker(); while (true) { if (iteration > 0) { boolean converged = true; for (int i = 0; i < simplex.getSize(); i++) { PointValuePair prev = previous[i]; converged = converged && checker.converged(iteration, prev, simplex.getPoint(i)); } if (converged) { // We have found an optimum. return simplex.getPoint(0); } }  // We still need to search. previous = simplex.getPoints(); simplex.iterate(evalFunc, comparator);  ++iteration; } }
 protected PointValuePair doOptimize() { checkParameters();  // Indirect call to "computeObjectiveValue" in order to update the // evaluations counter. final MultivariateFunction evalFunc = new MultivariateFunction() { public double value(double[] point) { return computeObjectiveValue(point); } };  final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() { public int compare(final PointValuePair o1, final PointValuePair o2) { final double v1 = o1.getValue(); final double v2 = o2.getValue(); return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1); } };  // Initialize search. simplex.build(getStartPoint()); simplex.evaluate(evalFunc, comparator);  PointValuePair[] previous = null; int iteration = 0; final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker(); while (true) { if (iteration > 0) { boolean converged = true; for (int i = 0; i < simplex.getSize(); i++) { PointValuePair prev = previous[i]; converged = converged && checker.converged(iteration, prev, simplex.getPoint(i)); } if (converged) { // We have found an optimum. return simplex.getPoint(0); } }  // We still need to search. previous = simplex.getPoints(); simplex.iterate(evalFunc, comparator);  ++iteration; } }
 protected PointValuePair doOptimize() { final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker(); final double[] point = getStartPoint(); final GoalType goal = getGoalType(); final int n = point.length; double[] r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; i++) { r[i] = -r[i]; } }  // Initial search direction. double[] steepestDescent = preconditioner.precondition(point, r); double[] searchDirection = steepestDescent.clone();  double delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * searchDirection[i]; }  PointValuePair current = null; int iter = 0; int maxEval = getMaxEvaluations(); while (true) { ++iter;  final double objective = computeObjectiveValue(point); PointValuePair previous = current; current = new PointValuePair(point, objective); if (previous != null) { if (checker.converged(iter, previous, current)) { // We have found an optimum. return current; } }  // Find the optimal step in the search direction. final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection); final double uB = findUpperBound(lsf, 0, initialStep); // XXX Last parameters is set to a value close to zero in order to // work around the divergence problem in the "testCircleFitting" // unit test (see MATH-439). final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15); maxEval -= solver.getEvaluations(); // Subtract used up evaluations.  // Validate new point. for (int i = 0; i < point.length; ++i) { point[i] += step * searchDirection[i]; }  r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; ++i) { r[i] = -r[i]; } }  // Compute beta. final double deltaOld = delta; final double[] newSteepestDescent = preconditioner.precondition(point, r); delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * newSteepestDescent[i]; }  final double beta; switch (updateFormula) { case FLETCHER_REEVES: beta = delta / deltaOld; break; case POLAK_RIBIERE: double deltaMid = 0; for (int i = 0; i < r.length; ++i) { deltaMid += r[i] * steepestDescent[i]; } beta = (delta - deltaMid) / deltaOld; break; default: // Should never happen. throw new MathInternalError(); } steepestDescent = newSteepestDescent;  // Compute conjugate search direction. if (iter % n == 0 || beta < 0) { // Break conjugation: reset search direction. searchDirection = steepestDescent.clone(); } else { // Compute new conjugate search direction. for (int i = 0; i < n; ++i) { searchDirection[i] = steepestDescent[i] + beta * searchDirection[i]; } } } }
 protected PointValuePair doOptimize() { final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker(); final double[] point = getStartPoint(); final GoalType goal = getGoalType(); final int n = point.length; double[] r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; i++) { r[i] = -r[i]; } }  // Initial search direction. double[] steepestDescent = preconditioner.precondition(point, r); double[] searchDirection = steepestDescent.clone();  double delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * searchDirection[i]; }  PointValuePair current = null; int iter = 0; int maxEval = getMaxEvaluations(); while (true) { ++iter;  final double objective = computeObjectiveValue(point); PointValuePair previous = current; current = new PointValuePair(point, objective); if (previous != null) { if (checker.converged(iter, previous, current)) { // We have found an optimum. return current; } }  // Find the optimal step in the search direction. final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection); final double uB = findUpperBound(lsf, 0, initialStep); // XXX Last parameters is set to a value close to zero in order to // work around the divergence problem in the "testCircleFitting" // unit test (see MATH-439). final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15); maxEval -= solver.getEvaluations(); // Subtract used up evaluations.  // Validate new point. for (int i = 0; i < point.length; ++i) { point[i] += step * searchDirection[i]; }  r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; ++i) { r[i] = -r[i]; } }  // Compute beta. final double deltaOld = delta; final double[] newSteepestDescent = preconditioner.precondition(point, r); delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * newSteepestDescent[i]; }  final double beta; switch (updateFormula) { case FLETCHER_REEVES: beta = delta / deltaOld; break; case POLAK_RIBIERE: double deltaMid = 0; for (int i = 0; i < r.length; ++i) { deltaMid += r[i] * steepestDescent[i]; } beta = (delta - deltaMid) / deltaOld; break; default: // Should never happen. throw new MathInternalError(); } steepestDescent = newSteepestDescent;  // Compute conjugate search direction. if (iter % n == 0 || beta < 0) { // Break conjugation: reset search direction. searchDirection = steepestDescent.clone(); } else { // Compute new conjugate search direction. for (int i = 0; i < n; ++i) { searchDirection[i] = steepestDescent[i] + beta * searchDirection[i]; } } } }
 protected PointValuePair doOptimize() { final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker(); final double[] point = getStartPoint(); final GoalType goal = getGoalType(); final int n = point.length; double[] r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; i++) { r[i] = -r[i]; } }  // Initial search direction. double[] steepestDescent = preconditioner.precondition(point, r); double[] searchDirection = steepestDescent.clone();  double delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * searchDirection[i]; }  PointValuePair current = null; int iter = 0; int maxEval = getMaxEvaluations(); while (true) { ++iter;  final double objective = computeObjectiveValue(point); PointValuePair previous = current; current = new PointValuePair(point, objective); if (previous != null) { if (checker.converged(iter, previous, current)) { // We have found an optimum. return current; } }  // Find the optimal step in the search direction. final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection); final double uB = findUpperBound(lsf, 0, initialStep); // XXX Last parameters is set to a value close to zero in order to // work around the divergence problem in the "testCircleFitting" // unit test (see MATH-439). final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15); maxEval -= solver.getEvaluations(); // Subtract used up evaluations.  // Validate new point. for (int i = 0; i < point.length; ++i) { point[i] += step * searchDirection[i]; }  r = computeObjectiveGradient(point); if (goal == GoalType.MINIMIZE) { for (int i = 0; i < n; ++i) { r[i] = -r[i]; } }  // Compute beta. final double deltaOld = delta; final double[] newSteepestDescent = preconditioner.precondition(point, r); delta = 0; for (int i = 0; i < n; ++i) { delta += r[i] * newSteepestDescent[i]; }  final double beta; switch (updateFormula) { case FLETCHER_REEVES: beta = delta / deltaOld; break; case POLAK_RIBIERE: double deltaMid = 0; for (int i = 0; i < r.length; ++i) { deltaMid += r[i] * steepestDescent[i]; } beta = (delta - deltaMid) / deltaOld; break; default: // Should never happen. throw new MathInternalError(); } steepestDescent = newSteepestDescent;  // Compute conjugate search direction. if (iter % n == 0 || beta < 0) { // Break conjugation: reset search direction. searchDirection = steepestDescent.clone(); } else { // Compute new conjugate search direction. for (int i = 0; i < n; ++i) { searchDirection[i] = steepestDescent[i] + beta * searchDirection[i]; } } } }
 protected BaseOptimizer(ConvergenceChecker<PAIR> checker) { this.checker = checker;  evaluations = new Incrementor(0, new MaxEvalCallback()); iterations = new Incrementor(0, new MaxIterCallback()); }
 public PointVectorValuePair doOptimize() { checkParameters();  final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();  // Computation will be useless without a checker (see "for-loop"). if (checker == null) { throw new NullArgumentException(); }  final double[] targetValues = getTarget(); final int nR = targetValues.length; // Number of observed data.  final RealMatrix weightMatrix = getWeight(); // Diagonal of the weight matrix. final double[] residualsWeights = new double[nR]; for (int i = 0; i < nR; i++) { residualsWeights[i] = weightMatrix.getEntry(i, i); }  final double[] currentPoint = getStartPoint(); final int nC = currentPoint.length;  // iterate until convergence is reached PointVectorValuePair current = null; int iter = 0; for (boolean converged = false; !converged;) { ++iter;  // evaluate the objective function and its jacobian PointVectorValuePair previous = current; // Value of the objective function at "currentPoint". final double[] currentObjective = computeObjectiveValue(currentPoint); final double[] currentResiduals = computeResiduals(currentObjective); final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint); current = new PointVectorValuePair(currentPoint, currentObjective);  // build the linear problem final double[]   b = new double[nC]; final double[][] a = new double[nC][nC]; for (int i = 0; i < nR; ++i) {  final double[] grad   = weightedJacobian.getRow(i); final double weight   = residualsWeights[i]; final double residual = currentResiduals[i];  // compute the normal equation final double wr = weight * residual; for (int j = 0; j < nC; ++j) { b[j] += wr * grad[j]; }  // build the contribution matrix for measurement i for (int k = 0; k < nC; ++k) { double[] ak = a[k]; double wgk = weight * grad[k]; for (int l = 0; l < nC; ++l) { ak[l] += wgk * grad[l]; } } }  try { // solve the linearized least squares problem RealMatrix mA = new BlockRealMatrix(a); DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver(); final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray(); // update the estimated parameters for (int i = 0; i < nC; ++i) { currentPoint[i] += dX[i]; } } catch (SingularMatrixException e) { throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM); }  // Check convergence. if (previous != null) { converged = checker.converged(iter, previous, current); if (converged) { setCost(computeCost(currentResiduals)); return current; } } } // Must never happen. throw new MathInternalError(); }
 public PointVectorValuePair doOptimize() { checkParameters();  final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();  // Computation will be useless without a checker (see "for-loop"). if (checker == null) { throw new NullArgumentException(); }  final double[] targetValues = getTarget(); final int nR = targetValues.length; // Number of observed data.  final RealMatrix weightMatrix = getWeight(); // Diagonal of the weight matrix. final double[] residualsWeights = new double[nR]; for (int i = 0; i < nR; i++) { residualsWeights[i] = weightMatrix.getEntry(i, i); }  final double[] currentPoint = getStartPoint(); final int nC = currentPoint.length;  // iterate until convergence is reached PointVectorValuePair current = null; int iter = 0; for (boolean converged = false; !converged;) { ++iter;  // evaluate the objective function and its jacobian PointVectorValuePair previous = current; // Value of the objective function at "currentPoint". final double[] currentObjective = computeObjectiveValue(currentPoint); final double[] currentResiduals = computeResiduals(currentObjective); final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint); current = new PointVectorValuePair(currentPoint, currentObjective);  // build the linear problem final double[]   b = new double[nC]; final double[][] a = new double[nC][nC]; for (int i = 0; i < nR; ++i) {  final double[] grad   = weightedJacobian.getRow(i); final double weight   = residualsWeights[i]; final double residual = currentResiduals[i];  // compute the normal equation final double wr = weight * residual; for (int j = 0; j < nC; ++j) { b[j] += wr * grad[j]; }  // build the contribution matrix for measurement i for (int k = 0; k < nC; ++k) { double[] ak = a[k]; double wgk = weight * grad[k]; for (int l = 0; l < nC; ++l) { ak[l] += wgk * grad[l]; } } }  try { // solve the linearized least squares problem RealMatrix mA = new BlockRealMatrix(a); DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver(); final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray(); // update the estimated parameters for (int i = 0; i < nC; ++i) { currentPoint[i] += dX[i]; } } catch (SingularMatrixException e) { throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM); }  // Check convergence. if (previous != null) { converged = checker.converged(iter, previous, current); if (converged) { setCost(computeCost(currentResiduals)); return current; } } } // Must never happen. throw new MathInternalError(); }
 protected PointValuePair doOptimize() { checkParameters();  final GoalType goal = getGoalType(); final double[] guess = getStartPoint(); final int n = guess.length;  final double[][] direc = new double[n][n]; for (int i = 0; i < n; i++) { direc[i][i] = 1; }  final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();  double[] x = guess; double fVal = computeObjectiveValue(x); double[] x1 = x.clone(); int iter = 0; while (true) { ++iter;  double fX = fVal; double fX2 = 0; double delta = 0; int bigInd = 0; double alphaMin = 0;  for (int i = 0; i < n; i++) { final double[] d = MathArrays.copyOf(direc[i]);  fX2 = fVal;  final UnivariatePointValuePair optimum = line.search(x, d); fVal = optimum.getValue(); alphaMin = optimum.getPoint(); final double[][] result = newPointAndDirection(x, d, alphaMin); x = result[0];  if ((fX2 - fVal) > delta) { delta = fX2 - fVal; bigInd = i; } }  // Default convergence check. boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);  final PointValuePair previous = new PointValuePair(x1, fX); final PointValuePair current = new PointValuePair(x, fVal); if (!stop) { // User-defined stopping criteria. if (checker != null) { stop = checker.converged(iter, previous, current); } } if (stop) { if (goal == GoalType.MINIMIZE) { return (fVal < fX) ? current : previous; } else { return (fVal > fX) ? current : previous; } }  final double[] d = new double[n]; final double[] x2 = new double[n]; for (int i = 0; i < n; i++) { d[i] = x[i] - x1[i]; x2[i] = 2 * x[i] - x1[i]; }  x1 = x.clone(); fX2 = computeObjectiveValue(x2);  if (fX > fX2) { double t = 2 * (fX + fX2 - 2 * fVal); double temp = fX - fVal - delta; t *= temp * temp; temp = fX - fX2; t -= delta * temp * temp;  if (t < 0.0) { final UnivariatePointValuePair optimum = line.search(x, d); fVal = optimum.getValue(); alphaMin = optimum.getPoint(); final double[][] result = newPointAndDirection(x, d, alphaMin); x = result[0];  final int lastInd = n - 1; direc[bigInd] = direc[lastInd]; direc[lastInd] = result[1]; } } } }
 protected PointValuePair doOptimize() { checkParameters();  final GoalType goal = getGoalType(); final double[] guess = getStartPoint(); final int n = guess.length;  final double[][] direc = new double[n][n]; for (int i = 0; i < n; i++) { direc[i][i] = 1; }  final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();  double[] x = guess; double fVal = computeObjectiveValue(x); double[] x1 = x.clone(); int iter = 0; while (true) { ++iter;  double fX = fVal; double fX2 = 0; double delta = 0; int bigInd = 0; double alphaMin = 0;  for (int i = 0; i < n; i++) { final double[] d = MathArrays.copyOf(direc[i]);  fX2 = fVal;  final UnivariatePointValuePair optimum = line.search(x, d); fVal = optimum.getValue(); alphaMin = optimum.getPoint(); final double[][] result = newPointAndDirection(x, d, alphaMin); x = result[0];  if ((fX2 - fVal) > delta) { delta = fX2 - fVal; bigInd = i; } }  // Default convergence check. boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);  final PointValuePair previous = new PointValuePair(x1, fX); final PointValuePair current = new PointValuePair(x, fVal); if (!stop) { // User-defined stopping criteria. if (checker != null) { stop = checker.converged(iter, previous, current); } } if (stop) { if (goal == GoalType.MINIMIZE) { return (fVal < fX) ? current : previous; } else { return (fVal > fX) ? current : previous; } }  final double[] d = new double[n]; final double[] x2 = new double[n]; for (int i = 0; i < n; i++) { d[i] = x[i] - x1[i]; x2[i] = 2 * x[i] - x1[i]; }  x1 = x.clone(); fX2 = computeObjectiveValue(x2);  if (fX > fX2) { double t = 2 * (fX + fX2 - 2 * fVal); double temp = fX - fVal - delta; t *= temp * temp; temp = fX - fX2; t -= delta * temp * temp;  if (t < 0.0) { final UnivariatePointValuePair optimum = line.search(x, d); fVal = optimum.getValue(); alphaMin = optimum.getPoint(); final double[][] result = newPointAndDirection(x, d, alphaMin); x = result[0];  final int lastInd = n - 1; direc[bigInd] = direc[lastInd]; direc[lastInd] = result[1]; } } } }
 protected PointValuePair doOptimize() { // -------------------- Initialization -------------------------------- isMinimize = getGoalType().equals(GoalType.MINIMIZE); final FitnessFunction fitfun = new FitnessFunction(); final double[] guess = getStartPoint(); // number of objective variables/problem dimension dimension = guess.length; initializeCMA(guess); iterations = 0; double bestValue = fitfun.value(guess); push(fitnessHistory, bestValue); PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue); PointValuePair lastResult = null;  // -------------------- Generation Loop --------------------------------  generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {  // Generate and evaluate lambda offspring final RealMatrix arz = randn1(dimension, lambda); final RealMatrix arx = zeros(dimension, lambda); final double[] fitness = new double[lambda]; // generate random offspring for (int k = 0; k < lambda; k++) { RealMatrix arxk = null; for (int i = 0; i < checkFeasableCount + 1; i++) { if (diagonalOnly <= 0) { arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)) .scalarMultiply(sigma)); // m + sig * Normal(0,C) } else { arxk = xmean.add(times(diagD,arz.getColumnMatrix(k)) .scalarMultiply(sigma)); } if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) { break; } // regenerate random arguments for row arz.setColumn(k, randn(dimension)); } copyColumn(arxk, 0, arx, k); try { fitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness } catch (TooManyEvaluationsException e) { break generationLoop; } } // Sort by fitness and compute weighted mean into xmean final int[] arindex = sortedIndices(fitness); // Calculate new xmean, this is selection and recombination final RealMatrix xold = xmean; // for speed up of Eq. (2) and (3) final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu)); xmean = bestArx.multiply(weights); final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu)); final RealMatrix zmean = bestArz.multiply(weights); final boolean hsig = updateEvolutionPaths(zmean, xold); if (diagonalOnly <= 0) { updateCovariance(hsig, bestArx, arz, arindex, xold); } else { updateCovarianceDiagonalOnly(hsig, bestArz); } // Adapt step size sigma - Eq. (5) sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps)); final double bestFitness = fitness[arindex[0]]; final double worstFitness = fitness[arindex[arindex.length - 1]]; if (bestValue > bestFitness) { bestValue = bestFitness; lastResult = optimum; optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness); if (getConvergenceChecker() != null && lastResult != null) { if (getConvergenceChecker().converged(iterations, optimum, lastResult)) { break generationLoop; } } } // handle termination criteria // Break, if fitness is good enough if (stopFitness != 0) { // only if stopFitness is defined if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) { break generationLoop; } } final double[] sqrtDiagC = sqrt(diagC).getColumn(0); final double[] pcCol = pc.getColumn(0); for (int i = 0; i < dimension; i++) { if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) { break; } if (i >= dimension - 1) { break generationLoop; } } for (int i = 0; i < dimension; i++) { if (sigma * sqrtDiagC[i] > stopTolUpX) { break generationLoop; } } final double historyBest = min(fitnessHistory); final double historyWorst = max(fitnessHistory); if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) { break generationLoop; } if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) { break generationLoop; } // condition number of the covariance matrix exceeds 1e14 if (max(diagD) / min(diagD) > 1e7) { break generationLoop; } // user defined termination if (getConvergenceChecker() != null) { final PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness); if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) { break generationLoop; } lastResult = current; } // Adjust step size in case of equal function values (flat fitness) if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) { sigma = sigma * Math.exp(0.2 + cs / damps); } if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) { sigma = sigma * Math.exp(0.2 + cs / damps); } // store best in history push(fitnessHistory,bestFitness); fitfun.setValueRange(worstFitness-bestFitness); if (generateStatistics) { statisticsSigmaHistory.add(sigma); statisticsFitnessHistory.add(bestFitness); statisticsMeanHistory.add(xmean.transpose()); statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5)); } } return optimum; }
 public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial) throws MaxIterationsExceededException, FunctionEvaluationException {  clearResult(); verifySequence(min, initial, max);  // return the initial guess if it is good enough double yInitial = f.value(initial); if (Math.abs(yInitial) <= functionValueAccuracy) { setResult(initial, 0); return result; }  // return the first endpoint if it is good enough double yMin = f.value(min); if (Math.abs(yMin) <= functionValueAccuracy) { setResult(yMin, 0); return result; }  // reduce interval if min and initial bracket the root if (yInitial * yMin < 0) { return solve(f, min, yMin, initial, yInitial, min, yMin); }  // return the second endpoint if it is good enough double yMax = f.value(max); if (Math.abs(yMax) <= functionValueAccuracy) { setResult(yMax, 0); return result; }  // reduce interval if initial and max bracket the root if (yInitial * yMax < 0) { return solve(f, initial, yInitial, max, yMax, initial, yInitial); }  if (yMin * yMax > 0) { throw MathRuntimeException.createIllegalArgumentException( NON_BRACKETING_MESSAGE, min, max, yMin, yMax); }  // full Brent algorithm starting with provided initial guess return solve(f, min, yMin, max, yMax, initial, yInitial);  }
 public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial) throws MaxIterationsExceededException, FunctionEvaluationException {  clearResult(); verifySequence(min, initial, max);  // return the initial guess if it is good enough double yInitial = f.value(initial); if (Math.abs(yInitial) <= functionValueAccuracy) { setResult(initial, 0); return result; }  // return the first endpoint if it is good enough double yMin = f.value(min); if (Math.abs(yMin) <= functionValueAccuracy) { setResult(yMin, 0); return result; }  // reduce interval if min and initial bracket the root if (yInitial * yMin < 0) { return solve(f, min, yMin, initial, yInitial, min, yMin); }  // return the second endpoint if it is good enough double yMax = f.value(max); if (Math.abs(yMax) <= functionValueAccuracy) { setResult(yMax, 0); return result; }  // reduce interval if initial and max bracket the root if (yInitial * yMax < 0) { return solve(f, initial, yInitial, max, yMax, initial, yInitial); }  if (yMin * yMax > 0) { throw MathRuntimeException.createIllegalArgumentException( NON_BRACKETING_MESSAGE, min, max, yMin, yMax); }  // full Brent algorithm starting with provided initial guess return solve(f, min, yMin, max, yMax, initial, yInitial);  }
 boolean canCollapseUnannotatedChildNames() { if (type == Type.OTHER || globalSets != 1 || localSets != 0) { return false; }  // Don't try to collapse if the one global set is a twin reference. // We could theoretically handle this case in CollapseProperties, but // it's probably not worth the effort.  if (isClassOrEnum) { return true; } return (type == Type.FUNCTION || aliasingGets == 0) && (parent == null || parent.canCollapseUnannotatedChildNames()); }
 public boolean recordBlockDescription(String description) { if (parseDocumentation) { populated = true; } return currentInfo.documentBlock(description); }
 public Node getChildBefore(Node child) { if (child == first) { return null; } Node n = first;  while (n.next != child) { n = n.next; if (n == null) { throw new RuntimeException("node is not a child"); } } return n; }
 private void findAliases(NodeTraversal t) { Scope scope = t.getScope(); for (Var v : scope.getVarIterable()) { Node n = v.getNode(); Node parent = n.getParent(); boolean isVar = parent.isVar(); if (isVar && n.getFirstChild() != null && n.getFirstChild().isQualifiedName()) { recordAlias(v); } else if (v.isBleedingFunction()) { // Bleeding functions already get a BAD_PARAMETERS error, so just // do nothing. } else if (parent.getType() == Token.LP) { // Parameters of the scope function also get a BAD_PARAMETERS // error. } else if (isVar) { Node grandparent = parent.getParent(); Node value = n.hasChildren() ? v.getInitialValue().detachFromParent() : null; Node varNode = parent;  String name = n.getString(); int nameCount = scopedAliasNames.count(name); scopedAliasNames.add(name); String globalName = "$jscomp.scope." + name + (nameCount == 0 ? "" : ("$" + nameCount));  compiler.ensureLibraryInjected("base");  // First, we need to free up the function expression (EXPR) // to be used in another expression. // Replace "function NAME() { ... }" with "var NAME;".  // We can't keep the local name on the function expression, // because IE is buggy and will leak the name into the global // scope. This is covered in more detail here: // http://wiki.ecmascript.org/lib/exe/fetch.php?id=resources:resources&cache=cache&media=resources:jscriptdeviationsfromes3.pdf // // This will only cause problems if this is a hoisted, recursive // function, and the programmer is using the hoisting.  // If this is a VAR, we can just detach the expression and // the tree will still be valid.  // Add $jscomp.scope.name = EXPR; // Make sure we copy over all the jsdoc and debug info. if (value != null || v.getJSDocInfo() != null) { Node newDecl = NodeUtil.newQualifiedNameNodeDeclaration( compiler.getCodingConvention(), globalName, value, v.getJSDocInfo()) .useSourceInfoIfMissingFromForTree(n); NodeUtil.setDebugInformation( newDecl.getFirstChild().getFirstChild(), n, name);  grandparent.addChildBefore(newDecl, varNode); }  // Rewrite "var name = EXPR;" to "var name = $jscomp.scope.name;" v.getNameNode().addChildToFront( NodeUtil.newQualifiedNameNode( compiler.getCodingConvention(), globalName, n, name));  recordAlias(v); } else { // Do not other kinds of local symbols, like catch params. report(t, n, GOOG_SCOPE_NON_ALIAS_LOCAL, n.getString()); } } }
 private void findAliases(NodeTraversal t) { Scope scope = t.getScope(); for (Var v : scope.getVarIterable()) { Node n = v.getNode(); Node parent = n.getParent(); boolean isVar = parent.isVar(); if (isVar && n.getFirstChild() != null && n.getFirstChild().isQualifiedName()) { recordAlias(v); } else if (v.isBleedingFunction()) { // Bleeding functions already get a BAD_PARAMETERS error, so just // do nothing. } else if (parent.getType() == Token.LP) { // Parameters of the scope function also get a BAD_PARAMETERS // error. } else if (isVar) { Node grandparent = parent.getParent(); Node value = n.hasChildren() ? v.getInitialValue().detachFromParent() : null; Node varNode = parent;  String name = n.getString(); int nameCount = scopedAliasNames.count(name); scopedAliasNames.add(name); String globalName = "$jscomp.scope." + name + (nameCount == 0 ? "" : ("$" + nameCount));  compiler.ensureLibraryInjected("base");  // First, we need to free up the function expression (EXPR) // to be used in another expression. // Replace "function NAME() { ... }" with "var NAME;".  // We can't keep the local name on the function expression, // because IE is buggy and will leak the name into the global // scope. This is covered in more detail here: // http://wiki.ecmascript.org/lib/exe/fetch.php?id=resources:resources&cache=cache&media=resources:jscriptdeviationsfromes3.pdf // // This will only cause problems if this is a hoisted, recursive // function, and the programmer is using the hoisting.  // If this is a VAR, we can just detach the expression and // the tree will still be valid.  // Add $jscomp.scope.name = EXPR; // Make sure we copy over all the jsdoc and debug info. if (value != null || v.getJSDocInfo() != null) { Node newDecl = NodeUtil.newQualifiedNameNodeDeclaration( compiler.getCodingConvention(), globalName, value, v.getJSDocInfo()) .useSourceInfoIfMissingFromForTree(n); NodeUtil.setDebugInformation( newDecl.getFirstChild().getFirstChild(), n, name);  grandparent.addChildBefore(newDecl, varNode); }  // Rewrite "var name = EXPR;" to "var name = $jscomp.scope.name;" v.getNameNode().addChildToFront( NodeUtil.newQualifiedNameNode( compiler.getCodingConvention(), globalName, n, name));  recordAlias(v); } else { // Do not other kinds of local symbols, like catch params. report(t, n, GOOG_SCOPE_NON_ALIAS_LOCAL, n.getString()); } } }
 private void findAliases(NodeTraversal t) { Scope scope = t.getScope(); for (Var v : scope.getVarIterable()) { Node n = v.getNode(); Node parent = n.getParent(); boolean isVar = parent.isVar(); if (isVar && n.getFirstChild() != null && n.getFirstChild().isQualifiedName()) { recordAlias(v); } else if (v.isBleedingFunction()) { // Bleeding functions already get a BAD_PARAMETERS error, so just // do nothing. } else if (parent.getType() == Token.LP) { // Parameters of the scope function also get a BAD_PARAMETERS // error. } else if (isVar) { Node grandparent = parent.getParent(); Node value = n.hasChildren() ? v.getInitialValue().detachFromParent() : null; Node varNode = parent;  String name = n.getString(); int nameCount = scopedAliasNames.count(name); scopedAliasNames.add(name); String globalName = "$jscomp.scope." + name + (nameCount == 0 ? "" : ("$" + nameCount));  compiler.ensureLibraryInjected("base");  // First, we need to free up the function expression (EXPR) // to be used in another expression. // Replace "function NAME() { ... }" with "var NAME;".  // We can't keep the local name on the function expression, // because IE is buggy and will leak the name into the global // scope. This is covered in more detail here: // http://wiki.ecmascript.org/lib/exe/fetch.php?id=resources:resources&cache=cache&media=resources:jscriptdeviationsfromes3.pdf // // This will only cause problems if this is a hoisted, recursive // function, and the programmer is using the hoisting.  // If this is a VAR, we can just detach the expression and // the tree will still be valid.  // Add $jscomp.scope.name = EXPR; // Make sure we copy over all the jsdoc and debug info. if (value != null || v.getJSDocInfo() != null) { Node newDecl = NodeUtil.newQualifiedNameNodeDeclaration( compiler.getCodingConvention(), globalName, value, v.getJSDocInfo()) .useSourceInfoIfMissingFromForTree(n); NodeUtil.setDebugInformation( newDecl.getFirstChild().getFirstChild(), n, name);  grandparent.addChildBefore(newDecl, varNode); }  // Rewrite "var name = EXPR;" to "var name = $jscomp.scope.name;" v.getNameNode().addChildToFront( NodeUtil.newQualifiedNameNode( compiler.getCodingConvention(), globalName, n, name));  recordAlias(v); } else { // Do not other kinds of local symbols, like catch params. report(t, n, GOOG_SCOPE_NON_ALIAS_LOCAL, n.getString()); } } }
 public void removeValue(int index) { this.keys.remove(index); this.values.remove(index); if (index < this.keys.size()) { rebuildIndex(); } }
 public void removeValue(Comparable key) { int index = getIndex(key); if (index < 0) { return; } removeValue(index); }
 public void removeColumn(Comparable columnKey) { Iterator iterator = this.rows.iterator(); while (iterator.hasNext()) { DefaultKeyedValues rowData = (DefaultKeyedValues) iterator.next(); rowData.removeValue(columnKey); } this.columnKeys.remove(columnKey); }
 public static String getPackageName(String className) { if (className == null) { return StringUtils.EMPTY; }  // Strip array encoding // Strip Object type encoding  int i = className.lastIndexOf(PACKAGE_SEPARATOR_CHAR); if (i == -1) { return StringUtils.EMPTY; } return className.substring(0, i); }
 public static String getPackageName(String className) { if (className == null) { return StringUtils.EMPTY; }  // Strip array encoding // Strip Object type encoding  int i = className.lastIndexOf(PACKAGE_SEPARATOR_CHAR); if (i == -1) { return StringUtils.EMPTY; } return className.substring(0, i); }
 public static String getShortClassName(String className) { if (className == null) { return StringUtils.EMPTY; } if (className.length() == 0) { return StringUtils.EMPTY; }   // Handle array encoding // Strip Object type encoding   int lastDotIdx = className.lastIndexOf(PACKAGE_SEPARATOR_CHAR); int innerIdx = className.indexOf( INNER_CLASS_SEPARATOR_CHAR, lastDotIdx == -1 ? 0 : lastDotIdx + 1); String out = className.substring(lastDotIdx + 1); if (innerIdx != -1) { out = out.replace(INNER_CLASS_SEPARATOR_CHAR, PACKAGE_SEPARATOR_CHAR); } return out; }
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (str.startsWith("0x") || str.startsWith("-0x")) { return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar)) { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { //Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number }  return createBigDecimal(str);  } } }
 public static boolean isNumber(String str) { if (StringUtils.isEmpty(str)) { return false; } char[] chars = str.toCharArray(); int sz = chars.length; boolean hasExp = false; boolean hasDecPoint = false; boolean allowSigns = false; boolean foundDigit = false; // deal with any possible sign up front int start = (chars[0] == '-') ? 1 : 0; if (sz > start + 1) { if (chars[start] == '0' && chars[start + 1] == 'x') { int i = start + 2; if (i == sz) { return false; // str == "0x" } // checking hex (it can't be anything else) for (; i < chars.length; i++) { if ((chars[i] < '0' || chars[i] > '9') && (chars[i] < 'a' || chars[i] > 'f') && (chars[i] < 'A' || chars[i] > 'F')) { return false; } } return true; } } sz--; // don't want to loop to the last char, check it afterwords // for type qualifiers int i = start; // loop to the next to last char or to the last char if we need another digit to // make a valid number (e.g. chars[0..5] = "1234E") while (i < sz || (i < sz + 1 && allowSigns && !foundDigit)) { if (chars[i] >= '0' && chars[i] <= '9') { foundDigit = true; allowSigns = false;  } else if (chars[i] == '.') { if (hasDecPoint || hasExp) { // two decimal points or dec in exponent return false; } hasDecPoint = true; } else if (chars[i] == 'e' || chars[i] == 'E') { // we've already taken care of hex. if (hasExp) { // two E's return false; } if (!foundDigit) { return false; } hasExp = true; allowSigns = true; } else if (chars[i] == '+' || chars[i] == '-') { if (!allowSigns) { return false; } allowSigns = false; foundDigit = false; // we need a digit after the E } else { return false; } i++; } if (i < chars.length) { if (chars[i] >= '0' && chars[i] <= '9') { // no type qualifier, OK return true; } if (chars[i] == 'e' || chars[i] == 'E') { // can't have an E at the last byte return false; } if (!allowSigns && (chars[i] == 'd' || chars[i] == 'D' || chars[i] == 'f' || chars[i] == 'F')) { return foundDigit; } if (chars[i] == 'l' || chars[i] == 'L') { // not allowing L with an exponent return foundDigit && !hasExp; } // last character is illegal return false; } // allowSigns is true iff the val ends in 'E' // found digit it to make sure weird stuff like '.' and '1E-' doesn't pass return !allowSigns && foundDigit; }
 private void replaceAssignmentExpression(Var v, Reference ref, Map<String, String> varmap) { // Compute all of the assignments necessary List<Node> nodes = Lists.newArrayList(); Node val = ref.getAssignedValue(); blacklistVarReferencesInTree(val, v.scope); Preconditions.checkState(val.getType() == Token.OBJECTLIT); Set<String> all = Sets.newLinkedHashSet(varmap.keySet()); for (Node key = val.getFirstChild(); key != null; key = key.getNext()) { String var = key.getString(); Node value = key.removeFirstChild(); // TODO(user): Copy type information. nodes.add( new Node(Token.ASSIGN, Node.newString(Token.NAME, varmap.get(var)), value)); all.remove(var); }  // TODO(user): Better source information. for (String var : all) { nodes.add( new Node(Token.ASSIGN, Node.newString(Token.NAME, varmap.get(var)), NodeUtil.newUndefinedNode(null))); }  Node replacement; // All assignments evaluate to true, so make sure that the // expr statement evaluates to true in case it matters. nodes.add(new Node(Token.TRUE));  // Join these using COMMA.  A COMMA node must have 2 children, so we // create a tree. In the tree the first child be the COMMA to match // the parser, otherwise tree equality tests fail. nodes = Lists.reverse(nodes); replacement = new Node(Token.COMMA); Node cur = replacement; int i; for (i = 0; i < nodes.size() - 2; i++) { cur.addChildToFront(nodes.get(i)); Node t = new Node(Token.COMMA); cur.addChildToFront(t); cur = t; } cur.addChildToFront(nodes.get(i)); cur.addChildToFront(nodes.get(i + 1));  Node replace = ref.getParent(); replacement.copyInformationFromForTree(replace);  if (replace.getType() == Token.VAR) { replace.getParent().replaceChild( replace, NodeUtil.newExpr(replacement)); } else { replace.getParent().replaceChild(replace, replacement); } }
 public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {  if (n.getType() == Token.FUNCTION) { // Don't traverse functions that are constructors or have the @this // or @override annotation. JSDocInfo jsDoc = getFunctionJsDocInfo(n); if (jsDoc != null && (jsDoc.isConstructor() || jsDoc.isInterface() || jsDoc.hasThisType() || jsDoc.isOverride())) { return false; }  // Don't traverse functions unless they would normally // be able to have a @this annotation associated with them. e.g., // var a = function() { }; // or // function a() {} // or // a.x = function() {}; // or // var a = {x: function() {}}; int pType = parent.getType(); if (!(pType == Token.BLOCK || pType == Token.SCRIPT || pType == Token.NAME || pType == Token.ASSIGN ||  // object literal keys pType == Token.STRING || pType == Token.NUMBER)) { return false; }  // Don't traverse functions that are getting lent to a prototype. }  if (parent != null && parent.getType() == Token.ASSIGN) { Node lhs = parent.getFirstChild(); Node rhs = lhs.getNext();  if (n == lhs) { // Always traverse the left side of the assignment. To handle // nested assignments properly (e.g., (a = this).property = c;), // assignLhsChild should not be overridden. if (assignLhsChild == null) { assignLhsChild = lhs; } } else { // Only traverse the right side if it's not an assignment to a prototype // property or subproperty. if (NodeUtil.isGet(lhs)) { if (lhs.getType() == Token.GETPROP && lhs.getLastChild().getString().equals("prototype")) { return false; } Node llhs = lhs.getFirstChild(); if (llhs.getType() == Token.GETPROP && llhs.getLastChild().getString().equals("prototype")) { return false; } } } }  return true; }
 protected void computeGeometricalProperties() {  final Vector2D[][] v = getVertices();  if (v.length == 0) { final BSPTree<Euclidean2D> tree = getTree(false); if ((Boolean) tree.getAttribute()) { // the instance covers the whole space setSize(Double.POSITIVE_INFINITY); setBarycenter(Vector2D.NaN); } else { setSize(0); setBarycenter(new Vector2D(0, 0)); } } else if (v[0][0] == null) { // there is at least one open-loop: the polygon is infinite setSize(Double.POSITIVE_INFINITY); setBarycenter(Vector2D.NaN); } else { // all loops are closed, we compute some integrals around the shape  double sum  = 0; double sumX = 0; double sumY = 0;  for (Vector2D[] loop : v) { double x1 = loop[loop.length - 1].getX(); double y1 = loop[loop.length - 1].getY(); for (final Vector2D point : loop) { final double x0 = x1; final double y0 = y1; x1 = point.getX(); y1 = point.getY(); final double factor = x0 * y1 - y0 * x1; sum  += factor; sumX += factor * (x0 + x1); sumY += factor * (y0 + y1); } }  if (sum < 0) { // the polygon as a finite outside surrounded by an infinite inside setSize(Double.POSITIVE_INFINITY); setBarycenter(Vector2D.NaN); } else { setSize(sum / 2); setBarycenter(new Vector2D(sumX / (3 * sum), sumY / (3 * sum))); }  }  }
 public int getOffsetFromLocal(long instantLocal) { // get the offset at instantLocal (first estimate) final int offsetLocal = getOffset(instantLocal); // adjust instantLocal using the estimate and recalc the offset final long instantAdjusted = instantLocal - offsetLocal; final int offsetAdjusted = getOffset(instantAdjusted); // if the offsets differ, we must be near a DST boundary if (offsetLocal != offsetAdjusted) { // we need to ensure that time is always after the DST gap // this happens naturally for positive offsets, but not for negative if ((offsetLocal - offsetAdjusted) < 0) { // if we just return offsetAdjusted then the time is pushed // back before the transition, whereas it should be // on or after the transition long nextLocal = nextTransition(instantAdjusted); long nextAdjusted = nextTransition(instantLocal - offsetAdjusted); if (nextLocal != nextAdjusted) { return offsetLocal; } } } return offsetAdjusted; }
 public Object getObject(Comparable rowKey, Comparable columnKey) { if (rowKey == null) { throw new IllegalArgumentException("Null 'rowKey' argument."); } if (columnKey == null) { throw new IllegalArgumentException("Null 'columnKey' argument."); } int row = this.rowKeys.indexOf(rowKey); if (row < 0) { throw new UnknownKeyException("Row key (" + rowKey + ") not recognised."); } int column = this.columnKeys.indexOf(columnKey); if (column < 0) { throw new UnknownKeyException("Column key (" + columnKey + ") not recognised."); } if (row >= 0) { KeyedObjects rowData = (KeyedObjects) this.rows.get(row); return rowData.getObject(columnKey); } else { return null; } }
 public Object getObject(Comparable rowKey, Comparable columnKey) { if (rowKey == null) { throw new IllegalArgumentException("Null 'rowKey' argument."); } if (columnKey == null) { throw new IllegalArgumentException("Null 'columnKey' argument."); } int row = this.rowKeys.indexOf(rowKey); if (row < 0) { throw new UnknownKeyException("Row key (" + rowKey + ") not recognised."); } int column = this.columnKeys.indexOf(columnKey); if (column < 0) { throw new UnknownKeyException("Column key (" + columnKey + ") not recognised."); } if (row >= 0) { KeyedObjects rowData = (KeyedObjects) this.rows.get(row); return rowData.getObject(columnKey); } else { return null; } }
 public void removeColumn(Comparable columnKey) { int index = getColumnIndex(columnKey); if (index < 0) { throw new UnknownKeyException("Column key (" + columnKey + ") not recognised."); } Iterator iterator = this.rows.iterator(); while (iterator.hasNext()) { KeyedObjects rowData = (KeyedObjects) iterator.next(); rowData.removeValue(columnKey); } this.columnKeys.remove(columnKey); }
 public void removeRow(Comparable rowKey) { int index = getRowIndex(rowKey); removeRow(index); }
 static boolean isSimpleNumber(String s) { int len = s.length(); for (int index = 0; index < len; index++) { char c = s.charAt(index); if (c < '0' || c > '9') { return false; } } return len > 0; }
 public static boolean isNumber(String str) { if (StringUtils.isEmpty(str)) { return false; } char[] chars = str.toCharArray(); int sz = chars.length; boolean hasExp = false; boolean hasDecPoint = false; boolean allowSigns = false; boolean foundDigit = false; // deal with any possible sign up front int start = (chars[0] == '-') ? 1 : 0; if (sz > start + 1) { if (chars[start] == '0' && chars[start + 1] == 'x') { int i = start + 2; if (i == sz) { return false; // str == "0x" } // checking hex (it can't be anything else) for (; i < chars.length; i++) { if ((chars[i] < '0' || chars[i] > '9') && (chars[i] < 'a' || chars[i] > 'f') && (chars[i] < 'A' || chars[i] > 'F')) { return false; } } return true; } } sz--; // don't want to loop to the last char, check it afterwords // for type qualifiers int i = start; // loop to the next to last char or to the last char if we need another digit to // make a valid number (e.g. chars[0..5] = "1234E") while (i < sz || (i < sz + 1 && allowSigns && !foundDigit)) { if (chars[i] >= '0' && chars[i] <= '9') { foundDigit = true; allowSigns = false;  } else if (chars[i] == '.') { if (hasDecPoint || hasExp) { // two decimal points or dec in exponent return false; } hasDecPoint = true; } else if (chars[i] == 'e' || chars[i] == 'E') { // we've already taken care of hex. if (hasExp) { // two E's return false; } if (!foundDigit) { return false; } hasExp = true; allowSigns = true; } else if (chars[i] == '+' || chars[i] == '-') { if (!allowSigns) { return false; } allowSigns = false; foundDigit = false; // we need a digit after the E } else { return false; } i++; } if (i < chars.length) { if (chars[i] >= '0' && chars[i] <= '9') { // no type qualifier, OK return true; } if (chars[i] == 'e' || chars[i] == 'E') { // can't have an E at the last byte return false; } if (chars[i] == '.') { if (hasDecPoint || hasExp) { // two decimal points or dec in exponent return false; } // single trailing decimal point after non-exponent is ok return foundDigit; } if (!allowSigns && (chars[i] == 'd' || chars[i] == 'D' || chars[i] == 'f' || chars[i] == 'F')) { return foundDigit; } if (chars[i] == 'l' || chars[i] == 'L') { // not allowing L with an exponent or decimal point return foundDigit && !hasExp; } // last character is illegal return false; } // allowSigns is true iff the val ends in 'E' // found digit it to make sure weird stuff like '.' and '1E-' doesn't pass return !allowSigns && foundDigit; }
 boolean expectCanAssignTo(NodeTraversal t, Node n, JSType rightType, JSType leftType, String msg) { if (!rightType.canAssignTo(leftType)) { if ((leftType.isConstructor() || leftType.isEnumType()) && (rightType.isConstructor() || rightType.isEnumType())) { registerMismatch(rightType, leftType, null); } else { mismatch(t, n, msg, rightType, leftType); } return false; } return true; }
 boolean expectCanAssignToPropertyOf(NodeTraversal t, Node n, JSType rightType, JSType leftType, Node owner, String propName) { // The NoType check is a hack to make typedefs work OK. if (!leftType.isNoType() && !rightType.canAssignTo(leftType)) { if ((leftType.isConstructor() || leftType.isEnumType()) && (rightType.isConstructor() || rightType.isEnumType())) { registerMismatch(rightType, leftType, null); } else { // Do not type-check interface methods, because we expect that // they will have dummy implementations that do not match the type // annotations. JSType ownerType = getJSType(owner); if (ownerType.isFunctionPrototypeType()) { FunctionType ownerFn = ownerType.toObjectType().getOwnerFunction(); if (ownerFn.isInterface() && rightType.isFunctionType() && leftType.isFunctionType()) { return true; } }  mismatch(t, n, "assignment to property " + propName + " of " + getReadableJSTypeName(owner, true), rightType, leftType); } return false; } return true; }
 private StringBuffer appendQuotedString(String pattern, ParsePosition pos, StringBuffer appendTo, boolean escapingOn) { int start = pos.getIndex(); char[] c = pattern.toCharArray(); if (escapingOn && c[start] == QUOTE) { return appendTo == null ? null : appendTo.append(QUOTE); } int lastHold = start; for (int i = pos.getIndex(); i < pattern.length(); i++) { if (escapingOn && pattern.substring(i).startsWith(ESCAPED_QUOTE)) { appendTo.append(c, lastHold, pos.getIndex() - lastHold).append( QUOTE); pos.setIndex(i + ESCAPED_QUOTE.length()); lastHold = pos.getIndex(); continue; } switch (c[pos.getIndex()]) { case QUOTE: next(pos); return appendTo == null ? null : appendTo.append(c, lastHold, pos.getIndex() - lastHold); default: next(pos); } } throw new IllegalArgumentException( "Unterminated quoted string at position " + start); }
 private static Node computeFollowNode( Node fromNode, Node node, ControlFlowAnalysis cfa) { /* * This is the case where: * * 1. Parent is null implies that we are transferring control to the end of * the script. * * 2. Parent is a function implies that we are transferring control back to * the caller of the function. * * 3. If the node is a return statement, we should also transfer control * back to the caller of the function. * * 4. If the node is root then we have reached the end of what we have been * asked to traverse. * * In all cases we should transfer control to a "symbolic return" node. * This will make life easier for DFAs. */ Node parent = node.getParent(); if (parent == null || parent.isFunction() || (cfa != null && node == cfa.root)) { return null; }  // If we are just before a IF/WHILE/DO/FOR: switch (parent.getType()) { // The follow() of any of the path from IF would be what follows IF. case Token.IF: return computeFollowNode(fromNode, parent, cfa); case Token.CASE: case Token.DEFAULT_CASE: // After the body of a CASE, the control goes to the body of the next // case, without having to go to the case condition. if (parent.getNext() != null) { if (parent.getNext().isCase()) { return parent.getNext().getFirstChild().getNext(); } else if (parent.getNext().isDefaultCase()) { return parent.getNext().getFirstChild(); } else { Preconditions.checkState(false, "Not reachable"); } } else { return computeFollowNode(fromNode, parent, cfa); } break; case Token.FOR: if (NodeUtil.isForIn(parent)) { return parent; } else { return parent.getFirstChild().getNext().getNext(); } case Token.WHILE: case Token.DO: return parent; case Token.TRY: // If we are coming out of the TRY block... if (parent.getFirstChild() == node) { if (NodeUtil.hasFinally(parent)) { // and have FINALLY block. return computeFallThrough(parent.getLastChild()); } else { // and have no FINALLY. return computeFollowNode(fromNode, parent, cfa); } // CATCH block. } else if (NodeUtil.getCatchBlock(parent) == node){ if (NodeUtil.hasFinally(parent)) { // and have FINALLY block. return computeFallThrough(node.getNext()); } else { return computeFollowNode(fromNode, parent, cfa); } // If we are coming out of the FINALLY block... } else if (parent.getLastChild() == node){ if (cfa != null) { for (Node finallyNode : cfa.finallyMap.get(parent)) { cfa.createEdge(fromNode, Branch.UNCOND, finallyNode); } } return computeFollowNode(fromNode, parent, cfa); } }  // Now that we are done with the special cases follow should be its // immediate sibling, unless its sibling is a function Node nextSibling = node.getNext();  // Skip function declarations because control doesn't get pass into it. while (nextSibling != null && nextSibling.isFunction()) { nextSibling = nextSibling.getNext(); }  if (nextSibling != null) { return computeFallThrough(nextSibling); } else { // If there are no more siblings, control is transferred up the AST. return computeFollowNode(fromNode, parent, cfa); } }
 public boolean evaluateStep(final StepInterpolator interpolator) throws DerivativeException, EventException, ConvergenceException {  try {  forward = interpolator.isForward(); final double t1 = interpolator.getCurrentTime(); final int    n  = Math.max(1, (int) Math.ceil(Math.abs(t1 - t0) / maxCheckInterval)); final double h  = (t1 - t0) / n;  double ta = t0; double ga = g0; double tb = t0 + (interpolator.isForward() ? convergence : -convergence); for (int i = 0; i < n; ++i) {  // evaluate handler value at the end of the substep tb += h; interpolator.setInterpolatedTime(tb); final double gb = handler.g(tb, interpolator.getInterpolatedState());  // check events occurrence if (g0Positive ^ (gb >= 0)) { // there is a sign change: an event is expected during this step  // this is a corner case: // - there was an event near ta, // - there is another event between ta and tb // - when ta was computed, convergence was reached on the "wrong side" of the interval // this implies that the real sign of ga is the same as gb, so we need to slightly // shift ta to make sure ga and gb get opposite signs and the solver won't complain // about bracketing // this should never happen  // variation direction, with respect to the integration direction increasing = gb >= ga;  final UnivariateRealFunction f = new UnivariateRealFunction() { public double value(final double t) throws FunctionEvaluationException { try { interpolator.setInterpolatedTime(t); return handler.g(t, interpolator.getInterpolatedState()); } catch (DerivativeException e) { throw new FunctionEvaluationException(e, t); } catch (EventException e) { throw new FunctionEvaluationException(e, t); } } }; final BrentSolver solver = new BrentSolver(); solver.setAbsoluteAccuracy(convergence); solver.setMaximalIterationCount(maxIterationCount); final double root = (ta <= tb) ? solver.solve(f, ta, tb) : solver.solve(f, tb, ta); if ((Math.abs(root - ta) <= convergence) && (Math.abs(root - previousEventTime) <= convergence)) { // we have either found nothing or found (again ?) a past event, we simply ignore it ta = tb; ga = gb; } else if (Double.isNaN(previousEventTime) || (Math.abs(previousEventTime - root) > convergence)) { pendingEventTime = root; if (pendingEvent && (Math.abs(t1 - pendingEventTime) <= convergence)) { // we were already waiting for this event which was // found during a previous call for a step that was // rejected, this step must now be accepted since it // properly ends exactly at the event occurrence return false; } // either we were not waiting for the event or it has // moved in such a way the step cannot be accepted pendingEvent = true; return true; }  } else { // no sign change: there is no event for now ta = tb; ga = gb; }  }  // no event during the whole step pendingEvent     = false; pendingEventTime = Double.NaN; return false;  } catch (FunctionEvaluationException e) { final Throwable cause = e.getCause(); if ((cause != null) && (cause instanceof DerivativeException)) { throw (DerivativeException) cause; } else if ((cause != null) && (cause instanceof EventException)) { throw (EventException) cause; } throw new EventException(e); }  }
 private void readTypeVariables() { for (Type type : typeVariable.getBounds()) { registerTypeVariablesOn(type); } registerTypeVariablesOn(getActualTypeArgumentFor(typeVariable)); }
 public static String random(int count, int start, int end, boolean letters, boolean numbers, char[] chars, Random random) { if (count == 0) { return ""; } else if (count < 0) { throw new IllegalArgumentException("Requested random string length " + count + " is less than 0."); } if (chars != null && chars.length == 0) { throw new IllegalArgumentException("The chars array must not be empty"); }  if (start == 0 && end == 0) { if (chars != null) { end = chars.length; } else { if (!letters && !numbers) { end = Integer.MAX_VALUE; } else { end = 'z' + 1; start = ' '; } } }  char[] buffer = new char[count]; int gap = end - start;  while (count-- != 0) { char ch; if (chars == null) { ch = (char) (random.nextInt(gap) + start); } else { ch = chars[random.nextInt(gap) + start]; } if (letters && Character.isLetter(ch) || numbers && Character.isDigit(ch) || !letters && !numbers) { if(ch >= 56320 && ch <= 57343) { if(count == 0) { count++; } else { // low surrogate, insert high surrogate after putting it in buffer[count] = ch; count--; buffer[count] = (char) (55296 + random.nextInt(128)); } } else if(ch >= 55296 && ch <= 56191) { if(count == 0) { count++; } else { // high surrogate, insert low surrogate before putting it in buffer[count] = (char) (56320 + random.nextInt(128)); count--; buffer[count] = ch; } } else if(ch >= 56192 && ch <= 56319) { // private high surrogate, no effing clue, so skip it count++; } else { buffer[count] = ch; } } else { count++; } } return new String(buffer); }
 public static Locale toLocale(final String str) { if (str == null) { return null; } final int len = str.length(); if (len < 2) { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch0 = str.charAt(0); final char ch1 = str.charAt(1); if (!Character.isLowerCase(ch0) || !Character.isLowerCase(ch1)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 2) { return new Locale(str); } if (len < 5) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(2) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch3 = str.charAt(3); if (ch3 == '_') { return new Locale(str.substring(0, 2), "", str.substring(4)); } final char ch4 = str.charAt(4); if (!Character.isUpperCase(ch3) || !Character.isUpperCase(ch4)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 5) { return new Locale(str.substring(0, 2), str.substring(3, 5)); } if (len < 7) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(5) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale(str.substring(0, 2), str.substring(3, 5), str.substring(6)); }
 public static Locale toLocale(final String str) { if (str == null) { return null; } final int len = str.length(); if (len < 2) { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch0 = str.charAt(0); final char ch1 = str.charAt(1); if (!Character.isLowerCase(ch0) || !Character.isLowerCase(ch1)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 2) { return new Locale(str); } if (len < 5) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(2) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch3 = str.charAt(3); if (ch3 == '_') { return new Locale(str.substring(0, 2), "", str.substring(4)); } final char ch4 = str.charAt(4); if (!Character.isUpperCase(ch3) || !Character.isUpperCase(ch4)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 5) { return new Locale(str.substring(0, 2), str.substring(3, 5)); } if (len < 7) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(5) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale(str.substring(0, 2), str.substring(3, 5), str.substring(6)); }
 static Double getStringNumberValue(String rawJsString) { // vertical tab is not always whitespace  String s = trimJsWhiteSpace(rawJsString); // return ScriptRuntime.toNumber(s); if (s.length() == 0) { return 0.0; }  if (s.length() > 2 && s.charAt(0) == '0' && (s.charAt(1) == 'x' || s.charAt(1) == 'X')) { // Attempt to convert hex numbers. try { return Double.valueOf(Integer.parseInt(s.substring(2), 16)); } catch (NumberFormatException e) { return Double.NaN; } }  if (s.length() > 3 && (s.charAt(0) == '-' || s.charAt(0) == '+') && s.charAt(1) == '0' && (s.charAt(2) == 'x' || s.charAt(2) == 'X')) { // hex numbers with explicit signs vary between browsers. return null; }  // FireFox and IE treat the "Infinity" differently. FireFox is case // insensitive, but IE treats "infinity" as NaN.  So leave it alone. if (s.equals("infinity") || s.equals("-infinity") || s.equals("+infinity")) { return null; }  try { return Double.parseDouble(s); } catch (NumberFormatException e) { return Double.NaN; } }
 static TernaryValue isStrWhiteSpaceChar(int c) { switch (c) { case '\u000B': // <VT> return TernaryValue.TRUE; case ' ': // <SP> case '\n': // <LF> case '\r': // <CR> case '\t': // <TAB> case '\u00A0': // <NBSP> case '\u000C': // <FF> case '\u2028': // <LS> case '\u2029': // <PS> case '\uFEFF': // <BOM> return TernaryValue.TRUE; default: return (Character.getType(c) == Character.SPACE_SEPARATOR) ? TernaryValue.TRUE : TernaryValue.FALSE; } }
 public double getChiSquare() { double chiSquare = 0; for (int i = 0; i < rows; ++i) { final double residual = residuals[i]; chiSquare += residual * residual / residualsWeights[i]; } return chiSquare; }
 public double getRMS() { double criterion = 0; for (int i = 0; i < rows; ++i) { final double residual = residuals[i]; criterion += residual * residual * residualsWeights[i]; } return Math.sqrt(criterion / rows); }
 public static Class<?>[] toClass(Object[] array) { if (array == null) { return null; } else if (array.length == 0) { return ArrayUtils.EMPTY_CLASS_ARRAY; } Class<?>[] classes = new Class[array.length]; for (int i = 0; i < array.length; i++) { classes[i] = array[i].getClass(); } return classes; }
 private void inferPropertyTypesToMatchConstraint( JSType type, JSType constraint) { if (type == null || constraint == null) { return; }  ObjectType constraintObj = ObjectType.cast(constraint.restrictByNotNullOrUndefined()); if (constraintObj != null && constraintObj.isRecordType()) { ObjectType objType = ObjectType.cast(type.restrictByNotNullOrUndefined()); if (objType != null) { for (String prop : constraintObj.getOwnPropertyNames()) { JSType propType = constraintObj.getPropertyType(prop); if (!objType.isPropertyTypeDeclared(prop)) { JSType typeToInfer = propType; if (!objType.hasProperty(prop)) { typeToInfer = getNativeType(VOID_TYPE).getLeastSupertype(propType); } objType.defineInferredProperty(prop, typeToInfer, null); } } } } }
 private void injectMockCandidate(Class<?> awaitingInjectionClazz, Set<Object> mocks, Object fieldInstance) { for(Field field : orderedInstanceFieldsFrom(awaitingInjectionClazz)) { mockCandidateFilter.filterCandidate(mocks, field, fieldInstance).thenInject(); } }
 void maybeDeclareQualifiedName(NodeTraversal t, JSDocInfo info, Node n, Node parent, Node rhsValue) { Node ownerNode = n.getFirstChild(); String ownerName = ownerNode.getQualifiedName(); String qName = n.getQualifiedName(); String propName = n.getLastChild().getString(); Preconditions.checkArgument(qName != null && ownerName != null);  // Precedence of type information on GETPROPs: // 1) @type annnotation / @enum annotation // 2) ASSIGN to FUNCTION literal // 3) @param/@return annotation (with no function literal) // 4) ASSIGN to something marked @const // 5) ASSIGN to anything else // // 1, 3, and 4 are declarations, 5 is inferred, and 2 is a declaration iff // the function has jsdoc or has not been declared before. // // FUNCTION literals are special because TypedScopeCreator is very smart // about getting as much type information as possible for them.  // Determining type for #1 + #2 + #3 + #4 JSType valueType = getDeclaredType(t.getSourceName(), info, n, rhsValue); if (valueType == null && rhsValue != null) { // Determining type for #5 valueType = rhsValue.getJSType(); } // Function prototypes are special. // It's a common JS idiom to do: // F.prototype = { ... }; // So if F does not have an explicitly declared super type, // allow F.prototype to be redefined arbitrarily. if ("prototype".equals(propName)) { Var qVar = scope.getVar(qName); if (qVar != null) { // If the programmer has declared that F inherits from Super, // and they assign F.prototype to an object literal, // then they are responsible for making sure that the object literal's // implicit prototype is set up appropriately. We just obey // the @extends tag. ObjectType qVarType = ObjectType.cast(qVar.getType()); if (qVarType != null && rhsValue != null && rhsValue.isObjectLit()) { typeRegistry.resetImplicitPrototype( rhsValue.getJSType(), qVarType.getImplicitPrototype()); } else if (!qVar.isTypeInferred()) { // If the programmer has declared that F inherits from Super, // and they assign F.prototype to some arbitrary expression, // there's not much we can do. We just ignore the expression, // and hope they've annotated their code in a way to tell us // what props are going to be on that prototype. return; } if (qVar.getScope() == scope) { scope.undeclare(qVar); } } }  if (valueType == null) { if (parent.isExprResult()) { stubDeclarations.add(new StubDeclaration( n, t.getInput() != null && t.getInput().isExtern(), ownerName)); }  return; }  // NOTE(nicksantos): Determining whether a property is declared or not // is really really obnoxious. // // The problem is that there are two (equally valid) coding styles: // // (function() { //   /* The authoritative definition of goog.bar. */ //   goog.bar = function() {}; // })(); // // function f() { //   goog.bar(); //   /* Reset goog.bar to a no-op. */ //   goog.bar = function() {}; // } // // In a dynamic language with first-class functions, it's very difficult // to know which one the user intended without looking at lots of // contextual information (the second example demonstrates a small case // of this, but there are some really pathological cases as well). // // The current algorithm checks if either the declaration has // jsdoc type information, or @const with a known type, // or a function literal with a name we haven't seen before. boolean inferred = true; if (info != null) { // Determining declaration for #1 + #3 + #4 inferred = !(info.hasType() || info.hasEnumParameterType() || (info.isConstant() && valueType != null && !valueType.isUnknownType()) || FunctionTypeBuilder.isFunctionTypeDeclaration(info)); }  if (inferred) { // Determining declaration for #2 inferred = !(rhsValue != null && rhsValue.isFunction() && (info != null || !scope.isDeclared(qName, false))); }  if (!inferred) { ObjectType ownerType = getObjectSlot(ownerName); if (ownerType != null) { // Only declare this as an official property if it has not been // declared yet. boolean isExtern = t.getInput() != null && t.getInput().isExtern(); if ((!ownerType.hasOwnProperty(propName) || ownerType.isPropertyTypeInferred(propName)) && ((isExtern && !ownerType.isNativeObjectType()) || !ownerType.isInstanceType())) { // If the property is undeclared or inferred, declare it now. ownerType.defineDeclaredProperty(propName, valueType, n); } }  // If the property is already declared, the error will be // caught when we try to declare it in the current scope. defineSlot(n, parent, valueType, inferred); } else if (rhsValue != null && rhsValue.isTrue()) { // We declare these for delegate proxy method properties. FunctionType ownerType = JSType.toMaybeFunctionType(getObjectSlot(ownerName)); if (ownerType != null) { JSType ownerTypeOfThis = ownerType.getTypeOfThis(); String delegateName = codingConvention.getDelegateSuperclassName(); JSType delegateType = delegateName == null ? null : typeRegistry.getType(delegateName); if (delegateType != null && ownerTypeOfThis.isSubtype(delegateType)) { defineSlot(n, parent, getNativeType(BOOLEAN_TYPE), true); } } } }
 FunctionTypeBuilder inferFromOverriddenFunction( @Nullable FunctionType oldType, @Nullable Node paramsParent) { if (oldType == null) { return this; }  returnType = oldType.getReturnType(); returnTypeInferred = oldType.isReturnTypeInferred(); if (paramsParent == null) { // Not a function literal. parametersNode = oldType.getParametersNode(); if (parametersNode == null) { parametersNode = new FunctionParamBuilder(typeRegistry).build(); } } else { // We're overriding with a function literal. Apply type information // to each parameter of the literal. FunctionParamBuilder paramBuilder = new FunctionParamBuilder(typeRegistry); Iterator<Node> oldParams = oldType.getParameters().iterator(); boolean warnedAboutArgList = false; boolean oldParamsListHitOptArgs = false; for (Node currentParam = paramsParent.getFirstChild(); currentParam != null; currentParam = currentParam.getNext()) { if (oldParams.hasNext()) { Node oldParam = oldParams.next(); Node newParam = paramBuilder.newParameterFromNode(oldParam);  oldParamsListHitOptArgs = oldParamsListHitOptArgs || oldParam.isVarArgs() || oldParam.isOptionalArg();  // The subclass method might write its var_args as individual // arguments. if (currentParam.getNext() != null && newParam.isVarArgs()) { newParam.setVarArgs(false); newParam.setOptionalArg(true); } } else { warnedAboutArgList |= addParameter( paramBuilder, typeRegistry.getNativeType(UNKNOWN_TYPE), warnedAboutArgList, codingConvention.isOptionalParameter(currentParam) || oldParamsListHitOptArgs, codingConvention.isVarArgsParameter(currentParam)); } }  // Clone any remaining params that aren't in the function literal.  parametersNode = paramBuilder.build(); } return this; }
 FunctionTypeBuilder inferParameterTypes(@Nullable Node argsParent, @Nullable JSDocInfo info) { if (argsParent == null) { if (info == null) { return this; } else { return inferParameterTypes(info); } }  // arguments Node oldParameterType = null; if (parametersNode != null) { oldParameterType = parametersNode.getFirstChild(); }  FunctionParamBuilder builder = new FunctionParamBuilder(typeRegistry); boolean warnedAboutArgList = false; Set<String> allJsDocParams = (info == null) ? Sets.<String>newHashSet() : Sets.newHashSet(info.getParameterNames()); boolean foundTemplateType = false; boolean isVarArgs = false; for (Node arg : argsParent.children()) { String argumentName = arg.getString(); allJsDocParams.remove(argumentName);  // type from JSDocInfo JSType parameterType = null; boolean isOptionalParam = isOptionalParameter(arg, info); isVarArgs = isVarArgsParameter(arg, info);  if (info != null && info.hasParameterType(argumentName)) { parameterType = info.getParameterType(argumentName).evaluate(scope, typeRegistry); } else if (oldParameterType != null && oldParameterType.getJSType() != null) { parameterType = oldParameterType.getJSType(); isOptionalParam = oldParameterType.isOptionalArg(); isVarArgs = oldParameterType.isVarArgs(); } else { parameterType = typeRegistry.getNativeType(UNKNOWN_TYPE); }  if (templateTypeName != null && parameterType.restrictByNotNullOrUndefined().isTemplateType()) { if (foundTemplateType) { reportError(TEMPLATE_TYPE_DUPLICATED, fnName); } foundTemplateType = true; } warnedAboutArgList |= addParameter( builder, parameterType, warnedAboutArgList, isOptionalParam, isVarArgs);  if (oldParameterType != null) { oldParameterType = oldParameterType.getNext(); } }  // Copy over any old parameters that aren't in the param list.  if (templateTypeName != null && !foundTemplateType) { reportError(TEMPLATE_TYPE_EXPECTED, fnName); }  for (String inexistentName : allJsDocParams) { reportWarning(INEXISTANT_PARAM, inexistentName, fnName); }  parametersNode = builder.build(); return this; }
 public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {  sanityChecks(equations, t); setEquations(equations); final boolean forward = t > equations.getTime();  // create some internal working arrays final double[] y0  = equations.getCompleteState(); final double[] y = y0.clone(); final int stages = c.length + 1; final double[][] yDotK = new double[stages][y.length]; final double[] yTmp    = y0.clone(); final double[] yDotTmp = new double[y.length];  // set up an interpolator sharing the integrator arrays final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy(); interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers()); interpolator.storeTime(equations.getTime());  // set up integration control objects stepStart         = equations.getTime(); double  hNew      = 0; boolean firstTime = true; initIntegration(equations.getTime(), y0, t);  // main integration loop isLastStep = false; do {  interpolator.shift();  // iterate over step size, ensuring local normalized error is smaller than 1 double error = 10; while (error >= 1.0) {  if (firstTime || !fsal) { // first stage computeDerivatives(stepStart, y, yDotK[0]); }  if (firstTime) { final double[] scale = new double[mainSetDimension]; if (vecAbsoluteTolerance == null) { for (int i = 0; i < scale.length; ++i) { scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * FastMath.abs(y[i]); } } else { for (int i = 0; i < scale.length; ++i) { scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * FastMath.abs(y[i]); } } hNew = initializeStep(forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]); firstTime = false; }  stepSize = hNew;  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // estimate the error at the end of the step error = estimateError(yDotK, y, yTmp, stepSize); if (error >= 1.0) { // reject the step and attempt to reduce error by stepsize control final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); hNew = filterStep(stepSize * factor, forward, false); }  }  // local error is small enough: accept the step, trigger events and step handlers interpolator.storeTime(stepStart + stepSize); System.arraycopy(yTmp, 0, y, 0, y0.length); System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length); stepStart = acceptStep(interpolator, y, yDotTmp, t); System.arraycopy(y, 0, yTmp, 0, y.length);  if (!isLastStep) {  // prepare next step interpolator.storeTime(stepStart);  if (fsal) { // save the last evaluation for the next step System.arraycopy(yDotTmp, 0, yDotK[0], 0, y0.length); }  // stepsize control for next step final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); final double  scaledH    = stepSize * factor; final double  nextT      = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast);  final double  filteredNextT      = stepStart + hNew; final boolean filteredNextIsLast = forward ? (filteredNextT >= t) : (filteredNextT <= t); if (filteredNextIsLast) { hNew = t - stepStart; }  }  } while (!isLastStep);  // dispatch results equations.setTime(stepStart); equations.setCompleteState(y);  resetInternalState();  }
 public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {  sanityChecks(equations, t); setEquations(equations); final boolean forward = t > equations.getTime();  // create some internal working arrays final double[] y0  = equations.getCompleteState(); final double[] y = y0.clone(); final int stages = c.length + 1; final double[][] yDotK = new double[stages][y.length]; final double[] yTmp    = y0.clone(); final double[] yDotTmp = new double[y.length];  // set up an interpolator sharing the integrator arrays final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy(); interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers()); interpolator.storeTime(equations.getTime());  // set up integration control objects stepStart         = equations.getTime(); double  hNew      = 0; boolean firstTime = true; initIntegration(equations.getTime(), y0, t);  // main integration loop isLastStep = false; do {  interpolator.shift();  // iterate over step size, ensuring local normalized error is smaller than 1 double error = 10; while (error >= 1.0) {  if (firstTime || !fsal) { // first stage computeDerivatives(stepStart, y, yDotK[0]); }  if (firstTime) { final double[] scale = new double[mainSetDimension]; if (vecAbsoluteTolerance == null) { for (int i = 0; i < scale.length; ++i) { scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * FastMath.abs(y[i]); } } else { for (int i = 0; i < scale.length; ++i) { scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * FastMath.abs(y[i]); } } hNew = initializeStep(forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]); firstTime = false; }  stepSize = hNew;  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // estimate the error at the end of the step error = estimateError(yDotK, y, yTmp, stepSize); if (error >= 1.0) { // reject the step and attempt to reduce error by stepsize control final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); hNew = filterStep(stepSize * factor, forward, false); }  }  // local error is small enough: accept the step, trigger events and step handlers interpolator.storeTime(stepStart + stepSize); System.arraycopy(yTmp, 0, y, 0, y0.length); System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length); stepStart = acceptStep(interpolator, y, yDotTmp, t); System.arraycopy(y, 0, yTmp, 0, y.length);  if (!isLastStep) {  // prepare next step interpolator.storeTime(stepStart);  if (fsal) { // save the last evaluation for the next step System.arraycopy(yDotTmp, 0, yDotK[0], 0, y0.length); }  // stepsize control for next step final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); final double  scaledH    = stepSize * factor; final double  nextT      = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast);  final double  filteredNextT      = stepStart + hNew; final boolean filteredNextIsLast = forward ? (filteredNextT >= t) : (filteredNextT <= t); if (filteredNextIsLast) { hNew = t - stepStart; }  }  } while (!isLastStep);  // dispatch results equations.setTime(stepStart); equations.setCompleteState(y);  resetInternalState();  }
 public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {  sanityChecks(equations, t); setEquations(equations); final boolean forward = t > equations.getTime();  // create some internal working arrays final double[] y0  = equations.getCompleteState(); final double[] y = y0.clone(); final int stages = c.length + 1; final double[][] yDotK = new double[stages][y.length]; final double[] yTmp    = y0.clone(); final double[] yDotTmp = new double[y.length];  // set up an interpolator sharing the integrator arrays final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy(); interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers()); interpolator.storeTime(equations.getTime());  // set up integration control objects stepStart         = equations.getTime(); double  hNew      = 0; boolean firstTime = true; initIntegration(equations.getTime(), y0, t);  // main integration loop isLastStep = false; do {  interpolator.shift();  // iterate over step size, ensuring local normalized error is smaller than 1 double error = 10; while (error >= 1.0) {  if (firstTime || !fsal) { // first stage computeDerivatives(stepStart, y, yDotK[0]); }  if (firstTime) { final double[] scale = new double[mainSetDimension]; if (vecAbsoluteTolerance == null) { for (int i = 0; i < scale.length; ++i) { scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * FastMath.abs(y[i]); } } else { for (int i = 0; i < scale.length; ++i) { scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * FastMath.abs(y[i]); } } hNew = initializeStep(forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]); firstTime = false; }  stepSize = hNew;  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // estimate the error at the end of the step error = estimateError(yDotK, y, yTmp, stepSize); if (error >= 1.0) { // reject the step and attempt to reduce error by stepsize control final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); hNew = filterStep(stepSize * factor, forward, false); }  }  // local error is small enough: accept the step, trigger events and step handlers interpolator.storeTime(stepStart + stepSize); System.arraycopy(yTmp, 0, y, 0, y0.length); System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length); stepStart = acceptStep(interpolator, y, yDotTmp, t); System.arraycopy(y, 0, yTmp, 0, y.length);  if (!isLastStep) {  // prepare next step interpolator.storeTime(stepStart);  if (fsal) { // save the last evaluation for the next step System.arraycopy(yDotTmp, 0, yDotK[0], 0, y0.length); }  // stepsize control for next step final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp))); final double  scaledH    = stepSize * factor; final double  nextT      = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast);  final double  filteredNextT      = stepStart + hNew; final boolean filteredNextIsLast = forward ? (filteredNextT >= t) : (filteredNextT <= t); if (filteredNextIsLast) { hNew = t - stepStart; }  }  } while (!isLastStep);  // dispatch results equations.setTime(stepStart); equations.setCompleteState(y);  resetInternalState();  }
 private static boolean isReduceableFunctionExpression(Node n) { return NodeUtil.isFunctionExpression(n); }
 private Node tryFoldShift(Node n, Node left, Node right) { if (left.getType() == Token.NUMBER && right.getType() == Token.NUMBER) {  double result; double lval = left.getDouble(); double rval = right.getDouble();  // check ranges.  We do not do anything that would clip the double to // a 32-bit range, since the user likely does not intend that. if (!(lval >= Integer.MIN_VALUE && lval <= Integer.MAX_VALUE)) { error(BITWISE_OPERAND_OUT_OF_RANGE, left); return n; }  // only the lower 5 bits are used when shifting, so don't do anything // if the shift amount is outside [0,32) if (!(rval >= 0 && rval < 32)) { error(SHIFT_AMOUNT_OUT_OF_BOUNDS, right); return n; }  // Convert the numbers to ints int lvalInt = (int) lval; if (lvalInt != lval) { error(FRACTIONAL_BITWISE_OPERAND, left); return n; }  int rvalInt = (int) rval; if (rvalInt != rval) { error(FRACTIONAL_BITWISE_OPERAND, right); return n; }  switch (n.getType()) { case Token.LSH: result = lvalInt << rvalInt; break; case Token.RSH: result = lvalInt >> rvalInt; break; case Token.URSH: // JavaScript handles zero shifts on signed numbers differently than // Java as an Java int can not represent the unsigned 32-bit number // where JavaScript can so use a long here. result = lvalInt >>> rvalInt; break; default: throw new AssertionError("Unknown shift operator: " + Node.tokenToName(n.getType())); }  Node newNumber = Node.newNumber(result); n.getParent().replaceChild(n, newNumber); reportCodeChange();  return newNumber; }  return n; }
 public double doubleValue() { double result = numerator.doubleValue() / denominator.doubleValue(); // Numerator and/or denominator must be out of range: // Calculate how far to shift them to put them in range. return result; }
 public float floatValue() { float result = numerator.floatValue() / denominator.floatValue(); // Numerator and/or denominator must be out of range: // Calculate how far to shift them to put them in range. return result; }
 public static String escapeJava(String str) { return escapeJavaStyleString(str, false); }
 public static void escapeJava(Writer out, String str) throws IOException { escapeJavaStyleString(out, str, false); }
 public static String escapeJavaScript(String str) { return escapeJavaStyleString(str, true); }
 public static void escapeJavaScript(Writer out, String str) throws IOException { escapeJavaStyleString(out, str, true); }
 private static String escapeJavaStyleString(String str, boolean escapeSingleQuotes) { if (str == null) { return null; } try { StringWriter writer = new StringWriter(str.length() * 2); escapeJavaStyleString(writer, str, escapeSingleQuotes); return writer.toString(); } catch (IOException ioe) { // this should never ever happen while writing to a StringWriter ioe.printStackTrace(); return null; } }
 private static String escapeJavaStyleString(String str, boolean escapeSingleQuotes) { if (str == null) { return null; } try { StringWriter writer = new StringWriter(str.length() * 2); escapeJavaStyleString(writer, str, escapeSingleQuotes); return writer.toString(); } catch (IOException ioe) { // this should never ever happen while writing to a StringWriter ioe.printStackTrace(); return null; } }
 private static void escapeJavaStyleString(Writer out, String str, boolean escapeSingleQuote) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (str == null) { return; } int sz; sz = str.length(); for (int i = 0; i < sz; i++) { char ch = str.charAt(i);  // handle unicode if (ch > 0xfff) { out.write("\\u" + hex(ch)); } else if (ch > 0xff) { out.write("\\u0" + hex(ch)); } else if (ch > 0x7f) { out.write("\\u00" + hex(ch)); } else if (ch < 32) { switch (ch) { case '\b' : out.write('\\'); out.write('b'); break; case '\n' : out.write('\\'); out.write('n'); break; case '\t' : out.write('\\'); out.write('t'); break; case '\f' : out.write('\\'); out.write('f'); break; case '\r' : out.write('\\'); out.write('r'); break; default : if (ch > 0xf) { out.write("\\u00" + hex(ch)); } else { out.write("\\u000" + hex(ch)); } break; } } else { switch (ch) { case '\'' : if (escapeSingleQuote) { out.write('\\'); } out.write('\''); break; case '"' : out.write('\\'); out.write('"'); break; case '\\' : out.write('\\'); out.write('\\'); break; case '/' : out.write('\\'); out.write('/'); break; default : out.write(ch); break; } } } }
 private static void escapeJavaStyleString(Writer out, String str, boolean escapeSingleQuote) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (str == null) { return; } int sz; sz = str.length(); for (int i = 0; i < sz; i++) { char ch = str.charAt(i);  // handle unicode if (ch > 0xfff) { out.write("\\u" + hex(ch)); } else if (ch > 0xff) { out.write("\\u0" + hex(ch)); } else if (ch > 0x7f) { out.write("\\u00" + hex(ch)); } else if (ch < 32) { switch (ch) { case '\b' : out.write('\\'); out.write('b'); break; case '\n' : out.write('\\'); out.write('n'); break; case '\t' : out.write('\\'); out.write('t'); break; case '\f' : out.write('\\'); out.write('f'); break; case '\r' : out.write('\\'); out.write('r'); break; default : if (ch > 0xf) { out.write("\\u00" + hex(ch)); } else { out.write("\\u000" + hex(ch)); } break; } } else { switch (ch) { case '\'' : if (escapeSingleQuote) { out.write('\\'); } out.write('\''); break; case '"' : out.write('\\'); out.write('"'); break; case '\\' : out.write('\\'); out.write('\\'); break; case '/' : out.write('\\'); out.write('/'); break; default : out.write(ch); break; } } } }
 public void escape(Writer writer, String str) throws IOException { int len = str.length(); for (int i = 0; i < len; i++) { char c = str.charAt(i); String entityName = this.entityName(c); if (entityName == null) { if (c > 0x7F) { writer.write("&#"); writer.write(Integer.toString(c, 10)); writer.write(';'); } else { writer.write(c); } } else { writer.write('&'); writer.write(entityName); writer.write(';'); } } }
 public void escape(Writer writer, String str) throws IOException { int len = str.length(); for (int i = 0; i < len; i++) { char c = str.charAt(i); String entityName = this.entityName(c); if (entityName == null) { if (c > 0x7F) { writer.write("&#"); writer.write(Integer.toString(c, 10)); writer.write(';'); } else { writer.write(c); } } else { writer.write('&'); writer.write(entityName); writer.write(';'); } } }
 private Integer getPivotRow(SimplexTableau tableau, final int col) { // create a list of all the rows that tie for the lowest score in the minimum ratio test List<Integer> minRatioPositions = new ArrayList<Integer>(); double minRatio = Double.MAX_VALUE; for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) { final double rhs = tableau.getEntry(i, tableau.getWidth() - 1); final double entry = tableau.getEntry(i, col);  if (Precision.compareTo(entry, 0d, maxUlps) > 0) { final double ratio = rhs / entry; // check if the entry is strictly equal to the current min ratio // do not use a ulp/epsilon check final int cmp = Double.compare(ratio, minRatio); if (cmp == 0) { minRatioPositions.add(i); } else if (cmp < 0) { minRatio = ratio; minRatioPositions = new ArrayList<Integer>(); minRatioPositions.add(i); } } }  if (minRatioPositions.size() == 0) { return null; } else if (minRatioPositions.size() > 1) { // there's a degeneracy as indicated by a tie in the minimum ratio test  // 1. check if there's an artificial variable that can be forced out of the basis for (Integer row : minRatioPositions) { for (int i = 0; i < tableau.getNumArtificialVariables(); i++) { int column = i + tableau.getArtificialVariableOffset(); final double entry = tableau.getEntry(row, column); if (Precision.equals(entry, 1d, maxUlps) && row.equals(tableau.getBasicRow(column))) { return row; } } }  // 2. apply Bland's rule to prevent cycling: //    take the row for which the corresponding basic variable has the smallest index // // see http://www.stanford.edu/class/msande310/blandrule.pdf // see http://en.wikipedia.org/wiki/Bland%27s_rule (not equivalent to the above paper) // // Additional heuristic: if we did not get a solution after half of maxIterations //                       revert to the simple case of just returning the top-most row // This heuristic is based on empirical data gathered while investigating MATH-828. Integer minRow = null; int minIndex = tableau.getWidth(); for (Integer row : minRatioPositions) { int i = tableau.getNumObjectiveFunctions(); for (; i < tableau.getWidth() - 1 && minRow != row; i++) { if (row == tableau.getBasicRow(i)) { if (i < minIndex) { minIndex = i; minRow = row; } } } } return minRow; } return minRatioPositions.get(0); }
 private Integer getPivotRow(SimplexTableau tableau, final int col) { // create a list of all the rows that tie for the lowest score in the minimum ratio test List<Integer> minRatioPositions = new ArrayList<Integer>(); double minRatio = Double.MAX_VALUE; for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) { final double rhs = tableau.getEntry(i, tableau.getWidth() - 1); final double entry = tableau.getEntry(i, col);  if (Precision.compareTo(entry, 0d, maxUlps) > 0) { final double ratio = rhs / entry; // check if the entry is strictly equal to the current min ratio // do not use a ulp/epsilon check final int cmp = Double.compare(ratio, minRatio); if (cmp == 0) { minRatioPositions.add(i); } else if (cmp < 0) { minRatio = ratio; minRatioPositions = new ArrayList<Integer>(); minRatioPositions.add(i); } } }  if (minRatioPositions.size() == 0) { return null; } else if (minRatioPositions.size() > 1) { // there's a degeneracy as indicated by a tie in the minimum ratio test  // 1. check if there's an artificial variable that can be forced out of the basis for (Integer row : minRatioPositions) { for (int i = 0; i < tableau.getNumArtificialVariables(); i++) { int column = i + tableau.getArtificialVariableOffset(); final double entry = tableau.getEntry(row, column); if (Precision.equals(entry, 1d, maxUlps) && row.equals(tableau.getBasicRow(column))) { return row; } } }  // 2. apply Bland's rule to prevent cycling: //    take the row for which the corresponding basic variable has the smallest index // // see http://www.stanford.edu/class/msande310/blandrule.pdf // see http://en.wikipedia.org/wiki/Bland%27s_rule (not equivalent to the above paper) // // Additional heuristic: if we did not get a solution after half of maxIterations //                       revert to the simple case of just returning the top-most row // This heuristic is based on empirical data gathered while investigating MATH-828. Integer minRow = null; int minIndex = tableau.getWidth(); for (Integer row : minRatioPositions) { int i = tableau.getNumObjectiveFunctions(); for (; i < tableau.getWidth() - 1 && minRow != row; i++) { if (row == tableau.getBasicRow(i)) { if (i < minIndex) { minIndex = i; minRow = row; } } } } return minRow; } return minRatioPositions.get(0); }
 protected void dropPhase1Objective() { if (getNumObjectiveFunctions() == 1) { return; }  List<Integer> columnsToDrop = new ArrayList<Integer>(); columnsToDrop.add(0);  // positive cost non-artificial variables for (int i = getNumObjectiveFunctions(); i < getArtificialVariableOffset(); i++) { final double entry = tableau.getEntry(0, i); if (Precision.compareTo(entry, 0d, maxUlps) > 0) { columnsToDrop.add(i); } }  // non-basic artificial variables for (int i = 0; i < getNumArtificialVariables(); i++) { int col = i + getArtificialVariableOffset(); if (getBasicRow(col) == null) { columnsToDrop.add(col); } }  double[][] matrix = new double[getHeight() - 1][getWidth() - columnsToDrop.size()]; for (int i = 1; i < getHeight(); i++) { int col = 0; for (int j = 0; j < getWidth(); j++) { if (!columnsToDrop.contains(j)) { matrix[i - 1][col++] = tableau.getEntry(i, j); } } }  for (int i = columnsToDrop.size() - 1; i >= 0; i--) { columnLabels.remove((int) columnsToDrop.get(i)); }  this.tableau = new Array2DRowRealMatrix(matrix); this.numArtificialVariables = 0; }
 private Node parseContextTypeExpression(JsDocToken token) { return parseTypeName(token); }
 public void appendTo(StringBuffer buffer, Calendar calendar) { if (zone.useDaylightTime() && calendar.get(Calendar.DST_OFFSET) != 0) { buffer.append(getTimeZoneDisplay(zone, true, mStyle, mLocale)); } else { buffer.append(getTimeZoneDisplay(zone, false, mStyle, mLocale)); } }
 public int parseArguments(Parameters params) throws CmdLineException { String param = params.getParameter(0);  if (param == null) { setter.addValue(true); return 0; } else { String lowerParam = param.toLowerCase(); if (TRUES.contains(lowerParam)) { setter.addValue(true); } else if (FALSES.contains(lowerParam)) { setter.addValue(false); } else { setter.addValue(true); return 0; } return 1; } }
 public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {  sanityChecks(equations, t0, y0, t, y); setEquations(equations); resetEvaluations(); final boolean forward = t > t0;  // create some internal working arrays final int stages = c.length + 1; if (y != y0) { System.arraycopy(y0, 0, y, 0, y0.length); } final double[][] yDotK = new double[stages][]; for (int i = 0; i < stages; ++i) { yDotK [i] = new double[y0.length]; } final double[] yTmp = new double[y0.length];  // set up an interpolator sharing the integrator arrays AbstractStepInterpolator interpolator; if (requiresDenseOutput() || (! eventsHandlersManager.isEmpty())) { final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy(); rki.reinitialize(this, yTmp, yDotK, forward); interpolator = rki; } else { interpolator = new DummyStepInterpolator(yTmp, yDotK[stages - 1], forward); } interpolator.storeTime(t0);  // set up integration control objects stepStart = t0; stepSize  = forward ? step : -step; for (StepHandler handler : stepHandlers) { handler.reset(); } CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager); boolean lastStep = false;  // main integration loop while (!lastStep) {  interpolator.shift();  for (boolean loop = true; loop;) {  // first stage computeDerivatives(stepStart, y, yDotK[0]);  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // discrete events handling interpolator.storeTime(stepStart + stepSize); if (manager.evaluateStep(interpolator)) { final double dt = manager.getEventTime() - stepStart; if (Math.abs(dt) <= Math.ulp(stepStart)) { // we cannot simply truncate the step, reject the current computation // and let the loop compute another state with the truncated step. // it is so small (much probably exactly 0 due to limited accuracy) // that the code above would fail handling it. // So we set up an artificial 0 size step by copying states loop     = false; } else { // reject the step to match exactly the next switch time stepSize = dt; } } else { loop = false; }  }  // the step has been accepted final double nextStep = stepStart + stepSize; System.arraycopy(yTmp, 0, y, 0, y0.length); manager.stepAccepted(nextStep, y); lastStep = manager.stop();  // provide the step data to the step handler interpolator.storeTime(nextStep); for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, lastStep); } stepStart = nextStep;  if (manager.reset(stepStart, y) && ! lastStep) { // some events handler has triggered changes that // invalidate the derivatives, we need to recompute them computeDerivatives(stepStart, y, yDotK[0]); }  // make sure step size is set to default before next step stepSize = forward ? step : -step;  }  final double stopTime = stepStart; stepStart = Double.NaN; stepSize  = Double.NaN; return stopTime;  }
 public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {  sanityChecks(equations, t0, y0, t, y); setEquations(equations); resetEvaluations(); final boolean forward = t > t0;  // create some internal working arrays final int stages = c.length + 1; if (y != y0) { System.arraycopy(y0, 0, y, 0, y0.length); } final double[][] yDotK = new double[stages][y0.length]; final double[] yTmp = new double[y0.length];  // set up an interpolator sharing the integrator arrays AbstractStepInterpolator interpolator; if (requiresDenseOutput() || (! eventsHandlersManager.isEmpty())) { final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy(); rki.reinitialize(this, yTmp, yDotK, forward); interpolator = rki; } else { interpolator = new DummyStepInterpolator(yTmp, yDotK[stages - 1], forward); } interpolator.storeTime(t0);  // set up integration control objects stepStart         = t0; double  hNew      = 0; boolean firstTime = true; for (StepHandler handler : stepHandlers) { handler.reset(); } CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager); boolean lastStep = false;  // main integration loop while (!lastStep) {  interpolator.shift();  double error = 0; for (boolean loop = true; loop;) {  if (firstTime || !fsal) { // first stage computeDerivatives(stepStart, y, yDotK[0]); }  if (firstTime) { final double[] scale = new double[y0.length]; if (vecAbsoluteTolerance == null) { for (int i = 0; i < scale.length; ++i) { scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * Math.abs(y[i]); } } else { for (int i = 0; i < scale.length; ++i) { scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * Math.abs(y[i]); } } hNew = initializeStep(equations, forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]); firstTime = false; }  stepSize = hNew;  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // estimate the error at the end of the step error = estimateError(yDotK, y, yTmp, stepSize); if (error <= 1.0) {  // discrete events handling interpolator.storeTime(stepStart + stepSize); if (manager.evaluateStep(interpolator)) { final double dt = manager.getEventTime() - stepStart; if (Math.abs(dt) <= Math.ulp(stepStart)) { // we cannot simply truncate the step, reject the current computation // and let the loop compute another state with the truncated step. // it is so small (much probably exactly 0 due to limited accuracy) // that the code above would fail handling it. // So we set up an artificial 0 size step by copying states loop     = false; } else { // reject the step to match exactly the next switch time hNew = dt; } } else { // accept the step loop = false; }  } else { // reject the step and attempt to reduce error by stepsize control final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp))); hNew = filterStep(stepSize * factor, forward, false); }  }  // the step has been accepted final double nextStep = stepStart + stepSize; System.arraycopy(yTmp, 0, y, 0, y0.length); manager.stepAccepted(nextStep, y); lastStep = manager.stop();  // provide the step data to the step handler interpolator.storeTime(nextStep); for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, lastStep); } stepStart = nextStep;  if (fsal) { // save the last evaluation for the next step System.arraycopy(yDotK[stages - 1], 0, yDotK[0], 0, y0.length); }  if (manager.reset(stepStart, y) && ! lastStep) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them computeDerivatives(stepStart, y, yDotK[0]); }  if (! lastStep) { // in some rare cases we may get here with stepSize = 0, for example // when an event occurs at integration start, reducing the first step // to zero; we have to reset the step to some safe non zero value stepSize = filterStep(stepSize, forward, true);  // stepsize control for next step final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp))); final double  scaledH    = stepSize * factor; final double  nextT      = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast); }  }  final double stopTime = stepStart; resetInternalState(); return stopTime;  }
 static float toJavaVersionInt(String version) { return toVersionInt(toJavaVersionIntArray(version, JAVA_VERSION_TRIM_SIZE)); }
 private boolean canInline() { // Cannot inline a parameter. if (getDefCfgNode().isFunction()) { return false; }  // If one of our dependencies has been inlined, then our dependency // graph is wrong. Re-computing it would take another CFG computation, // so we just back off for now. for (Var dependency : defMetadata.depends) { if (inlinedNewDependencies.contains(dependency)) { return false; } }  getDefinition(getDefCfgNode(), null); getNumUseInUseCfgNode(useCfgNode, null);  // Definition was not found. if (def == null) { return false; }  // Check that the assignment isn't used as a R-Value. // TODO(user): Certain cases we can still inline. if (def.isAssign() && !NodeUtil.isExprAssign(def.getParent())) { return false; }  // The right of the definition has side effect: // Example, for x: // x = readProp(b), modifyProp(b); print(x); if (checkRightOf(def, getDefCfgNode(), SIDE_EFFECT_PREDICATE)) { return false; }  // Similar check as the above but this time, all the sub-expressions // left of the use of the variable. // x = readProp(b); modifyProp(b), print(x); if (checkLeftOf(use, useCfgNode, SIDE_EFFECT_PREDICATE)) { return false; }  // TODO(user): Side-effect is OK sometimes. As long as there are no // side-effect function down all paths to the use. Once we have all the // side-effect analysis tool. if (NodeUtil.mayHaveSideEffects(def.getLastChild(), compiler)) { return false; }  // TODO(user): We could inline all the uses if the expression is short.  // Finally we have to make sure that there are no more than one use // in the program and in the CFG node. Even when it is semantically // correctly inlining twice increases code size. if (numUseWithinUseCfgNode != 1) { return false; }  // Make sure that the name is not within a loop if (NodeUtil.isWithinLoop(use)) { return false; }   Collection<Node> uses = reachingUses.getUses(varName, getDefCfgNode());  if (uses.size() != 1) { return false; }  // We give up inlining stuff with R-Value that has: // 1) GETPROP, GETELEM, // 2) anything that creates a new object. // 3) a direct reference to a catch expression. // Example: // var x = a.b.c; j.c = 1; print(x); // Inlining print(a.b.c) is not safe consider j and be alias to a.b. // TODO(user): We could get more accuracy by looking more in-detail // what j is and what x is trying to into to. // TODO(johnlenz): rework catch expression handling when we // have lexical scope support so catch expressions don't // need to be special cased. if (NodeUtil.has(def.getLastChild(), new Predicate<Node>() { @Override public boolean apply(Node input) { switch (input.getType()) { case Token.GETELEM: case Token.GETPROP: case Token.ARRAYLIT: case Token.OBJECTLIT: case Token.REGEXP: case Token.NEW: return true; } return false; } }, new Predicate<Node>() { @Override public boolean apply(Node input) { // Recurse if the node is not a function. return !input.isFunction(); } })) { return false; }  // We can skip the side effect check along the paths of two nodes if // they are just next to each other. if (NodeUtil.isStatementBlock(getDefCfgNode().getParent()) && getDefCfgNode().getNext() != useCfgNode) { // Similar side effect check as above but this time the side effect is // else where along the path. // x = readProp(b); while(modifyProp(b)) {}; print(x); CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch> pathCheck = new CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch>( cfg, cfg.getDirectedGraphNode(getDefCfgNode()), cfg.getDirectedGraphNode(useCfgNode), SIDE_EFFECT_PREDICATE, Predicates. <DiGraphEdge<Node, ControlFlowGraph.Branch>>alwaysTrue(), false); if (pathCheck.somePathsSatisfyPredicate()) { return false; } }  return true; }
 private boolean canInline() { // Cannot inline a parameter. if (getDefCfgNode().isFunction()) { return false; }  // If one of our dependencies has been inlined, then our dependency // graph is wrong. Re-computing it would take another CFG computation, // so we just back off for now. for (Var dependency : defMetadata.depends) { if (inlinedNewDependencies.contains(dependency)) { return false; } }  getDefinition(getDefCfgNode(), null); getNumUseInUseCfgNode(useCfgNode, null);  // Definition was not found. if (def == null) { return false; }  // Check that the assignment isn't used as a R-Value. // TODO(user): Certain cases we can still inline. if (def.isAssign() && !NodeUtil.isExprAssign(def.getParent())) { return false; }  // The right of the definition has side effect: // Example, for x: // x = readProp(b), modifyProp(b); print(x); if (checkRightOf(def, getDefCfgNode(), SIDE_EFFECT_PREDICATE)) { return false; }  // Similar check as the above but this time, all the sub-expressions // left of the use of the variable. // x = readProp(b); modifyProp(b), print(x); if (checkLeftOf(use, useCfgNode, SIDE_EFFECT_PREDICATE)) { return false; }  // TODO(user): Side-effect is OK sometimes. As long as there are no // side-effect function down all paths to the use. Once we have all the // side-effect analysis tool. if (NodeUtil.mayHaveSideEffects(def.getLastChild(), compiler)) { return false; }  // TODO(user): We could inline all the uses if the expression is short.  // Finally we have to make sure that there are no more than one use // in the program and in the CFG node. Even when it is semantically // correctly inlining twice increases code size. if (numUseWithinUseCfgNode != 1) { return false; }  // Make sure that the name is not within a loop if (NodeUtil.isWithinLoop(use)) { return false; }   Collection<Node> uses = reachingUses.getUses(varName, getDefCfgNode());  if (uses.size() != 1) { return false; }  // We give up inlining stuff with R-Value that has: // 1) GETPROP, GETELEM, // 2) anything that creates a new object. // 3) a direct reference to a catch expression. // Example: // var x = a.b.c; j.c = 1; print(x); // Inlining print(a.b.c) is not safe consider j and be alias to a.b. // TODO(user): We could get more accuracy by looking more in-detail // what j is and what x is trying to into to. // TODO(johnlenz): rework catch expression handling when we // have lexical scope support so catch expressions don't // need to be special cased. if (NodeUtil.has(def.getLastChild(), new Predicate<Node>() { @Override public boolean apply(Node input) { switch (input.getType()) { case Token.GETELEM: case Token.GETPROP: case Token.ARRAYLIT: case Token.OBJECTLIT: case Token.REGEXP: case Token.NEW: return true; } return false; } }, new Predicate<Node>() { @Override public boolean apply(Node input) { // Recurse if the node is not a function. return !input.isFunction(); } })) { return false; }  // We can skip the side effect check along the paths of two nodes if // they are just next to each other. if (NodeUtil.isStatementBlock(getDefCfgNode().getParent()) && getDefCfgNode().getNext() != useCfgNode) { // Similar side effect check as above but this time the side effect is // else where along the path. // x = readProp(b); while(modifyProp(b)) {}; print(x); CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch> pathCheck = new CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch>( cfg, cfg.getDirectedGraphNode(getDefCfgNode()), cfg.getDirectedGraphNode(useCfgNode), SIDE_EFFECT_PREDICATE, Predicates. <DiGraphEdge<Node, ControlFlowGraph.Branch>>alwaysTrue(), false); if (pathCheck.somePathsSatisfyPredicate()) { return false; } }  return true; }
 private boolean canInline() { // Cannot inline a parameter. if (getDefCfgNode().isFunction()) { return false; }  // If one of our dependencies has been inlined, then our dependency // graph is wrong. Re-computing it would take another CFG computation, // so we just back off for now. for (Var dependency : defMetadata.depends) { if (inlinedNewDependencies.contains(dependency)) { return false; } }  getDefinition(getDefCfgNode(), null); getNumUseInUseCfgNode(useCfgNode, null);  // Definition was not found. if (def == null) { return false; }  // Check that the assignment isn't used as a R-Value. // TODO(user): Certain cases we can still inline. if (def.isAssign() && !NodeUtil.isExprAssign(def.getParent())) { return false; }  // The right of the definition has side effect: // Example, for x: // x = readProp(b), modifyProp(b); print(x); if (checkRightOf(def, getDefCfgNode(), SIDE_EFFECT_PREDICATE)) { return false; }  // Similar check as the above but this time, all the sub-expressions // left of the use of the variable. // x = readProp(b); modifyProp(b), print(x); if (checkLeftOf(use, useCfgNode, SIDE_EFFECT_PREDICATE)) { return false; }  // TODO(user): Side-effect is OK sometimes. As long as there are no // side-effect function down all paths to the use. Once we have all the // side-effect analysis tool. if (NodeUtil.mayHaveSideEffects(def.getLastChild(), compiler)) { return false; }  // TODO(user): We could inline all the uses if the expression is short.  // Finally we have to make sure that there are no more than one use // in the program and in the CFG node. Even when it is semantically // correctly inlining twice increases code size. if (numUseWithinUseCfgNode != 1) { return false; }  // Make sure that the name is not within a loop if (NodeUtil.isWithinLoop(use)) { return false; }   Collection<Node> uses = reachingUses.getUses(varName, getDefCfgNode());  if (uses.size() != 1) { return false; }  // We give up inlining stuff with R-Value that has: // 1) GETPROP, GETELEM, // 2) anything that creates a new object. // 3) a direct reference to a catch expression. // Example: // var x = a.b.c; j.c = 1; print(x); // Inlining print(a.b.c) is not safe consider j and be alias to a.b. // TODO(user): We could get more accuracy by looking more in-detail // what j is and what x is trying to into to. // TODO(johnlenz): rework catch expression handling when we // have lexical scope support so catch expressions don't // need to be special cased. if (NodeUtil.has(def.getLastChild(), new Predicate<Node>() { @Override public boolean apply(Node input) { switch (input.getType()) { case Token.GETELEM: case Token.GETPROP: case Token.ARRAYLIT: case Token.OBJECTLIT: case Token.REGEXP: case Token.NEW: return true; } return false; } }, new Predicate<Node>() { @Override public boolean apply(Node input) { // Recurse if the node is not a function. return !input.isFunction(); } })) { return false; }  // We can skip the side effect check along the paths of two nodes if // they are just next to each other. if (NodeUtil.isStatementBlock(getDefCfgNode().getParent()) && getDefCfgNode().getNext() != useCfgNode) { // Similar side effect check as above but this time the side effect is // else where along the path. // x = readProp(b); while(modifyProp(b)) {}; print(x); CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch> pathCheck = new CheckPathsBetweenNodes<Node, ControlFlowGraph.Branch>( cfg, cfg.getDirectedGraphNode(getDefCfgNode()), cfg.getDirectedGraphNode(useCfgNode), SIDE_EFFECT_PREDICATE, Predicates. <DiGraphEdge<Node, ControlFlowGraph.Branch>>alwaysTrue(), false); if (pathCheck.somePathsSatisfyPredicate()) { return false; } }  return true; }
 public void enterScope(NodeTraversal t) {  if (t.inGlobalScope()) { return; // Don't even brother. All global variables are likely escaped. }  if (LiveVariablesAnalysis.MAX_VARIABLES_TO_ANALYZE < t.getScope().getVarCount()) { return; }  // Compute the forward reaching definition. ControlFlowAnalysis cfa = new ControlFlowAnalysis(compiler, false, true); // Process the body of the function. Preconditions.checkState(t.getScopeRoot().isFunction()); cfa.process(null, t.getScopeRoot().getLastChild()); cfg = cfa.getCfg(); reachingDef = new MustBeReachingVariableDef(cfg, t.getScope(), compiler); reachingDef.analyze(); candidates = Lists.newLinkedList();  // Using the forward reaching definition search to find all the inline // candidates new NodeTraversal(compiler, new GatherCandiates()).traverse( t.getScopeRoot().getLastChild());  // Compute the backward reaching use. The CFG can be reused. reachingUses = new MaybeReachingVariableUse(cfg, t.getScope(), compiler); reachingUses.analyze(); for (Candidate c : candidates) { if (c.canInline()) { c.inlineVariable();  // If definition c has dependencies, then inlining it may have // introduced new dependencies for our other inlining candidates. // // MustBeReachingVariableDef uses this dependency graph in its // analysis, so some of these candidates may no longer be valid. // We keep track of when the variable dependency graph changed // so that we can back off appropriately. if (!c.defMetadata.depends.isEmpty()) { inlinedNewDependencies.add(t.getScope().getVar(c.varName)); } } } }
 boolean dependsOnOuterScopeVars(String name, Node useNode) { Preconditions.checkArgument(getCfg().hasNode(useNode)); GraphNode<Node, Branch> n = getCfg().getNode(useNode); FlowState<MustDef> state = n.getAnnotation(); Definition def = state.getIn().reachingDef.get(jsScope.getVar(name));  for (Var s : def.depends) { if (s.scope != jsScope) { return true; } } return false; }
 private void computeDependence(final Definition def, Node rValue) { NodeTraversal.traverse(compiler, rValue, new AbstractCfgNodeTraversalCallback() { @Override public void visit(NodeTraversal t, Node n, Node parent) { if (n.isName() && jsScope.isDeclared(n.getString(), true)) { Var dep = jsScope.getVar(n.getString()); def.depends.add(dep); } } }); }
 public void process(Node externs, Node root) { (new NodeTraversal(compiler, this)).traverse(root); }
 public double getMaximumExplodePercent() { double result = 0.0; Iterator iterator = this.dataset.getKeys().iterator(); while (iterator.hasNext()) { Comparable key = (Comparable) iterator.next(); Number explode = (Number) this.explodePercentages.get(key); if (explode != null) { result = Math.max(result, explode.doubleValue()); } } return result; }
 public PiePlotState initialise(Graphics2D g2, Rectangle2D plotArea, PiePlot plot, Integer index, PlotRenderingInfo info) {  PiePlotState state = new PiePlotState(info); state.setPassesRequired(2); state.setTotal(DatasetUtilities.calculatePieDatasetTotal( plot.getDataset())); state.setLatestAngle(plot.getStartAngle()); return state;  }
 private boolean isSafeReplacement(Node node, Node replacement) { // No checks are needed for simple names. if (node.isName()) { return true; } Preconditions.checkArgument(node.isGetProp());  node = node.getFirstChild(); if (node.isName() && isNameAssignedTo(node.getString(), replacement)) { return false; }  return true; }
 public int getDomainAxisIndex(CategoryAxis axis) { return this.domainAxes.indexOf(axis); }
 public int getRangeAxisIndex(ValueAxis axis) { int result = this.rangeAxes.indexOf(axis); if (result < 0) { // try the parent plot Plot parent = getParent(); if (parent instanceof CategoryPlot) { CategoryPlot p = (CategoryPlot) parent; result = p.getRangeAxisIndex(axis); } } return result; }
 public int parseInto(ReadWritableInstant instant, String text, int position) { DateTimeParser parser = requireParser(); if (instant == null) { throw new IllegalArgumentException("Instant must not be null"); }  long instantMillis = instant.getMillis(); Chronology chrono = instant.getChronology(); long instantLocal = instantMillis + chrono.getZone().getOffset(instantMillis); chrono = selectChronology(chrono);  DateTimeParserBucket bucket = new DateTimeParserBucket( instantLocal, chrono, iLocale, iPivotYear, iDefaultYear); int newPos = parser.parseInto(bucket, text, position); instant.setMillis(bucket.computeMillis(false, text)); if (iOffsetParsed && bucket.getOffsetInteger() != null) { int parsedOffset = bucket.getOffsetInteger(); DateTimeZone parsedZone = DateTimeZone.forOffsetMillis(parsedOffset); chrono = chrono.withZone(parsedZone); } else if (bucket.getZone() != null) { chrono = chrono.withZone(bucket.getZone()); } instant.setChronology(chrono); if (iZone != null) { instant.setZone(iZone); } return newPos; }
 public long computeMillis(boolean resetFields, String text) { SavedField[] savedFields = iSavedFields; int count = iSavedFieldsCount; if (iSavedFieldsShared) { iSavedFields = savedFields = (SavedField[])iSavedFields.clone(); iSavedFieldsShared = false; } sort(savedFields, count); if (count > 0) { // alter base year for parsing if first field is month or day DurationField months = DurationFieldType.months().getField(iChrono); DurationField days = DurationFieldType.days().getField(iChrono); DurationField first = savedFields[0].iField.getDurationField(); if (compareReverse(first, months) >= 0 && compareReverse(first, days) <= 0) { saveField(DateTimeFieldType.year(), iDefaultYear); return computeMillis(resetFields, text); } }  long millis = iMillis; try { for (int i = 0; i < count; i++) { millis = savedFields[i].set(millis, resetFields); } } catch (IllegalFieldValueException e) { if (text != null) { e.prependMessage("Cannot parse \"" + text + '"'); } throw e; }  if (iZone == null) { millis -= iOffset; } else { int offset = iZone.getOffsetFromLocal(millis); millis -= offset; if (offset != iZone.getOffset(millis)) { String message = "Illegal instant due to time zone offset transition (" + iZone + ')'; if (text != null) { message = "Cannot parse \"" + text + "\": " + message; } throw new IllegalArgumentException(message); } }  return millis; }
 public void process(Node externs, Node root) { new NodeTraversal( compiler, new NormalizeStatements(compiler, assertOnChange)) .traverse(root); if (MAKE_LOCAL_NAMES_UNIQUE) { MakeDeclaredNamesUnique renamer = new MakeDeclaredNamesUnique(); NodeTraversal t = new NodeTraversal(compiler, renamer); t.traverseRoots(externs, root); } // It is important that removeDuplicateDeclarations runs after // MakeDeclaredNamesUnique in order for catch block exception names to be // handled properly. Specifically, catch block exception names are // only valid within the catch block, but our currect Scope logic // has no concept of this and includes it in the containing function // (or global scope). MakeDeclaredNamesUnique makes the catch exception // names unique so that removeDuplicateDeclarations() will properly handle // cases where a function scope variable conflict with a exception name: //   function f() { //      try {throw 0;} catch(e) {e; /* catch scope 'e'*/} //      var e = 1; // f scope 'e' //   } // otherwise 'var e = 1' would be rewritten as 'e = 1'. // TODO(johnlenz): Introduce a seperate scope for catch nodes. removeDuplicateDeclarations(externs, root); new PropagateConstantAnnotationsOverVars(compiler, assertOnChange) .process(externs, root);  if (!compiler.getLifeCycleStage().isNormalized()) { compiler.setLifeCycleStage(LifeCycleStage.NORMALIZED); } }
 private void createSynthesizedExternVar(String varName) { Node nameNode = Node.newString(Token.NAME, varName);  // Mark the variable as constant if it matches the coding convention // for constant vars. // NOTE(nicksantos): honestly, i'm not sure how much this matters. // AFAIK, all people who use the CONST coding convention also // compile with undeclaredVars as errors. We have some test // cases for this configuration though, and it makes them happier. if (compiler.getCodingConvention().isConstant(varName)) { nameNode.putBooleanProp(Node.IS_CONSTANT_NAME, true); }  getSynthesizedExternsRoot().addChildToBack( new Node(Token.VAR, nameNode)); varsToDeclareInExterns.remove(varName); }
 public static boolean containsIgnoreCase(String str, String searchStr) { if (str == null || searchStr == null) { return false; } return contains(str.toUpperCase(), searchStr.toUpperCase()); }
 private static String replaceEach(String text, String[] searchList, String[] replacementList, boolean repeat, int timeToLive) {  // mchyzer Performance note: This creates very few new objects (one major goal) // let me know if there are performance requests, we can create a harness to measure  if (text == null || text.length() == 0 || searchList == null || searchList.length == 0 || replacementList == null || replacementList.length == 0) { return text; }  // if recursing, this shouldnt be less than 0 if (timeToLive < 0) { throw new IllegalStateException("TimeToLive of " + timeToLive + " is less than 0: " + text); }  int searchLength = searchList.length; int replacementLength = replacementList.length;  // make sure lengths are ok, these need to be equal if (searchLength != replacementLength) { throw new IllegalArgumentException("Search and Replace array lengths don't match: " + searchLength + " vs " + replacementLength); }  // keep track of which still have matches boolean[] noMoreMatchesForReplIndex = new boolean[searchLength];  // index on index that the match was found int textIndex = -1; int replaceIndex = -1; int tempIndex = -1;  // index of replace array that will replace the search string found // NOTE: logic duplicated below START for (int i = 0; i < searchLength; i++) { if (noMoreMatchesForReplIndex[i] || searchList[i] == null || searchList[i].length() == 0 || replacementList[i] == null) { continue; } tempIndex = text.indexOf(searchList[i]);  // see if we need to keep searching for this if (tempIndex == -1) { noMoreMatchesForReplIndex[i] = true; } else { if (textIndex == -1 || tempIndex < textIndex) { textIndex = tempIndex; replaceIndex = i; } } } // NOTE: logic mostly below END  // no search strings found, we are done if (textIndex == -1) { return text; }  int start = 0;  // get a good guess on the size of the result buffer so it doesnt have to double if it goes over a bit int increase = 0;  // count the replacement text elements that are larger than their corresponding text being replaced for (int i = 0; i < searchList.length; i++) { int greater = replacementList[i].length() - searchList[i].length(); if (greater > 0) { increase += 3 * greater; // assume 3 matches } } // have upper-bound at 20% increase, then let Java take over increase = Math.min(increase, text.length() / 5);  StringBuilder buf = new StringBuilder(text.length() + increase);  while (textIndex != -1) {  for (int i = start; i < textIndex; i++) { buf.append(text.charAt(i)); } buf.append(replacementList[replaceIndex]);  start = textIndex + searchList[replaceIndex].length();  textIndex = -1; replaceIndex = -1; tempIndex = -1; // find the next earliest match // NOTE: logic mostly duplicated above START for (int i = 0; i < searchLength; i++) { if (noMoreMatchesForReplIndex[i] || searchList[i] == null || searchList[i].length() == 0 || replacementList[i] == null) { continue; } tempIndex = text.indexOf(searchList[i], start);  // see if we need to keep searching for this if (tempIndex == -1) { noMoreMatchesForReplIndex[i] = true; } else { if (textIndex == -1 || tempIndex < textIndex) { textIndex = tempIndex; replaceIndex = i; } } } // NOTE: logic duplicated above END  } int textLength = text.length(); for (int i = start; i < textLength; i++) { buf.append(text.charAt(i)); } String result = buf.toString(); if (!repeat) { return result; }  return replaceEach(result, searchList, replacementList, repeat, timeToLive - 1); }
 protected UnivariatePointValuePair doOptimize() { final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final double lo = getMin(); final double mid = getStartValue(); final double hi = getMax();  // Optional additional convergence criteria. final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();  double a; double b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(x); if (!isMinim) { fx = -fx; } double fv = fx; double fw = fx;  UnivariatePointValuePair previous = null; UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx);  int iter = 0; while (true) { final double m = 0.5 * (a + b); final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold; final double tol2 = 2 * tol1;  // Default stopping criterion. final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a); if (!stop) { double p = 0; double q = 0; double r = 0; double u = 0;  if (FastMath.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (FastMath.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(u); if (!isMinim) { fu = -fu; }  // User-defined convergence checker. previous = current; current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);  if (checker != null) { if (checker.converged(iter, previous, current)) { return current; } }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || Precision.equals(w, x)) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) { v = u; fv = fu; } } } else { // Default termination (Brent's criterion). return current; } ++iter; } }
 protected UnivariatePointValuePair doOptimize() { final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final double lo = getMin(); final double mid = getStartValue(); final double hi = getMax();  // Optional additional convergence criteria. final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();  double a; double b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(x); if (!isMinim) { fx = -fx; } double fv = fx; double fw = fx;  UnivariatePointValuePair previous = null; UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx);  int iter = 0; while (true) { final double m = 0.5 * (a + b); final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold; final double tol2 = 2 * tol1;  // Default stopping criterion. final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a); if (!stop) { double p = 0; double q = 0; double r = 0; double u = 0;  if (FastMath.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (FastMath.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(u); if (!isMinim) { fu = -fu; }  // User-defined convergence checker. previous = current; current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);  if (checker != null) { if (checker.converged(iter, previous, current)) { return current; } }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || Precision.equals(w, x)) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) { v = u; fv = fu; } } } else { // Default termination (Brent's criterion). return current; } ++iter; } }
 public Class getGenericType(Field field) { Type generic = field.getGenericType(); if (generic != null && generic instanceof ParameterizedType) { Type actual = ((ParameterizedType) generic).getActualTypeArguments()[0]; return (Class) actual; //in case of nested generics we don't go deep }  return Object.class; }
 public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {  if (n.getType() == Token.FUNCTION) { // Don't traverse functions that are constructors or have the @this // or @override annotation. JSDocInfo jsDoc = getFunctionJsDocInfo(n); if (jsDoc != null && (jsDoc.isConstructor() || jsDoc.hasThisType() || jsDoc.isOverride())) { return false; }  // Don't traverse functions unless they would normally // be able to have a @this annotation associated with them. e.g., // var a = function() { }; // or // function a() {} // or // a.x = function() {}; int pType = parent.getType(); if (!(pType == Token.BLOCK || pType == Token.SCRIPT || pType == Token.NAME || pType == Token.ASSIGN)) { return false; } }  if (parent != null && parent.getType() == Token.ASSIGN) { Node lhs = parent.getFirstChild(); Node rhs = lhs.getNext();  if (n == lhs) { // Always traverse the left side of the assignment. To handle // nested assignments properly (e.g., (a = this).property = c;), // assignLhsChild should not be overridden. if (assignLhsChild == null) { assignLhsChild = lhs; } } else { // Only traverse the right side if it's not an assignment to a prototype // property or subproperty. if (lhs.getType() == Token.GETPROP && lhs.getLastChild().getString().equals("prototype")) { return false; } if (lhs.getQualifiedName() != null && lhs.getQualifiedName().contains(".prototype.")) { return false; } } }  return true; }
 public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {  if (n.getType() == Token.FUNCTION) { // Don't traverse functions that are constructors or have the @this // or @override annotation. JSDocInfo jsDoc = getFunctionJsDocInfo(n); if (jsDoc != null && (jsDoc.isConstructor() || jsDoc.hasThisType() || jsDoc.isOverride())) { return false; }  // Don't traverse functions unless they would normally // be able to have a @this annotation associated with them. e.g., // var a = function() { }; // or // function a() {} // or // a.x = function() {}; int pType = parent.getType(); if (!(pType == Token.BLOCK || pType == Token.SCRIPT || pType == Token.NAME || pType == Token.ASSIGN)) { return false; } }  if (parent != null && parent.getType() == Token.ASSIGN) { Node lhs = parent.getFirstChild(); Node rhs = lhs.getNext();  if (n == lhs) { // Always traverse the left side of the assignment. To handle // nested assignments properly (e.g., (a = this).property = c;), // assignLhsChild should not be overridden. if (assignLhsChild == null) { assignLhsChild = lhs; } } else { // Only traverse the right side if it's not an assignment to a prototype // property or subproperty. if (lhs.getType() == Token.GETPROP && lhs.getLastChild().getString().equals("prototype")) { return false; } if (lhs.getQualifiedName() != null && lhs.getQualifiedName().contains(".prototype.")) { return false; } } }  return true; }
 public PoissonDistributionImpl(double p, double epsilon, int maxIterations) { if (p <= 0) { throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.NOT_POSITIVE_POISSON_MEAN, p); } mean = p; normal = new NormalDistributionImpl(p, FastMath.sqrt(p)); this.epsilon = epsilon; this.maxIterations = maxIterations; }
 public static boolean containsAny(CharSequence cs, char[] searchChars) { if (isEmpty(cs) || ArrayUtils.isEmpty(searchChars)) { return false; } int csLength = cs.length(); int searchLength = searchChars.length; for (int i = 0; i < csLength; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLength; j++) { if (searchChars[j] == ch) { // ch is a supplementary character // ch is in the Basic Multilingual Plane return true; } } } return false; }
 private synchronized String[] getNameSet(Locale locale, String id, String nameKey) { if (locale == null || id == null || nameKey == null) { return null; }  Map<String, Map<String, Object>> byIdCache = iByLocaleCache.get(locale); if (byIdCache == null) { iByLocaleCache.put(locale, byIdCache = createCache()); }  Map<String, Object> byNameKeyCache = byIdCache.get(id); if (byNameKeyCache == null) { byIdCache.put(id, byNameKeyCache = createCache());  String[][] zoneStringsLoc = DateTimeUtils.getDateFormatSymbols(locale).getZoneStrings(); String[] setLoc = null; for (String[] strings : zoneStringsLoc) { if (strings != null && strings.length == 5 && id.equals(strings[0])) { setLoc = strings;  byNameKeyCache.put(setLoc[2], new String[] {setLoc[2], setLoc[1]}); // need to handle case where summer and winter have the same // abbreviation, such as EST in Australia [1716305] // we handle this by appending "-Summer", cf ZoneInfoCompiler if (setLoc[2].equals(setLoc[4])) { byNameKeyCache.put(setLoc[4] + "-Summer", new String[] {setLoc[4], setLoc[3]}); } else { byNameKeyCache.put(setLoc[4], new String[] {setLoc[4], setLoc[3]}); } break; } } } return (String[]) byNameKeyCache.get(nameKey); }
 private ExtractionInfo extractMultilineTextualBlock(JsDocToken token, WhitespaceOption option) {  if (token == JsDocToken.EOC || token == JsDocToken.EOL || token == JsDocToken.EOF) { return new ExtractionInfo("", token); }  stream.update(); int startLineno = stream.getLineno(); int startCharno = stream.getCharno() + 1;  // Read the content from the first line. String line = stream.getRemainingJSDocLine(); if (option != WhitespaceOption.PRESERVE) { line = line.trim(); }  StringBuilder builder = new StringBuilder(); builder.append(line);  state = State.SEARCHING_ANNOTATION; token = next();  boolean ignoreStar = false;  // Track the start of the line to count whitespace that // the tokenizer skipped. Because this case is rare, it's easier // to do this here than in the tokenizer.  do { switch (token) { case STAR: if (ignoreStar) { // Mark the position after the star as the new start of the line. } else { // The star is part of the comment. if (builder.length() > 0) { builder.append(' '); }  builder.append('*'); }  token = next(); continue;  case EOL: if (option != WhitespaceOption.SINGLE_LINE) { builder.append("\n"); }  ignoreStar = true; token = next(); continue;  default: ignoreStar = false; state = State.SEARCHING_ANNOTATION;  // All tokens must be separated by a space.  if (token == JsDocToken.EOC || token == JsDocToken.EOF || // When we're capturing a license block, annotations // in the block are ok. (token == JsDocToken.ANNOTATION && option != WhitespaceOption.PRESERVE)) { String multilineText = builder.toString();  if (option != WhitespaceOption.PRESERVE) { multilineText = multilineText.trim(); }  int endLineno = stream.getLineno(); int endCharno = stream.getCharno();  if (multilineText.length() > 0) { jsdocBuilder.markText(multilineText, startLineno, startCharno, endLineno, endCharno); }  return new ExtractionInfo(multilineText, token); }  if (builder.length() > 0) { builder.append(' '); } builder.append(toString(token));  line = stream.getRemainingJSDocLine();  if (option != WhitespaceOption.PRESERVE) { line = trimEnd(line); }  builder.append(line); token = next(); } } while (true); }
 chooseInitialCenters(final Collection<T> points, final int k, final Random random) {  final List<T> pointSet = new ArrayList<T>(points); final List<Cluster<T>> resultSet = new ArrayList<Cluster<T>>();  // Choose one center uniformly at random from among the data points. final T firstPoint = pointSet.remove(random.nextInt(pointSet.size())); resultSet.add(new Cluster<T>(firstPoint));  final double[] dx2 = new double[pointSet.size()]; while (resultSet.size() < k) { // For each data point x, compute D(x), the distance between x and // the nearest center that has already been chosen. int sum = 0; for (int i = 0; i < pointSet.size(); i++) { final T p = pointSet.get(i); final Cluster<T> nearest = getNearestCluster(resultSet, p); final double d = p.distanceFrom(nearest.getCenter()); sum += d * d; dx2[i] = sum; }  // Add one new data point as a center. Each point x is chosen with // probability proportional to D(x)2 final double r = random.nextDouble() * sum; for (int i = 0 ; i < dx2.length; i++) { if (dx2[i] >= r) { final T p = pointSet.remove(i); resultSet.add(new Cluster<T>(p)); break; } } }  return resultSet;  }
 public void add(DurationFieldType type, int amount) { if (type == null) { throw new IllegalArgumentException("Field must not be null"); } setMillis(type.getField(getChronology()).add(getMillis(), amount)); }
 public void addDays(final int days) { setMillis(getChronology().days().add(getMillis(), days)); }
 public void addHours(final int hours) { setMillis(getChronology().hours().add(getMillis(), hours)); }
 public void addMillis(final int millis) { setMillis(getChronology().millis().add(getMillis(), millis)); }
 public void addMinutes(final int minutes) { setMillis(getChronology().minutes().add(getMillis(), minutes)); }
 public void addMonths(final int months) { setMillis(getChronology().months().add(getMillis(), months)); }
 public void addSeconds(final int seconds) { setMillis(getChronology().seconds().add(getMillis(), seconds)); }
 public void addWeeks(final int weeks) { setMillis(getChronology().weeks().add(getMillis(), weeks)); }
 public void addWeekyears(final int weekyears) { setMillis(getChronology().weekyears().add(getMillis(), weekyears)); }
 public void addYears(final int years) { setMillis(getChronology().years().add(getMillis(), years)); }
 void replace() { if (firstNode == null) { // Don't touch the base case ('goog'). replacementNode = candidateDefinition; return; }  // Handle the case where there is a duplicate definition for an explicitly // provided symbol. if (candidateDefinition != null && explicitNode != null) { explicitNode.detachFromParent(); compiler.reportCodeChange();  // Does this need a VAR keyword? replacementNode = candidateDefinition; if (NodeUtil.isExpressionNode(candidateDefinition)) { candidateDefinition.putBooleanProp(Node.IS_NAMESPACE, true); Node assignNode = candidateDefinition.getFirstChild(); Node nameNode = assignNode.getFirstChild(); if (nameNode.getType() == Token.NAME) { // Need to convert this assign to a var declaration. Node valueNode = nameNode.getNext(); assignNode.removeChild(nameNode); assignNode.removeChild(valueNode); nameNode.addChildToFront(valueNode); Node varNode = new Node(Token.VAR, nameNode); varNode.copyInformationFrom(candidateDefinition); candidateDefinition.getParent().replaceChild( candidateDefinition, varNode); nameNode.setJSDocInfo(assignNode.getJSDocInfo()); compiler.reportCodeChange(); replacementNode = varNode; } } } else { // Handle the case where there's not a duplicate definition. replacementNode = createDeclarationNode(); if (firstModule == minimumModule) { firstNode.getParent().addChildBefore(replacementNode, firstNode); } else { // In this case, the name was implicitly provided by two independent // modules. We need to move this code up to a common module. int indexOfDot = namespace.indexOf('.'); if (indexOfDot == -1) { // Any old place is fine. compiler.getNodeForCodeInsertion(minimumModule) .addChildToBack(replacementNode); } else { // Add it after the parent namespace. ProvidedName parentName = providedNames.get(namespace.substring(0, indexOfDot)); Preconditions.checkNotNull(parentName); Preconditions.checkNotNull(parentName.replacementNode); parentName.replacementNode.getParent().addChildAfter( replacementNode, parentName.replacementNode); } } if (explicitNode != null) { explicitNode.detachFromParent(); } compiler.reportCodeChange(); } }
 private String exceptionCauseMessageIfAvailable(Exception details) { return details.getCause().getMessage(); }
 public void noMoreInteractionsWanted(Invocation undesired, List<VerificationAwareInvocation> invocations) { ScenarioPrinter scenarioPrinter = new ScenarioPrinter(); String scenario = scenarioPrinter.print(invocations);  throw new NoInteractionsWanted(join( "No interactions wanted here:", new LocationImpl(), "But found this interaction on mock '" + undesired.getMock() + "':", undesired.getLocation(), scenario )); }
 public void noMoreInteractionsWantedInOrder(Invocation undesired) { throw new VerificationInOrderFailure(join( "No interactions wanted here:", new LocationImpl(), "But found this interaction on mock '" + undesired.getMock() + "':", undesired.getLocation() )); }
 private OriginalMapping getOriginalMappingForEntry(Entry entry) { if (entry.getSourceFileId() == UNMAPPED) { return null; } else { // Adjust the line/column here to be start at 1. Builder x = OriginalMapping.newBuilder() .setOriginalFile(sources[entry.getSourceFileId()]) .setLineNumber(entry.getSourceLine()) .setColumnPosition(entry.getSourceColumn()); if (entry.getNameId() != UNMAPPED) { x.setIdentifier(names[entry.getNameId()]); } return x.build(); } }
 public void addMapping( Node node, FilePosition outputStartPosition, FilePosition outputEndPosition) { String sourceFile = node.getSourceFileName();  // If the node does not have an associated source file or // its line number is -1, then the node does not have sufficient // information for a mapping to be useful. if (sourceFile == null || node.getLineno() < 0) { return; }  sourceFile = fixupSourceLocation(sourceFile);  String originalName = (String) node.getProp(Node.ORIGINALNAME_PROP);  // Strangely, Rhino source lines are one based but columns are // zero based. // We don't change this for the v1 or v2 source maps but for // v3 we make them both 0 based.  generator.addMapping( sourceFile, originalName, new FilePosition(node.getLineno(), node.getCharno()), outputStartPosition, outputEndPosition); }
 public double getFunctionValue() { return optimizer.getFunctionValue(); }
 public double getResult() { return optimizer.getResult(); }
 protected final double doSolve() { // Get initial solution double x0 = getMin(); double x1 = getMax(); double f0 = computeObjectiveValue(x0); double f1 = computeObjectiveValue(x1);  // If one of the bounds is the exact root, return it. Since these are // not under-approximations or over-approximations, we can return them // regardless of the allowed solutions. if (f0 == 0.0) { return x0; } if (f1 == 0.0) { return x1; }  // Verify bracketing of initial solution. verifyBracketing(x0, x1);  // Get accuracies. final double ftol = getFunctionValueAccuracy(); final double atol = getAbsoluteAccuracy(); final double rtol = getRelativeAccuracy();  // Keep track of inverted intervals, meaning that the left bound is // larger than the right bound. boolean inverted = false;  // Keep finding better approximations. while (true) { // Calculate the next approximation. final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0)); final double fx = computeObjectiveValue(x);  // If the new approximation is the exact root, return it. Since // this is not an under-approximation or an over-approximation, // we can return it regardless of the allowed solutions. if (fx == 0.0) { return x; }  // Update the bounds with the new approximation. if (f1 * fx < 0) { // The value of x1 has switched to the other bound, thus inverting // the interval. x0 = x1; f0 = f1; inverted = !inverted; } else { switch (method) { case ILLINOIS: f0 *= 0.5; break; case PEGASUS: f0 *= f1 / (f1 + fx); break; case REGULA_FALSI: // Nothing. if (x == x1) { x0 = 0.5 * (x0 + x1 - FastMath.max(rtol * FastMath.abs(x1), atol)); f0 = computeObjectiveValue(x0); } break; default: // Should never happen. throw new MathInternalError(); } } // Update from [x0, x1] to [x0, x]. x1 = x; f1 = fx;  // If the function value of the last approximation is too small, // given the function value accuracy, then we can't get closer to // the root than we already are. if (FastMath.abs(f1) <= ftol) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: if (inverted) { return x1; } break; case RIGHT_SIDE: if (!inverted) { return x1; } break; case BELOW_SIDE: if (f1 <= 0) { return x1; } break; case ABOVE_SIDE: if (f1 >= 0) { return x1; } break; default: throw new MathInternalError(); } }  // If the current interval is within the given accuracies, we // are satisfied with the current approximation. if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: return inverted ? x1 : x0; case RIGHT_SIDE: return inverted ? x0 : x1; case BELOW_SIDE: return (f1 <= 0) ? x1 : x0; case ABOVE_SIDE: return (f1 >= 0) ? x1 : x0; default: throw new MathInternalError(); } } } }
 private static String extractClassNameIfGoog(Node node, Node parent, String functionName){ String className = null; if (NodeUtil.isExprCall(parent)) { Node callee = node.getFirstChild(); if (callee != null && callee.getType() == Token.GETPROP) { String qualifiedName = callee.getQualifiedName(); if (functionName.equals(qualifiedName)) { Node target = callee.getNext(); if (target != null) { className = target.getString(); } } } } return className; }
 static boolean isValidDefineValue(Node val, Set<String> defines) { switch (val.getType()) { case Token.STRING: case Token.NUMBER: case Token.TRUE: case Token.FALSE: return true;  // Binary operators are only valid if both children are valid. case Token.BITAND: case Token.BITNOT: case Token.BITOR: case Token.BITXOR:  // Uniary operators are valid if the child is valid. case Token.NOT: case Token.NEG: return isValidDefineValue(val.getFirstChild(), defines);  // Names are valid if and only if they are defines themselves. case Token.NAME: case Token.GETPROP: if (val.isQualifiedName()) { return defines.contains(val.getQualifiedName()); } } return false; }
 static boolean isValidDefineValue(Node val, Set<String> defines) { switch (val.getType()) { case Token.STRING: case Token.NUMBER: case Token.TRUE: case Token.FALSE: return true;  // Binary operators are only valid if both children are valid. case Token.BITAND: case Token.BITNOT: case Token.BITOR: case Token.BITXOR:  // Uniary operators are valid if the child is valid. case Token.NOT: case Token.NEG: return isValidDefineValue(val.getFirstChild(), defines);  // Names are valid if and only if they are defines themselves. case Token.NAME: case Token.GETPROP: if (val.isQualifiedName()) { return defines.contains(val.getQualifiedName()); } } return false; }
 public EqualsBuilder append(Object lhs, Object rhs) { if (isEquals == false) { return this; } if (lhs == rhs) { return this; } if (lhs == null || rhs == null) { this.setEquals(false); return this; } Class lhsClass = lhs.getClass(); if (!lhsClass.isArray()) { // The simple case, not an array, just test the element isEquals = lhs.equals(rhs); } else if (lhs.getClass() != rhs.getClass()) { // Here when we compare different dimensions, for example: a boolean[][] to a boolean[] this.setEquals(false); } // 'Switch' on type of array, to dispatch to the correct handler // This handles multi dimensional arrays of the same depth else if (lhs instanceof long[]) { append((long[]) lhs, (long[]) rhs); } else if (lhs instanceof int[]) { append((int[]) lhs, (int[]) rhs); } else if (lhs instanceof short[]) { append((short[]) lhs, (short[]) rhs); } else if (lhs instanceof char[]) { append((char[]) lhs, (char[]) rhs); } else if (lhs instanceof byte[]) { append((byte[]) lhs, (byte[]) rhs); } else if (lhs instanceof double[]) { append((double[]) lhs, (double[]) rhs); } else if (lhs instanceof float[]) { append((float[]) lhs, (float[]) rhs); } else if (lhs instanceof boolean[]) { append((boolean[]) lhs, (boolean[]) rhs); } else { // Not an array of primitives append((Object[]) lhs, (Object[]) rhs); } return this; }
 private boolean isInlinableObject(List<Reference> refs) { boolean ret = false; Set<String> validProperties = Sets.newHashSet(); for (Reference ref : refs) { Node name = ref.getNode(); Node parent = ref.getParent(); Node gramps = ref.getGrandparent();  // Ignore most indirect references, like x.y (but not x.y(), // since the function referenced by y might reference 'this'). // if (parent.isGetProp()) { Preconditions.checkState(parent.getFirstChild() == name); // A call target may be using the object as a 'this' value. if (gramps.isCall() && gramps.getFirstChild() == parent) { return false; }  // Deleting a property has different semantics from deleting // a variable, so deleted properties should not be inlined.  // NOTE(nicksantos): This pass's object-splitting algorithm has // a blind spot. It assumes that if a property isn't defined on an // object, then the value is undefined. This is not true, because // Object.prototype can have arbitrary properties on it. // // We short-circuit this problem by bailing out if we see a reference // to a property that isn't defined on the object literal. This // isn't a perfect algorithm, but it should catch most cases. String propName = parent.getLastChild().getString(); if (!validProperties.contains(propName)) { if (NodeUtil.isVarOrSimpleAssignLhs(parent, gramps)) { validProperties.add(propName); } else { return false; } } continue; }  // Only rewrite VAR declarations or simple assignment statements if (!isVarOrAssignExprLhs(name)) { return false; }  Node val = ref.getAssignedValue(); if (val == null) { // A var with no assignment. continue; }  // We're looking for object literal assignments only. if (!val.isObjectLit()) { return false; }  // Make sure that the value is not self-referential. IOW, // disallow things like x = {b: x.a}. // // TODO: Only exclude unorderable self-referential // assignments. i.e. x = {a: x.b, b: x.a} is not orderable, // but x = {a: 1, b: x.a} is. // // Also, ES5 getters/setters aren't handled by this pass. for (Node child = val.getFirstChild(); child != null; child = child.getNext()) { if (child.isGetterDef() || child.isSetterDef()) { // ES5 get/set not supported. return false; }  validProperties.add(child.getString());  Node childVal = child.getFirstChild(); // Check if childVal is the parent of any of the passed in // references, as that is how self-referential assignments // will happen. for (Reference t : refs) { Node refNode = t.getParent(); while (!NodeUtil.isStatementBlock(refNode)) { if (refNode == childVal) { // There's a self-referential assignment return false; } refNode = refNode.getParent(); } } }   // We have found an acceptable object literal assignment. As // long as there are no other assignments that mess things up, // we can inline. ret = true; } return ret; }
 public double getNumericalMean() { return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize(); }
 private void inlineNonConstants( Var v, ReferenceCollection referenceInfo, boolean maybeModifiedArguments) { int refCount = referenceInfo.references.size(); Reference declaration = referenceInfo.references.get(0); Reference init = referenceInfo.getInitializingReference(); int firstRefAfterInit = (declaration == init) ? 2 : 3;  if (refCount > 1 && isImmutableAndWellDefinedVariable(v, referenceInfo)) { // if the variable is referenced more than once, we can only // inline it if it's immutable and never defined before referenced. Node value; if (init != null) { value = init.getAssignedValue(); } else { // Create a new node for variable that is never initialized. Node srcLocation = declaration.getNode(); value = NodeUtil.newUndefinedNode(srcLocation); } Preconditions.checkNotNull(value); inlineWellDefinedVariable(v, value, referenceInfo.references); staleVars.add(v); } else if (refCount == firstRefAfterInit) { // The variable likely only read once, try some more // complex inlining heuristics. Reference reference = referenceInfo.references.get( firstRefAfterInit - 1); if (canInline(declaration, init, reference)) { inline(v, declaration, init, reference); staleVars.add(v); } } else if (declaration != init && refCount == 2) { if (isValidDeclaration(declaration) && isValidInitialization(init)) { // The only reference is the initialization, remove the assignment and // the variable declaration. Node value = init.getAssignedValue(); Preconditions.checkNotNull(value); inlineWellDefinedVariable(v, value, referenceInfo.references); staleVars.add(v); } }  // If this variable was not inlined normally, check if we can // inline an alias of it. (If the variable was inlined, then the // reference data is out of sync. We're better off just waiting for // the next pass.) if (!maybeModifiedArguments && !staleVars.contains(v) && referenceInfo.isWellDefined() && referenceInfo.isAssignedOnceInLifetime()) { // Inlining the variable based solely on well-defined and assigned // once is *NOT* correct. We relax the correctness requirement if // the variable is declared constant. List<Reference> refs = referenceInfo.references; for (int i = 1 /* start from a read */; i < refs.size(); i++) { Node nameNode = refs.get(i).getNode(); if (aliasCandidates.containsKey(nameNode)) { AliasCandidate candidate = aliasCandidates.get(nameNode); if (!staleVars.contains(candidate.alias) && !isVarInlineForbidden(candidate.alias)) { Reference aliasInit; aliasInit = candidate.refInfo.getInitializingReference(); Node value = aliasInit.getAssignedValue(); Preconditions.checkNotNull(value); inlineWellDefinedVariable(candidate.alias, value, candidate.refInfo.references); staleVars.add(candidate.alias); } } } } }
 boolean isAssignedOnceInLifetime() { Reference ref = getOneAndOnlyAssignment(); if (ref == null) { return false; }  // Make sure this assignment is not in a loop. for (BasicBlock block = ref.getBasicBlock(); block != null; block = block.getParent()) { if (block.isFunction) { break; } else if (block.isLoop) { return false; } }  return true; }
 static boolean isSimpleNumber(String s) { int len = s.length(); for (int index = 0; index < len; index++) { char c = s.charAt(index); if (c < '0' || c > '9') { return false; } } return len > 0 && s.charAt(0) != '0'; }
 static boolean isSimpleNumber(String s) { int len = s.length(); for (int index = 0; index < len; index++) { char c = s.charAt(index); if (c < '0' || c > '9') { return false; } } return len > 0 && s.charAt(0) != '0'; }
 public OpenMapRealVector ebeDivide(RealVector v) { checkVectorDimensions(v.getDimension()); OpenMapRealVector res = new OpenMapRealVector(this); /* * MATH-803: it is not sufficient to loop through non zero entries of * this only. Indeed, if this[i] = 0d and v[i] = 0d, then * this[i] / v[i] = NaN, and not 0d. */ Iterator iter = entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() / v.getEntry(iter.key())); } return res; }
 public OpenMapRealVector ebeMultiply(RealVector v) { checkVectorDimensions(v.getDimension()); OpenMapRealVector res = new OpenMapRealVector(this); Iterator iter = entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() * v.getEntry(iter.key())); } /* * MATH-803: the above loop assumes that 0d * x  = 0d for any double x, * which allows to consider only the non-zero entries of this. However, * this fails if this[i] == 0d and (v[i] = NaN or v[i] = Infinity). * * These special cases are handled below. */ return res; }
 public String generateToolTipFragment(String toolTipText) { return " title=\"" + toolTipText + "\" alt=\"\""; }
 public StringBuffer format(Calendar calendar, StringBuffer buf) { if (mTimeZoneForced) { calendar = (Calendar) calendar.clone(); calendar.setTimeZone(mTimeZone); } return applyRules(calendar, buf); }
 public static boolean areEqual(Object o1, Object o2) { if (o1 == null || o2 == null) { return o1 == null && o2 == null; } else if (isArray(o1)) { return isArray(o2) && areArraysEqual(o1, o2); } else { return o1.equals(o2); } }
 public double cumulativeProbability(double x) throws MathException { final double dev = x - mean; try { return 0.5 * (1.0 + Erf.erf((dev) / (standardDeviation * FastMath.sqrt(2.0)))); } catch (MaxIterationsExceededException ex) { if (x < (mean - 20 * standardDeviation)) { // JDK 1.5 blows at 38 return 0; } else if (x > (mean + 20 * standardDeviation)) { return 1; } else { throw ex; } } }
 public StrBuilder appendFixedWidthPadRight(Object obj, int width, char padChar) { if (width > 0) { ensureCapacity(size + width); String str = (obj == null ? getNullText() : obj.toString()); int strLen = str.length(); if (strLen >= width) { str.getChars(0, strLen, buffer, size); } else { int padLen = width - strLen; str.getChars(0, strLen, buffer, size); for (int i = 0; i < padLen; i++) { buffer[size + strLen + i] = padChar; } } size += width; } return this; }
 public static double cosh(double x) { if (x != x) { return x; }  // cosh[z] = (exp(z) + exp(-z))/2  // for numbers with magnitude 20 or so, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return 0.5 * exp(-x); }  final double hiPrec[] = new double[2]; if (x < 0.0) { x = -x; } exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  double result = ya + yb; result *= 0.5; return result; }
 public static double cosh(double x) { if (x != x) { return x; }  // cosh[z] = (exp(z) + exp(-z))/2  // for numbers with magnitude 20 or so, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return 0.5 * exp(-x); }  final double hiPrec[] = new double[2]; if (x < 0.0) { x = -x; } exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  double result = ya + yb; result *= 0.5; return result; }
 public static double cosh(double x) { if (x != x) { return x; }  // cosh[z] = (exp(z) + exp(-z))/2  // for numbers with magnitude 20 or so, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return 0.5 * exp(-x); }  final double hiPrec[] = new double[2]; if (x < 0.0) { x = -x; } exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  double result = ya + yb; result *= 0.5; return result; }
 public static double sinh(double x) { boolean negate = false; if (x != x) { return x; }  // sinh[z] = (exp(z) - exp(-z) / 2  // for values of z larger than about 20, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return -0.5 * exp(-x); }  if (x == 0) { return x; }  if (x < 0.0) { x = -x; negate = true; }  double result;  if (x > 0.25) { double hiPrec[] = new double[2]; exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  recipa = -recipa; recipb = -recipb;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  result = ya + yb; result *= 0.5; } else { double hiPrec[] = new double[2]; expm1(x, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  /* Compute expm1(-x) = -expm1(x) / (expm1(x) + 1) */ double denom = 1.0 + ya; double denomr = 1.0 / denom; double denomb = -(denom - 1.0 - ya) + yb; double ratio = ya * denomr; double temp = ratio * HEX_40000000; double ra = ratio + temp - temp; double rb = ratio - ra;  temp = denom * HEX_40000000; double za = denom + temp - temp; double zb = denom - za;  rb += (ya - za*ra - za*rb - zb*ra - zb*rb) * denomr;  // Adjust for yb rb += yb*denomr;                        // numerator rb += -ya * denomb * denomr * denomr;   // denominator  // y = y - 1/y temp = ya + ra; yb += -(temp - ya - ra); ya = temp; temp = ya + rb; yb += -(temp - ya - rb); ya = temp;  result = ya + yb; result *= 0.5; }  if (negate) { result = -result; }  return result; }
 public static double sinh(double x) { boolean negate = false; if (x != x) { return x; }  // sinh[z] = (exp(z) - exp(-z) / 2  // for values of z larger than about 20, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return -0.5 * exp(-x); }  if (x == 0) { return x; }  if (x < 0.0) { x = -x; negate = true; }  double result;  if (x > 0.25) { double hiPrec[] = new double[2]; exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  recipa = -recipa; recipb = -recipb;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  result = ya + yb; result *= 0.5; } else { double hiPrec[] = new double[2]; expm1(x, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  /* Compute expm1(-x) = -expm1(x) / (expm1(x) + 1) */ double denom = 1.0 + ya; double denomr = 1.0 / denom; double denomb = -(denom - 1.0 - ya) + yb; double ratio = ya * denomr; double temp = ratio * HEX_40000000; double ra = ratio + temp - temp; double rb = ratio - ra;  temp = denom * HEX_40000000; double za = denom + temp - temp; double zb = denom - za;  rb += (ya - za*ra - za*rb - zb*ra - zb*rb) * denomr;  // Adjust for yb rb += yb*denomr;                        // numerator rb += -ya * denomb * denomr * denomr;   // denominator  // y = y - 1/y temp = ya + ra; yb += -(temp - ya - ra); ya = temp; temp = ya + rb; yb += -(temp - ya - rb); ya = temp;  result = ya + yb; result *= 0.5; }  if (negate) { result = -result; }  return result; }
 public static double sinh(double x) { boolean negate = false; if (x != x) { return x; }  // sinh[z] = (exp(z) - exp(-z) / 2  // for values of z larger than about 20, // exp(-z) can be ignored in comparison with exp(z)  if (x > 20) { // Avoid overflow (MATH-905). return 0.5 * exp(x); } if (x < -20) { // Avoid overflow (MATH-905). return -0.5 * exp(-x); }  if (x == 0) { return x; }  if (x < 0.0) { x = -x; negate = true; }  double result;  if (x > 0.25) { double hiPrec[] = new double[2]; exp(x, 0.0, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  double temp = ya * HEX_40000000; double yaa = ya + temp - temp; double yab = ya - yaa;  // recip = 1/y double recip = 1.0/ya; temp = recip * HEX_40000000; double recipa = recip + temp - temp; double recipb = recip - recipa;  // Correct for rounding in division recipb += (1.0 - yaa*recipa - yaa*recipb - yab*recipa - yab*recipb) * recip; // Account for yb recipb += -yb * recip * recip;  recipa = -recipa; recipb = -recipb;  // y = y + 1/y temp = ya + recipa; yb += -(temp - ya - recipa); ya = temp; temp = ya + recipb; yb += -(temp - ya - recipb); ya = temp;  result = ya + yb; result *= 0.5; } else { double hiPrec[] = new double[2]; expm1(x, hiPrec);  double ya = hiPrec[0] + hiPrec[1]; double yb = -(ya - hiPrec[0] - hiPrec[1]);  /* Compute expm1(-x) = -expm1(x) / (expm1(x) + 1) */ double denom = 1.0 + ya; double denomr = 1.0 / denom; double denomb = -(denom - 1.0 - ya) + yb; double ratio = ya * denomr; double temp = ratio * HEX_40000000; double ra = ratio + temp - temp; double rb = ratio - ra;  temp = denom * HEX_40000000; double za = denom + temp - temp; double zb = denom - za;  rb += (ya - za*ra - za*rb - zb*ra - zb*rb) * denomr;  // Adjust for yb rb += yb*denomr;                        // numerator rb += -ya * denomb * denomr * denomr;   // denominator  // y = y - 1/y temp = ya + ra; yb += -(temp - ya - ra); ya = temp; temp = ya + rb; yb += -(temp - ya - rb); ya = temp;  result = ya + yb; result *= 0.5; }  if (negate) { result = -result; }  return result; }
 public final void translate(CharSequence input, Writer out) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (input == null) { return; } int pos = 0; int len = Character.codePointCount(input, 0, input.length()); while (pos < len) { int consumed = translate(input, pos, out); if (consumed == 0) { char[] c = Character.toChars(Character.codePointAt(input, pos)); out.write(c); } else { //          // contract with translators is that they have to understand codepoints //          // and they just took care of a surrogate pair for (int pt = 0; pt < consumed; pt++) { if (pos < len - 2) { pos += Character.charCount(Character.codePointAt(input, pos)); } else { pos++; } } pos--; } pos++; } }
 public final void translate(CharSequence input, Writer out) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (input == null) { return; } int pos = 0; int len = Character.codePointCount(input, 0, input.length()); while (pos < len) { int consumed = translate(input, pos, out); if (consumed == 0) { char[] c = Character.toChars(Character.codePointAt(input, pos)); out.write(c); } else { //          // contract with translators is that they have to understand codepoints //          // and they just took care of a surrogate pair for (int pt = 0; pt < consumed; pt++) { if (pos < len - 2) { pos += Character.charCount(Character.codePointAt(input, pos)); } else { pos++; } } pos--; } pos++; } }
 private Node tryFoldArrayJoin(Node n) { Node callTarget = n.getFirstChild();  if (callTarget == null || !NodeUtil.isGetProp(callTarget)) { return n; }  Node right = callTarget.getNext(); if (right != null) { if (!NodeUtil.isImmutableValue(right)) { return n; } }  Node arrayNode = callTarget.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return n; }  // "," is the default, it doesn't need to be explicit  String joinString = (right == null) ? "," : NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = null; int foldedSize = 0; Node prev = null; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem) || elem.getType() == Token.EMPTY) { if (sb == null) { sb = new StringBuilder(); } else { sb.append(joinString); } sb.append(NodeUtil.getArrayElementStringValue(elem)); } else { if (sb != null) { Preconditions.checkNotNull(prev); // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add( Node.newString(sb.toString()).copyInformationFrom(prev)); sb = null; } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } prev = elem; elem = elem.getNext(); }  if (sb != null) { Preconditions.checkNotNull(prev); // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add( Node.newString(sb.toString()).copyInformationFrom(prev)); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); n.getParent().replaceChild(n, emptyStringNode); reportCodeChange(); return emptyStringNode; case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return n; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString("").copyInformationFrom(n), foldedStringNode); foldedStringNode = replacement; } n.getParent().replaceChild(n, foldedStringNode); reportCodeChange(); return foldedStringNode; default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return n; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += (right != null) ? InlineCostEstimator.getCost(right) : 0; if (foldedSize > originalSize) { return n; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } reportCodeChange(); break; }  return n; }
 private Node tryFoldArrayJoin(Node n) { Node callTarget = n.getFirstChild();  if (callTarget == null || !NodeUtil.isGetProp(callTarget)) { return n; }  Node right = callTarget.getNext(); if (right != null) { if (!NodeUtil.isImmutableValue(right)) { return n; } }  Node arrayNode = callTarget.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return n; }  // "," is the default, it doesn't need to be explicit  String joinString = (right == null) ? "," : NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = null; int foldedSize = 0; Node prev = null; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem) || elem.getType() == Token.EMPTY) { if (sb == null) { sb = new StringBuilder(); } else { sb.append(joinString); } sb.append(NodeUtil.getArrayElementStringValue(elem)); } else { if (sb != null) { Preconditions.checkNotNull(prev); // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add( Node.newString(sb.toString()).copyInformationFrom(prev)); sb = null; } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } prev = elem; elem = elem.getNext(); }  if (sb != null) { Preconditions.checkNotNull(prev); // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add( Node.newString(sb.toString()).copyInformationFrom(prev)); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); n.getParent().replaceChild(n, emptyStringNode); reportCodeChange(); return emptyStringNode; case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return n; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString("").copyInformationFrom(n), foldedStringNode); foldedStringNode = replacement; } n.getParent().replaceChild(n, foldedStringNode); reportCodeChange(); return foldedStringNode; default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return n; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += (right != null) ? InlineCostEstimator.getCost(right) : 0; if (foldedSize > originalSize) { return n; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } reportCodeChange(); break; }  return n; }
 public double percentageValue() { return multiply(100).doubleValue(); }
 protected static int between(ReadablePartial start, ReadablePartial end, ReadablePeriod zeroInstance) { if (start == null || end == null) { throw new IllegalArgumentException("ReadablePartial objects must not be null"); } if (start.size() != end.size()) { throw new IllegalArgumentException("ReadablePartial objects must have the same set of fields"); } for (int i = 0, isize = start.size(); i < isize; i++) { if (start.getFieldType(i) != end.getFieldType(i)) { throw new IllegalArgumentException("ReadablePartial objects must have the same set of fields"); } } if (DateTimeUtils.isContiguous(start) == false) { throw new IllegalArgumentException("ReadablePartial objects must be contiguous"); } Chronology chrono = DateTimeUtils.getChronology(start.getChronology()).withUTC(); int[] values = chrono.get(zeroInstance, chrono.set(start, 0L), chrono.set(end, 0L)); return values[0]; }
 public int translate(CharSequence input, int index, Writer out) throws IOException { // TODO: Protect from ArrayIndexOutOfBounds if(input.charAt(index) == '&' && input.charAt(index + 1) == '#') { int start = index + 2; boolean isHex = false;  char firstChar = input.charAt(start); if(firstChar == 'x' || firstChar == 'X') { start++; isHex = true; }  int end = start; while(input.charAt(end) != ';') { end++; }  int entityValue; try { if(isHex) { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 16); } else { entityValue = Integer.parseInt(input.subSequence(start, end).toString(), 10); } } catch(NumberFormatException nfe) { return 0; }  out.write(entityValue); return 2 + (end - start) + (isHex ? 1 : 0) + 1; } return 0; }
 public void captureArgumentsFrom(Invocation invocation) { if (invocation.getMethod().isVarArgs()) { int indexOfVararg = invocation.getRawArguments().length - 1; throw new UnsupportedOperationException();  } else { for (int position = 0; position < matchers.size(); position++) { Matcher m = matchers.get(position); if (m instanceof CapturesArguments) { ((CapturesArguments) m).captureFrom(invocation.getArgumentAt(position, Object.class)); } } }  //        for (int position = 0; position < matchers.size(); position++) { //            Matcher m = matchers.get(position); //            if (m instanceof CapturesArguments && invocation.getRawArguments().length > position) { //                //TODO SF - this whole lot can be moved captureFrom implementation //                if(isVariableArgument(invocation, position) && isVarargMatcher(m)) { //                    Object array = invocation.getRawArguments()[position]; //                    for (int i = 0; i < Array.getLength(array); i++) { //                        ((CapturesArguments) m).captureFrom(Array.get(array, i)); //                    } //                    //since we've captured all varargs already, it does not make sense to process other matchers. //                    return; //                } else { //                    ((CapturesArguments) m).captureFrom(invocation.getRawArguments()[position]); //                } //            } //        } }
 private boolean toStringEquals(Matcher m, Object arg) { return StringDescription.toString(m).equals(arg.toString()); }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; VectorialPointValuePair current = new VectorialPointValuePair(point, objective); while (true) { incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix VectorialPointValuePair previous = current; updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals); // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return current; }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm); // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost(); current = new VectorialPointValuePair(point, objective);  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm);  // tests for convergence. // we use the vectorial convergence checker } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; } if (checker==null) { if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return current; } } else { if (checker.converged(getIterations(), previous, current)) { return current; } } // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance); }  }  }  }
 public Rotation(Vector3D u1, Vector3D u2, Vector3D v1, Vector3D v2) {  // norms computation double u1u1 = u1.getNormSq(); double u2u2 = u2.getNormSq(); double v1v1 = v1.getNormSq(); double v2v2 = v2.getNormSq(); if ((u1u1 == 0) || (u2u2 == 0) || (v1v1 == 0) || (v2v2 == 0)) { throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.ZERO_NORM_FOR_ROTATION_DEFINING_VECTOR); }  // normalize v1 in order to have (v1'|v1') = (u1|u1) v1 = new Vector3D(FastMath.sqrt(u1u1 / v1v1), v1);  // adjust v2 in order to have (u1|u2) = (v1'|v2') and (v2'|v2') = (u2|u2) double u1u2   = u1.dotProduct(u2); double v1v2   = v1.dotProduct(v2); double coeffU = u1u2 / u1u1; double coeffV = v1v2 / u1u1; double beta   = FastMath.sqrt((u2u2 - u1u2 * coeffU) / (v2v2 - v1v2 * coeffV)); double alpha  = coeffU - beta * coeffV; v2 = new Vector3D(alpha, v1, beta, v2);  // preliminary computation Vector3D uRef  = u1; Vector3D vRef  = v1; Vector3D v1Su1 = v1.subtract(u1); Vector3D v2Su2 = v2.subtract(u2); Vector3D k     = v1Su1.crossProduct(v2Su2); Vector3D u3    = u1.crossProduct(u2); double c       = k.dotProduct(u3); if (c == 0) { // the (q1, q2, q3) vector is close to the (u1, u2) plane // we try other vectors Vector3D v3 = Vector3D.crossProduct(v1, v2); Vector3D v3Su3 = v3.subtract(u3); k = v1Su1.crossProduct(v3Su3); Vector3D u2Prime = u1.crossProduct(u3); c = k.dotProduct(u2Prime);  if (c == 0) { // the (q1, q2, q3) vector is also close to the (u1, u3) plane, // it is almost aligned with u1: we try (u2, u3) and (v2, v3) k = v2Su2.crossProduct(v3Su3);; c = k.dotProduct(u2.crossProduct(u3));;  if (c == 0) { // the (q1, q2, q3) vector is aligned with everything // this is really the identity rotation q0 = 1.0; q1 = 0.0; q2 = 0.0; q3 = 0.0; return; }  // we will have to use u2 and v2 to compute the scalar part uRef = u2; vRef = v2;  }  }  // compute the vectorial part c = FastMath.sqrt(c); double inv = 1.0 / (c + c); q1 = inv * k.getX(); q2 = inv * k.getY(); q3 = inv * k.getZ();  // compute the scalar part k = new Vector3D(uRef.getY() * q3 - uRef.getZ() * q2, uRef.getZ() * q1 - uRef.getX() * q3, uRef.getX() * q2 - uRef.getY() * q1); q0 = vRef.dotProduct(k) / (2 * k.getNormSq());  }
 public Rotation(Vector3D u1, Vector3D u2, Vector3D v1, Vector3D v2) {  // norms computation double u1u1 = u1.getNormSq(); double u2u2 = u2.getNormSq(); double v1v1 = v1.getNormSq(); double v2v2 = v2.getNormSq(); if ((u1u1 == 0) || (u2u2 == 0) || (v1v1 == 0) || (v2v2 == 0)) { throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.ZERO_NORM_FOR_ROTATION_DEFINING_VECTOR); }  // normalize v1 in order to have (v1'|v1') = (u1|u1) v1 = new Vector3D(FastMath.sqrt(u1u1 / v1v1), v1);  // adjust v2 in order to have (u1|u2) = (v1'|v2') and (v2'|v2') = (u2|u2) double u1u2   = u1.dotProduct(u2); double v1v2   = v1.dotProduct(v2); double coeffU = u1u2 / u1u1; double coeffV = v1v2 / u1u1; double beta   = FastMath.sqrt((u2u2 - u1u2 * coeffU) / (v2v2 - v1v2 * coeffV)); double alpha  = coeffU - beta * coeffV; v2 = new Vector3D(alpha, v1, beta, v2);  // preliminary computation Vector3D uRef  = u1; Vector3D vRef  = v1; Vector3D v1Su1 = v1.subtract(u1); Vector3D v2Su2 = v2.subtract(u2); Vector3D k     = v1Su1.crossProduct(v2Su2); Vector3D u3    = u1.crossProduct(u2); double c       = k.dotProduct(u3); if (c == 0) { // the (q1, q2, q3) vector is close to the (u1, u2) plane // we try other vectors Vector3D v3 = Vector3D.crossProduct(v1, v2); Vector3D v3Su3 = v3.subtract(u3); k = v1Su1.crossProduct(v3Su3); Vector3D u2Prime = u1.crossProduct(u3); c = k.dotProduct(u2Prime);  if (c == 0) { // the (q1, q2, q3) vector is also close to the (u1, u3) plane, // it is almost aligned with u1: we try (u2, u3) and (v2, v3) k = v2Su2.crossProduct(v3Su3);; c = k.dotProduct(u2.crossProduct(u3));;  if (c == 0) { // the (q1, q2, q3) vector is aligned with everything // this is really the identity rotation q0 = 1.0; q1 = 0.0; q2 = 0.0; q3 = 0.0; return; }  // we will have to use u2 and v2 to compute the scalar part uRef = u2; vRef = v2;  }  }  // compute the vectorial part c = FastMath.sqrt(c); double inv = 1.0 / (c + c); q1 = inv * k.getX(); q2 = inv * k.getY(); q3 = inv * k.getZ();  // compute the scalar part k = new Vector3D(uRef.getY() * q3 - uRef.getZ() * q2, uRef.getZ() * q1 - uRef.getX() * q3, uRef.getX() * q2 - uRef.getY() * q1); q0 = vRef.dotProduct(k) / (2 * k.getNormSq());  }
 public Rotation(Vector3D u1, Vector3D u2, Vector3D v1, Vector3D v2) {  // norms computation double u1u1 = u1.getNormSq(); double u2u2 = u2.getNormSq(); double v1v1 = v1.getNormSq(); double v2v2 = v2.getNormSq(); if ((u1u1 == 0) || (u2u2 == 0) || (v1v1 == 0) || (v2v2 == 0)) { throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.ZERO_NORM_FOR_ROTATION_DEFINING_VECTOR); }  // normalize v1 in order to have (v1'|v1') = (u1|u1) v1 = new Vector3D(FastMath.sqrt(u1u1 / v1v1), v1);  // adjust v2 in order to have (u1|u2) = (v1'|v2') and (v2'|v2') = (u2|u2) double u1u2   = u1.dotProduct(u2); double v1v2   = v1.dotProduct(v2); double coeffU = u1u2 / u1u1; double coeffV = v1v2 / u1u1; double beta   = FastMath.sqrt((u2u2 - u1u2 * coeffU) / (v2v2 - v1v2 * coeffV)); double alpha  = coeffU - beta * coeffV; v2 = new Vector3D(alpha, v1, beta, v2);  // preliminary computation Vector3D uRef  = u1; Vector3D vRef  = v1; Vector3D v1Su1 = v1.subtract(u1); Vector3D v2Su2 = v2.subtract(u2); Vector3D k     = v1Su1.crossProduct(v2Su2); Vector3D u3    = u1.crossProduct(u2); double c       = k.dotProduct(u3); if (c == 0) { // the (q1, q2, q3) vector is close to the (u1, u2) plane // we try other vectors Vector3D v3 = Vector3D.crossProduct(v1, v2); Vector3D v3Su3 = v3.subtract(u3); k = v1Su1.crossProduct(v3Su3); Vector3D u2Prime = u1.crossProduct(u3); c = k.dotProduct(u2Prime);  if (c == 0) { // the (q1, q2, q3) vector is also close to the (u1, u3) plane, // it is almost aligned with u1: we try (u2, u3) and (v2, v3) k = v2Su2.crossProduct(v3Su3);; c = k.dotProduct(u2.crossProduct(u3));;  if (c == 0) { // the (q1, q2, q3) vector is aligned with everything // this is really the identity rotation q0 = 1.0; q1 = 0.0; q2 = 0.0; q3 = 0.0; return; }  // we will have to use u2 and v2 to compute the scalar part uRef = u2; vRef = v2;  }  }  // compute the vectorial part c = FastMath.sqrt(c); double inv = 1.0 / (c + c); q1 = inv * k.getX(); q2 = inv * k.getY(); q3 = inv * k.getZ();  // compute the scalar part k = new Vector3D(uRef.getY() * q3 - uRef.getZ() * q2, uRef.getZ() * q1 - uRef.getX() * q3, uRef.getX() * q2 - uRef.getY() * q1); q0 = vRef.dotProduct(k) / (2 * k.getNormSq());  }
 public <T> T createMock(MockCreationSettings<T> settings, MockHandler handler) { if (settings.getSerializableMode() == SerializableMode.ACROSS_CLASSLOADERS) { throw new MockitoException("Serialization across classloaders not yet supported with ByteBuddyMockMaker"); } Class<? extends T> mockedProxyType = cachingMockBytecodeGenerator.get( settings.getTypeToMock(), settings.getExtraInterfaces() ); T mockInstance = null; try { mockInstance = classInstantiator.instantiate(mockedProxyType); MockMethodInterceptor.MockAccess mockAccess = (MockMethodInterceptor.MockAccess) mockInstance; mockAccess.setMockitoInterceptor(new MockMethodInterceptor(asInternalMockHandler(handler), settings));  return ensureMockIsAssignableToMockedType(settings, mockInstance); } catch (ClassCastException cce) { throw new MockitoException(join( "ClassCastException occurred while creating the mockito mock :", "  class to mock : " + describeClass(mockedProxyType), "  created class : " + describeClass(settings.getTypeToMock()), "  proxy instance class : " + describeClass(mockInstance), "  instance creation by : " + classInstantiator.getClass().getSimpleName(), "", "You might experience classloading issues, please ask the mockito mailing-list.", "" ),cce); } catch (org.mockito.internal.creation.instance.InstantiationException e) { throw new MockitoException("Unable to create mock instance of type '" + mockedProxyType.getSuperclass().getSimpleName() + "'", e); } }
 public <T> T createMock(MockCreationSettings<T> settings, MockHandler handler) { if (settings.getSerializableMode() == SerializableMode.ACROSS_CLASSLOADERS) { throw new MockitoException("Serialization across classloaders not yet supported with ByteBuddyMockMaker"); } Class<? extends T> mockedProxyType = cachingMockBytecodeGenerator.get( settings.getTypeToMock(), settings.getExtraInterfaces() ); T mockInstance = null; try { mockInstance = classInstantiator.instantiate(mockedProxyType); MockMethodInterceptor.MockAccess mockAccess = (MockMethodInterceptor.MockAccess) mockInstance; mockAccess.setMockitoInterceptor(new MockMethodInterceptor(asInternalMockHandler(handler), settings));  return ensureMockIsAssignableToMockedType(settings, mockInstance); } catch (ClassCastException cce) { throw new MockitoException(join( "ClassCastException occurred while creating the mockito mock :", "  class to mock : " + describeClass(mockedProxyType), "  created class : " + describeClass(settings.getTypeToMock()), "  proxy instance class : " + describeClass(mockInstance), "  instance creation by : " + classInstantiator.getClass().getSimpleName(), "", "You might experience classloading issues, please ask the mockito mailing-list.", "" ),cce); } catch (org.mockito.internal.creation.instance.InstantiationException e) { throw new MockitoException("Unable to create mock instance of type '" + mockedProxyType.getSuperclass().getSimpleName() + "'", e); } }
 static boolean evaluatesToLocalValue(Node value, Predicate<Node> locals) { switch (value.getType()) { case Token.ASSIGN: // A result that is aliased by a non-local name, is the effectively the // same as returning a non-local name, but this doesn't matter if the // value is immutable. return NodeUtil.isImmutableValue(value.getLastChild()) || (locals.apply(value) && evaluatesToLocalValue(value.getLastChild(), locals)); case Token.COMMA: return evaluatesToLocalValue(value.getLastChild(), locals); case Token.AND: case Token.OR: return evaluatesToLocalValue(value.getFirstChild(), locals) && evaluatesToLocalValue(value.getLastChild(), locals); case Token.HOOK: return evaluatesToLocalValue(value.getFirstChild().getNext(), locals) && evaluatesToLocalValue(value.getLastChild(), locals); case Token.INC: case Token.DEC: if (value.getBooleanProp(Node.INCRDECR_PROP)) { return evaluatesToLocalValue(value.getFirstChild(), locals); } else { return true; } case Token.THIS: return locals.apply(value); case Token.NAME: return isImmutableValue(value) || locals.apply(value); case Token.GETELEM: case Token.GETPROP: // There is no information about the locality of object properties. return locals.apply(value); case Token.CALL: return callHasLocalResult(value) || isToStringMethodCall(value) || locals.apply(value); case Token.NEW: // TODO(nicksantos): This needs to be changed so that it // returns true iff we're sure the value was never aliased from inside // the constructor (similar to callHasLocalResult) return true; case Token.FUNCTION: case Token.REGEXP: case Token.ARRAYLIT: case Token.OBJECTLIT: // Literals objects with non-literal children are allowed. return true; case Token.IN: // TODO(johnlenz): should IN operator be included in #isSimpleOperator? return true; default: // Other op force a local value: //  x = '' + g (x is now an local string) //  x -= g (x is now an local number) if (isAssignmentOp(value) || isSimpleOperator(value) || isImmutableValue(value)) { return true; }  throw new IllegalStateException( "Unexpected expression node" + value + "\n parent:" + value.getParent()); } }
 public Iterator<Chromosome> iterator() { return chromosomes.iterator(); }
 public static Range iterateDomainBounds(XYDataset dataset, boolean includeInterval) { if (dataset == null) { throw new IllegalArgumentException("Null 'dataset' argument."); } double minimum = Double.POSITIVE_INFINITY; double maximum = Double.NEGATIVE_INFINITY; int seriesCount = dataset.getSeriesCount(); double lvalue; double uvalue; if (includeInterval && dataset instanceof IntervalXYDataset) { IntervalXYDataset intervalXYData = (IntervalXYDataset) dataset; for (int series = 0; series < seriesCount; series++) { int itemCount = dataset.getItemCount(series); for (int item = 0; item < itemCount; item++) { lvalue = intervalXYData.getStartXValue(series, item); uvalue = intervalXYData.getEndXValue(series, item); if (!Double.isNaN(lvalue)) { minimum = Math.min(minimum, lvalue); } if (!Double.isNaN(uvalue)) { maximum = Math.max(maximum, uvalue); } } } } else { for (int series = 0; series < seriesCount; series++) { int itemCount = dataset.getItemCount(series); for (int item = 0; item < itemCount; item++) { lvalue = dataset.getXValue(series, item); uvalue = lvalue; if (!Double.isNaN(lvalue)) { minimum = Math.min(minimum, lvalue); maximum = Math.max(maximum, uvalue); } } } } if (minimum > maximum) { return null; } else { return new Range(minimum, maximum); } }
 public static Range iterateRangeBounds(XYDataset dataset, boolean includeInterval) { double minimum = Double.POSITIVE_INFINITY; double maximum = Double.NEGATIVE_INFINITY; int seriesCount = dataset.getSeriesCount();  // handle three cases by dataset type if (includeInterval && dataset instanceof IntervalXYDataset) { // handle special case of IntervalXYDataset IntervalXYDataset ixyd = (IntervalXYDataset) dataset; for (int series = 0; series < seriesCount; series++) { int itemCount = dataset.getItemCount(series); for (int item = 0; item < itemCount; item++) { double lvalue = ixyd.getStartYValue(series, item); double uvalue = ixyd.getEndYValue(series, item); if (!Double.isNaN(lvalue)) { minimum = Math.min(minimum, lvalue); } if (!Double.isNaN(uvalue)) { maximum = Math.max(maximum, uvalue); } } } } else if (includeInterval && dataset instanceof OHLCDataset) { // handle special case of OHLCDataset OHLCDataset ohlc = (OHLCDataset) dataset; for (int series = 0; series < seriesCount; series++) { int itemCount = dataset.getItemCount(series); for (int item = 0; item < itemCount; item++) { double lvalue = ohlc.getLowValue(series, item); double uvalue = ohlc.getHighValue(series, item); if (!Double.isNaN(lvalue)) { minimum = Math.min(minimum, lvalue); } if (!Double.isNaN(uvalue)) { maximum = Math.max(maximum, uvalue); } } } } else { // standard case - plain XYDataset for (int series = 0; series < seriesCount; series++) { int itemCount = dataset.getItemCount(series); for (int item = 0; item < itemCount; item++) { double value = dataset.getYValue(series, item); if (!Double.isNaN(value)) { minimum = Math.min(minimum, value); maximum = Math.max(maximum, value); } } } } if (minimum == Double.POSITIVE_INFINITY) { return null; } else { return new Range(minimum, maximum); } }
 public void visit(NodeTraversal t, Node n, Node parent) { // VOID nodes appear when there are extra semicolons at the BLOCK level. // I've been unable to think of any cases where this indicates a bug, // and apparently some people like keeping these semicolons around, // so we'll allow it. if (n.isEmpty() || n.isComma()) { return; }  if (parent == null) { return; }  // Do not try to remove a block or an expr result. We already handle // these cases when we visit the child, and the peephole passes will // fix up the tree in more clever ways when these are removed. if (n.isExprResult()) { return; }  // This no-op statement was there so that JSDoc information could // be attached to the name. This check should not complain about it. if (n.isQualifiedName() && n.getJSDocInfo() != null) { return; }  boolean isResultUsed = NodeUtil.isExpressionResultUsed(n); boolean isSimpleOp = NodeUtil.isSimpleOperatorType(n.getType()); if (parent.getType() == Token.COMMA) { if (isResultUsed) { return; } if (n == parent.getLastChild()) { for (Node an : parent.getAncestors()) { int ancestorType = an.getType(); if (ancestorType == Token.COMMA) continue; if (ancestorType != Token.EXPR_RESULT && ancestorType != Token.BLOCK) return; else break; } } } else if (parent.getType() != Token.EXPR_RESULT && parent.getType() != Token.BLOCK) { if (! (parent.getType() == Token.FOR && parent.getChildCount() == 4 && (n == parent.getFirstChild() || n == parent.getFirstChild().getNext().getNext()))) { return; } } if ( (isSimpleOp || !NodeUtil.mayHaveSideEffects(n, t.getCompiler()))) { String msg = "This code lacks side-effects. Is there a bug?"; if (n.isString()) { msg = "Is there a missing '+' on the previous line?"; } else if (isSimpleOp) { msg = "The result of the '" + Token.name(n.getType()).toLowerCase() + "' operator is not being used."; }  t.getCompiler().report( t.makeError(n, level, USELESS_CODE_ERROR, msg)); // TODO(johnlenz): determine if it is necessary to // try to protect side-effect free statements as well. if (!NodeUtil.isStatement(n)) { problemNodes.add(n); } } }
 public void visit(NodeTraversal t, Node n, Node parent) { // VOID nodes appear when there are extra semicolons at the BLOCK level. // I've been unable to think of any cases where this indicates a bug, // and apparently some people like keeping these semicolons around, // so we'll allow it. if (n.isEmpty() || n.isComma()) { return; }  if (parent == null) { return; }  // Do not try to remove a block or an expr result. We already handle // these cases when we visit the child, and the peephole passes will // fix up the tree in more clever ways when these are removed. if (n.isExprResult()) { return; }  // This no-op statement was there so that JSDoc information could // be attached to the name. This check should not complain about it. if (n.isQualifiedName() && n.getJSDocInfo() != null) { return; }  boolean isResultUsed = NodeUtil.isExpressionResultUsed(n); boolean isSimpleOp = NodeUtil.isSimpleOperatorType(n.getType()); if (parent.getType() == Token.COMMA) { if (isResultUsed) { return; } if (n == parent.getLastChild()) { for (Node an : parent.getAncestors()) { int ancestorType = an.getType(); if (ancestorType == Token.COMMA) continue; if (ancestorType != Token.EXPR_RESULT && ancestorType != Token.BLOCK) return; else break; } } } else if (parent.getType() != Token.EXPR_RESULT && parent.getType() != Token.BLOCK) { if (! (parent.getType() == Token.FOR && parent.getChildCount() == 4 && (n == parent.getFirstChild() || n == parent.getFirstChild().getNext().getNext()))) { return; } } if ( (isSimpleOp || !NodeUtil.mayHaveSideEffects(n, t.getCompiler()))) { String msg = "This code lacks side-effects. Is there a bug?"; if (n.isString()) { msg = "Is there a missing '+' on the previous line?"; } else if (isSimpleOp) { msg = "The result of the '" + Token.name(n.getType()).toLowerCase() + "' operator is not being used."; }  t.getCompiler().report( t.makeError(n, level, USELESS_CODE_ERROR, msg)); // TODO(johnlenz): determine if it is necessary to // try to protect side-effect free statements as well. if (!NodeUtil.isStatement(n)) { problemNodes.add(n); } } }
 protected List<Rule> parsePattern() { DateFormatSymbols symbols = new DateFormatSymbols(mLocale); List<Rule> rules = new ArrayList<Rule>();  String[] ERAs = symbols.getEras(); String[] months = symbols.getMonths(); String[] shortMonths = symbols.getShortMonths(); String[] weekdays = symbols.getWeekdays(); String[] shortWeekdays = symbols.getShortWeekdays(); String[] AmPmStrings = symbols.getAmPmStrings();  int length = mPattern.length(); int[] indexRef = new int[1];  for (int i = 0; i < length; i++) { indexRef[0] = i; String token = parseToken(mPattern, indexRef); i = indexRef[0];  int tokenLen = token.length(); if (tokenLen == 0) { break; }  Rule rule; char c = token.charAt(0);  switch (c) { case 'G': // era designator (text) rule = new TextField(Calendar.ERA, ERAs); break; case 'y': // year (number) if (tokenLen >= 4) { rule = selectNumberRule(Calendar.YEAR, tokenLen); } else { rule = TwoDigitYearField.INSTANCE; } break; case 'M': // month in year (text and number) if (tokenLen >= 4) { rule = new TextField(Calendar.MONTH, months); } else if (tokenLen == 3) { rule = new TextField(Calendar.MONTH, shortMonths); } else if (tokenLen == 2) { rule = TwoDigitMonthField.INSTANCE; } else { rule = UnpaddedMonthField.INSTANCE; } break; case 'd': // day in month (number) rule = selectNumberRule(Calendar.DAY_OF_MONTH, tokenLen); break; case 'h': // hour in am/pm (number, 1..12) rule = new TwelveHourField(selectNumberRule(Calendar.HOUR, tokenLen)); break; case 'H': // hour in day (number, 0..23) rule = selectNumberRule(Calendar.HOUR_OF_DAY, tokenLen); break; case 'm': // minute in hour (number) rule = selectNumberRule(Calendar.MINUTE, tokenLen); break; case 's': // second in minute (number) rule = selectNumberRule(Calendar.SECOND, tokenLen); break; case 'S': // millisecond (number) rule = selectNumberRule(Calendar.MILLISECOND, tokenLen); break; case 'E': // day in week (text) rule = new TextField(Calendar.DAY_OF_WEEK, tokenLen < 4 ? shortWeekdays : weekdays); break; case 'D': // day in year (number) rule = selectNumberRule(Calendar.DAY_OF_YEAR, tokenLen); break; case 'F': // day of week in month (number) rule = selectNumberRule(Calendar.DAY_OF_WEEK_IN_MONTH, tokenLen); break; case 'w': // week in year (number) rule = selectNumberRule(Calendar.WEEK_OF_YEAR, tokenLen); break; case 'W': // week in month (number) rule = selectNumberRule(Calendar.WEEK_OF_MONTH, tokenLen); break; case 'a': // am/pm marker (text) rule = new TextField(Calendar.AM_PM, AmPmStrings); break; case 'k': // hour in day (1..24) rule = new TwentyFourHourField(selectNumberRule(Calendar.HOUR_OF_DAY, tokenLen)); break; case 'K': // hour in am/pm (0..11) rule = selectNumberRule(Calendar.HOUR, tokenLen); break; case 'z': // time zone (text) if (tokenLen >= 4) { rule = new TimeZoneNameRule(mTimeZone, mLocale, TimeZone.LONG); } else { rule = new TimeZoneNameRule(mTimeZone, mLocale, TimeZone.SHORT); } break; case 'Z': // time zone (value) if (tokenLen == 1) { rule = TimeZoneNumberRule.INSTANCE_NO_COLON; } else { rule = TimeZoneNumberRule.INSTANCE_COLON; } break; case '\'': // literal text String sub = token.substring(1); if (sub.length() == 1) { rule = new CharacterLiteral(sub.charAt(0)); } else { rule = new StringLiteral(sub); } break; default: throw new IllegalArgumentException("Illegal pattern component: " + token); }  rules.add(rule); }  return rules; }
 public static <T> T[] addAll(T[] array1, T... array2) { if (array1 == null) { return clone(array2); } else if (array2 == null) { return clone(array1); } final Class<?> type1 = array1.getClass().getComponentType(); T[] joinedArray = (T[]) Array.newInstance(type1, array1.length + array2.length); System.arraycopy(array1, 0, joinedArray, 0, array1.length); System.arraycopy(array2, 0, joinedArray, array1.length, array2.length); // Check if problem is incompatible types return joinedArray; }
 public Range getDataRange(ValueAxis axis) {  Range result = null; List mappedDatasets = new ArrayList(); List includedAnnotations = new ArrayList(); boolean isDomainAxis = true;  // is it a domain axis? int domainIndex = getDomainAxisIndex(axis); if (domainIndex >= 0) { isDomainAxis = true; mappedDatasets.addAll(getDatasetsMappedToDomainAxis( new Integer(domainIndex))); if (domainIndex == 0) { // grab the plot's annotations Iterator iterator = this.annotations.iterator(); while (iterator.hasNext()) { XYAnnotation annotation = (XYAnnotation) iterator.next(); if (annotation instanceof XYAnnotationBoundsInfo) { includedAnnotations.add(annotation); } } } }  // or is it a range axis? int rangeIndex = getRangeAxisIndex(axis); if (rangeIndex >= 0) { isDomainAxis = false; mappedDatasets.addAll(getDatasetsMappedToRangeAxis( new Integer(rangeIndex))); if (rangeIndex == 0) { Iterator iterator = this.annotations.iterator(); while (iterator.hasNext()) { XYAnnotation annotation = (XYAnnotation) iterator.next(); if (annotation instanceof XYAnnotationBoundsInfo) { includedAnnotations.add(annotation); } } } }  // iterate through the datasets that map to the axis and get the union // of the ranges. Iterator iterator = mappedDatasets.iterator(); while (iterator.hasNext()) { XYDataset d = (XYDataset) iterator.next(); if (d != null) { XYItemRenderer r = getRendererForDataset(d); if (isDomainAxis) { if (r != null) { result = Range.combine(result, r.findDomainBounds(d)); } else { result = Range.combine(result, DatasetUtilities.findDomainBounds(d)); } } else { if (r != null) { result = Range.combine(result, r.findRangeBounds(d)); } else { result = Range.combine(result, DatasetUtilities.findRangeBounds(d)); } }  Collection c = r.getAnnotations(); Iterator i = c.iterator(); while (i.hasNext()) { XYAnnotation a = (XYAnnotation) i.next(); if (a instanceof XYAnnotationBoundsInfo) { includedAnnotations.add(a); } } } }  Iterator it = includedAnnotations.iterator(); while (it.hasNext()) { XYAnnotationBoundsInfo xyabi = (XYAnnotationBoundsInfo) it.next(); if (xyabi.getIncludeInDataBounds()) { if (isDomainAxis) { result = Range.combine(result, xyabi.getXRange()); } else { result = Range.combine(result, xyabi.getYRange()); } } }  return result;  }
 Node parseInputs() { boolean devMode = options.devMode != DevMode.OFF;  // If old roots exist (we are parsing a second time), detach each of the // individual file parse trees. if (externsRoot != null) { externsRoot.detachChildren(); } if (jsRoot != null) { jsRoot.detachChildren(); }  // Parse main JS sources. jsRoot = IR.block(); jsRoot.setIsSyntheticBlock(true);  externsRoot = IR.block(); externsRoot.setIsSyntheticBlock(true);  externAndJsRoot = IR.block(externsRoot, jsRoot); externAndJsRoot.setIsSyntheticBlock(true);  if (options.tracer.isOn()) { tracker = new PerformanceTracker(jsRoot, options.tracer); addChangeHandler(tracker.getCodeChangeHandler()); }  Tracer tracer = newTracer("parseInputs");  try { // Parse externs sources. for (CompilerInput input : externs) { Node n = input.getAstRoot(this); if (hasErrors()) { return null; } externsRoot.addChildToBack(n); }  // Modules inferred in ProcessCommonJS pass. if (options.transformAMDToCJSModules || options.processCommonJSModules) { processAMDAndCommonJSModules(); }  hoistExterns(externsRoot);  // Check if the sources need to be re-ordered. boolean staleInputs = false; if (options.dependencyOptions.needsManagement() && options.closurePass) { for (CompilerInput input : inputs) { // Forward-declare all the provided types, so that they // are not flagged even if they are dropped from the process. for (String provide : input.getProvides()) { getTypeRegistry().forwardDeclareType(provide); } }  try { inputs = (moduleGraph == null ? new JSModuleGraph(modules) : moduleGraph) .manageDependencies(options.dependencyOptions, inputs); staleInputs = true; } catch (CircularDependencyException e) { report(JSError.make( JSModule.CIRCULAR_DEPENDENCY_ERROR, e.getMessage()));  // If in IDE mode, we ignore the error and keep going. if (hasErrors()) { return null; } } catch (MissingProvideException e) { report(JSError.make( MISSING_ENTRY_ERROR, e.getMessage()));  // If in IDE mode, we ignore the error and keep going. if (hasErrors()) { return null; } } }  hoistNoCompileFiles();  if (staleInputs) { repartitionInputs(); }  // Build the AST. for (CompilerInput input : inputs) { Node n = input.getAstRoot(this); if (n == null) { continue; }  if (devMode) { runSanityCheck(); if (hasErrors()) { return null; } }  if (options.sourceMapOutputPath != null || options.nameReferenceReportPath != null) {  // Annotate the nodes in the tree with information from the // input file. This information is used to construct the SourceMap. SourceInformationAnnotator sia = new SourceInformationAnnotator( input.getName(), options.devMode != DevMode.OFF); NodeTraversal.traverse(this, n, sia); }  jsRoot.addChildToBack(n); }  if (hasErrors()) { return null; } return externAndJsRoot; } finally { stopTracer(tracer, "parseInputs"); } }
 public String getLine(int lineNumber) { String js = ""; try { // NOTE(nicksantos): Right now, this is optimized for few warnings. // This is probably the right trade-off, but will be slow if there // are lots of warnings in one file. js = getCode(); } catch (IOException e) { return null; }  int pos = 0; int startLine = 1;  // If we've saved a previous offset and it's for a line less than the // one we're searching for, then start at that point. if (lineNumber >= lastLine) { pos = lastOffset; startLine = lastLine; }  for (int n = startLine; n < lineNumber; n++) { int nextpos = js.indexOf('\n', pos); if (nextpos == -1) { return null; } pos = nextpos + 1; }  // Remember this offset for the next search we do. lastOffset = pos; lastLine = lineNumber;  if (js.indexOf('\n', pos) == -1) { // If next new line cannot be found, there are two cases // 1. pos already reaches the end of file, then null should be returned // 2. otherwise, return the contents between pos and the end of file. return null; } else { return js.substring(pos, js.indexOf('\n', pos)); } }
 protected double doSolve() {  // prepare arrays with the first points final double[] x = new double[maximalOrder + 1]; final double[] y = new double[maximalOrder + 1]; x[0] = getMin(); x[1] = getStartValue(); x[2] = getMax(); verifySequence(x[0], x[1], x[2]);  // evaluate initial guess y[1] = computeObjectiveValue(x[1]); if (Precision.equals(y[1], 0.0, 1)) { // return the initial guess if it is a perfect root. return x[1]; }  // evaluate first  endpoint y[0] = computeObjectiveValue(x[0]); if (Precision.equals(y[0], 0.0, 1)) { // return the first endpoint if it is a perfect root. return x[0]; }  int nbPoints; int signChangeIndex; if (y[0] * y[1] < 0) {  // reduce interval if it brackets the root nbPoints        = 2; signChangeIndex = 1;  } else {  // evaluate second endpoint y[2] = computeObjectiveValue(x[2]); if (Precision.equals(y[2], 0.0, 1)) { // return the second endpoint if it is a perfect root. return x[2]; }  if (y[1] * y[2] < 0) { // use all computed point as a start sampling array for solving nbPoints        = 3; signChangeIndex = 2; } else { throw new NoBracketingException(x[0], x[2], y[0], y[2]); }  }  // prepare a work array for inverse polynomial interpolation final double[] tmpX = new double[x.length];  // current tightest bracketing of the root double xA    = x[signChangeIndex - 1]; double yA    = y[signChangeIndex - 1]; double absYA = FastMath.abs(yA); int agingA   = 0; double xB    = x[signChangeIndex]; double yB    = y[signChangeIndex]; double absYB = FastMath.abs(yB); int agingB   = 0;  // search loop while (true) {  // check convergence of bracketing interval final double xTol = getAbsoluteAccuracy() + getRelativeAccuracy() * FastMath.max(FastMath.abs(xA), FastMath.abs(xB)); if (((xB - xA) <= xTol) || (FastMath.max(absYA, absYB) < getFunctionValueAccuracy())) { switch (allowed) { case ANY_SIDE : return absYA < absYB ? xA : xB; case LEFT_SIDE : return xA; case RIGHT_SIDE : return xB; case BELOW_SIDE : return (yA <= 0) ? xA : xB; case ABOVE_SIDE : return (yA <  0) ? xB : xA; default : // this should never happen throw new MathInternalError(null); } }  // target for the next evaluation point double targetY; if (agingA >= MAXIMAL_AGING) { // we keep updating the high bracket, try to compensate this targetY = -REDUCTION_FACTOR * yB; } else if (agingB >= MAXIMAL_AGING) { // we keep updating the low bracket, try to compensate this targetY = -REDUCTION_FACTOR * yA; } else { // bracketing is balanced, try to find the root itself targetY = 0; }  // make a few attempts to guess a root, double nextX; int start = 0; int end   = nbPoints; do {  // guess a value for current target, using inverse polynomial interpolation System.arraycopy(x, start, tmpX, start, end - start); nextX = guessX(targetY, tmpX, y, start, end);  if (!((nextX > xA) && (nextX < xB))) { // the guessed root is not strictly inside of the tightest bracketing interval  // the guessed root is either not strictly inside the interval or it // is a NaN (which occurs when some sampling points share the same y) // we try again with a lower interpolation order if (signChangeIndex - start >= end - signChangeIndex) { // we have more points before the sign change, drop the lowest point ++start; } else { // we have more points after sign change, drop the highest point --end; }  // we need to do one more attempt nextX = Double.NaN;  }  } while (Double.isNaN(nextX) && (end - start > 1));  if (Double.isNaN(nextX)) { // fall back to bisection nextX = xA + 0.5 * (xB - xA); start = signChangeIndex - 1; end   = signChangeIndex; }  // evaluate the function at the guessed root final double nextY = computeObjectiveValue(nextX); if (Precision.equals(nextY, 0.0, 1)) { // we have found an exact root, since it is not an approximation // we don't need to bother about the allowed solutions setting return nextX; }  if ((nbPoints > 2) && (end - start != nbPoints)) {  // we have been forced to ignore some points to keep bracketing, // they are probably too far from the root, drop them from now on nbPoints = end - start; System.arraycopy(x, start, x, 0, nbPoints); System.arraycopy(y, start, y, 0, nbPoints); signChangeIndex -= start;  } else  if (nbPoints == x.length) {  // we have to drop one point in order to insert the new one nbPoints--;  // keep the tightest bracketing interval as centered as possible if (signChangeIndex >= (x.length + 1) / 2) { // we drop the lowest point, we have to shift the arrays and the index System.arraycopy(x, 1, x, 0, nbPoints); System.arraycopy(y, 1, y, 0, nbPoints); --signChangeIndex; }  }  // insert the last computed point //(by construction, we know it lies inside the tightest bracketing interval) System.arraycopy(x, signChangeIndex, x, signChangeIndex + 1, nbPoints - signChangeIndex); x[signChangeIndex] = nextX; System.arraycopy(y, signChangeIndex, y, signChangeIndex + 1, nbPoints - signChangeIndex); y[signChangeIndex] = nextY; ++nbPoints;  // update the bracketing interval if (nextY * yA <= 0) { // the sign change occurs before the inserted point xB = nextX; yB = nextY; absYB = FastMath.abs(yB); ++agingA; agingB = 0; } else { // the sign change occurs after the inserted point xA = nextX; yA = nextY; absYA = FastMath.abs(yA); agingA = 0; ++agingB;  // update the sign change index signChangeIndex++;  }  }  }
 protected double doSolve() {  // prepare arrays with the first points final double[] x = new double[maximalOrder + 1]; final double[] y = new double[maximalOrder + 1]; x[0] = getMin(); x[1] = getStartValue(); x[2] = getMax(); verifySequence(x[0], x[1], x[2]);  // evaluate initial guess y[1] = computeObjectiveValue(x[1]); if (Precision.equals(y[1], 0.0, 1)) { // return the initial guess if it is a perfect root. return x[1]; }  // evaluate first  endpoint y[0] = computeObjectiveValue(x[0]); if (Precision.equals(y[0], 0.0, 1)) { // return the first endpoint if it is a perfect root. return x[0]; }  int nbPoints; int signChangeIndex; if (y[0] * y[1] < 0) {  // reduce interval if it brackets the root nbPoints        = 2; signChangeIndex = 1;  } else {  // evaluate second endpoint y[2] = computeObjectiveValue(x[2]); if (Precision.equals(y[2], 0.0, 1)) { // return the second endpoint if it is a perfect root. return x[2]; }  if (y[1] * y[2] < 0) { // use all computed point as a start sampling array for solving nbPoints        = 3; signChangeIndex = 2; } else { throw new NoBracketingException(x[0], x[2], y[0], y[2]); }  }  // prepare a work array for inverse polynomial interpolation final double[] tmpX = new double[x.length];  // current tightest bracketing of the root double xA    = x[signChangeIndex - 1]; double yA    = y[signChangeIndex - 1]; double absYA = FastMath.abs(yA); int agingA   = 0; double xB    = x[signChangeIndex]; double yB    = y[signChangeIndex]; double absYB = FastMath.abs(yB); int agingB   = 0;  // search loop while (true) {  // check convergence of bracketing interval final double xTol = getAbsoluteAccuracy() + getRelativeAccuracy() * FastMath.max(FastMath.abs(xA), FastMath.abs(xB)); if (((xB - xA) <= xTol) || (FastMath.max(absYA, absYB) < getFunctionValueAccuracy())) { switch (allowed) { case ANY_SIDE : return absYA < absYB ? xA : xB; case LEFT_SIDE : return xA; case RIGHT_SIDE : return xB; case BELOW_SIDE : return (yA <= 0) ? xA : xB; case ABOVE_SIDE : return (yA <  0) ? xB : xA; default : // this should never happen throw new MathInternalError(null); } }  // target for the next evaluation point double targetY; if (agingA >= MAXIMAL_AGING) { // we keep updating the high bracket, try to compensate this targetY = -REDUCTION_FACTOR * yB; } else if (agingB >= MAXIMAL_AGING) { // we keep updating the low bracket, try to compensate this targetY = -REDUCTION_FACTOR * yA; } else { // bracketing is balanced, try to find the root itself targetY = 0; }  // make a few attempts to guess a root, double nextX; int start = 0; int end   = nbPoints; do {  // guess a value for current target, using inverse polynomial interpolation System.arraycopy(x, start, tmpX, start, end - start); nextX = guessX(targetY, tmpX, y, start, end);  if (!((nextX > xA) && (nextX < xB))) { // the guessed root is not strictly inside of the tightest bracketing interval  // the guessed root is either not strictly inside the interval or it // is a NaN (which occurs when some sampling points share the same y) // we try again with a lower interpolation order if (signChangeIndex - start >= end - signChangeIndex) { // we have more points before the sign change, drop the lowest point ++start; } else { // we have more points after sign change, drop the highest point --end; }  // we need to do one more attempt nextX = Double.NaN;  }  } while (Double.isNaN(nextX) && (end - start > 1));  if (Double.isNaN(nextX)) { // fall back to bisection nextX = xA + 0.5 * (xB - xA); start = signChangeIndex - 1; end   = signChangeIndex; }  // evaluate the function at the guessed root final double nextY = computeObjectiveValue(nextX); if (Precision.equals(nextY, 0.0, 1)) { // we have found an exact root, since it is not an approximation // we don't need to bother about the allowed solutions setting return nextX; }  if ((nbPoints > 2) && (end - start != nbPoints)) {  // we have been forced to ignore some points to keep bracketing, // they are probably too far from the root, drop them from now on nbPoints = end - start; System.arraycopy(x, start, x, 0, nbPoints); System.arraycopy(y, start, y, 0, nbPoints); signChangeIndex -= start;  } else  if (nbPoints == x.length) {  // we have to drop one point in order to insert the new one nbPoints--;  // keep the tightest bracketing interval as centered as possible if (signChangeIndex >= (x.length + 1) / 2) { // we drop the lowest point, we have to shift the arrays and the index System.arraycopy(x, 1, x, 0, nbPoints); System.arraycopy(y, 1, y, 0, nbPoints); --signChangeIndex; }  }  // insert the last computed point //(by construction, we know it lies inside the tightest bracketing interval) System.arraycopy(x, signChangeIndex, x, signChangeIndex + 1, nbPoints - signChangeIndex); x[signChangeIndex] = nextX; System.arraycopy(y, signChangeIndex, y, signChangeIndex + 1, nbPoints - signChangeIndex); y[signChangeIndex] = nextY; ++nbPoints;  // update the bracketing interval if (nextY * yA <= 0) { // the sign change occurs before the inserted point xB = nextX; yB = nextY; absYB = FastMath.abs(yB); ++agingA; agingB = 0; } else { // the sign change occurs after the inserted point xA = nextX; yA = nextY; absYA = FastMath.abs(yA); agingA = 0; ++agingB;  // update the sign change index signChangeIndex++;  }  }  }
 private FlowScope traverseNew(Node n, FlowScope scope) {  Node constructor = n.getFirstChild(); scope = traverse(constructor, scope); JSType constructorType = constructor.getJSType(); JSType type = null; if (constructorType != null) { constructorType = constructorType.restrictByNotNullOrUndefined(); if (constructorType.isUnknownType()) { type = getNativeType(UNKNOWN_TYPE); } else { FunctionType ct = constructorType.toMaybeFunctionType(); if (ct == null && constructorType instanceof FunctionType) { // If constructorType is a NoObjectType, then toMaybeFunctionType will // return null. But NoObjectType implements the FunctionType // interface, precisely because it can validly construct objects. ct = (FunctionType) constructorType; } if (ct != null && ct.isConstructor()) { type = ct.getInstanceType(); } } } n.setJSType(type); for (Node arg = constructor.getNext(); arg != null; arg = arg.getNext()) { scope = traverse(arg, scope); } return scope; }
 private FlowScope traverseNew(Node n, FlowScope scope) {  Node constructor = n.getFirstChild(); scope = traverse(constructor, scope); JSType constructorType = constructor.getJSType(); JSType type = null; if (constructorType != null) { constructorType = constructorType.restrictByNotNullOrUndefined(); if (constructorType.isUnknownType()) { type = getNativeType(UNKNOWN_TYPE); } else { FunctionType ct = constructorType.toMaybeFunctionType(); if (ct == null && constructorType instanceof FunctionType) { // If constructorType is a NoObjectType, then toMaybeFunctionType will // return null. But NoObjectType implements the FunctionType // interface, precisely because it can validly construct objects. ct = (FunctionType) constructorType; } if (ct != null && ct.isConstructor()) { type = ct.getInstanceType(); } } } n.setJSType(type); for (Node arg = constructor.getNext(); arg != null; arg = arg.getNext()) { scope = traverse(arg, scope); } return scope; }
 public Object answer(InvocationOnMock invocation) { if (methodsGuru.isToString(invocation.getMethod())) { Object mock = invocation.getMock(); MockName name = mockUtil.getMockName(mock); if (name.isDefault()) { return "Mock for " + mockUtil.getMockSettings(mock).getTypeToMock().getSimpleName() + ", hashCode: " + mock.hashCode(); } else { return name.toString(); } } else if (methodsGuru.isCompareToMethod(invocation.getMethod())) { //see issue 184. //mocks by default should return 0 if references are the same, otherwise some other value because they are not the same. Hence we return 1 (anything but 0 is good). //Only for compareTo() method by the Comparable interface return 1; }  Class<?> returnType = invocation.getMethod().getReturnType(); return returnValueFor(returnType); }
 protected void iterateSimplex(final Comparator<RealPointValuePair> comparator) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  while (true) {  incrementIterationsCounter();  // save the original vertex final RealPointValuePair[] original = simplex; final RealPointValuePair best = original[0];  // perform a reflection step final RealPointValuePair reflected = evaluateNewSimplex(original, 1.0, comparator); if (comparator.compare(reflected, best) < 0) {  // compute the expanded simplex final RealPointValuePair[] reflectedSimplex = simplex; final RealPointValuePair expanded = evaluateNewSimplex(original, khi, comparator); if (comparator.compare(reflected, expanded) <= 0) { // accept the reflected simplex simplex = reflectedSimplex; }  return;  }  // compute the contracted simplex final RealPointValuePair contracted = evaluateNewSimplex(original, gamma, comparator); if (comparator.compare(contracted, best) < 0) { // accept the contracted simplex  // check convergence return; }  }  }
 private Node performArithmeticOp(int opType, Node left, Node right) { // Unlike other operations, ADD operands are not always converted // to Number. if (opType == Token.ADD && (NodeUtil.mayBeString(left, false) || NodeUtil.mayBeString(right, false))) { return null; }  double result;  // TODO(johnlenz): Handle NaN with unknown value. BIT ops convert NaN // to zero so this is a little akward here.  Double lValObj = NodeUtil.getNumberValue(left); if (lValObj == null) { return null; } Double rValObj = NodeUtil.getNumberValue(right); if (rValObj == null) { return null; }  double lval = lValObj; double rval = rValObj;  switch (opType) { case Token.BITAND: result = ScriptRuntime.toInt32(lval) & ScriptRuntime.toInt32(rval); break; case Token.BITOR: result = ScriptRuntime.toInt32(lval) | ScriptRuntime.toInt32(rval); break; case Token.BITXOR: result = ScriptRuntime.toInt32(lval) ^ ScriptRuntime.toInt32(rval); break; case Token.ADD: result = lval + rval; break; case Token.SUB: result = lval - rval; break; case Token.MUL: result = lval * rval; break; case Token.MOD: if (rval == 0) { error(DiagnosticType.error("JSC_DIVIDE_BY_0_ERROR", "Divide by 0"), right); return null; } result = lval % rval; break; case Token.DIV: if (rval == 0) { error(DiagnosticType.error("JSC_DIVIDE_BY_0_ERROR", "Divide by 0"), right); return null; } result = lval / rval; break; default: throw new Error("Unexpected arithmetic operator"); }  // TODO(johnlenz): consider removing the result length check. // length of the left and right value plus 1 byte for the operator. if (String.valueOf(result).length() <= String.valueOf(lval).length() + String.valueOf(rval).length() + 1 &&  // Do not try to fold arithmetic for numbers > 2^53. After that // point, fixed-point math starts to break down and become inaccurate. Math.abs(result) <= MAX_FOLD_NUMBER) { Node newNumber = Node.newNumber(result); return newNumber; } else if (Double.isNaN(result)) { return Node.newString(Token.NAME, "NaN"); } else if (result == Double.POSITIVE_INFINITY) { return Node.newString(Token.NAME, "Infinity"); } else if (result == Double.NEGATIVE_INFINITY) { return new Node(Token.NEG, Node.newString(Token.NAME, "Infinity")); }  return null; }
 private Node performArithmeticOp(int opType, Node left, Node right) { // Unlike other operations, ADD operands are not always converted // to Number. if (opType == Token.ADD && (NodeUtil.mayBeString(left, false) || NodeUtil.mayBeString(right, false))) { return null; }  double result;  // TODO(johnlenz): Handle NaN with unknown value. BIT ops convert NaN // to zero so this is a little akward here.  Double lValObj = NodeUtil.getNumberValue(left); if (lValObj == null) { return null; } Double rValObj = NodeUtil.getNumberValue(right); if (rValObj == null) { return null; }  double lval = lValObj; double rval = rValObj;  switch (opType) { case Token.BITAND: result = ScriptRuntime.toInt32(lval) & ScriptRuntime.toInt32(rval); break; case Token.BITOR: result = ScriptRuntime.toInt32(lval) | ScriptRuntime.toInt32(rval); break; case Token.BITXOR: result = ScriptRuntime.toInt32(lval) ^ ScriptRuntime.toInt32(rval); break; case Token.ADD: result = lval + rval; break; case Token.SUB: result = lval - rval; break; case Token.MUL: result = lval * rval; break; case Token.MOD: if (rval == 0) { error(DiagnosticType.error("JSC_DIVIDE_BY_0_ERROR", "Divide by 0"), right); return null; } result = lval % rval; break; case Token.DIV: if (rval == 0) { error(DiagnosticType.error("JSC_DIVIDE_BY_0_ERROR", "Divide by 0"), right); return null; } result = lval / rval; break; default: throw new Error("Unexpected arithmetic operator"); }  // TODO(johnlenz): consider removing the result length check. // length of the left and right value plus 1 byte for the operator. if (String.valueOf(result).length() <= String.valueOf(lval).length() + String.valueOf(rval).length() + 1 &&  // Do not try to fold arithmetic for numbers > 2^53. After that // point, fixed-point math starts to break down and become inaccurate. Math.abs(result) <= MAX_FOLD_NUMBER) { Node newNumber = Node.newNumber(result); return newNumber; } else if (Double.isNaN(result)) { return Node.newString(Token.NAME, "NaN"); } else if (result == Double.POSITIVE_INFINITY) { return Node.newString(Token.NAME, "Infinity"); } else if (result == Double.NEGATIVE_INFINITY) { return new Node(Token.NEG, Node.newString(Token.NAME, "Infinity")); }  return null; }
 public Paint getPaint(double value) { double v = Math.max(value, this.lowerBound); v = Math.min(v, this.upperBound); int g = (int) ((value - this.lowerBound) / (this.upperBound - this.lowerBound) * 255.0); return new Color(g, g, g); }
 public Complex divide(Complex divisor) throws NullArgumentException { MathUtils.checkNotNull(divisor); if (isNaN || divisor.isNaN) { return NaN; }  if (divisor.getReal() == 0.0 && divisor.getImaginary() == 0.0) { return NaN; }  if (divisor.isInfinite() && !isInfinite()) { return ZERO; }  final double c = divisor.getReal(); final double d = divisor.getImaginary();  if (FastMath.abs(c) < FastMath.abs(d)) { double q = c / d; double denominator = c * q + d; return createComplex((real * q + imaginary) / denominator, (imaginary * q - real) / denominator); } else { double q = d / c; double denominator = d * q + c; return createComplex((imaginary * q + real) / denominator, (imaginary - real * q) / denominator); } }
 public Complex divide(Complex divisor) throws NullArgumentException { MathUtils.checkNotNull(divisor); if (isNaN || divisor.isNaN) { return NaN; }  if (divisor.getReal() == 0.0 && divisor.getImaginary() == 0.0) { return NaN; }  if (divisor.isInfinite() && !isInfinite()) { return ZERO; }  final double c = divisor.getReal(); final double d = divisor.getImaginary();  if (FastMath.abs(c) < FastMath.abs(d)) { double q = c / d; double denominator = c * q + d; return createComplex((real * q + imaginary) / denominator, (imaginary * q - real) / denominator); } else { double q = d / c; double denominator = d * q + c; return createComplex((imaginary * q + real) / denominator, (imaginary - real * q) / denominator); } }
 public Complex divide(double divisor) { if (isNaN || Double.isNaN(divisor)) { return NaN; } if (divisor == 0d) { return NaN; } if (Double.isInfinite(divisor)) { return !isInfinite() ? ZERO : NaN; } return createComplex(real / divisor, imaginary  / divisor); }
 public String unescape(String str) { int firstAmp = str.indexOf('&'); if (firstAmp < 0) { return str; }  StringBuffer buf = new StringBuffer(str.length()); buf.append(str.substring(0, firstAmp)); for (int i = firstAmp; i < str.length(); ++i) { char ch = str.charAt(i); if (ch == '&') { int semi = str.indexOf(';', i + 1); if (semi == -1) { buf.append(ch); continue; } int amph = str.indexOf('&', i + 1); if( amph != -1 && amph < semi ) { // Then the text looks like &...&...; buf.append(ch); continue; } String entityName = str.substring(i + 1, semi); int entityValue; if (entityName.length() == 0) { entityValue = -1; } else if (entityName.charAt(0) == '#') { if (entityName.length() == 1) { entityValue = -1; } else { char charAt1 = entityName.charAt(1); try { if (charAt1 == 'x' || charAt1=='X') { entityValue = Integer.valueOf(entityName.substring(2), 16).intValue(); } else { entityValue = Integer.parseInt(entityName.substring(1)); } } catch (NumberFormatException ex) { entityValue = -1; } } } else { entityValue = this.entityValue(entityName); } if (entityValue == -1) { buf.append('&'); buf.append(entityName); buf.append(';'); } else { buf.append((char) (entityValue)); } i = semi; } else { buf.append(ch); } } return buf.toString(); }
 public String unescape(String str) { int firstAmp = str.indexOf('&'); if (firstAmp < 0) { return str; }  StringBuffer buf = new StringBuffer(str.length()); buf.append(str.substring(0, firstAmp)); for (int i = firstAmp; i < str.length(); ++i) { char ch = str.charAt(i); if (ch == '&') { int semi = str.indexOf(';', i + 1); if (semi == -1) { buf.append(ch); continue; } int amph = str.indexOf('&', i + 1); if( amph != -1 && amph < semi ) { // Then the text looks like &...&...; buf.append(ch); continue; } String entityName = str.substring(i + 1, semi); int entityValue; if (entityName.length() == 0) { entityValue = -1; } else if (entityName.charAt(0) == '#') { if (entityName.length() == 1) { entityValue = -1; } else { char charAt1 = entityName.charAt(1); try { if (charAt1 == 'x' || charAt1=='X') { entityValue = Integer.valueOf(entityName.substring(2), 16).intValue(); } else { entityValue = Integer.parseInt(entityName.substring(1)); } } catch (NumberFormatException ex) { entityValue = -1; } } } else { entityValue = this.entityValue(entityName); } if (entityValue == -1) { buf.append('&'); buf.append(entityName); buf.append(';'); } else { buf.append((char) (entityValue)); } i = semi; } else { buf.append(ch); } } return buf.toString(); }
 public void unescape(Writer writer, String string) throws IOException { int firstAmp = string.indexOf('&'); if (firstAmp < 0) { writer.write(string); return; }  writer.write(string, 0, firstAmp); int len = string.length(); for (int i = firstAmp; i < len; i++) { char c = string.charAt(i); if (c == '&') { int nextIdx = i+1; int semiColonIdx = string.indexOf(';', nextIdx); if (semiColonIdx == -1) { writer.write(c); continue; } int amphersandIdx = string.indexOf('&', i + 1); if( amphersandIdx != -1 && amphersandIdx < semiColonIdx ) { // Then the text looks like &...&...; writer.write(c); continue; } String entityContent = string.substring(nextIdx, semiColonIdx); int entityValue = -1; int entityContentLen = entityContent.length(); if (entityContentLen > 0) { if (entityContent.charAt(0) == '#') { //escaped value content is an integer (decimal or hexidecimal) if (entityContentLen > 1) { char isHexChar = entityContent.charAt(1); try { switch (isHexChar) { case 'X' : case 'x' : { entityValue = Integer.parseInt(entityContent.substring(2), 16); } default : { entityValue = Integer.parseInt(entityContent.substring(1), 10); } } } catch (NumberFormatException e) { } } } else { //escaped value content is an entity name entityValue = this.entityValue(entityContent); } }  if (entityValue == -1) { writer.write('&'); writer.write(entityContent); writer.write(';'); } else { writer.write(entityValue); } i = semiColonIdx; //move index up to the semi-colon } else { writer.write(c); } } }
 public void unescape(Writer writer, String string) throws IOException { int firstAmp = string.indexOf('&'); if (firstAmp < 0) { writer.write(string); return; }  writer.write(string, 0, firstAmp); int len = string.length(); for (int i = firstAmp; i < len; i++) { char c = string.charAt(i); if (c == '&') { int nextIdx = i+1; int semiColonIdx = string.indexOf(';', nextIdx); if (semiColonIdx == -1) { writer.write(c); continue; } int amphersandIdx = string.indexOf('&', i + 1); if( amphersandIdx != -1 && amphersandIdx < semiColonIdx ) { // Then the text looks like &...&...; writer.write(c); continue; } String entityContent = string.substring(nextIdx, semiColonIdx); int entityValue = -1; int entityContentLen = entityContent.length(); if (entityContentLen > 0) { if (entityContent.charAt(0) == '#') { //escaped value content is an integer (decimal or hexidecimal) if (entityContentLen > 1) { char isHexChar = entityContent.charAt(1); try { switch (isHexChar) { case 'X' : case 'x' : { entityValue = Integer.parseInt(entityContent.substring(2), 16); } default : { entityValue = Integer.parseInt(entityContent.substring(1), 10); } } } catch (NumberFormatException e) { } } } else { //escaped value content is an entity name entityValue = this.entityValue(entityContent); } }  if (entityValue == -1) { writer.write('&'); writer.write(entityContent); writer.write(';'); } else { writer.write(entityValue); } i = semiColonIdx; //move index up to the semi-colon } else { writer.write(c); } } }
 public void unescape(Writer writer, String string) throws IOException { int firstAmp = string.indexOf('&'); if (firstAmp < 0) { writer.write(string); return; }  writer.write(string, 0, firstAmp); int len = string.length(); for (int i = firstAmp; i < len; i++) { char c = string.charAt(i); if (c == '&') { int nextIdx = i+1; int semiColonIdx = string.indexOf(';', nextIdx); if (semiColonIdx == -1) { writer.write(c); continue; } int amphersandIdx = string.indexOf('&', i + 1); if( amphersandIdx != -1 && amphersandIdx < semiColonIdx ) { // Then the text looks like &...&...; writer.write(c); continue; } String entityContent = string.substring(nextIdx, semiColonIdx); int entityValue = -1; int entityContentLen = entityContent.length(); if (entityContentLen > 0) { if (entityContent.charAt(0) == '#') { //escaped value content is an integer (decimal or hexidecimal) if (entityContentLen > 1) { char isHexChar = entityContent.charAt(1); try { switch (isHexChar) { case 'X' : case 'x' : { entityValue = Integer.parseInt(entityContent.substring(2), 16); } default : { entityValue = Integer.parseInt(entityContent.substring(1), 10); } } } catch (NumberFormatException e) { } } } else { //escaped value content is an entity name entityValue = this.entityValue(entityContent); } }  if (entityValue == -1) { writer.write('&'); writer.write(entityContent); writer.write(';'); } else { writer.write(entityValue); } i = semiColonIdx; //move index up to the semi-colon } else { writer.write(c); } } }
 private String format(JSError error, boolean warning) { // extract source excerpt SourceExcerptProvider source = getSource(); String sourceExcerpt = source == null ? null : excerpt.get( source, error.sourceName, error.lineNumber, excerptFormatter);  // formatting the message StringBuilder b = new StringBuilder(); if (error.sourceName != null) { b.append(error.sourceName); if (error.lineNumber > 0) { b.append(':'); b.append(error.lineNumber); } b.append(": "); }  b.append(getLevelName(warning ? CheckLevel.WARNING : CheckLevel.ERROR)); b.append(" - ");  b.append(error.description); b.append('\n'); if (sourceExcerpt != null) { b.append(sourceExcerpt); b.append('\n'); int charno = error.getCharno();  // padding equal to the excerpt and arrow at the end // charno == sourceExpert.length() means something is missing // at the end of the line if (excerpt.equals(LINE) && 0 <= charno && charno < sourceExcerpt.length()) { for (int i = 0; i < charno; i++) { char c = sourceExcerpt.charAt(i); if (Character.isWhitespace(c)) { b.append(c); } else { b.append(' '); } } b.append("^\n"); } } return b.toString(); }
 public double solve(double min, double max) throws MaxIterationsExceededException, FunctionEvaluationException {  clearResult(); verifyInterval(min, max);  double ret = Double.NaN;  double yMin = f.value(min); double yMax = f.value(max);  // Verify bracketing double sign = yMin * yMax; if (sign >= 0) { // check if either value is close to a zero // neither value is close to zero and min and max do not bracket root. throw new IllegalArgumentException ("Function values at endpoints do not have different signs." + "  Endpoints: [" + min + "," + max + "]" + "  Values: [" + yMin + "," + yMax + "]"); } else { // solve using only the first endpoint as initial guess ret = solve(min, yMin, max, yMax, min, yMin); // either min or max is a root }  return ret; }
 public double solve(double min, double max) throws MaxIterationsExceededException, FunctionEvaluationException {  clearResult(); verifyInterval(min, max);  double ret = Double.NaN;  double yMin = f.value(min); double yMax = f.value(max);  // Verify bracketing double sign = yMin * yMax; if (sign >= 0) { // check if either value is close to a zero // neither value is close to zero and min and max do not bracket root. throw new IllegalArgumentException ("Function values at endpoints do not have different signs." + "  Endpoints: [" + min + "," + max + "]" + "  Values: [" + yMin + "," + yMax + "]"); } else { // solve using only the first endpoint as initial guess ret = solve(min, yMin, max, yMax, min, yMin); // either min or max is a root }  return ret; }
 private String format(JSError error, boolean warning) { // extract source excerpt SourceExcerptProvider source = getSource(); String sourceExcerpt = source == null ? null : excerpt.get( source, error.sourceName, error.lineNumber, excerptFormatter);  // formatting the message StringBuilder b = new StringBuilder(); if (error.sourceName != null) { b.append(error.sourceName); if (error.lineNumber > 0) { b.append(':'); b.append(error.lineNumber); } b.append(": "); }  b.append(getLevelName(warning ? CheckLevel.WARNING : CheckLevel.ERROR)); b.append(" - ");  b.append(error.description); b.append('\n'); if (sourceExcerpt != null) { b.append(sourceExcerpt); b.append('\n'); int charno = error.getCharno();  // padding equal to the excerpt and arrow at the end // charno == sourceExpert.length() means something is missing // at the end of the line if (excerpt.equals(LINE) && 0 <= charno && charno < sourceExcerpt.length()) { for (int i = 0; i < charno; i++) { char c = sourceExcerpt.charAt(i); if (Character.isWhitespace(c)) { b.append(c); } else { b.append(' '); } } b.append("^\n"); } } return b.toString(); }
 private Node tryMinimizeIf(Node n) {  Node parent = n.getParent();  Node cond = n.getFirstChild();  /* If the condition is a literal, we'll let other * optimizations try to remove useless code. */ if (NodeUtil.isLiteralValue(cond, true)) { return n; }  Node thenBranch = cond.getNext(); Node elseBranch = thenBranch.getNext();  if (elseBranch == null) { if (isFoldableExpressBlock(thenBranch)) { Node expr = getBlockExpression(thenBranch); if (!late && isPropertyAssignmentInExpression(expr)) { // Keep opportunities for CollapseProperties such as // a.longIdentifier || a.longIdentifier = ... -> var a = ...; // until CollapseProperties has been run. return n; }  if (cond.isNot()) { // if(!x)bar(); -> x||bar(); if (isLowerPrecedenceInExpression(cond, OR_PRECEDENCE) && isLowerPrecedenceInExpression(expr.getFirstChild(), OR_PRECEDENCE)) { // It's not okay to add two sets of parentheses. return n; }  Node or = IR.or( cond.removeFirstChild(), expr.removeFirstChild()).srcref(n); Node newExpr = NodeUtil.newExpr(or); parent.replaceChild(n, newExpr); reportCodeChange();  return newExpr; }  // if(x)foo(); -> x&&foo(); if (isLowerPrecedenceInExpression(cond, AND_PRECEDENCE) && isLowerPrecedenceInExpression(expr.getFirstChild(), AND_PRECEDENCE)) { // One additional set of parentheses is worth the change even if // there is no immediate code size win. However, two extra pair of // {}, we would have to think twice. (unless we know for sure the // we can further optimize its parent. return n; }  n.removeChild(cond); Node and = IR.and(cond, expr.removeFirstChild()).srcref(n); Node newExpr = NodeUtil.newExpr(and); parent.replaceChild(n, newExpr); reportCodeChange();  return newExpr; } else {  // Try to combine two IF-ELSE if (NodeUtil.isStatementBlock(thenBranch) && thenBranch.hasOneChild()) { Node innerIf = thenBranch.getFirstChild();  if (innerIf.isIf()) { Node innerCond = innerIf.getFirstChild(); Node innerThenBranch = innerCond.getNext(); Node innerElseBranch = innerThenBranch.getNext();  if (innerElseBranch == null && !(isLowerPrecedenceInExpression(cond, AND_PRECEDENCE) && isLowerPrecedenceInExpression(innerCond, AND_PRECEDENCE))) { n.detachChildren(); n.addChildToBack( IR.and( cond, innerCond.detachFromParent()) .srcref(cond)); n.addChildrenToBack(innerThenBranch.detachFromParent()); reportCodeChange(); // Not worth trying to fold the current IF-ELSE into && because // the inner IF-ELSE wasn't able to be folded into && anyways. return n; } } } }  return n; }  /* TODO(dcc) This modifies the siblings of n, which is undesirable for a * peephole optimization. This should probably get moved to another pass. */ tryRemoveRepeatedStatements(n);  // if(!x)foo();else bar(); -> if(x)bar();else foo(); // An additional set of curly braces isn't worth it. if (cond.isNot() && !consumesDanglingElse(elseBranch)) { n.replaceChild(cond, cond.removeFirstChild()); n.removeChild(thenBranch); n.addChildToBack(thenBranch); reportCodeChange(); return n; }  // if(x)return 1;else return 2; -> return x?1:2; if (isReturnExpressBlock(thenBranch) && isReturnExpressBlock(elseBranch)) { Node thenExpr = getBlockReturnExpression(thenBranch); Node elseExpr = getBlockReturnExpression(elseBranch); n.removeChild(cond); thenExpr.detachFromParent(); elseExpr.detachFromParent();  // note - we ignore any cases with "return;", technically this // can be converted to "return undefined;" or some variant, but // that does not help code size. Node returnNode = IR.returnNode( IR.hook(cond, thenExpr, elseExpr) .srcref(n)); parent.replaceChild(n, returnNode); reportCodeChange(); return returnNode; }  boolean thenBranchIsExpressionBlock = isFoldableExpressBlock(thenBranch); boolean elseBranchIsExpressionBlock = isFoldableExpressBlock(elseBranch);  if (thenBranchIsExpressionBlock && elseBranchIsExpressionBlock) { Node thenOp = getBlockExpression(thenBranch).getFirstChild(); Node elseOp = getBlockExpression(elseBranch).getFirstChild(); if (thenOp.getType() == elseOp.getType()) { // if(x)a=1;else a=2; -> a=x?1:2; if (NodeUtil.isAssignmentOp(thenOp)) { Node lhs = thenOp.getFirstChild(); if (areNodesEqualForInlining(lhs, elseOp.getFirstChild()) && // if LHS has side effects, don't proceed [since the optimization // evaluates LHS before cond] // NOTE - there are some circumstances where we can // proceed even if there are side effects... !mayEffectMutableState(lhs)) {  n.removeChild(cond); Node assignName = thenOp.removeFirstChild(); Node thenExpr = thenOp.removeFirstChild(); Node elseExpr = elseOp.getLastChild(); elseOp.removeChild(elseExpr);  Node hookNode = IR.hook(cond, thenExpr, elseExpr).srcref(n); Node assign = new Node(thenOp.getType(), assignName, hookNode) .srcref(thenOp); Node expr = NodeUtil.newExpr(assign); parent.replaceChild(n, expr); reportCodeChange();  return expr; } } } // if(x)foo();else bar(); -> x?foo():bar() n.removeChild(cond); thenOp.detachFromParent(); elseOp.detachFromParent(); Node expr = IR.exprResult( IR.hook(cond, thenOp, elseOp).srcref(n)); parent.replaceChild(n, expr); reportCodeChange(); return expr; }  boolean thenBranchIsVar = isVarBlock(thenBranch); boolean elseBranchIsVar = isVarBlock(elseBranch);  // if(x)var y=1;else y=2  ->  var y=x?1:2 if (thenBranchIsVar && elseBranchIsExpressionBlock && getBlockExpression(elseBranch).getFirstChild().isAssign()) {  Node var = getBlockVar(thenBranch); Node elseAssign = getBlockExpression(elseBranch).getFirstChild();  Node name1 = var.getFirstChild(); Node maybeName2 = elseAssign.getFirstChild();  if (name1.hasChildren() && maybeName2.isName() && name1.getString().equals(maybeName2.getString())) { Node thenExpr = name1.removeChildren(); Node elseExpr = elseAssign.getLastChild().detachFromParent(); cond.detachFromParent(); Node hookNode = IR.hook(cond, thenExpr, elseExpr) .srcref(n); var.detachFromParent(); name1.addChildrenToBack(hookNode); parent.replaceChild(n, var); reportCodeChange(); return var; }  // if(x)y=1;else var y=2  ->  var y=x?1:2 } else if (elseBranchIsVar && thenBranchIsExpressionBlock && getBlockExpression(thenBranch).getFirstChild().isAssign()) {  Node var = getBlockVar(elseBranch); Node thenAssign = getBlockExpression(thenBranch).getFirstChild();  Node maybeName1 = thenAssign.getFirstChild(); Node name2 = var.getFirstChild();  if (name2.hasChildren() && maybeName1.isName() && maybeName1.getString().equals(name2.getString())) { Node thenExpr = thenAssign.getLastChild().detachFromParent(); Node elseExpr = name2.removeChildren(); cond.detachFromParent(); Node hookNode = IR.hook(cond, thenExpr, elseExpr) .srcref(n); var.detachFromParent(); name2.addChildrenToBack(hookNode); parent.replaceChild(n, var); reportCodeChange();  return var; } }  return n; }
 boolean parse() { int lineno; int charno;  // JSTypes are represented as Rhino AST nodes, and then resolved later. JSTypeExpression type;  state = State.SEARCHING_ANNOTATION; skipEOLs();  JsDocToken token = next();  List<ExtendedTypeInfo> extendedTypes = Lists.newArrayList();  // Always record that we have a comment. if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo blockInfo = extractBlockComment(token); token = blockInfo.token; if (!blockInfo.string.isEmpty()) { jsdocBuilder.recordBlockDescription(blockInfo.string); } } else { if (token != JsDocToken.ANNOTATION && token != JsDocToken.EOC) { // Mark that there was a description, but don't bother marking // what it was. jsdocBuilder.recordBlockDescription(""); } }  // Parse the actual JsDoc. retry: for (;;) { switch (token) { case ANNOTATION: if (state == State.SEARCHING_ANNOTATION) { state = State.SEARCHING_NEWLINE; lineno = stream.getLineno(); charno = stream.getCharno();  String annotationName = stream.getString(); Annotation annotation = annotationNames.get(annotationName); if (annotation == null) { parser.addParserWarning("msg.bad.jsdoc.tag", annotationName, stream.getLineno(), stream.getCharno()); } else { // Mark the beginning of the annotation. jsdocBuilder.markAnnotation(annotationName, lineno, charno);  switch (annotation) { case AUTHOR: if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo authorInfo = extractSingleLineBlock(); String author = authorInfo.string;  if (author.length() == 0) { parser.addParserWarning("msg.jsdoc.authormissing", stream.getLineno(), stream.getCharno()); } else { jsdocBuilder.addAuthor(author); } token = authorInfo.token; } else { token = eatTokensUntilEOL(token); } continue retry;  case CONSTANT: if (!jsdocBuilder.recordConstancy()) { parser.addParserWarning("msg.jsdoc.const", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case CONSTRUCTOR: if (!jsdocBuilder.recordConstructor()) { if (jsdocBuilder.isInterfaceRecorded()) { parser.addTypeWarning("msg.jsdoc.interface.constructor", stream.getLineno(), stream.getCharno()); } else { parser.addTypeWarning("msg.jsdoc.incompat.type", stream.getLineno(), stream.getCharno()); } } token = eatTokensUntilEOL(); continue retry;  case DEPRECATED: if (!jsdocBuilder.recordDeprecated()) { parser.addParserWarning("msg.jsdoc.deprecated", stream.getLineno(), stream.getCharno()); }  // Find the reason/description, if any. ExtractionInfo reasonInfo = extractMultilineTextualBlock(token);  String reason = reasonInfo.string;  if (reason.length() > 0) { jsdocBuilder.recordDeprecationReason(reason); }  token = reasonInfo.token; continue retry;  case INTERFACE: if (!jsdocBuilder.recordInterface()) { if (jsdocBuilder.isConstructorRecorded()) { parser.addTypeWarning("msg.jsdoc.interface.constructor", stream.getLineno(), stream.getCharno()); } else { parser.addTypeWarning("msg.jsdoc.incompat.type", stream.getLineno(), stream.getCharno()); } } token = eatTokensUntilEOL(); continue retry;  case DESC: if (jsdocBuilder.isDescriptionRecorded()) { parser.addParserWarning("msg.jsdoc.desc.extra", stream.getLineno(), stream.getCharno()); token = eatTokensUntilEOL(); continue retry; } else { ExtractionInfo descriptionInfo = extractMultilineTextualBlock(token);  String description = descriptionInfo.string;  jsdocBuilder.recordDescription(description); token = descriptionInfo.token; continue retry; }  case FILE_OVERVIEW: String fileOverview = ""; if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo fileOverviewInfo = extractMultilineTextualBlock(token, WhitespaceOption.TRIM);  fileOverview = fileOverviewInfo.string;  token = fileOverviewInfo.token; } else { token = eatTokensUntilEOL(token); }  if (!jsdocBuilder.recordFileOverview(fileOverview) || fileOverviewJSDocInfo != null) { parser.addParserWarning("msg.jsdoc.fileoverview.extra", stream.getLineno(), stream.getCharno()); } continue retry;  case LICENSE: case PRESERVE: ExtractionInfo preserveInfo = extractMultilineTextualBlock(token, WhitespaceOption.PRESERVE);  String preserve = preserveInfo.string;  if (preserve.length() > 0) { if (fileLevelJsDocBuilder != null) { fileLevelJsDocBuilder.append(preserve); } }  token = preserveInfo.token; continue retry;  case ENUM: token = next(); lineno = stream.getLineno(); charno = stream.getCharno();  type = null; if (token != JsDocToken.EOL && token != JsDocToken.EOC) { type = createJSTypeExpression( parseAndRecordTypeNode(token)); }  if (type == null) { type = createJSTypeExpression(newStringNode("number")); } if (!jsdocBuilder.recordEnumParameterType(type)) { parser.addTypeWarning( "msg.jsdoc.incompat.type", lineno, charno); } token = eatTokensUntilEOL(token); continue retry;  case EXPORT: if (!jsdocBuilder.recordExport()) { parser.addParserWarning("msg.jsdoc.export", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case EXTERNS: if (!jsdocBuilder.recordExterns()) { parser.addParserWarning("msg.jsdoc.externs", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case JAVA_DISPATCH: if (!jsdocBuilder.recordJavaDispatch()) { parser.addParserWarning("msg.jsdoc.javadispatch", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case EXTENDS: case IMPLEMENTS: skipEOLs(); token = next(); lineno = stream.getLineno(); charno = stream.getCharno(); boolean matchingRc = false;  if (token == JsDocToken.LC) { token = next(); matchingRc = true; }  if (token == JsDocToken.STRING) { Node typeNode = parseAndRecordTypeNameNode( token, lineno, charno, matchingRc);  lineno = stream.getLineno(); charno = stream.getCharno();  typeNode = wrapNode(Token.BANG, typeNode); if (typeNode != null && !matchingRc) { typeNode.putBooleanProp(Node.BRACELESS_TYPE, true); } type = createJSTypeExpression(typeNode);  if (annotation == Annotation.EXTENDS) { // record the extended type, check later extendedTypes.add(new ExtendedTypeInfo( type, stream.getLineno(), stream.getCharno())); } else { Preconditions.checkState( annotation == Annotation.IMPLEMENTS); if (!jsdocBuilder.recordImplementedInterface(type)) { parser.addTypeWarning("msg.jsdoc.implements.duplicate", lineno, charno); } } token = next(); if (matchingRc) { if (token != JsDocToken.RC) { parser.addTypeWarning("msg.jsdoc.missing.rc", stream.getLineno(), stream.getCharno()); } } else if (token != JsDocToken.EOL && token != JsDocToken.EOF && token != JsDocToken.EOC) { parser.addTypeWarning("msg.end.annotation.expected", stream.getLineno(), stream.getCharno()); } } else { parser.addTypeWarning("msg.no.type.name", lineno, charno); } token = eatTokensUntilEOL(token); continue retry;  case HIDDEN: if (!jsdocBuilder.recordHiddenness()) { parser.addParserWarning("msg.jsdoc.hidden", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case LENDS: skipEOLs();  matchingRc = false; if (match(JsDocToken.LC)) { token = next(); matchingRc = true; }  if (match(JsDocToken.STRING)) { token = next(); if (!jsdocBuilder.recordLends(stream.getString())) { parser.addTypeWarning("msg.jsdoc.lends.incompatible", stream.getLineno(), stream.getCharno()); } } else { parser.addTypeWarning("msg.jsdoc.lends.missing", stream.getLineno(), stream.getCharno()); }  if (matchingRc && !match(JsDocToken.RC)) { parser.addTypeWarning("msg.jsdoc.missing.rc", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case MEANING: ExtractionInfo meaningInfo = extractMultilineTextualBlock(token); String meaning = meaningInfo.string; token = meaningInfo.token; if (!jsdocBuilder.recordMeaning(meaning)) { parser.addParserWarning("msg.jsdoc.meaning.extra", stream.getLineno(), stream.getCharno()); } continue retry;  case NO_ALIAS: if (!jsdocBuilder.recordNoAlias()) { parser.addParserWarning("msg.jsdoc.noalias", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case NO_COMPILE: if (!jsdocBuilder.recordNoCompile()) { parser.addParserWarning("msg.jsdoc.nocompile", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case NO_TYPE_CHECK: if (!jsdocBuilder.recordNoTypeCheck()) { parser.addParserWarning("msg.jsdoc.nocheck", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case NOT_IMPLEMENTED: token = eatTokensUntilEOL(); continue retry;  case INHERIT_DOC: case OVERRIDE: if (!jsdocBuilder.recordOverride()) { parser.addTypeWarning("msg.jsdoc.override", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case THROWS: skipEOLs(); token = next(); lineno = stream.getLineno(); charno = stream.getCharno(); type = null;  if (token == JsDocToken.LC) { type = createJSTypeExpression( parseAndRecordTypeNode(token));  if (type == null) { // parsing error reported during recursive descent // recovering parsing token = eatTokensUntilEOL(); continue retry; } }  // *Update* the token to that after the type annotation. token = current();  // Save the throw type. jsdocBuilder.recordThrowType(type);  // Find the throw's description (if applicable). if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo descriptionInfo = extractMultilineTextualBlock(token);  String description = descriptionInfo.string;  if (description.length() > 0) { jsdocBuilder.recordThrowDescription(type, description); }  token = descriptionInfo.token; } else { token = eatTokensUntilEOL(token); } continue retry;  case PARAM: skipEOLs(); token = next(); lineno = stream.getLineno(); charno = stream.getCharno(); type = null;  if (token == JsDocToken.LC) { type = createJSTypeExpression( parseAndRecordParamTypeNode(token));  if (type == null) { // parsing error reported during recursive descent // recovering parsing token = eatTokensUntilEOL(); continue retry; } skipEOLs(); token = next(); lineno = stream.getLineno(); charno = stream.getCharno(); }  String name = null; boolean isBracketedParam = JsDocToken.LB == token; if (isBracketedParam) { token = next(); }  if (JsDocToken.STRING != token) { parser.addTypeWarning("msg.missing.variable.name", lineno, charno); } else { name = stream.getString();  if (isBracketedParam) { token = next();  // Throw out JsDocToolkit's "default" parameter // annotation.  It makes no sense under our type // system. if (JsDocToken.EQUALS == token) { token = next(); if (JsDocToken.STRING == token) { token = next(); } }  if (JsDocToken.RB != token) { reportTypeSyntaxWarning("msg.jsdoc.missing.rb"); } else if (type != null) { // Make the type expression optional, if it isn't // already. type = JSTypeExpression.makeOptionalArg(type); } }  // If the param name has a DOT in it, just throw it out // quietly. We do not handle the JsDocToolkit method // for handling properties of params. if (name.indexOf('.') > -1) { name = null; } else if (!jsdocBuilder.recordParameter(name, type)) { if (jsdocBuilder.hasParameter(name)) { parser.addTypeWarning("msg.dup.variable.name", name, lineno, charno); } else { parser.addTypeWarning("msg.jsdoc.incompat.type", name, lineno, charno); } } }  if (name == null) { token = eatTokensUntilEOL(token); continue retry; }  jsdocBuilder.markName(name, lineno, charno);  // Find the parameter's description (if applicable). if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo paramDescriptionInfo = extractMultilineTextualBlock(token);  String paramDescription = paramDescriptionInfo.string;  if (paramDescription.length() > 0) { jsdocBuilder.recordParameterDescription(name, paramDescription); }  token = paramDescriptionInfo.token; } else { token = eatTokensUntilEOL(token); } continue retry;  case PRESERVE_TRY: if (!jsdocBuilder.recordPreserveTry()) { parser.addParserWarning("msg.jsdoc.preservertry", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case PRIVATE: if (!jsdocBuilder.recordVisibility(Visibility.PRIVATE)) { parser.addParserWarning("msg.jsdoc.visibility.private", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case PROTECTED: if (!jsdocBuilder.recordVisibility(Visibility.PROTECTED)) { parser.addParserWarning("msg.jsdoc.visibility.protected", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case PUBLIC: if (!jsdocBuilder.recordVisibility(Visibility.PUBLIC)) { parser.addParserWarning("msg.jsdoc.visibility.public", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case NO_SHADOW: if (!jsdocBuilder.recordNoShadow()) { parser.addParserWarning("msg.jsdoc.noshadow", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case NO_SIDE_EFFECTS: if (!jsdocBuilder.recordNoSideEffects()) { parser.addParserWarning("msg.jsdoc.nosideeffects", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case MODIFIES: token = parseModifiesTag(next()); continue retry;  case IMPLICIT_CAST: if (!jsdocBuilder.recordImplicitCast()) { parser.addTypeWarning("msg.jsdoc.implicitcast", stream.getLineno(), stream.getCharno()); } token = eatTokensUntilEOL(); continue retry;  case SEE: if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo referenceInfo = extractSingleLineBlock(); String reference = referenceInfo.string;  if (reference.length() == 0) { parser.addParserWarning("msg.jsdoc.seemissing", stream.getLineno(), stream.getCharno()); } else { jsdocBuilder.addReference(reference); }  token = referenceInfo.token; } else { token = eatTokensUntilEOL(token); } continue retry;  case SUPPRESS: token = parseSuppressTag(next()); continue retry;  case TEMPLATE: ExtractionInfo templateInfo = extractSingleLineBlock(); String templateTypeName = templateInfo.string;  if (templateTypeName.length() == 0) { parser.addTypeWarning("msg.jsdoc.templatemissing", stream.getLineno(), stream.getCharno()); } else if (!jsdocBuilder.recordTemplateTypeName( templateTypeName)) { parser.addTypeWarning("msg.jsdoc.template.at.most.once", stream.getLineno(), stream.getCharno()); }  token = templateInfo.token; continue retry;  case VERSION: ExtractionInfo versionInfo = extractSingleLineBlock(); String version = versionInfo.string;  if (version.length() == 0) { parser.addParserWarning("msg.jsdoc.versionmissing", stream.getLineno(), stream.getCharno()); } else { if (!jsdocBuilder.recordVersion(version)) { parser.addParserWarning("msg.jsdoc.extraversion", stream.getLineno(), stream.getCharno()); } }  token = versionInfo.token; continue retry;  case DEFINE: case RETURN: case THIS: case TYPE: case TYPEDEF: lineno = stream.getLineno(); charno = stream.getCharno();  Node typeNode = null; if (!lookAheadForTypeAnnotation() && annotation == Annotation.RETURN) { // If RETURN doesn't have a type annotation, record // it as the unknown type. typeNode = newNode(Token.QMARK); } else { skipEOLs(); token = next(); typeNode = parseAndRecordTypeNode(token, lineno, charno); }  if (annotation == Annotation.THIS) { typeNode = wrapNode(Token.BANG, typeNode); if (typeNode != null && token != JsDocToken.LC) { typeNode.putBooleanProp(Node.BRACELESS_TYPE, true); } } type = createJSTypeExpression(typeNode);  if (type == null) { // error reported during recursive descent // recovering parsing } else { switch (annotation) { case DEFINE: if (!jsdocBuilder.recordDefineType(type)) { parser.addParserWarning("msg.jsdoc.define", lineno, charno); } break;  case RETURN: if (!jsdocBuilder.recordReturnType(type)) { parser.addTypeWarning( "msg.jsdoc.incompat.type", lineno, charno); break; }  // Find the return's description (if applicable). if (jsdocBuilder.shouldParseDocumentation()) { ExtractionInfo returnDescriptionInfo = extractMultilineTextualBlock(token);  String returnDescription = returnDescriptionInfo.string;  if (returnDescription.length() > 0) { jsdocBuilder.recordReturnDescription( returnDescription); }  token = returnDescriptionInfo.token; } else { token = eatTokensUntilEOL(token); } continue retry;  case THIS: if (!jsdocBuilder.recordThisType(type)) { parser.addTypeWarning( "msg.jsdoc.incompat.type", lineno, charno); } break;  case TYPE: if (!jsdocBuilder.recordType(type)) { parser.addTypeWarning( "msg.jsdoc.incompat.type", lineno, charno); } break;  case TYPEDEF: if (!jsdocBuilder.recordTypedef(type)) { parser.addTypeWarning( "msg.jsdoc.incompat.type", lineno, charno); } break; }  token = eatTokensUntilEOL(); } continue retry; } } } break;  case EOC: if (hasParsedFileOverviewDocInfo()) { fileOverviewJSDocInfo = retrieveAndResetParsedJSDocInfo(); } checkExtendedTypes(extendedTypes); return true;  case EOF: // discard any accumulated information jsdocBuilder.build(null); parser.addParserWarning("msg.unexpected.eof", stream.getLineno(), stream.getCharno()); checkExtendedTypes(extendedTypes); return false;  case EOL: if (state == State.SEARCHING_NEWLINE) { state = State.SEARCHING_ANNOTATION; } token = next(); continue retry;  default: if (token == JsDocToken.STAR && state == State.SEARCHING_ANNOTATION) { token = next(); continue retry; } else { state = State.SEARCHING_NEWLINE; token = eatTokensUntilEOL(); continue retry; } }  // next token token = next(); } }
 private Node parseBasicTypeExpression(JsDocToken token) { if (token == JsDocToken.STAR) { return newNode(Token.STAR); } else if (token == JsDocToken.LB) { skipEOLs(); return parseArrayType(next()); } else if (token == JsDocToken.LC) { skipEOLs(); return parseRecordType(next()); } else if (token == JsDocToken.LP) { skipEOLs(); return parseUnionType(next()); } else if (token == JsDocToken.STRING) { String string = stream.getString(); if ("function".equals(string)) { skipEOLs(); return parseFunctionType(next()); } else if ("null".equals(string) || "undefined".equals(string)) { return newStringNode(string); } else { return parseTypeName(token); } }  return reportGenericTypeSyntaxWarning(); }
 private Node parseFunctionType(JsDocToken token) { // NOTE(nicksantos): We're not implementing generics at the moment, so // just throw out TypeParameters. if (token != JsDocToken.LP) { return reportTypeSyntaxWarning("msg.jsdoc.missing.lp"); }  Node functionType = newNode(Token.FUNCTION); Node parameters = null; skipEOLs(); if (!match(JsDocToken.RP)) { token = next();  boolean hasParams = true; if (token == JsDocToken.STRING) { String tokenStr = stream.getString(); boolean isThis = "this".equals(tokenStr); boolean isNew = "new".equals(tokenStr); if (isThis || isNew) { if (match(JsDocToken.COLON)) { next(); skipEOLs(); Node contextType = wrapNode( isThis ? Token.THIS : Token.NEW, parseTypeName(next())); if (contextType == null) { return null; }  functionType.addChildToFront(contextType); } else { return reportTypeSyntaxWarning("msg.jsdoc.missing.colon"); }  if (match(JsDocToken.COMMA)) { next(); skipEOLs(); token = next(); } else { hasParams = false; } } }  if (hasParams) { parameters = parseParametersType(token); if (parameters == null) { return null; } } }  if (parameters != null) { functionType.addChildToBack(parameters); }  skipEOLs(); if (!match(JsDocToken.RP)) { return reportTypeSyntaxWarning("msg.jsdoc.missing.rp"); }  skipEOLs(); Node resultType = parseResultType(next()); if (resultType == null) { return null; } else { functionType.addChildToBack(resultType); } return functionType; }
 public long add(long instant, int value) { if (instant >= iCutover) { instant = iGregorianField.add(instant, value); if (instant < iCutover) { // Only adjust if gap fully crossed. if (instant + iGapDuration < iCutover) { instant = gregorianToJulian(instant); } } } else { instant = iJulianField.add(instant, value); if (instant >= iCutover) { // Only adjust if gap fully crossed. if (instant - iGapDuration >= iCutover) { // no special handling for year zero as cutover always after year zero instant = julianToGregorian(instant); } } } return instant; }
 public long add(long instant, long value) { if (instant >= iCutover) { instant = iGregorianField.add(instant, value); if (instant < iCutover) { // Only adjust if gap fully crossed. if (instant + iGapDuration < iCutover) { instant = gregorianToJulian(instant); } } } else { instant = iJulianField.add(instant, value); if (instant >= iCutover) { // Only adjust if gap fully crossed. if (instant - iGapDuration >= iCutover) { // no special handling for year zero as cutover always after year zero instant = julianToGregorian(instant); } } } return instant; }
 public static synchronized GJChronology getInstance( DateTimeZone zone, ReadableInstant gregorianCutover, int minDaysInFirstWeek) {  zone = DateTimeUtils.getZone(zone); Instant cutoverInstant; if (gregorianCutover == null) { cutoverInstant = DEFAULT_CUTOVER; } else { cutoverInstant = gregorianCutover.toInstant(); }  GJChronology chrono; synchronized (cCache) { ArrayList<GJChronology> chronos = cCache.get(zone); if (chronos == null) { chronos = new ArrayList<GJChronology>(2); cCache.put(zone, chronos); } else { for (int i = chronos.size(); --i >= 0;) { chrono = chronos.get(i); if (minDaysInFirstWeek == chrono.getMinimumDaysInFirstWeek() && cutoverInstant.equals(chrono.getGregorianCutover())) {  return chrono; } } } if (zone == DateTimeZone.UTC) { chrono = new GJChronology (JulianChronology.getInstance(zone, minDaysInFirstWeek), GregorianChronology.getInstance(zone, minDaysInFirstWeek), cutoverInstant); } else { chrono = getInstance(DateTimeZone.UTC, cutoverInstant, minDaysInFirstWeek); chrono = new GJChronology (ZonedChronology.getInstance(chrono, zone), chrono.iJulianChronology, chrono.iGregorianChronology, chrono.iCutoverInstant); } chronos.add(chrono); } return chrono; }
 public static Locale toLocale(String str) { if (str == null) { return null; } int len = str.length(); if (len != 2 && len != 5 && len < 7) { throw new IllegalArgumentException("Invalid locale format: " + str); } char ch0 = str.charAt(0); char ch1 = str.charAt(1); if (ch0 < 'a' || ch0 > 'z' || ch1 < 'a' || ch1 > 'z') { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 2) { return new Locale(str, ""); } else { if (str.charAt(2) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } char ch3 = str.charAt(3); char ch4 = str.charAt(4); if (ch3 < 'A' || ch3 > 'Z' || ch4 < 'A' || ch4 > 'Z') { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 5) { return new Locale(str.substring(0, 2), str.substring(3, 5)); } else { if (str.charAt(5) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale(str.substring(0, 2), str.substring(3, 5), str.substring(6)); } } }
 public static Locale toLocale(String str) { if (str == null) { return null; } int len = str.length(); if (len != 2 && len != 5 && len < 7) { throw new IllegalArgumentException("Invalid locale format: " + str); } char ch0 = str.charAt(0); char ch1 = str.charAt(1); if (ch0 < 'a' || ch0 > 'z' || ch1 < 'a' || ch1 > 'z') { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 2) { return new Locale(str, ""); } else { if (str.charAt(2) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } char ch3 = str.charAt(3); char ch4 = str.charAt(4); if (ch3 < 'A' || ch3 > 'Z' || ch4 < 'A' || ch4 > 'Z') { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 5) { return new Locale(str.substring(0, 2), str.substring(3, 5)); } else { if (str.charAt(5) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale(str.substring(0, 2), str.substring(3, 5), str.substring(6)); } } }
 private Fraction(double value, double epsilon, int maxDenominator, int maxIterations) throws FractionConversionException { long overflow = Integer.MAX_VALUE; double r0 = value; long a0 = (long)FastMath.floor(r0); if (a0 > overflow) { throw new FractionConversionException(value, a0, 1l); }  // check for (almost) integer arguments, which should not go // to iterations. if (FastMath.abs(a0 - value) < epsilon) { this.numerator = (int) a0; this.denominator = 1; return; }  long p0 = 1; long q0 = 0; long p1 = a0; long q1 = 1;  long p2 = 0; long q2 = 1;  int n = 0; boolean stop = false; do { ++n; double r1 = 1.0 / (r0 - a0); long a1 = (long)FastMath.floor(r1); p2 = (a1 * p1) + p0; q2 = (a1 * q1) + q0; if ((p2 > overflow) || (q2 > overflow)) { throw new FractionConversionException(value, p2, q2); }  double convergent = (double)p2 / (double)q2; if (n < maxIterations && FastMath.abs(convergent - value) > epsilon && q2 < maxDenominator) { p0 = p1; p1 = p2; q0 = q1; q1 = q2; a0 = a1; r0 = r1; } else { stop = true; } } while (!stop);  if (n >= maxIterations) { throw new FractionConversionException(value, maxIterations); }  if (q2 < maxDenominator) { this.numerator = (int) p2; this.denominator = (int) q2; } else { this.numerator = (int) p1; this.denominator = (int) q1; }  }
 private Fraction(double value, double epsilon, int maxDenominator, int maxIterations) throws FractionConversionException { long overflow = Integer.MAX_VALUE; double r0 = value; long a0 = (long)FastMath.floor(r0); if (a0 > overflow) { throw new FractionConversionException(value, a0, 1l); }  // check for (almost) integer arguments, which should not go // to iterations. if (FastMath.abs(a0 - value) < epsilon) { this.numerator = (int) a0; this.denominator = 1; return; }  long p0 = 1; long q0 = 0; long p1 = a0; long q1 = 1;  long p2 = 0; long q2 = 1;  int n = 0; boolean stop = false; do { ++n; double r1 = 1.0 / (r0 - a0); long a1 = (long)FastMath.floor(r1); p2 = (a1 * p1) + p0; q2 = (a1 * q1) + q0; if ((p2 > overflow) || (q2 > overflow)) { throw new FractionConversionException(value, p2, q2); }  double convergent = (double)p2 / (double)q2; if (n < maxIterations && FastMath.abs(convergent - value) > epsilon && q2 < maxDenominator) { p0 = p1; p1 = p2; q0 = q1; q1 = q2; a0 = a1; r0 = r1; } else { stop = true; } } while (!stop);  if (n >= maxIterations) { throw new FractionConversionException(value, maxIterations); }  if (q2 < maxDenominator) { this.numerator = (int) p2; this.denominator = (int) q2; } else { this.numerator = (int) p1; this.denominator = (int) q1; }  }
 public double[] fit() { final double[] guess = (new ParameterGuesser(getObservations())).guess(); return fit(new Gaussian.Parametric(), guess); }
 private Node computeFollowing(Node n) { Node next = ControlFlowAnalysis.computeFollowNode(n); return next; }
 private Node tryRemoveUnconditionalBranching(Node n) { /* * For each of the unconditional branching control flow node, check to see * if the ControlFlowAnalysis.computeFollowNode of that node is same as * the branching target. If it is, the branch node is safe to be removed. * * This is not as clever as MinimizeExitPoints because it doesn't do any * if-else conversion but it handles more complicated switch statements * much nicer. */  // If n is null the target is the end of the function, nothing to do. if (n == null) { return n; }  DiGraphNode<Node, Branch> gNode = curCfg.getDirectedGraphNode(n);  if (gNode == null) { return n; }  if (n.getParent() == null) { List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1) { return tryRemoveUnconditionalBranching(outEdges.get(0).getDestination().getValue()); } } switch (n.getType()) { case Token.BLOCK: if (n.hasChildren()) { Node first = n.getFirstChild(); return tryRemoveUnconditionalBranching(first); } else { return tryRemoveUnconditionalBranching(ControlFlowAnalysis.computeFollowNode(n)); } case Token.RETURN: if (n.hasChildren()) { break; } case Token.BREAK: case Token.CONTINUE:  // We are looking for a control flow changing statement that always // branches to the same node. If removing it the control flow still // branches to that same node. It is safe to remove it. List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1 && // If there is a next node, there is no chance this jump is useless. (n.getNext() == null || n.getNext().getType() == Token.FUNCTION)) {  Preconditions.checkState(outEdges.get(0).getValue() == Branch.UNCOND); Node fallThrough = tryRemoveUnconditionalBranching(computeFollowing(n)); Node nextCfgNode = outEdges.get(0).getDestination().getValue(); if (nextCfgNode == fallThrough) { removeDeadExprStatementSafely(n); return fallThrough; } } } return n; }
 private Node tryRemoveUnconditionalBranching(Node n) { /* * For each of the unconditional branching control flow node, check to see * if the ControlFlowAnalysis.computeFollowNode of that node is same as * the branching target. If it is, the branch node is safe to be removed. * * This is not as clever as MinimizeExitPoints because it doesn't do any * if-else conversion but it handles more complicated switch statements * much nicer. */  // If n is null the target is the end of the function, nothing to do. if (n == null) { return n; }  DiGraphNode<Node, Branch> gNode = curCfg.getDirectedGraphNode(n);  if (gNode == null) { return n; }  if (n.getParent() == null) { List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1) { return tryRemoveUnconditionalBranching(outEdges.get(0).getDestination().getValue()); } } switch (n.getType()) { case Token.BLOCK: if (n.hasChildren()) { Node first = n.getFirstChild(); return tryRemoveUnconditionalBranching(first); } else { return tryRemoveUnconditionalBranching(ControlFlowAnalysis.computeFollowNode(n)); } case Token.RETURN: if (n.hasChildren()) { break; } case Token.BREAK: case Token.CONTINUE:  // We are looking for a control flow changing statement that always // branches to the same node. If removing it the control flow still // branches to that same node. It is safe to remove it. List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1 && // If there is a next node, there is no chance this jump is useless. (n.getNext() == null || n.getNext().getType() == Token.FUNCTION)) {  Preconditions.checkState(outEdges.get(0).getValue() == Branch.UNCOND); Node fallThrough = tryRemoveUnconditionalBranching(computeFollowing(n)); Node nextCfgNode = outEdges.get(0).getDestination().getValue(); if (nextCfgNode == fallThrough) { removeDeadExprStatementSafely(n); return fallThrough; } } } return n; }
 private Node tryRemoveUnconditionalBranching(Node n) { /* * For each of the unconditional branching control flow node, check to see * if the ControlFlowAnalysis.computeFollowNode of that node is same as * the branching target. If it is, the branch node is safe to be removed. * * This is not as clever as MinimizeExitPoints because it doesn't do any * if-else conversion but it handles more complicated switch statements * much nicer. */  // If n is null the target is the end of the function, nothing to do. if (n == null) { return n; }  DiGraphNode<Node, Branch> gNode = curCfg.getDirectedGraphNode(n);  if (gNode == null) { return n; }  if (n.getParent() == null) { List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1) { return tryRemoveUnconditionalBranching(outEdges.get(0).getDestination().getValue()); } } switch (n.getType()) { case Token.BLOCK: if (n.hasChildren()) { Node first = n.getFirstChild(); return tryRemoveUnconditionalBranching(first); } else { return tryRemoveUnconditionalBranching(ControlFlowAnalysis.computeFollowNode(n)); } case Token.RETURN: if (n.hasChildren()) { break; } case Token.BREAK: case Token.CONTINUE:  // We are looking for a control flow changing statement that always // branches to the same node. If removing it the control flow still // branches to that same node. It is safe to remove it. List<DiGraphEdge<Node,Branch>> outEdges = gNode.getOutEdges(); if (outEdges.size() == 1 && // If there is a next node, there is no chance this jump is useless. (n.getNext() == null || n.getNext().getType() == Token.FUNCTION)) {  Preconditions.checkState(outEdges.get(0).getValue() == Branch.UNCOND); Node fallThrough = tryRemoveUnconditionalBranching(computeFollowing(n)); Node nextCfgNode = outEdges.get(0).getDestination().getValue(); if (nextCfgNode == fallThrough) { removeDeadExprStatementSafely(n); return fallThrough; } } } return n; }
 static boolean functionCallHasSideEffects( Node callNode, @Nullable AbstractCompiler compiler) { if (callNode.getType() != Token.CALL) { throw new IllegalStateException( "Expected CALL node, got " + Token.name(callNode.getType())); }  if (callNode.isNoSideEffectsCall()) { return false; }  Node nameNode = callNode.getFirstChild();  // Built-in functions with no side effects. if (nameNode.getType() == Token.NAME) { String name = nameNode.getString(); if (BUILTIN_FUNCTIONS_WITHOUT_SIDEEFFECTS.contains(name)) { return false; } } else if (nameNode.getType() == Token.GETPROP) { if (callNode.hasOneChild() && OBJECT_METHODS_WITHOUT_SIDEEFFECTS.contains( nameNode.getLastChild().getString())) { return false; }  if (callNode.isOnlyModifiesThisCall() && evaluatesToLocalValue(nameNode.getFirstChild())) { return false; }  // Functions in the "Math" namespace have no side effects.  if (compiler != null && !compiler.hasRegExpGlobalReferences()) { if (nameNode.getFirstChild().getType() == Token.REGEXP && REGEXP_METHODS.contains(nameNode.getLastChild().getString())) { return false; } else if (nameNode.getFirstChild().getType() == Token.STRING && STRING_REGEXP_METHODS.contains( nameNode.getLastChild().getString())) { Node param = nameNode.getNext(); if (param != null && (param.getType() == Token.STRING || param.getType() == Token.REGEXP)) return false; } } }  return true; }
 Node processAssignment(Assignment assignmentNode) { Node assign = processInfixExpression(assignmentNode); return assign; }
 Node processUnaryExpression(UnaryExpression exprNode) { int type = transformTokenType(exprNode.getType()); Node operand = transform(exprNode.getOperand()); if (type == Token.NEG && operand.getType() == Token.NUMBER) { operand.setDouble(-operand.getDouble()); return operand; } else {  Node node = newNode(type, operand); if (exprNode.isPostfix()) { node.putBooleanProp(Node.INCRDECR_PROP, true); } return node; } }
 private void updateSimpleDeclaration(String alias, Name refName, Ref ref) { Node rvalue = ref.node.getNext(); Node parent = ref.node.getParent(); Node gramps = parent.getParent(); Node greatGramps = gramps.getParent(); Node greatGreatGramps = greatGramps.getParent();   // Create the new alias node. Node nameNode = NodeUtil.newName( compiler.getCodingConvention(), alias, gramps.getFirstChild(), refName.fullName()); NodeUtil.copyNameAnnotations(ref.node.getLastChild(), nameNode);  if (gramps.getType() == Token.EXPR_RESULT) { // BEFORE: a.b.c = ...; //   exprstmt //     assign //       getprop //         getprop //           name a //           string b //         string c //       NODE // AFTER: var a$b$c = ...; //   var //     name a$b$c //       NODE  // Remove the rvalue (NODE). parent.removeChild(rvalue); nameNode.addChildToFront(rvalue);  Node varNode = new Node(Token.VAR, nameNode); greatGramps.replaceChild(gramps, varNode); } else { // This must be a complex assignment. Preconditions.checkNotNull(ref.getTwin());  // BEFORE: // ... (x.y = 3); // // AFTER: // var x$y; // ... (x$y = 3);  Node current = gramps; Node currentParent = gramps.getParent(); for (; currentParent.getType() != Token.SCRIPT && currentParent.getType() != Token.BLOCK; current = currentParent, currentParent = currentParent.getParent()) {}  // Create a stub variable declaration right // before the current statement. Node stubVar = new Node(Token.VAR, nameNode.cloneTree()) .copyInformationFrom(nameNode); currentParent.addChildBefore(stubVar, current);  parent.replaceChild(ref.node, nameNode); }  compiler.reportCodeChange(); }
 boolean canCollapseUnannotatedChildNames() { if (type == Type.OTHER || globalSets != 1 || localSets != 0) { return false; }  // Don't try to collapse if the one global set is a twin reference. // We could theoretically handle this case in CollapseProperties, but // it's probably not worth the effort. Preconditions.checkNotNull(declaration); if (declaration.getTwin() != null) { return false; }  if (isClassOrEnum) { return true; }  // If this is a key of an aliased object literal, then it will be aliased // later. So we won't be able to collapse its properties. if (parent != null && parent.shouldKeepKeys()) { return false; }  // If this is aliased, then its properties can't be collapsed either. if (type != Type.FUNCTION && aliasingGets > 0) { return false; }  return (parent == null || parent.canCollapseUnannotatedChildNames()); }
 static String strEscape(String s, char quote, String doublequoteEscape, String singlequoteEscape, String backslashEscape, CharsetEncoder outputCharsetEncoder) { StringBuilder sb = new StringBuilder(s.length() + 2); sb.append(quote); for (int i = 0; i < s.length(); i++) { char c = s.charAt(i); switch (c) { case '\0': sb.append("\\0"); break; case '\n': sb.append("\\n"); break; case '\r': sb.append("\\r"); break; case '\t': sb.append("\\t"); break; case '\\': sb.append(backslashEscape); break; case '\"': sb.append(doublequoteEscape); break; case '\'': sb.append(singlequoteEscape); break; case '>':                       // Break --> into --\> or ]]> into ]]\> if (i >= 2 && ((s.charAt(i - 1) == '-' && s.charAt(i - 2) == '-') || (s.charAt(i - 1) == ']' && s.charAt(i - 2) == ']'))) { sb.append("\\>"); } else { sb.append(c); } break; case '<': // Break </script into <\/script final String END_SCRIPT = "/script";  // Break <!-- into <\!-- final String START_COMMENT = "!--";  if (s.regionMatches(true, i + 1, END_SCRIPT, 0, END_SCRIPT.length())) { sb.append("<\\"); } else if (s.regionMatches(false, i + 1, START_COMMENT, 0, START_COMMENT.length())) { sb.append("<\\"); } else { sb.append(c); } break; default: // If we're given an outputCharsetEncoder, then check if the //  character can be represented in this character set. if (outputCharsetEncoder != null) { if (outputCharsetEncoder.canEncode(c)) { sb.append(c); } else { // Unicode-escape the character. appendHexJavaScriptRepresentation(sb, c); } } else { // No charsetEncoder provided - pass straight latin characters // through, and escape the rest.  Doing the explicit character // check is measurably faster than using the CharsetEncoder. if (c > 0x1f && c < 0x7f) { sb.append(c); } else { // Other characters can be misinterpreted by some js parsers, // or perhaps mangled by proxies along the way, // so we play it safe and unicode escape them. appendHexJavaScriptRepresentation(sb, c); } } } } sb.append(quote); return sb.toString(); }
 public TimeSeries createCopy(int start, int end) throws CloneNotSupportedException { if (start < 0) { throw new IllegalArgumentException("Requires start >= 0."); } if (end < start) { throw new IllegalArgumentException("Requires start <= end."); } TimeSeries copy = (TimeSeries) super.clone(); copy.data = new java.util.ArrayList(); if (this.data.size() > 0) { for (int index = start; index <= end; index++) { TimeSeriesDataItem item = (TimeSeriesDataItem) this.data.get(index); TimeSeriesDataItem clone = (TimeSeriesDataItem) item.clone(); try { copy.add(clone); } catch (SeriesException e) { e.printStackTrace(); } } } return copy; }
 public TimeSeries createCopy(int start, int end) throws CloneNotSupportedException { if (start < 0) { throw new IllegalArgumentException("Requires start >= 0."); } if (end < start) { throw new IllegalArgumentException("Requires start <= end."); } TimeSeries copy = (TimeSeries) super.clone(); copy.data = new java.util.ArrayList(); if (this.data.size() > 0) { for (int index = start; index <= end; index++) { TimeSeriesDataItem item = (TimeSeriesDataItem) this.data.get(index); TimeSeriesDataItem clone = (TimeSeriesDataItem) item.clone(); try { copy.add(clone); } catch (SeriesException e) { e.printStackTrace(); } } } return copy; }
 public static <T> T any(Class<T> clazz) { return (T) reportMatcher(Any.ANY).returnFor(clazz); }
 public static <T> T any() { return (T) anyObject(); }
 public static boolean anyBoolean() { return reportMatcher(Any.ANY).returnFalse(); }
 public static byte anyByte() { return reportMatcher(Any.ANY).returnZero(); }
 public static char anyChar() { return reportMatcher(Any.ANY).returnChar(); }
 public static Collection anyCollection() { return reportMatcher(Any.ANY).returnList(); }
 public static <T> Collection<T> anyCollectionOf(Class<T> clazz) { return (Collection) reportMatcher(Any.ANY).returnList(); }
 public static double anyDouble() { return reportMatcher(Any.ANY).returnZero(); }
 public static float anyFloat() { return reportMatcher(Any.ANY).returnZero(); }
 public static int anyInt() { return reportMatcher(Any.ANY).returnZero(); }
 public static List anyList() { return reportMatcher(Any.ANY).returnList(); }
 public static <T> List<T> anyListOf(Class<T> clazz) { return (List) reportMatcher(Any.ANY).returnList(); }
 public static long anyLong() { return reportMatcher(Any.ANY).returnZero(); }
 public static Map anyMap() { return reportMatcher(Any.ANY).returnMap(); }
 public static <K, V>  Map<K, V> anyMapOf(Class<K> keyClazz, Class<V> valueClazz) { return reportMatcher(Any.ANY).returnMap(); }
 public static <T> T anyObject() { return (T) reportMatcher(Any.ANY).returnNull(); }
 public static Set anySet() { return reportMatcher(Any.ANY).returnSet(); }
 public static <T> Set<T> anySetOf(Class<T> clazz) { return (Set) reportMatcher(Any.ANY).returnSet(); }
 public static short anyShort() { return reportMatcher(Any.ANY).returnZero(); }
 public static String anyString() { return reportMatcher(Any.ANY).returnString(); }
 public boolean removeDomainMarker(int index, Marker marker, Layer layer, boolean notify) { ArrayList markers; if (layer == Layer.FOREGROUND) { markers = (ArrayList) this.foregroundDomainMarkers.get(new Integer( index)); } else { markers = (ArrayList) this.backgroundDomainMarkers.get(new Integer( index)); } boolean removed = markers.remove(marker); if (removed && notify) { fireChangeEvent(); } return removed; }
 public boolean removeRangeMarker(int index, Marker marker, Layer layer, boolean notify) { if (marker == null) { throw new IllegalArgumentException("Null 'marker' argument."); } ArrayList markers; if (layer == Layer.FOREGROUND) { markers = (ArrayList) this.foregroundRangeMarkers.get(new Integer( index)); } else { markers = (ArrayList) this.backgroundRangeMarkers.get(new Integer( index)); } boolean removed = markers.remove(marker); if (removed && notify) { fireChangeEvent(); } return removed; }
 public boolean removeDomainMarker(int index, Marker marker, Layer layer, boolean notify) { ArrayList markers; if (layer == Layer.FOREGROUND) { markers = (ArrayList) this.foregroundDomainMarkers.get(new Integer( index)); } else { markers = (ArrayList) this.backgroundDomainMarkers.get(new Integer( index)); } boolean removed = markers.remove(marker); if (removed && notify) { fireChangeEvent(); } return removed; }
 public boolean removeRangeMarker(int index, Marker marker, Layer layer, boolean notify) { if (marker == null) { throw new IllegalArgumentException("Null 'marker' argument."); } ArrayList markers; if (layer == Layer.FOREGROUND) { markers = (ArrayList) this.foregroundRangeMarkers.get(new Integer( index)); } else { markers = (ArrayList) this.backgroundRangeMarkers.get(new Integer( index)); } boolean removed = markers.remove(marker); if (removed && notify) { fireChangeEvent(); } return removed; }
 private void inlineAliases(GlobalNamespace namespace) { // Invariant: All the names in the worklist meet condition (a). Deque<Name> workList = new ArrayDeque<Name>(namespace.getNameForest()); while (!workList.isEmpty()) { Name name = workList.pop();  // Don't attempt to inline a getter or setter property as a variable. if (name.type == Name.Type.GET || name.type == Name.Type.SET) { continue; }  if (name.globalSets == 1 && name.localSets == 0 && name.aliasingGets > 0) { // {@code name} meets condition (b). Find all of its local aliases // and try to inline them. List<Ref> refs = Lists.newArrayList(name.getRefs()); for (Ref ref : refs) { if (ref.type == Type.ALIASING_GET && ref.scope.isLocal()) { // {@code name} meets condition (c). Try to inline it. if (inlineAliasIfPossible(ref, namespace)) { name.removeRef(ref); } } } }  // Check if {@code name} has any aliases left after the // local-alias-inlining above. if ((name.type == Name.Type.OBJECTLIT || name.type == Name.Type.FUNCTION) && name.aliasingGets == 0 && name.props != null) { // All of {@code name}'s children meet condition (a), so they can be // added to the worklist. workList.addAll(name.props); } } }
 static TernaryValue getImpureBooleanValue(Node n) { switch (n.getType()) { case Token.ASSIGN: case Token.COMMA: // For ASSIGN and COMMA the value is the value of the RHS. return getImpureBooleanValue(n.getLastChild()); case Token.NOT: TernaryValue value = getImpureBooleanValue(n.getLastChild()); return value.not(); case Token.AND: { TernaryValue lhs = getImpureBooleanValue(n.getFirstChild()); TernaryValue rhs = getImpureBooleanValue(n.getLastChild()); return lhs.and(rhs); } case Token.OR:  { TernaryValue lhs = getImpureBooleanValue(n.getFirstChild()); TernaryValue rhs = getImpureBooleanValue(n.getLastChild()); return lhs.or(rhs); } case Token.HOOK:  { TernaryValue trueValue = getImpureBooleanValue( n.getFirstChild().getNext()); TernaryValue falseValue = getImpureBooleanValue(n.getLastChild()); if (trueValue.equals(falseValue)) { return trueValue; } else { return TernaryValue.UNKNOWN; } } case Token.ARRAYLIT: case Token.OBJECTLIT: // ignoring side-effects return TernaryValue.TRUE;   default: return getPureBooleanValue(n); } }
 static TernaryValue getPureBooleanValue(Node n) { switch (n.getType()) { case Token.STRING: return TernaryValue.forBoolean(n.getString().length() > 0);  case Token.NUMBER: return TernaryValue.forBoolean(n.getDouble() != 0);  case Token.NOT: return getPureBooleanValue(n.getLastChild()).not();  case Token.NULL: case Token.FALSE: return TernaryValue.FALSE;  case Token.VOID: return TernaryValue.FALSE;  case Token.NAME: String name = n.getString(); if ("undefined".equals(name) || "NaN".equals(name)) { // We assume here that programs don't change the value of the keyword // undefined to something other than the value undefined. return TernaryValue.FALSE; } else if ("Infinity".equals(name)) { return TernaryValue.TRUE; } break;  case Token.TRUE: case Token.REGEXP: return TernaryValue.TRUE;  case Token.ARRAYLIT: case Token.OBJECTLIT: if (!mayHaveSideEffects(n)) { return TernaryValue.TRUE; } break; }  return TernaryValue.UNKNOWN; }
 public static double linearCombination(final double[] a, final double[] b) throws DimensionMismatchException { final int len = a.length; if (len != b.length) { throw new DimensionMismatchException(len, b.length); }  // Revert to scalar multiplication.  final double[] prodHigh = new double[len]; double prodLowSum = 0;  for (int i = 0; i < len; i++) { final double ai = a[i]; final double ca = SPLIT_FACTOR * ai; final double aHigh = ca - (ca - ai); final double aLow = ai - aHigh;  final double bi = b[i]; final double cb = SPLIT_FACTOR * bi; final double bHigh = cb - (cb - bi); final double bLow = bi - bHigh; prodHigh[i] = ai * bi; final double prodLow = aLow * bLow - (((prodHigh[i] - aHigh * bHigh) - aLow * bHigh) - aHigh * bLow); prodLowSum += prodLow; }   final double prodHighCur = prodHigh[0]; double prodHighNext = prodHigh[1]; double sHighPrev = prodHighCur + prodHighNext; double sPrime = sHighPrev - prodHighNext; double sLowSum = (prodHighNext - (sHighPrev - sPrime)) + (prodHighCur - sPrime);  final int lenMinusOne = len - 1; for (int i = 1; i < lenMinusOne; i++) { prodHighNext = prodHigh[i + 1]; final double sHighCur = sHighPrev + prodHighNext; sPrime = sHighCur - prodHighNext; sLowSum += (prodHighNext - (sHighCur - sPrime)) + (sHighPrev - sPrime); sHighPrev = sHighCur; }  double result = sHighPrev + (prodLowSum + sLowSum);  if (Double.isNaN(result)) { // either we have split infinite numbers or some coefficients were NaNs, // just rely on the naive implementation and let IEEE754 handle this result = 0; for (int i = 0; i < len; ++i) { result += a[i] * b[i]; } }  return result; }
 public TimeSeries createCopy(RegularTimePeriod start, RegularTimePeriod end) throws CloneNotSupportedException {  if (start == null) { throw new IllegalArgumentException("Null 'start' argument."); } if (end == null) { throw new IllegalArgumentException("Null 'end' argument."); } if (start.compareTo(end) > 0) { throw new IllegalArgumentException( "Requires start on or before end."); } boolean emptyRange = false; int startIndex = getIndex(start); if (startIndex < 0) { startIndex = -(startIndex + 1); if (startIndex == this.data.size()) { emptyRange = true;  // start is after last data item } } int endIndex = getIndex(end); if (endIndex < 0) {             // end period is not in original series endIndex = -(endIndex + 1); // this is first item AFTER end period endIndex = endIndex - 1;    // so this is last item BEFORE end } if (endIndex < 0) { emptyRange = true; } if (emptyRange) { TimeSeries copy = (TimeSeries) super.clone(); copy.data = new java.util.ArrayList(); return copy; } else { return createCopy(startIndex, endIndex); }  }
 static boolean isRegistered(Object value) { return getRegistry().contains(new IDKey(value)); }
 static void register(Object value) { getRegistry().add(new IDKey(value)); }
 static void unregister(Object value) { getRegistry().remove(new IDKey(value)); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = FieldUtils.safeMultiply(hoursOffset, 60); if (hoursInMinutes < 0) { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, -minutesOffset); } else { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, minutesOffset); } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = FieldUtils.safeMultiply(hoursOffset, 60); if (hoursInMinutes < 0) { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, -minutesOffset); } else { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, minutesOffset); } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = FieldUtils.safeMultiply(hoursOffset, 60); if (hoursInMinutes < 0) { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, -minutesOffset); } else { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, minutesOffset); } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = FieldUtils.safeMultiply(hoursOffset, 60); if (hoursInMinutes < 0) { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, -minutesOffset); } else { minutesOffset = FieldUtils.safeAdd(hoursInMinutes, minutesOffset); } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public static DateTimeZone forOffsetMillis(int millisOffset) { String id = printOffset(millisOffset); return fixedOffsetZone(id, millisOffset); }
 protected final double doSolve() { // Get initial solution double x0 = getMin(); double x1 = getMax(); double f0 = computeObjectiveValue(x0); double f1 = computeObjectiveValue(x1);  // If one of the bounds is the exact root, return it. Since these are // not under-approximations or over-approximations, we can return them // regardless of the allowed solutions. if (f0 == 0.0) { return x0; } if (f1 == 0.0) { return x1; }  // Verify bracketing of initial solution. verifyBracketing(x0, x1);  // Get accuracies. final double ftol = getFunctionValueAccuracy(); final double atol = getAbsoluteAccuracy(); final double rtol = getRelativeAccuracy();  // Keep track of inverted intervals, meaning that the left bound is // larger than the right bound. boolean inverted = false;  // Keep finding better approximations. while (true) { // Calculate the next approximation. final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0)); final double fx = computeObjectiveValue(x);  // If the new approximation is the exact root, return it. Since // this is not an under-approximation or an over-approximation, // we can return it regardless of the allowed solutions. if (fx == 0.0) { return x; }  // Update the bounds with the new approximation. if (f1 * fx < 0) { // The value of x1 has switched to the other bound, thus inverting // the interval. x0 = x1; f0 = f1; inverted = !inverted; } else { switch (method) { case ILLINOIS: f0 *= 0.5; break; case PEGASUS: f0 *= f1 / (f1 + fx); break; // Update formula cannot make any progress: Update the // search interval. default: // Should never happen. } } // Update from [x0, x1] to [x0, x]. x1 = x; f1 = fx;  // If the function value of the last approximation is too small, // given the function value accuracy, then we can't get closer to // the root than we already are. if (FastMath.abs(f1) <= ftol) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: if (inverted) { return x1; } break; case RIGHT_SIDE: if (!inverted) { return x1; } break; case BELOW_SIDE: if (f1 <= 0) { return x1; } break; case ABOVE_SIDE: if (f1 >= 0) { return x1; } break; default: throw new MathInternalError(); } }  // If the current interval is within the given accuracies, we // are satisfied with the current approximation. if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: return inverted ? x1 : x0; case RIGHT_SIDE: return inverted ? x0 : x1; case BELOW_SIDE: return (f1 <= 0) ? x1 : x0; case ABOVE_SIDE: return (f1 >= 0) ? x1 : x0; default: throw new MathInternalError(); } } } }
 protected final double doSolve() { // Get initial solution double x0 = getMin(); double x1 = getMax(); double f0 = computeObjectiveValue(x0); double f1 = computeObjectiveValue(x1);  // If one of the bounds is the exact root, return it. Since these are // not under-approximations or over-approximations, we can return them // regardless of the allowed solutions. if (f0 == 0.0) { return x0; } if (f1 == 0.0) { return x1; }  // Verify bracketing of initial solution. verifyBracketing(x0, x1);  // Get accuracies. final double ftol = getFunctionValueAccuracy(); final double atol = getAbsoluteAccuracy(); final double rtol = getRelativeAccuracy();  // Keep track of inverted intervals, meaning that the left bound is // larger than the right bound. boolean inverted = false;  // Keep finding better approximations. while (true) { // Calculate the next approximation. final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0)); final double fx = computeObjectiveValue(x);  // If the new approximation is the exact root, return it. Since // this is not an under-approximation or an over-approximation, // we can return it regardless of the allowed solutions. if (fx == 0.0) { return x; }  // Update the bounds with the new approximation. if (f1 * fx < 0) { // The value of x1 has switched to the other bound, thus inverting // the interval. x0 = x1; f0 = f1; inverted = !inverted; } else { switch (method) { case ILLINOIS: f0 *= 0.5; break; case PEGASUS: f0 *= f1 / (f1 + fx); break; // Update formula cannot make any progress: Update the // search interval. default: // Should never happen. } } // Update from [x0, x1] to [x0, x]. x1 = x; f1 = fx;  // If the function value of the last approximation is too small, // given the function value accuracy, then we can't get closer to // the root than we already are. if (FastMath.abs(f1) <= ftol) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: if (inverted) { return x1; } break; case RIGHT_SIDE: if (!inverted) { return x1; } break; case BELOW_SIDE: if (f1 <= 0) { return x1; } break; case ABOVE_SIDE: if (f1 >= 0) { return x1; } break; default: throw new MathInternalError(); } }  // If the current interval is within the given accuracies, we // are satisfied with the current approximation. if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: return inverted ? x1 : x0; case RIGHT_SIDE: return inverted ? x0 : x1; case BELOW_SIDE: return (f1 <= 0) ? x1 : x0; case ABOVE_SIDE: return (f1 >= 0) ? x1 : x0; default: throw new MathInternalError(); } } } }
 protected final double doSolve() { // Get initial solution double x0 = getMin(); double x1 = getMax(); double f0 = computeObjectiveValue(x0); double f1 = computeObjectiveValue(x1);  // If one of the bounds is the exact root, return it. Since these are // not under-approximations or over-approximations, we can return them // regardless of the allowed solutions. if (f0 == 0.0) { return x0; } if (f1 == 0.0) { return x1; }  // Verify bracketing of initial solution. verifyBracketing(x0, x1);  // Get accuracies. final double ftol = getFunctionValueAccuracy(); final double atol = getAbsoluteAccuracy(); final double rtol = getRelativeAccuracy();  // Keep track of inverted intervals, meaning that the left bound is // larger than the right bound. boolean inverted = false;  // Keep finding better approximations. while (true) { // Calculate the next approximation. final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0)); final double fx = computeObjectiveValue(x);  // If the new approximation is the exact root, return it. Since // this is not an under-approximation or an over-approximation, // we can return it regardless of the allowed solutions. if (fx == 0.0) { return x; }  // Update the bounds with the new approximation. if (f1 * fx < 0) { // The value of x1 has switched to the other bound, thus inverting // the interval. x0 = x1; f0 = f1; inverted = !inverted; } else { switch (method) { case ILLINOIS: f0 *= 0.5; break; case PEGASUS: f0 *= f1 / (f1 + fx); break; // Update formula cannot make any progress: Update the // search interval. default: // Should never happen. } } // Update from [x0, x1] to [x0, x]. x1 = x; f1 = fx;  // If the function value of the last approximation is too small, // given the function value accuracy, then we can't get closer to // the root than we already are. if (FastMath.abs(f1) <= ftol) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: if (inverted) { return x1; } break; case RIGHT_SIDE: if (!inverted) { return x1; } break; case BELOW_SIDE: if (f1 <= 0) { return x1; } break; case ABOVE_SIDE: if (f1 >= 0) { return x1; } break; default: throw new MathInternalError(); } }  // If the current interval is within the given accuracies, we // are satisfied with the current approximation. if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) { switch (allowed) { case ANY_SIDE: return x1; case LEFT_SIDE: return inverted ? x1 : x0; case RIGHT_SIDE: return inverted ? x0 : x1; case BELOW_SIDE: return (f1 <= 0) ? x1 : x0; case ABOVE_SIDE: return (f1 >= 0) ? x1 : x0; default: throw new MathInternalError(); } } } }
 public double[] repairAndDecode(final double[] x) { return decode(x); }
 private boolean hasExceptionHandler(Node cfgNode) { return false; }
 private boolean isInlinableObject(List<Reference> refs) { boolean ret = false; for (Reference ref : refs) { Node name = ref.getNode(); Node parent = ref.getParent(); Node gramps = ref.getGrandparent();  // Ignore indirect references, like x.y (except x.y(), since // the function referenced by y might reference 'this'). // if (parent.isGetProp()) { Preconditions.checkState(parent.getFirstChild() == name); // A call target maybe using the object as a 'this' value. if (gramps.isCall() && gramps.getFirstChild() == parent) { return false; }  // NOTE(nicksantos): This pass's object-splitting algorithm has // a blind spot. It assumes that if a property isn't defined on an // object, then the value is undefined. This is not true, because // Object.prototype can have arbitrary properties on it. // // We short-circuit this problem by bailing out if we see a reference // to a property that isn't defined on the object literal. This // isn't a perfect algorithm, but it should catch most cases. continue; }  // Only rewrite VAR declarations or simple assignment statements if (!isVarOrAssignExprLhs(name)) { return false; }  Node val = ref.getAssignedValue(); if (val == null) { // A var with no assignment. continue; }  // We're looking for object literal assignments only. if (!val.isObjectLit()) { return false; }  // Make sure that the value is not self-refential. IOW, // disallow things like x = {b: x.a}. // // TODO: Only exclude unorderable self-referential // assignments. i.e. x = {a: x.b, b: x.a} is not orderable, // but x = {a: 1, b: x.a} is. // // Also, ES5 getters/setters aren't handled by this pass. for (Node child = val.getFirstChild(); child != null; child = child.getNext()) { if (child.isGetterDef() || child.isSetterDef()) { // ES5 get/set not supported. return false; }   Node childVal = child.getFirstChild(); // Check if childVal is the parent of any of the passed in // references, as that is how self-referential assignments // will happen. for (Reference t : refs) { Node refNode = t.getParent(); while (!NodeUtil.isStatementBlock(refNode)) { if (refNode == childVal) { // There's a self-referential assignment return false; } refNode = refNode.getParent(); } } }   // We have found an acceptable object literal assignment. As // long as there are no other assignments that mess things up, // we can inline. ret = true; } return ret; }
 private boolean isInlinableObject(List<Reference> refs) { boolean ret = false; for (Reference ref : refs) { Node name = ref.getNode(); Node parent = ref.getParent(); Node gramps = ref.getGrandparent();  // Ignore indirect references, like x.y (except x.y(), since // the function referenced by y might reference 'this'). // if (parent.isGetProp()) { Preconditions.checkState(parent.getFirstChild() == name); // A call target maybe using the object as a 'this' value. if (gramps.isCall() && gramps.getFirstChild() == parent) { return false; }  // NOTE(nicksantos): This pass's object-splitting algorithm has // a blind spot. It assumes that if a property isn't defined on an // object, then the value is undefined. This is not true, because // Object.prototype can have arbitrary properties on it. // // We short-circuit this problem by bailing out if we see a reference // to a property that isn't defined on the object literal. This // isn't a perfect algorithm, but it should catch most cases. continue; }  // Only rewrite VAR declarations or simple assignment statements if (!isVarOrAssignExprLhs(name)) { return false; }  Node val = ref.getAssignedValue(); if (val == null) { // A var with no assignment. continue; }  // We're looking for object literal assignments only. if (!val.isObjectLit()) { return false; }  // Make sure that the value is not self-refential. IOW, // disallow things like x = {b: x.a}. // // TODO: Only exclude unorderable self-referential // assignments. i.e. x = {a: x.b, b: x.a} is not orderable, // but x = {a: 1, b: x.a} is. // // Also, ES5 getters/setters aren't handled by this pass. for (Node child = val.getFirstChild(); child != null; child = child.getNext()) { if (child.isGetterDef() || child.isSetterDef()) { // ES5 get/set not supported. return false; }   Node childVal = child.getFirstChild(); // Check if childVal is the parent of any of the passed in // references, as that is how self-referential assignments // will happen. for (Reference t : refs) { Node refNode = t.getParent(); while (!NodeUtil.isStatementBlock(refNode)) { if (refNode == childVal) { // There's a self-referential assignment return false; } refNode = refNode.getParent(); } } }   // We have found an acceptable object literal assignment. As // long as there are no other assignments that mess things up, // we can inline. ret = true; } return ret; }
 private Integer getBasicRow(final int col) { Integer row = null; for (int i = getNumObjectiveFunctions(); i < getHeight(); i++) { if (!MathUtils.equals(getEntry(i, col), 0.0, epsilon)) { if (row == null) { row = i; } else { return null; } } } return row; }
 private static int greatestCommonDivisor(int u, int v) { // From Commons Math: //if either operand is abs 1, return 1: if (Math.abs(u) <= 1 || Math.abs(v) <= 1) { return 1; } // keep u and v negative, as negative integers range down to // -2^31, while positive numbers can only be as large as 2^31-1 // (i.e. we can't necessarily negate a negative number without // overflow) if (u>0) { u=-u; } // make u negative if (v>0) { v=-v; } // make v negative // B1. [Find power of 2] int k=0; while ((u&1)==0 && (v&1)==0 && k<31) { // while u and v are both even... u/=2; v/=2; k++; // cast out twos. } if (k==31) { throw new ArithmeticException("overflow: gcd is 2^31"); } // B2. Initialize: u and v have been divided by 2^k and at least //     one is odd. int t = ((u&1)==1) ? v : -(u/2)/*B3*/; // t negative: u was odd, v may be even (t replaces v) // t positive: u was even, v is odd (t replaces u) do { /* assert u<0 && v<0; */ // B4/B3: cast out twos from t. while ((t&1)==0) { // while t is even.. t/=2; // cast out twos } // B5 [reset max(u,v)] if (t>0) { u = -t; } else { v = t; } // B6/B3. at this point both u and v should be odd. t = (v - u)/2; // |u| larger: t positive (replace u) // |v| larger: t negative (replace v) } while (t!=0); return -u*(1<<k); // gcd is u*2^k }
 private void visitScript(NodeTraversal t, Node script) { Preconditions.checkArgument(scriptNodeCount == 1, "ProcessCommonJSModules supports only one invocation per " + "CompilerInput / script node"); String moduleName = guessCJSModuleName(normalizeSourceName(script.getSourceFileName())); script.addChildToFront(IR.var(IR.name(moduleName), IR.objectlit()) .copyInformationFromForTree(script)); if (reportDependencies) { CompilerInput ci = t.getInput(); ci.addProvide(moduleName); JSModule m = new JSModule(moduleName); m.addAndOverrideModule(ci); module = m; } script.addChildToFront(IR.exprResult( IR.call(IR.getprop(IR.name("goog"), IR.string("provide")), IR.string(moduleName))).copyInformationFromForTree(script));  emitOptionalModuleExportsOverride(script, moduleName);  // Rename vars to not conflict in global scope. NodeTraversal.traverse(compiler, script, new SuffixVarsCallback( moduleName));  compiler.reportCodeChange(); }
 private String normalizeSourceName(String filename) { // The DOS command shell will normalize "/" to "\", so we have to // wrestle it back.  if (filename.indexOf(filenamePrefix) == 0) { filename = filename.substring(filenamePrefix.length()); }  return filename; }
 protected Size2D arrangeFF(BlockContainer container, Graphics2D g2, RectangleConstraint constraint) { double[] w = new double[5]; double[] h = new double[5]; w[0] = constraint.getWidth(); if (this.topBlock != null) { RectangleConstraint c1 = new RectangleConstraint(w[0], null, LengthConstraintType.FIXED, 0.0, new Range(0.0, constraint.getHeight()), LengthConstraintType.RANGE); Size2D size = this.topBlock.arrange(g2, c1); h[0] = size.height; } w[1] = w[0]; if (this.bottomBlock != null) { RectangleConstraint c2 = new RectangleConstraint(w[0], null, LengthConstraintType.FIXED, 0.0, new Range(0.0, constraint.getHeight() - h[0]), LengthConstraintType.RANGE); Size2D size = this.bottomBlock.arrange(g2, c2); h[1] = size.height; } h[2] = constraint.getHeight() - h[1] - h[0]; if (this.leftBlock != null) { RectangleConstraint c3 = new RectangleConstraint(0.0, new Range(0.0, constraint.getWidth()), LengthConstraintType.RANGE, h[2], null, LengthConstraintType.FIXED); Size2D size = this.leftBlock.arrange(g2, c3); w[2] = size.width; } h[3] = h[2]; if (this.rightBlock != null) { RectangleConstraint c4 = new RectangleConstraint(0.0, new Range(0.0, constraint.getWidth() - w[2]), LengthConstraintType.RANGE, h[2], null, LengthConstraintType.FIXED); Size2D size = this.rightBlock.arrange(g2, c4); w[3] = size.width; } h[4] = h[2]; w[4] = constraint.getWidth() - w[3] - w[2]; RectangleConstraint c5 = new RectangleConstraint(w[4], h[4]); if (this.centerBlock != null) { this.centerBlock.arrange(g2, c5); }  if (this.topBlock != null) { this.topBlock.setBounds(new Rectangle2D.Double(0.0, 0.0, w[0], h[0])); } if (this.bottomBlock != null) { this.bottomBlock.setBounds(new Rectangle2D.Double(0.0, h[0] + h[2], w[1], h[1])); } if (this.leftBlock != null) { this.leftBlock.setBounds(new Rectangle2D.Double(0.0, h[0], w[2], h[2])); } if (this.rightBlock != null) { this.rightBlock.setBounds(new Rectangle2D.Double(w[2] + w[4], h[0], w[3], h[3])); } if (this.centerBlock != null) { this.centerBlock.setBounds(new Rectangle2D.Double(w[2], h[0], w[4], h[4])); } return new Size2D(constraint.getWidth(), constraint.getHeight()); }
 private void visitGetProp(NodeTraversal t, Node n, Node parent) { // obj.prop or obj.method() // Lots of types can appear on the left, a call to a void function can // never be on the left. getPropertyType will decide what is acceptable // and what isn't. Node property = n.getLastChild(); Node objNode = n.getFirstChild(); JSType childType = getJSType(objNode);  if (childType.isDict()) { report(t, property, TypeValidator.ILLEGAL_PROPERTY_ACCESS, "'.'", "dict"); } else if (n.getJSType() != null && parent.isAssign()) { return; } else if (validator.expectNotNullOrUndefined(t, n, childType, "No properties on this expression", getNativeType(OBJECT_TYPE))) { checkPropertyAccess(childType, property.getString(), t, n); } ensureTyped(t, n); }
 public static long factorial(final int n) { long result = Math.round(factorialDouble(n)); if (result == Long.MAX_VALUE) { throw new ArithmeticException( "factorial value is too large to fit in a long"); } return factorials[n]; }
 public static double factorialDouble(final int n) { if (n < 0) { throw new IllegalArgumentException("must have n >= 0 for n!"); } return Math.floor(Math.exp(factorialLog(n)) + 0.5); }
 public static double factorialLog(final int n) { if (n < 0) { throw new IllegalArgumentException("must have n > 0 for n!"); } double logSum = 0; for (int i = 2; i <= n; i++) { logSum += Math.log((double)i); } return logSum; }
 public static boolean containsAny(CharSequence cs, char[] searchChars) { if (isEmpty(cs) || ArrayUtils.isEmpty(searchChars)) { return false; } int csLength = cs.length(); int searchLength = searchChars.length; int csLast = csLength - 1; int searchLast = searchLength - 1; for (int i = 0; i < csLength; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLength; j++) { if (searchChars[j] == ch) { if (i < csLast && j < searchLast && ch >= Character.MIN_HIGH_SURROGATE && ch <= Character.MAX_HIGH_SURROGATE) { // missing low surrogate, fine, like String.indexOf(String) if (searchChars[j + 1] == cs.charAt(i + 1)) { return true; } } else { // ch is in the Basic Multilingual Plane return true; } } } } return false; }
 public static boolean containsAny(CharSequence cs, char[] searchChars) { if (isEmpty(cs) || ArrayUtils.isEmpty(searchChars)) { return false; } int csLength = cs.length(); int searchLength = searchChars.length; int csLast = csLength - 1; int searchLast = searchLength - 1; for (int i = 0; i < csLength; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLength; j++) { if (searchChars[j] == ch) { if (i < csLast && j < searchLast && ch >= Character.MIN_HIGH_SURROGATE && ch <= Character.MAX_HIGH_SURROGATE) { // missing low surrogate, fine, like String.indexOf(String) if (searchChars[j + 1] == cs.charAt(i + 1)) { return true; } } else { // ch is in the Basic Multilingual Plane return true; } } } } return false; }
 public static boolean containsNone(CharSequence cs, char[] searchChars) { if (cs == null || searchChars == null) { return true; } int csLen = cs.length(); int searchLen = searchChars.length; for (int i = 0; i < csLen; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLen; j++) { if (searchChars[j] == ch) { // missing low surrogate, fine, like String.indexOf(String) // ch is in the Basic Multilingual Plane return false; } } } return true; }
 public static int indexOfAny(CharSequence cs, char[] searchChars) { if (isEmpty(cs) || ArrayUtils.isEmpty(searchChars)) { return INDEX_NOT_FOUND; } int csLen = cs.length(); int searchLen = searchChars.length; for (int i = 0; i < csLen; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLen; j++) { if (searchChars[j] == ch) { // ch is a supplementary character return i; } } } return INDEX_NOT_FOUND; }
 public static int indexOfAnyBut(CharSequence cs, char[] searchChars) { if (isEmpty(cs) || ArrayUtils.isEmpty(searchChars)) { return INDEX_NOT_FOUND; } int csLen = cs.length(); int searchLen = searchChars.length; outer: for (int i = 0; i < csLen; i++) { char ch = cs.charAt(i); for (int j = 0; j < searchLen; j++) { if (searchChars[j] == ch) { continue outer; } } return i; } return INDEX_NOT_FOUND; }
 public static int indexOfAnyBut(String str, String searchChars) { if (isEmpty(str) || isEmpty(searchChars)) { return INDEX_NOT_FOUND; } int strLen = str.length(); for (int i = 0; i < strLen; i++) { char ch = str.charAt(i); if (searchChars.indexOf(ch) < 0) { return i; } } return INDEX_NOT_FOUND; }
 public void atan2(final double[] y, final int yOffset, final double[] x, final int xOffset, final double[] result, final int resultOffset) {  // compute r = sqrt(x^2+y^2) double[] tmp1 = new double[getSize()]; multiply(x, xOffset, x, xOffset, tmp1, 0);      // x^2 double[] tmp2 = new double[getSize()]; multiply(y, yOffset, y, yOffset, tmp2, 0);      // y^2 add(tmp1, 0, tmp2, 0, tmp2, 0);                 // x^2 + y^2 rootN(tmp2, 0, 2, tmp1, 0);                     // r = sqrt(x^2 + y^2)  if (x[xOffset] >= 0) {  // compute atan2(y, x) = 2 atan(y / (r + x)) add(tmp1, 0, x, xOffset, tmp2, 0);          // r + x divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r + x) atan(tmp1, 0, tmp2, 0);                     // atan(y / (r + x)) for (int i = 0; i < tmp2.length; ++i) { result[resultOffset + i] = 2 * tmp2[i]; // 2 * atan(y / (r + x)) }  } else {  // compute atan2(y, x) = +/- pi - 2 atan(y / (r - x)) subtract(tmp1, 0, x, xOffset, tmp2, 0);     // r - x divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r - x) atan(tmp1, 0, tmp2, 0);                     // atan(y / (r - x)) result[resultOffset] = ((tmp2[0] <= 0) ? -FastMath.PI : FastMath.PI) - 2 * tmp2[0]; // +/-pi - 2 * atan(y / (r - x)) for (int i = 1; i < tmp2.length; ++i) { result[resultOffset + i] = -2 * tmp2[i]; // +/-pi - 2 * atan(y / (r - x)) }  }  // fix value to take special cases (+0/+0, +0/-0, -0/+0, -0/-0, +/-infinity) correctly  }
 public void atan2(final double[] y, final int yOffset, final double[] x, final int xOffset, final double[] result, final int resultOffset) {  // compute r = sqrt(x^2+y^2) double[] tmp1 = new double[getSize()]; multiply(x, xOffset, x, xOffset, tmp1, 0);      // x^2 double[] tmp2 = new double[getSize()]; multiply(y, yOffset, y, yOffset, tmp2, 0);      // y^2 add(tmp1, 0, tmp2, 0, tmp2, 0);                 // x^2 + y^2 rootN(tmp2, 0, 2, tmp1, 0);                     // r = sqrt(x^2 + y^2)  if (x[xOffset] >= 0) {  // compute atan2(y, x) = 2 atan(y / (r + x)) add(tmp1, 0, x, xOffset, tmp2, 0);          // r + x divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r + x) atan(tmp1, 0, tmp2, 0);                     // atan(y / (r + x)) for (int i = 0; i < tmp2.length; ++i) { result[resultOffset + i] = 2 * tmp2[i]; // 2 * atan(y / (r + x)) }  } else {  // compute atan2(y, x) = +/- pi - 2 atan(y / (r - x)) subtract(tmp1, 0, x, xOffset, tmp2, 0);     // r - x divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r - x) atan(tmp1, 0, tmp2, 0);                     // atan(y / (r - x)) result[resultOffset] = ((tmp2[0] <= 0) ? -FastMath.PI : FastMath.PI) - 2 * tmp2[0]; // +/-pi - 2 * atan(y / (r - x)) for (int i = 1; i < tmp2.length; ++i) { result[resultOffset + i] = -2 * tmp2[i]; // +/-pi - 2 * atan(y / (r - x)) }  }  // fix value to take special cases (+0/+0, +0/-0, -0/+0, -0/-0, +/-infinity) correctly  }
 public static double pow(double x, double y) { final double lns[] = new double[2];  if (y == 0.0) { return 1.0; }  if (x != x) { // X is NaN return x; }   if (x == 0) { long bits = Double.doubleToLongBits(x); if ((bits & 0x8000000000000000L) != 0) { // -zero long yi = (long) y;  if (y < 0 && y == yi && (yi & 1) == 1) { return Double.NEGATIVE_INFINITY; }  if (y > 0 && y == yi && (yi & 1) == 1) { return -0.0; } }  if (y < 0) { return Double.POSITIVE_INFINITY; } if (y > 0) { return 0.0; }  return Double.NaN; }  if (x == Double.POSITIVE_INFINITY) { if (y != y) { // y is NaN return y; } if (y < 0.0) { return 0.0; } else { return Double.POSITIVE_INFINITY; } }  if (y == Double.POSITIVE_INFINITY) { if (x * x == 1.0) { return Double.NaN; }  if (x * x > 1.0) { return Double.POSITIVE_INFINITY; } else { return 0.0; } }  if (x == Double.NEGATIVE_INFINITY) { if (y != y) { // y is NaN return y; }  if (y < 0) { long yi = (long) y; if (y == yi && (yi & 1) == 1) { return -0.0; }  return 0.0; }  if (y > 0)  { long yi = (long) y; if (y == yi && (yi & 1) == 1) { return Double.NEGATIVE_INFINITY; }  return Double.POSITIVE_INFINITY; } }  if (y == Double.NEGATIVE_INFINITY) {  if (x * x == 1.0) { return Double.NaN; }  if (x * x < 1.0) { return Double.POSITIVE_INFINITY; } else { return 0.0; } }  /* Handle special case x<0 */ if (x < 0) { // y is an even integer in this case if (y >= TWO_POWER_52 || y <= -TWO_POWER_52) { return pow(-x, y); }  if (y == (long) y) { // If y is an integer return ((long)y & 1) == 0 ? pow(-x, y) : -pow(-x, y); } else { return Double.NaN; } }  /* Split y into ya and yb such that y = ya+yb */ double ya; double yb; if (y < 8e298 && y > -8e298) { double tmp1 = y * HEX_40000000; ya = y + tmp1 - tmp1; yb = y - ya; } else { double tmp1 = y * 9.31322574615478515625E-10; double tmp2 = tmp1 * 9.31322574615478515625E-10; ya = (tmp1 + tmp2 - tmp1) * HEX_40000000 * HEX_40000000; yb = y - ya; }  /* Compute ln(x) */ final double lores = log(x, lns); if (Double.isInfinite(lores)){ // don't allow this to be converted to NaN return lores; }  double lna = lns[0]; double lnb = lns[1];  /* resplit lns */ double tmp1 = lna * HEX_40000000; double tmp2 = lna + tmp1 - tmp1; lnb += lna - tmp2; lna = tmp2;  // y*ln(x) = (aa+ab) final double aa = lna * ya; final double ab = lna * yb + lnb * ya + lnb * yb;  lna = aa+ab; lnb = -(lna - aa - ab);  double z = 1.0 / 120.0; z = z * lnb + (1.0 / 24.0); z = z * lnb + (1.0 / 6.0); z = z * lnb + 0.5; z = z * lnb + 1.0; z = z * lnb;  final double result = exp(lna, z, null); //result = result + result * z; return result; }
 public static Number createNumber(final String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } // Need to deal with all possible hex prefixes here final String[] hex_prefixes = {"0x", "0X", "-0x", "-0X", "#", "-#"}; int pfxLen = 0; for(final String pfx : hex_prefixes) { if (str.startsWith(pfx)) { pfxLen += pfx.length(); break; } } if (pfxLen > 0) { // we have a hex number final int hexDigits = str.length() - pfxLen; if (hexDigits > 16) { // too many for Long return createBigInteger(str); } if (hexDigits > 8) { // too many for an int return createLong(str); } return createInteger(str); } final char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; final int decPos = str.indexOf('.'); final int expPos = str.indexOf('e') + str.indexOf('E') + 1; // assumes both not present // if both e and E are present, this is caught by the checks on expPos (which prevent IOOBE) // and the parsing which will detect if e or E appear in a number due to using the wrong offset  int numDecimals = 0; // Check required precision (LANG-693) if (decPos > -1) { // there is a decimal point  if (expPos > -1) { // there is an exponent if (expPos < decPos || expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); numDecimals = dec.length(); // gets number of digits past the decimal to ensure no loss of precision for floating point numbers. } else { if (expPos > -1) { if (expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. final String numeric = str.substring(0, str.length() - 1); final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (final NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { final Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { final Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (final NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { // no decimal point and no exponent //Must be an Integer, Long, Biginteger try { return createInteger(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str); }  //Must be a Float, Double, BigDecimal final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { if(numDecimals <= 7){// If number has 7 or fewer digits past the decimal point then make it a float final Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { if(numDecimals <= 16){// If number has between 8 and 16 digits past the decimal point then make it a double final Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str); }
 public static Number createNumber(final String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } // Need to deal with all possible hex prefixes here final String[] hex_prefixes = {"0x", "0X", "-0x", "-0X", "#", "-#"}; int pfxLen = 0; for(final String pfx : hex_prefixes) { if (str.startsWith(pfx)) { pfxLen += pfx.length(); break; } } if (pfxLen > 0) { // we have a hex number final int hexDigits = str.length() - pfxLen; if (hexDigits > 16) { // too many for Long return createBigInteger(str); } if (hexDigits > 8) { // too many for an int return createLong(str); } return createInteger(str); } final char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; final int decPos = str.indexOf('.'); final int expPos = str.indexOf('e') + str.indexOf('E') + 1; // assumes both not present // if both e and E are present, this is caught by the checks on expPos (which prevent IOOBE) // and the parsing which will detect if e or E appear in a number due to using the wrong offset  int numDecimals = 0; // Check required precision (LANG-693) if (decPos > -1) { // there is a decimal point  if (expPos > -1) { // there is an exponent if (expPos < decPos || expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); numDecimals = dec.length(); // gets number of digits past the decimal to ensure no loss of precision for floating point numbers. } else { if (expPos > -1) { if (expPos > str.length()) { // prevents double exponent causing IOOBE throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. final String numeric = str.substring(0, str.length() - 1); final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (final NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { final Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { final Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (final NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { // no decimal point and no exponent //Must be an Integer, Long, Biginteger try { return createInteger(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str); }  //Must be a Float, Double, BigDecimal final boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { if(numDecimals <= 7){// If number has 7 or fewer digits past the decimal point then make it a float final Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number } try { if(numDecimals <= 16){// If number has between 8 and 16 digits past the decimal point then make it a double final Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } } catch (final NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str); }
 public static String formatPeriod(long startMillis, long endMillis, String format, boolean padWithZeros, TimeZone timezone) {  long millis = endMillis - startMillis; if (millis < 28 * DateUtils.MILLIS_PER_DAY) { return formatDuration(millis, format, padWithZeros); }  Token[] tokens = lexx(format);  // timezones get funky around 0, so normalizing everything to GMT // stops the hours being off Calendar start = Calendar.getInstance(timezone); start.setTime(new Date(startMillis)); Calendar end = Calendar.getInstance(timezone); end.setTime(new Date(endMillis));  // initial estimates int milliseconds = end.get(Calendar.MILLISECOND) - start.get(Calendar.MILLISECOND); int seconds = end.get(Calendar.SECOND) - start.get(Calendar.SECOND); int minutes = end.get(Calendar.MINUTE) - start.get(Calendar.MINUTE); int hours = end.get(Calendar.HOUR_OF_DAY) - start.get(Calendar.HOUR_OF_DAY); int days = end.get(Calendar.DAY_OF_MONTH) - start.get(Calendar.DAY_OF_MONTH); int months = end.get(Calendar.MONTH) - start.get(Calendar.MONTH); int years = end.get(Calendar.YEAR) - start.get(Calendar.YEAR);  // each initial estimate is adjusted in case it is under 0 while (milliseconds < 0) { milliseconds += 1000; seconds -= 1; } while (seconds < 0) { seconds += 60; minutes -= 1; } while (minutes < 0) { minutes += 60; hours -= 1; } while (hours < 0) { hours += 24; days -= 1; } while (days < 0) { days += 31; //days += 31; // TODO: Need tests to show this is bad and the new code is good. // HEN: It's a tricky subject. Jan 15th to March 10th. If I count days-first it is // 1 month and 26 days, but if I count month-first then it is 1 month and 23 days. // Also it's contextual - if asked for no M in the format then I should probably // be doing no calculating here. months -= 1; } while (months < 0) { months += 12; years -= 1; } milliseconds -= reduceAndCorrect(start, end, Calendar.MILLISECOND, milliseconds); seconds -= reduceAndCorrect(start, end, Calendar.SECOND, seconds); minutes -= reduceAndCorrect(start, end, Calendar.MINUTE, minutes); hours -= reduceAndCorrect(start, end, Calendar.HOUR_OF_DAY, hours); days -= reduceAndCorrect(start, end, Calendar.DAY_OF_MONTH, days); months -= reduceAndCorrect(start, end, Calendar.MONTH, months); years -= reduceAndCorrect(start, end, Calendar.YEAR, years);  // This next block of code adds in values that // aren't requested. This allows the user to ask for the // number of months and get the real count and not just 0->11. if (!Token.containsTokenWithValue(tokens, y)) { if (Token.containsTokenWithValue(tokens, M)) { months += 12 * years; years = 0; } else { // TODO: this is a bit weak, needs work to know about leap years days += 365 * years; years = 0; } } if (!Token.containsTokenWithValue(tokens, M)) { days += end.get(Calendar.DAY_OF_YEAR) - start.get(Calendar.DAY_OF_YEAR); months = 0; } if (!Token.containsTokenWithValue(tokens, d)) { hours += 24 * days; days = 0; } if (!Token.containsTokenWithValue(tokens, H)) { minutes += 60 * hours; hours = 0; } if (!Token.containsTokenWithValue(tokens, m)) { seconds += 60 * minutes; minutes = 0; } if (!Token.containsTokenWithValue(tokens, s)) { milliseconds += 1000 * seconds; seconds = 0; }  return format(tokens, years, months, days, hours, minutes, seconds, milliseconds, padWithZeros); }
 public static String formatPeriod(long startMillis, long endMillis, String format, boolean padWithZeros, TimeZone timezone) {  long millis = endMillis - startMillis; if (millis < 28 * DateUtils.MILLIS_PER_DAY) { return formatDuration(millis, format, padWithZeros); }  Token[] tokens = lexx(format);  // timezones get funky around 0, so normalizing everything to GMT // stops the hours being off Calendar start = Calendar.getInstance(timezone); start.setTime(new Date(startMillis)); Calendar end = Calendar.getInstance(timezone); end.setTime(new Date(endMillis));  // initial estimates int milliseconds = end.get(Calendar.MILLISECOND) - start.get(Calendar.MILLISECOND); int seconds = end.get(Calendar.SECOND) - start.get(Calendar.SECOND); int minutes = end.get(Calendar.MINUTE) - start.get(Calendar.MINUTE); int hours = end.get(Calendar.HOUR_OF_DAY) - start.get(Calendar.HOUR_OF_DAY); int days = end.get(Calendar.DAY_OF_MONTH) - start.get(Calendar.DAY_OF_MONTH); int months = end.get(Calendar.MONTH) - start.get(Calendar.MONTH); int years = end.get(Calendar.YEAR) - start.get(Calendar.YEAR);  // each initial estimate is adjusted in case it is under 0 while (milliseconds < 0) { milliseconds += 1000; seconds -= 1; } while (seconds < 0) { seconds += 60; minutes -= 1; } while (minutes < 0) { minutes += 60; hours -= 1; } while (hours < 0) { hours += 24; days -= 1; } while (days < 0) { days += 31; //days += 31; // TODO: Need tests to show this is bad and the new code is good. // HEN: It's a tricky subject. Jan 15th to March 10th. If I count days-first it is // 1 month and 26 days, but if I count month-first then it is 1 month and 23 days. // Also it's contextual - if asked for no M in the format then I should probably // be doing no calculating here. months -= 1; } while (months < 0) { months += 12; years -= 1; } milliseconds -= reduceAndCorrect(start, end, Calendar.MILLISECOND, milliseconds); seconds -= reduceAndCorrect(start, end, Calendar.SECOND, seconds); minutes -= reduceAndCorrect(start, end, Calendar.MINUTE, minutes); hours -= reduceAndCorrect(start, end, Calendar.HOUR_OF_DAY, hours); days -= reduceAndCorrect(start, end, Calendar.DAY_OF_MONTH, days); months -= reduceAndCorrect(start, end, Calendar.MONTH, months); years -= reduceAndCorrect(start, end, Calendar.YEAR, years);  // This next block of code adds in values that // aren't requested. This allows the user to ask for the // number of months and get the real count and not just 0->11. if (!Token.containsTokenWithValue(tokens, y)) { if (Token.containsTokenWithValue(tokens, M)) { months += 12 * years; years = 0; } else { // TODO: this is a bit weak, needs work to know about leap years days += 365 * years; years = 0; } } if (!Token.containsTokenWithValue(tokens, M)) { days += end.get(Calendar.DAY_OF_YEAR) - start.get(Calendar.DAY_OF_YEAR); months = 0; } if (!Token.containsTokenWithValue(tokens, d)) { hours += 24 * days; days = 0; } if (!Token.containsTokenWithValue(tokens, H)) { minutes += 60 * hours; hours = 0; } if (!Token.containsTokenWithValue(tokens, m)) { seconds += 60 * minutes; minutes = 0; } if (!Token.containsTokenWithValue(tokens, s)) { milliseconds += 1000 * seconds; seconds = 0; }  return format(tokens, years, months, days, hours, minutes, seconds, milliseconds, padWithZeros); }
 public static String formatPeriod(long startMillis, long endMillis, String format, boolean padWithZeros, TimeZone timezone) {  long millis = endMillis - startMillis; if (millis < 28 * DateUtils.MILLIS_PER_DAY) { return formatDuration(millis, format, padWithZeros); }  Token[] tokens = lexx(format);  // timezones get funky around 0, so normalizing everything to GMT // stops the hours being off Calendar start = Calendar.getInstance(timezone); start.setTime(new Date(startMillis)); Calendar end = Calendar.getInstance(timezone); end.setTime(new Date(endMillis));  // initial estimates int milliseconds = end.get(Calendar.MILLISECOND) - start.get(Calendar.MILLISECOND); int seconds = end.get(Calendar.SECOND) - start.get(Calendar.SECOND); int minutes = end.get(Calendar.MINUTE) - start.get(Calendar.MINUTE); int hours = end.get(Calendar.HOUR_OF_DAY) - start.get(Calendar.HOUR_OF_DAY); int days = end.get(Calendar.DAY_OF_MONTH) - start.get(Calendar.DAY_OF_MONTH); int months = end.get(Calendar.MONTH) - start.get(Calendar.MONTH); int years = end.get(Calendar.YEAR) - start.get(Calendar.YEAR);  // each initial estimate is adjusted in case it is under 0 while (milliseconds < 0) { milliseconds += 1000; seconds -= 1; } while (seconds < 0) { seconds += 60; minutes -= 1; } while (minutes < 0) { minutes += 60; hours -= 1; } while (hours < 0) { hours += 24; days -= 1; } while (days < 0) { days += 31; //days += 31; // TODO: Need tests to show this is bad and the new code is good. // HEN: It's a tricky subject. Jan 15th to March 10th. If I count days-first it is // 1 month and 26 days, but if I count month-first then it is 1 month and 23 days. // Also it's contextual - if asked for no M in the format then I should probably // be doing no calculating here. months -= 1; } while (months < 0) { months += 12; years -= 1; } milliseconds -= reduceAndCorrect(start, end, Calendar.MILLISECOND, milliseconds); seconds -= reduceAndCorrect(start, end, Calendar.SECOND, seconds); minutes -= reduceAndCorrect(start, end, Calendar.MINUTE, minutes); hours -= reduceAndCorrect(start, end, Calendar.HOUR_OF_DAY, hours); days -= reduceAndCorrect(start, end, Calendar.DAY_OF_MONTH, days); months -= reduceAndCorrect(start, end, Calendar.MONTH, months); years -= reduceAndCorrect(start, end, Calendar.YEAR, years);  // This next block of code adds in values that // aren't requested. This allows the user to ask for the // number of months and get the real count and not just 0->11. if (!Token.containsTokenWithValue(tokens, y)) { if (Token.containsTokenWithValue(tokens, M)) { months += 12 * years; years = 0; } else { // TODO: this is a bit weak, needs work to know about leap years days += 365 * years; years = 0; } } if (!Token.containsTokenWithValue(tokens, M)) { days += end.get(Calendar.DAY_OF_YEAR) - start.get(Calendar.DAY_OF_YEAR); months = 0; } if (!Token.containsTokenWithValue(tokens, d)) { hours += 24 * days; days = 0; } if (!Token.containsTokenWithValue(tokens, H)) { minutes += 60 * hours; hours = 0; } if (!Token.containsTokenWithValue(tokens, m)) { seconds += 60 * minutes; minutes = 0; } if (!Token.containsTokenWithValue(tokens, s)) { milliseconds += 1000 * seconds; seconds = 0; }  return format(tokens, years, months, days, hours, minutes, seconds, milliseconds, padWithZeros); }
 static int reduceAndCorrect(Calendar start, Calendar end, int field, int difference) { end.add( field, -1 * difference ); int endValue = end.get(field); int startValue = start.get(field); if (endValue < startValue) { int newdiff = startValue - endValue; end.add( field, newdiff ); return newdiff; } else { return 0; } }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MaxCountExceededException, DimensionMismatchException, NoBracketingException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime();  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // get state at event time interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState().clone();  // advance all event states to current time currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  boolean needReset = currentEvent.reset(eventT, eventY); if (needReset) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  // last part of the step, after the last event interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MaxCountExceededException, DimensionMismatchException, NoBracketingException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime();  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // get state at event time interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState().clone();  // advance all event states to current time currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  boolean needReset = currentEvent.reset(eventT, eventY); if (needReset) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  // last part of the step, after the last event interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MaxCountExceededException, DimensionMismatchException, NoBracketingException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime();  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // get state at event time interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState().clone();  // advance all event states to current time currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  boolean needReset = currentEvent.reset(eventT, eventY); if (needReset) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  // last part of the step, after the last event interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MaxCountExceededException, DimensionMismatchException, NoBracketingException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime();  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // get state at event time interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState().clone();  // advance all event states to current time currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  boolean needReset = currentEvent.reset(eventT, eventY); if (needReset) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; for (final EventState remaining : occuringEvents) { remaining.stepAccepted(eventT, eventY); } return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  // last part of the step, after the last event interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 public void add(BoxAndWhiskerItem item, Comparable rowKey, Comparable columnKey) {  this.data.addObject(item, rowKey, columnKey);  // update cached min and max values int r = this.data.getRowIndex(rowKey); int c = this.data.getColumnIndex(columnKey); if ((this.maximumRangeValueRow == r && this.maximumRangeValueColumn == c) || (this.minimumRangeValueRow == r && this.minimumRangeValueColumn == c))  { updateBounds(); }  double minval = Double.NaN; if (item.getMinOutlier() != null) { minval = item.getMinOutlier().doubleValue(); } double maxval = Double.NaN; if (item.getMaxOutlier() != null) { maxval = item.getMaxOutlier().doubleValue(); }  if (Double.isNaN(this.maximumRangeValue)) { this.maximumRangeValue = maxval; this.maximumRangeValueRow = r; this.maximumRangeValueColumn = c; } else if (maxval > this.maximumRangeValue) { this.maximumRangeValue = maxval; this.maximumRangeValueRow = r; this.maximumRangeValueColumn = c; }  if (Double.isNaN(this.minimumRangeValue)) { this.minimumRangeValue = minval; this.minimumRangeValueRow = r; this.minimumRangeValueColumn = c; } else if (minval < this.minimumRangeValue) { this.minimumRangeValue = minval; this.minimumRangeValueRow = r; this.minimumRangeValueColumn = c; }  this.rangeBounds = new Range(this.minimumRangeValue, this.maximumRangeValue); fireDatasetChanged();  }
 private void updateBounds() { this.minimumRangeValue = Double.NaN; this.maximumRangeValue = Double.NaN; }
 public Object handle(Invocation invocation) throws Throwable { if (invocationContainerImpl.hasAnswersForStubbing()) { // stubbing voids with stubVoid() or doAnswer() style InvocationMatcher invocationMatcher = matchersBinder.bindMatchers(mockingProgress .getArgumentMatcherStorage(), invocation); invocationContainerImpl.setMethodForStubbing(invocationMatcher); return null; } VerificationMode verificationMode = mockingProgress.pullVerificationMode();  InvocationMatcher invocationMatcher = matchersBinder.bindMatchers(mockingProgress.getArgumentMatcherStorage(), invocation);  mockingProgress.validateState();  //if verificationMode is not null then someone is doing verify() if (verificationMode != null) { //We need to check if verification was started on the correct mock // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138) if (verificationMode instanceof MockAwareVerificationMode && ((MockAwareVerificationMode) verificationMode).getMock() == invocation.getMock()) { VerificationDataImpl data = new VerificationDataImpl(invocationContainerImpl, invocationMatcher); verificationMode.verify(data); return null; // this means there is an invocation on a different mock. Re-adding verification mode // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138) } }  invocationContainerImpl.setInvocationForPotentialStubbing(invocationMatcher); OngoingStubbingImpl<T> ongoingStubbing = new OngoingStubbingImpl<T>(invocationContainerImpl); mockingProgress.reportOngoingStubbing(ongoingStubbing);  StubbedInvocationMatcher stubbedInvocation = invocationContainerImpl.findAnswerFor(invocation);  if (stubbedInvocation != null) { stubbedInvocation.captureArgumentsFrom(invocation); return stubbedInvocation.answer(invocation); } else { Object ret = mockSettings.getDefaultAnswer().answer(invocation);  // redo setting invocation for potential stubbing in case of partial // mocks / spies. // Without it, the real method inside 'when' might have delegated // to other self method and overwrite the intended stubbed method // with a different one. The reset is required to avoid runtime exception that validates return type with stubbed method signature. invocationContainerImpl.resetInvocationForPotentialStubbing(invocationMatcher); return ret; } }
 private Integer getBasicRow(final int col, boolean ignoreObjectiveRows) { Integer row = null; int start = getNumObjectiveFunctions(); for (int i = start; i < getHeight(); i++) { if (MathUtils.equals(getEntry(i, col), 1.0, epsilon) && (row == null)) { row = i; } else if (!MathUtils.equals(getEntry(i, col), 0.0, epsilon)) { return null; } } return row; }
 protected RealPointValuePair getSolution() { double[] coefficients = new double[getOriginalNumDecisionVariables()]; Integer negativeVarBasicRow = getBasicRow(getNegativeDecisionVariableOffset()); double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset()); Set<Integer> basicRows = new HashSet<Integer>(); for (int i = 0; i < coefficients.length; i++) { Integer basicRow = getBasicRow(getNumObjectiveFunctions() + i); if (basicRows.contains(basicRow)) { // if multiple variables can take a given value // then we choose the first and set the rest equal to 0 coefficients[i] = 0; } else { basicRows.add(basicRow); coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative); } } return new RealPointValuePair(coefficients, f.getValue(coefficients)); }
 protected RealPointValuePair getSolution() { double[] coefficients = new double[getOriginalNumDecisionVariables()]; Integer negativeVarBasicRow = getBasicRow(getNegativeDecisionVariableOffset()); double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset()); Set<Integer> basicRows = new HashSet<Integer>(); for (int i = 0; i < coefficients.length; i++) { Integer basicRow = getBasicRow(getNumObjectiveFunctions() + i); if (basicRows.contains(basicRow)) { // if multiple variables can take a given value // then we choose the first and set the rest equal to 0 coefficients[i] = 0; } else { basicRows.add(basicRow); coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative); } } return new RealPointValuePair(coefficients, f.getValue(coefficients)); }
 public void visit(NodeTraversal t, Node n, Node parent) {  // Record global variable and function declarations if (t.inGlobalScope()) { if (NodeUtil.isVarDeclaration(n)) { NameInformation ns = createNameInformation(t, n, parent); Preconditions.checkNotNull(ns); recordSet(ns.name, n); } else if (NodeUtil.isFunctionDeclaration(n)) { Node nameNode = n.getFirstChild(); NameInformation ns = createNameInformation(t, nameNode, n); if (ns != null) { JsName nameInfo = getName(nameNode.getString(), true); recordSet(nameInfo.name, nameNode); } } else if (NodeUtil.isObjectLitKey(n, parent)) { NameInformation ns = createNameInformation(t, n, parent); if (ns != null) { recordSet(ns.name, n); } } }  // Record assignments and call sites if (n.isAssign()) { Node nameNode = n.getFirstChild();  NameInformation ns = createNameInformation(t, nameNode, n); if (ns != null) { if (ns.isPrototype) { recordPrototypeSet(ns.prototypeClass, ns.prototypeProperty, n); } else { recordSet(ns.name, nameNode); } } } else if (n.isCall()) { Node nameNode = n.getFirstChild(); NameInformation ns = createNameInformation(t, nameNode, n); if (ns != null && ns.onlyAffectsClassDef) { JsName name = getName(ns.name, false); if (name != null) { refNodes.add(new ClassDefiningFunctionNode( name, n, parent, parent.getParent())); } } } }
 private void checkInterfaceConflictProperties(NodeTraversal t, Node n, String functionName, HashMap<String, ObjectType> properties, HashMap<String, ObjectType> currentProperties, ObjectType interfaceType) { ObjectType implicitProto = interfaceType.getImplicitPrototype(); Set<String> currentPropertyNames; // This can be the case if interfaceType is proxy to a non-existent // object (which is a bad type annotation, but shouldn't crash). currentPropertyNames = implicitProto.getOwnPropertyNames(); for (String name : currentPropertyNames) { ObjectType oType = properties.get(name); if (oType != null) { if (!interfaceType.getPropertyType(name).isEquivalentTo( oType.getPropertyType(name))) { compiler.report( t.makeError(n, INCOMPATIBLE_EXTENDED_PROPERTY_TYPE, functionName, name, oType.toString(), interfaceType.toString())); } } currentProperties.put(name, interfaceType); } for (ObjectType iType : interfaceType.getCtorExtendedInterfaces()) { checkInterfaceConflictProperties(t, n, functionName, properties, currentProperties, iType); } }
 Node parseInputs() { boolean devMode = options.devMode != DevMode.OFF;  // If old roots exist (we are parsing a second time), detach each of the // individual file parse trees. if (externsRoot != null) { externsRoot.detachChildren(); } if (jsRoot != null) { jsRoot.detachChildren(); }  // Parse main js sources. jsRoot = IR.block(); jsRoot.setIsSyntheticBlock(true);  externsRoot = IR.block(); externsRoot.setIsSyntheticBlock(true);  externAndJsRoot = IR.block(externsRoot, jsRoot); externAndJsRoot.setIsSyntheticBlock(true);  if (options.tracer.isOn()) { tracker = new PerformanceTracker(jsRoot, options.tracer); addChangeHandler(tracker.getCodeChangeHandler()); }  Tracer tracer = newTracer("parseInputs");  try { // Parse externs sources. for (CompilerInput input : externs) { Node n = input.getAstRoot(this); if (hasErrors()) { return null; } externsRoot.addChildToBack(n); }  // Modules inferred in ProcessCommonJS pass. if (options.transformAMDToCJSModules || options.processCommonJSModules) { processAMDAndCommonJSModules(); }  // Check if inputs need to be rebuilt from modules. boolean staleInputs = false;  // Check if the sources need to be re-ordered. if (options.dependencyOptions.needsManagement() && !options.skipAllPasses && options.closurePass) { for (CompilerInput input : inputs) { // Forward-declare all the provided types, so that they // are not flagged even if they are dropped from the process. for (String provide : input.getProvides()) { getTypeRegistry().forwardDeclareType(provide); } }  try { inputs = (moduleGraph == null ? new JSModuleGraph(modules) : moduleGraph) .manageDependencies(options.dependencyOptions, inputs); staleInputs = true; } catch (CircularDependencyException e) { report(JSError.make( JSModule.CIRCULAR_DEPENDENCY_ERROR, e.getMessage()));  // If in IDE mode, we ignore the error and keep going. if (hasErrors()) { return null; } } catch (MissingProvideException e) { report(JSError.make( MISSING_ENTRY_ERROR, e.getMessage()));  // If in IDE mode, we ignore the error and keep going. if (hasErrors()) { return null; } } }  for (CompilerInput input : inputs) { Node n = input.getAstRoot(this);  // Inputs can have a null AST during initial parse. if (n == null) { continue; }  if (n.getJSDocInfo() != null) { JSDocInfo info = n.getJSDocInfo(); if (info.isExterns()) { // If the input file is explicitly marked as an externs file, then // assume the programmer made a mistake and throw it into // the externs pile anyways. externsRoot.addChildToBack(n); input.setIsExtern(true);  input.getModule().remove(input);  externs.add(input); staleInputs = true; } else if (info.isNoCompile()) { input.getModule().remove(input); staleInputs = true; } } }  if (staleInputs) { fillEmptyModules(modules); rebuildInputsFromModules(); }  // Build the AST. for (CompilerInput input : inputs) { Node n = input.getAstRoot(this); if (n == null) { continue; }  if (devMode) { runSanityCheck(); if (hasErrors()) { return null; } }  if (options.sourceMapOutputPath != null || options.nameReferenceReportPath != null) {  // Annotate the nodes in the tree with information from the // input file. This information is used to construct the SourceMap. SourceInformationAnnotator sia = new SourceInformationAnnotator( input.getName(), options.devMode != DevMode.OFF); NodeTraversal.traverse(this, n, sia); }  jsRoot.addChildToBack(n); }  if (hasErrors()) { return null; } return externAndJsRoot; } finally { stopTracer(tracer, "parseInputs"); } }
 private CanInlineResult canInlineReferenceDirectly( Node callNode, Node fnNode) { if (!isDirectCallNodeReplacementPossible(fnNode)) { return CanInlineResult.NO; }  Node block = fnNode.getLastChild();  boolean hasSideEffects = false; if (block.hasChildren()) { Preconditions.checkState(block.hasOneChild()); Node stmt = block.getFirstChild(); if (stmt.isReturn()) { hasSideEffects = NodeUtil.mayHaveSideEffects(stmt.getFirstChild(), compiler); } } // CALL NODE: [ NAME, ARG1, ARG2, ... ] Node cArg = callNode.getFirstChild().getNext();  // Functions called via 'call' and 'apply' have a this-object as // the first parameter, but this is not part of the called function's // parameter list. if (!callNode.getFirstChild().isName()) { if (NodeUtil.isFunctionObjectCall(callNode)) { // TODO(johnlenz): Support replace this with a value. if (cArg == null || !cArg.isThis()) { return CanInlineResult.NO; } cArg = cArg.getNext(); } else { // ".apply" call should be filtered before this. Preconditions.checkState(!NodeUtil.isFunctionObjectApply(callNode)); } }  // FUNCTION NODE -> LP NODE: [ ARG1, ARG2, ... ] Node fnParam = NodeUtil.getFunctionParameters(fnNode).getFirstChild(); while (cArg != null || fnParam != null) { // For each named parameter check if a mutable argument use more than one. if (fnParam != null) { if (cArg != null) { if (hasSideEffects && NodeUtil.canBeSideEffected(cArg)) { return CanInlineResult.NO; } // Check for arguments that are evaluated more than once. // Note: Unlike block inlining, there it is not possible that a // parameter reference will be in a loop. if (NodeUtil.mayEffectMutableState(cArg, compiler) && NodeUtil.getNameReferenceCount( block, fnParam.getString()) > 1) { return CanInlineResult.NO; } }  // Move to the next name. fnParam = fnParam.getNext(); }  // For every call argument check for side-effects, even if there // isn't a named parameter to match. if (cArg != null) { if (NodeUtil.mayHaveSideEffects(cArg, compiler)) { return CanInlineResult.NO; } cArg = cArg.getNext(); } }  return CanInlineResult.YES; }
 private CanInlineResult canInlineReferenceDirectly( Node callNode, Node fnNode) { if (!isDirectCallNodeReplacementPossible(fnNode)) { return CanInlineResult.NO; }  Node block = fnNode.getLastChild();  boolean hasSideEffects = false; if (block.hasChildren()) { Preconditions.checkState(block.hasOneChild()); Node stmt = block.getFirstChild(); if (stmt.isReturn()) { hasSideEffects = NodeUtil.mayHaveSideEffects(stmt.getFirstChild(), compiler); } } // CALL NODE: [ NAME, ARG1, ARG2, ... ] Node cArg = callNode.getFirstChild().getNext();  // Functions called via 'call' and 'apply' have a this-object as // the first parameter, but this is not part of the called function's // parameter list. if (!callNode.getFirstChild().isName()) { if (NodeUtil.isFunctionObjectCall(callNode)) { // TODO(johnlenz): Support replace this with a value. if (cArg == null || !cArg.isThis()) { return CanInlineResult.NO; } cArg = cArg.getNext(); } else { // ".apply" call should be filtered before this. Preconditions.checkState(!NodeUtil.isFunctionObjectApply(callNode)); } }  // FUNCTION NODE -> LP NODE: [ ARG1, ARG2, ... ] Node fnParam = NodeUtil.getFunctionParameters(fnNode).getFirstChild(); while (cArg != null || fnParam != null) { // For each named parameter check if a mutable argument use more than one. if (fnParam != null) { if (cArg != null) { if (hasSideEffects && NodeUtil.canBeSideEffected(cArg)) { return CanInlineResult.NO; } // Check for arguments that are evaluated more than once. // Note: Unlike block inlining, there it is not possible that a // parameter reference will be in a loop. if (NodeUtil.mayEffectMutableState(cArg, compiler) && NodeUtil.getNameReferenceCount( block, fnParam.getString()) > 1) { return CanInlineResult.NO; } }  // Move to the next name. fnParam = fnParam.getNext(); }  // For every call argument check for side-effects, even if there // isn't a named parameter to match. if (cArg != null) { if (NodeUtil.mayHaveSideEffects(cArg, compiler)) { return CanInlineResult.NO; } cArg = cArg.getNext(); } }  return CanInlineResult.YES; }
 public int[] add(ReadablePartial partial, int fieldIndex, int[] values, int valueToAdd) { // overridden as superclass algorithm can't handle // 2004-02-29 + 48 months -> 2008-02-29 type dates if (valueToAdd == 0) { return values; } // month is largest field and being added to, such as month-day if (DateTimeUtils.isContiguous(partial)) { long instant = 0L; for (int i = 0, isize = partial.size(); i < isize; i++) { instant = partial.getFieldType(i).getField(iChronology).set(instant, values[i]); } instant = add(instant, valueToAdd); return iChronology.get(partial, instant); } else { return super.add(partial, fieldIndex, values, valueToAdd); } }
 public Complex parse(String source, ParsePosition pos) { int initialIndex = pos.getIndex();  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse real Number re = parseNumber(source, getRealFormat(), pos); if (re == null) { // invalid real number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // parse sign int startIndex = pos.getIndex(); char c = parseNextCharacter(source, pos); int sign = 0; switch (c) { case 0 : // no sign // return real only complex number return new Complex(re.doubleValue(), 0.0); case '-' : sign = -1; break; case '+' : sign = 1; break; default : // invalid sign // set index back to initial, error index should be the last // character examined. pos.setIndex(initialIndex); pos.setErrorIndex(startIndex); return null; }  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse imaginary Number im = parseNumber(source, getRealFormat(), pos); if (im == null) { // invalid imaginary number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // parse imaginary character int n = getImaginaryCharacter().length(); startIndex = pos.getIndex(); int endIndex = startIndex + n; if ( source.substring(startIndex, endIndex).compareTo( getImaginaryCharacter()) != 0) { // set index back to initial, error index should be the start index // character examined. pos.setIndex(initialIndex); pos.setErrorIndex(startIndex); return null; } pos.setIndex(endIndex);  return new Complex(re.doubleValue(), im.doubleValue() * sign); }
 String toStringHelper(boolean forAnnotations) { if (hasReferenceName()) { return getReferenceName(); } else if (prettyPrint) { // Don't pretty print recursively. prettyPrint = false;  // Use a tree set so that the properties are sorted. Set<String> propertyNames = Sets.newTreeSet(); for (ObjectType current = this; current != null && !current.isNativeObjectType() && propertyNames.size() <= MAX_PRETTY_PRINTED_PROPERTIES; current = current.getImplicitPrototype()) { propertyNames.addAll(current.getOwnPropertyNames()); }  StringBuilder sb = new StringBuilder(); sb.append("{");  int i = 0; for (String property : propertyNames) { if (i > 0) { sb.append(", "); }  sb.append(property); sb.append(": "); sb.append(getPropertyType(property).toString());  ++i; if (i == MAX_PRETTY_PRINTED_PROPERTIES) { sb.append(", ..."); break; } }  sb.append("}");  prettyPrint = true; return sb.toString(); } else { return "{...}"; } }
 String toStringHelper(boolean forAnnotations) { if (hasReferenceName()) { return getReferenceName(); } else if (prettyPrint) { // Don't pretty print recursively. prettyPrint = false;  // Use a tree set so that the properties are sorted. Set<String> propertyNames = Sets.newTreeSet(); for (ObjectType current = this; current != null && !current.isNativeObjectType() && propertyNames.size() <= MAX_PRETTY_PRINTED_PROPERTIES; current = current.getImplicitPrototype()) { propertyNames.addAll(current.getOwnPropertyNames()); }  StringBuilder sb = new StringBuilder(); sb.append("{");  int i = 0; for (String property : propertyNames) { if (i > 0) { sb.append(", "); }  sb.append(property); sb.append(": "); sb.append(getPropertyType(property).toString());  ++i; if (i == MAX_PRETTY_PRINTED_PROPERTIES) { sb.append(", ..."); break; } }  sb.append("}");  prettyPrint = true; return sb.toString(); } else { return "{...}"; } }
 String toStringHelper(boolean forAnnotations) { if (hasReferenceName()) { return getReferenceName(); } else if (prettyPrint) { // Don't pretty print recursively. prettyPrint = false;  // Use a tree set so that the properties are sorted. Set<String> propertyNames = Sets.newTreeSet(); for (ObjectType current = this; current != null && !current.isNativeObjectType() && propertyNames.size() <= MAX_PRETTY_PRINTED_PROPERTIES; current = current.getImplicitPrototype()) { propertyNames.addAll(current.getOwnPropertyNames()); }  StringBuilder sb = new StringBuilder(); sb.append("{");  int i = 0; for (String property : propertyNames) { if (i > 0) { sb.append(", "); }  sb.append(property); sb.append(": "); sb.append(getPropertyType(property).toString());  ++i; if (i == MAX_PRETTY_PRINTED_PROPERTIES) { sb.append(", ..."); break; } }  sb.append("}");  prettyPrint = true; return sb.toString(); } else { return "{...}"; } }
 public void captureArgumentsFrom(Invocation invocation) { if (invocation.getMethod().isVarArgs()) { int indexOfVararg = invocation.getRawArguments().length - 1; for (int position = 0; position < indexOfVararg; position++) { Matcher m = matchers.get(position); if (m instanceof CapturesArguments) { ((CapturesArguments) m).captureFrom(invocation.getArgumentAt(position, Object.class)); } } for (int position = indexOfVararg; position < matchers.size(); position++) { Matcher m = matchers.get(position); if (m instanceof CapturesArguments) { ((CapturesArguments) m).captureFrom(invocation.getRawArguments()[position - indexOfVararg]); } } } else { for (int position = 0; position < matchers.size(); position++) { Matcher m = matchers.get(position); if (m instanceof CapturesArguments) { ((CapturesArguments) m).captureFrom(invocation.getArgumentAt(position, Object.class)); } } } }
 private void updateBounds(TimePeriod period, int index) {  long start = period.getStart().getTime(); long end = period.getEnd().getTime(); long middle = start + ((end - start) / 2);  if (this.minStartIndex >= 0) { long minStart = getDataItem(this.minStartIndex).getPeriod() .getStart().getTime(); if (start < minStart) { this.minStartIndex = index; } } else { this.minStartIndex = index; }  if (this.maxStartIndex >= 0) { long maxStart = getDataItem(this.maxStartIndex).getPeriod() .getStart().getTime(); if (start > maxStart) { this.maxStartIndex = index; } } else { this.maxStartIndex = index; }  if (this.minMiddleIndex >= 0) { long s = getDataItem(this.minMiddleIndex).getPeriod().getStart() .getTime(); long e = getDataItem(this.minMiddleIndex).getPeriod().getEnd() .getTime(); long minMiddle = s + (e - s) / 2; if (middle < minMiddle) { this.minMiddleIndex = index; } } else { this.minMiddleIndex = index; }  if (this.maxMiddleIndex >= 0) { long s = getDataItem(this.minMiddleIndex).getPeriod().getStart() .getTime(); long e = getDataItem(this.minMiddleIndex).getPeriod().getEnd() .getTime(); long maxMiddle = s + (e - s) / 2; if (middle > maxMiddle) { this.maxMiddleIndex = index; } } else { this.maxMiddleIndex = index; }  if (this.minEndIndex >= 0) { long minEnd = getDataItem(this.minEndIndex).getPeriod().getEnd() .getTime(); if (end < minEnd) { this.minEndIndex = index; } } else { this.minEndIndex = index; }  if (this.maxEndIndex >= 0) { long maxEnd = getDataItem(this.maxEndIndex).getPeriod().getEnd() .getTime(); if (end > maxEnd) { this.maxEndIndex = index; } } else { this.maxEndIndex = index; }  }
 private void prelim(double[] lowerBound, double[] upperBound) { printMethod(); // XXX  final int n = currentBest.getDimension(); final int npt = numberOfInterpolationPoints; final int ndim = bMatrix.getRowDimension();  final double rhosq = initialTrustRegionRadius * initialTrustRegionRadius; final double recip = 1d / rhosq; final int np = n + 1;  // Set XBASE to the initial vector of variables, and set the initial // elements of XPT, BMAT, HQ, PQ and ZMAT to zero.  for (int j = 0; j < n; j++) { originShift.setEntry(j, currentBest.getEntry(j)); for (int k = 0; k < npt; k++) { interpolationPoints.setEntry(k, j, ZERO); } for (int i = 0; i < ndim; i++) { bMatrix.setEntry(i, j, ZERO); } } for (int i = 0, max = n * np / 2; i < max; i++) { modelSecondDerivativesValues.setEntry(i, ZERO); } for (int k = 0; k < npt; k++) { modelSecondDerivativesParameters.setEntry(k, ZERO); for (int j = 0, max = npt - np; j < max; j++) { zMatrix.setEntry(k, j, ZERO); } }  // Begin the initialization procedure. NF becomes one more than the number // of function values so far. The coordinates of the displacement of the // next initial interpolation point from XBASE are set in XPT(NF+1,.).  int ipt = 0; int jpt = 0; double fbeg = Double.NaN; do { final int nfm = getEvaluations(); final int nfx = nfm - n; final int nfmm = nfm - 1; final int nfxm = nfx - 1; double stepa = 0; double stepb = 0; if (nfm <= 2 * n) { if (nfm >= 1 && nfm <= n) { stepa = initialTrustRegionRadius; if (upperDifference.getEntry(nfmm) == ZERO) { stepa = -stepa; throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfmm, stepa); } else if (nfm > n) { stepa = interpolationPoints.getEntry(nfx, nfxm); stepb = -initialTrustRegionRadius; if (lowerDifference.getEntry(nfxm) == ZERO) { stepb = Math.min(TWO * initialTrustRegionRadius, upperDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } if (upperDifference.getEntry(nfxm) == ZERO) { stepb = Math.max(-TWO * initialTrustRegionRadius, lowerDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfxm, stepb); } } else { final int tmp1 = (nfm - np) / n; jpt = nfm - tmp1 * n - n; ipt = jpt + tmp1; if (ipt > n) { final int tmp2 = jpt; jpt = ipt - n; ipt = tmp2; throw new PathIsExploredException(); // XXX } final int iptMinus1 = ipt; final int jptMinus1 = jpt; interpolationPoints.setEntry(nfm, iptMinus1, interpolationPoints.getEntry(ipt, iptMinus1)); interpolationPoints.setEntry(nfm, jptMinus1, interpolationPoints.getEntry(jpt, jptMinus1)); }  // Calculate the next value of F. The least function value so far and // its index are required.  for (int j = 0; j < n; j++) { currentBest.setEntry(j, Math.min(Math.max(lowerBound[j], originShift.getEntry(j) + interpolationPoints.getEntry(nfm, j)), upperBound[j])); if (interpolationPoints.getEntry(nfm, j) == lowerDifference.getEntry(j)) { currentBest.setEntry(j, lowerBound[j]); } if (interpolationPoints.getEntry(nfm, j) == upperDifference.getEntry(j)) { currentBest.setEntry(j, upperBound[j]); } }  final double objectiveValue = computeObjectiveValue(currentBest.toArray()); final double f = isMinimize ? objectiveValue : -objectiveValue; final int numEval = getEvaluations(); // nfm + 1 fAtInterpolationPoints.setEntry(nfm, f);  if (numEval == 1) { fbeg = f; trustRegionCenterInterpolationPointIndex = 0; } else if (f < fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex)) { trustRegionCenterInterpolationPointIndex = nfm; }  // Set the nonzero initial elements of BMAT and the quadratic model in the // cases when NF is at most 2*N+1. If NF exceeds N+1, then the positions // of the NF-th and (NF-N)-th interpolation points may be switched, in // order that the function value at the first of them contributes to the // off-diagonal second derivative terms of the initial quadratic model.  if (numEval <= 2 * n + 1) { if (numEval >= 2 && numEval <= n + 1) { gradientAtTrustRegionCenter.setEntry(nfmm, (f - fbeg) / stepa); if (npt < numEval + n) { final double oneOverStepA = ONE / stepa; bMatrix.setEntry(0, nfmm, -oneOverStepA); bMatrix.setEntry(nfm, nfmm, oneOverStepA); bMatrix.setEntry(npt + nfmm, nfmm, -HALF * rhosq); throw new PathIsExploredException(); // XXX } } else if (numEval >= n + 2) { final int ih = nfx * (nfx + 1) / 2 - 1; final double tmp = (f - fbeg) / stepb; final double diff = stepb - stepa; modelSecondDerivativesValues.setEntry(ih, TWO * (tmp - gradientAtTrustRegionCenter.getEntry(nfxm)) / diff); gradientAtTrustRegionCenter.setEntry(nfxm, (gradientAtTrustRegionCenter.getEntry(nfxm) * stepb - tmp * stepa) / diff); if (stepa * stepb < ZERO) { if (f < fAtInterpolationPoints.getEntry(nfm - n)) { fAtInterpolationPoints.setEntry(nfm, fAtInterpolationPoints.getEntry(nfm - n)); fAtInterpolationPoints.setEntry(nfm - n, f); if (trustRegionCenterInterpolationPointIndex == nfm) { trustRegionCenterInterpolationPointIndex = nfm - n; } interpolationPoints.setEntry(nfm - n, nfxm, stepb); interpolationPoints.setEntry(nfm, nfxm, stepa); } } bMatrix.setEntry(0, nfxm, -(stepa + stepb) / (stepa * stepb)); bMatrix.setEntry(nfm, nfxm, -HALF / interpolationPoints.getEntry(nfm - n, nfxm)); bMatrix.setEntry(nfm - n, nfxm, -bMatrix.getEntry(0, nfxm) - bMatrix.getEntry(nfm, nfxm)); zMatrix.setEntry(0, nfxm, Math.sqrt(TWO) / (stepa * stepb)); zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) / rhosq); // zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) * recip); // XXX "testAckley" and "testDiffPow" fail. zMatrix.setEntry(nfm - n, nfxm, -zMatrix.getEntry(0, nfxm) - zMatrix.getEntry(nfm, nfxm)); }  // Set the off-diagonal second derivatives of the Lagrange functions and // the initial quadratic model.  } else { zMatrix.setEntry(0, nfxm, recip); zMatrix.setEntry(nfm, nfxm, recip); zMatrix.setEntry(ipt, nfxm, -recip); zMatrix.setEntry(jpt, nfxm, -recip);  final int ih = ipt * (ipt - 1) / 2 + jpt - 1; final double tmp = interpolationPoints.getEntry(nfm, ipt - 1) * interpolationPoints.getEntry(nfm, jpt - 1); modelSecondDerivativesValues.setEntry(ih, (fbeg - fAtInterpolationPoints.getEntry(ipt) - fAtInterpolationPoints.getEntry(jpt) + f) / tmp); throw new PathIsExploredException(); // XXX } } while (getEvaluations() < npt); } // prelim
 private void prelim(double[] lowerBound, double[] upperBound) { printMethod(); // XXX  final int n = currentBest.getDimension(); final int npt = numberOfInterpolationPoints; final int ndim = bMatrix.getRowDimension();  final double rhosq = initialTrustRegionRadius * initialTrustRegionRadius; final double recip = 1d / rhosq; final int np = n + 1;  // Set XBASE to the initial vector of variables, and set the initial // elements of XPT, BMAT, HQ, PQ and ZMAT to zero.  for (int j = 0; j < n; j++) { originShift.setEntry(j, currentBest.getEntry(j)); for (int k = 0; k < npt; k++) { interpolationPoints.setEntry(k, j, ZERO); } for (int i = 0; i < ndim; i++) { bMatrix.setEntry(i, j, ZERO); } } for (int i = 0, max = n * np / 2; i < max; i++) { modelSecondDerivativesValues.setEntry(i, ZERO); } for (int k = 0; k < npt; k++) { modelSecondDerivativesParameters.setEntry(k, ZERO); for (int j = 0, max = npt - np; j < max; j++) { zMatrix.setEntry(k, j, ZERO); } }  // Begin the initialization procedure. NF becomes one more than the number // of function values so far. The coordinates of the displacement of the // next initial interpolation point from XBASE are set in XPT(NF+1,.).  int ipt = 0; int jpt = 0; double fbeg = Double.NaN; do { final int nfm = getEvaluations(); final int nfx = nfm - n; final int nfmm = nfm - 1; final int nfxm = nfx - 1; double stepa = 0; double stepb = 0; if (nfm <= 2 * n) { if (nfm >= 1 && nfm <= n) { stepa = initialTrustRegionRadius; if (upperDifference.getEntry(nfmm) == ZERO) { stepa = -stepa; throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfmm, stepa); } else if (nfm > n) { stepa = interpolationPoints.getEntry(nfx, nfxm); stepb = -initialTrustRegionRadius; if (lowerDifference.getEntry(nfxm) == ZERO) { stepb = Math.min(TWO * initialTrustRegionRadius, upperDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } if (upperDifference.getEntry(nfxm) == ZERO) { stepb = Math.max(-TWO * initialTrustRegionRadius, lowerDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfxm, stepb); } } else { final int tmp1 = (nfm - np) / n; jpt = nfm - tmp1 * n - n; ipt = jpt + tmp1; if (ipt > n) { final int tmp2 = jpt; jpt = ipt - n; ipt = tmp2; throw new PathIsExploredException(); // XXX } final int iptMinus1 = ipt; final int jptMinus1 = jpt; interpolationPoints.setEntry(nfm, iptMinus1, interpolationPoints.getEntry(ipt, iptMinus1)); interpolationPoints.setEntry(nfm, jptMinus1, interpolationPoints.getEntry(jpt, jptMinus1)); }  // Calculate the next value of F. The least function value so far and // its index are required.  for (int j = 0; j < n; j++) { currentBest.setEntry(j, Math.min(Math.max(lowerBound[j], originShift.getEntry(j) + interpolationPoints.getEntry(nfm, j)), upperBound[j])); if (interpolationPoints.getEntry(nfm, j) == lowerDifference.getEntry(j)) { currentBest.setEntry(j, lowerBound[j]); } if (interpolationPoints.getEntry(nfm, j) == upperDifference.getEntry(j)) { currentBest.setEntry(j, upperBound[j]); } }  final double objectiveValue = computeObjectiveValue(currentBest.toArray()); final double f = isMinimize ? objectiveValue : -objectiveValue; final int numEval = getEvaluations(); // nfm + 1 fAtInterpolationPoints.setEntry(nfm, f);  if (numEval == 1) { fbeg = f; trustRegionCenterInterpolationPointIndex = 0; } else if (f < fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex)) { trustRegionCenterInterpolationPointIndex = nfm; }  // Set the nonzero initial elements of BMAT and the quadratic model in the // cases when NF is at most 2*N+1. If NF exceeds N+1, then the positions // of the NF-th and (NF-N)-th interpolation points may be switched, in // order that the function value at the first of them contributes to the // off-diagonal second derivative terms of the initial quadratic model.  if (numEval <= 2 * n + 1) { if (numEval >= 2 && numEval <= n + 1) { gradientAtTrustRegionCenter.setEntry(nfmm, (f - fbeg) / stepa); if (npt < numEval + n) { final double oneOverStepA = ONE / stepa; bMatrix.setEntry(0, nfmm, -oneOverStepA); bMatrix.setEntry(nfm, nfmm, oneOverStepA); bMatrix.setEntry(npt + nfmm, nfmm, -HALF * rhosq); throw new PathIsExploredException(); // XXX } } else if (numEval >= n + 2) { final int ih = nfx * (nfx + 1) / 2 - 1; final double tmp = (f - fbeg) / stepb; final double diff = stepb - stepa; modelSecondDerivativesValues.setEntry(ih, TWO * (tmp - gradientAtTrustRegionCenter.getEntry(nfxm)) / diff); gradientAtTrustRegionCenter.setEntry(nfxm, (gradientAtTrustRegionCenter.getEntry(nfxm) * stepb - tmp * stepa) / diff); if (stepa * stepb < ZERO) { if (f < fAtInterpolationPoints.getEntry(nfm - n)) { fAtInterpolationPoints.setEntry(nfm, fAtInterpolationPoints.getEntry(nfm - n)); fAtInterpolationPoints.setEntry(nfm - n, f); if (trustRegionCenterInterpolationPointIndex == nfm) { trustRegionCenterInterpolationPointIndex = nfm - n; } interpolationPoints.setEntry(nfm - n, nfxm, stepb); interpolationPoints.setEntry(nfm, nfxm, stepa); } } bMatrix.setEntry(0, nfxm, -(stepa + stepb) / (stepa * stepb)); bMatrix.setEntry(nfm, nfxm, -HALF / interpolationPoints.getEntry(nfm - n, nfxm)); bMatrix.setEntry(nfm - n, nfxm, -bMatrix.getEntry(0, nfxm) - bMatrix.getEntry(nfm, nfxm)); zMatrix.setEntry(0, nfxm, Math.sqrt(TWO) / (stepa * stepb)); zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) / rhosq); // zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) * recip); // XXX "testAckley" and "testDiffPow" fail. zMatrix.setEntry(nfm - n, nfxm, -zMatrix.getEntry(0, nfxm) - zMatrix.getEntry(nfm, nfxm)); }  // Set the off-diagonal second derivatives of the Lagrange functions and // the initial quadratic model.  } else { zMatrix.setEntry(0, nfxm, recip); zMatrix.setEntry(nfm, nfxm, recip); zMatrix.setEntry(ipt, nfxm, -recip); zMatrix.setEntry(jpt, nfxm, -recip);  final int ih = ipt * (ipt - 1) / 2 + jpt - 1; final double tmp = interpolationPoints.getEntry(nfm, ipt - 1) * interpolationPoints.getEntry(nfm, jpt - 1); modelSecondDerivativesValues.setEntry(ih, (fbeg - fAtInterpolationPoints.getEntry(ipt) - fAtInterpolationPoints.getEntry(jpt) + f) / tmp); throw new PathIsExploredException(); // XXX } } while (getEvaluations() < npt); } // prelim
 private void prelim(double[] lowerBound, double[] upperBound) { printMethod(); // XXX  final int n = currentBest.getDimension(); final int npt = numberOfInterpolationPoints; final int ndim = bMatrix.getRowDimension();  final double rhosq = initialTrustRegionRadius * initialTrustRegionRadius; final double recip = 1d / rhosq; final int np = n + 1;  // Set XBASE to the initial vector of variables, and set the initial // elements of XPT, BMAT, HQ, PQ and ZMAT to zero.  for (int j = 0; j < n; j++) { originShift.setEntry(j, currentBest.getEntry(j)); for (int k = 0; k < npt; k++) { interpolationPoints.setEntry(k, j, ZERO); } for (int i = 0; i < ndim; i++) { bMatrix.setEntry(i, j, ZERO); } } for (int i = 0, max = n * np / 2; i < max; i++) { modelSecondDerivativesValues.setEntry(i, ZERO); } for (int k = 0; k < npt; k++) { modelSecondDerivativesParameters.setEntry(k, ZERO); for (int j = 0, max = npt - np; j < max; j++) { zMatrix.setEntry(k, j, ZERO); } }  // Begin the initialization procedure. NF becomes one more than the number // of function values so far. The coordinates of the displacement of the // next initial interpolation point from XBASE are set in XPT(NF+1,.).  int ipt = 0; int jpt = 0; double fbeg = Double.NaN; do { final int nfm = getEvaluations(); final int nfx = nfm - n; final int nfmm = nfm - 1; final int nfxm = nfx - 1; double stepa = 0; double stepb = 0; if (nfm <= 2 * n) { if (nfm >= 1 && nfm <= n) { stepa = initialTrustRegionRadius; if (upperDifference.getEntry(nfmm) == ZERO) { stepa = -stepa; throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfmm, stepa); } else if (nfm > n) { stepa = interpolationPoints.getEntry(nfx, nfxm); stepb = -initialTrustRegionRadius; if (lowerDifference.getEntry(nfxm) == ZERO) { stepb = Math.min(TWO * initialTrustRegionRadius, upperDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } if (upperDifference.getEntry(nfxm) == ZERO) { stepb = Math.max(-TWO * initialTrustRegionRadius, lowerDifference.getEntry(nfxm)); throw new PathIsExploredException(); // XXX } interpolationPoints.setEntry(nfm, nfxm, stepb); } } else { final int tmp1 = (nfm - np) / n; jpt = nfm - tmp1 * n - n; ipt = jpt + tmp1; if (ipt > n) { final int tmp2 = jpt; jpt = ipt - n; ipt = tmp2; throw new PathIsExploredException(); // XXX } final int iptMinus1 = ipt; final int jptMinus1 = jpt; interpolationPoints.setEntry(nfm, iptMinus1, interpolationPoints.getEntry(ipt, iptMinus1)); interpolationPoints.setEntry(nfm, jptMinus1, interpolationPoints.getEntry(jpt, jptMinus1)); }  // Calculate the next value of F. The least function value so far and // its index are required.  for (int j = 0; j < n; j++) { currentBest.setEntry(j, Math.min(Math.max(lowerBound[j], originShift.getEntry(j) + interpolationPoints.getEntry(nfm, j)), upperBound[j])); if (interpolationPoints.getEntry(nfm, j) == lowerDifference.getEntry(j)) { currentBest.setEntry(j, lowerBound[j]); } if (interpolationPoints.getEntry(nfm, j) == upperDifference.getEntry(j)) { currentBest.setEntry(j, upperBound[j]); } }  final double objectiveValue = computeObjectiveValue(currentBest.toArray()); final double f = isMinimize ? objectiveValue : -objectiveValue; final int numEval = getEvaluations(); // nfm + 1 fAtInterpolationPoints.setEntry(nfm, f);  if (numEval == 1) { fbeg = f; trustRegionCenterInterpolationPointIndex = 0; } else if (f < fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex)) { trustRegionCenterInterpolationPointIndex = nfm; }  // Set the nonzero initial elements of BMAT and the quadratic model in the // cases when NF is at most 2*N+1. If NF exceeds N+1, then the positions // of the NF-th and (NF-N)-th interpolation points may be switched, in // order that the function value at the first of them contributes to the // off-diagonal second derivative terms of the initial quadratic model.  if (numEval <= 2 * n + 1) { if (numEval >= 2 && numEval <= n + 1) { gradientAtTrustRegionCenter.setEntry(nfmm, (f - fbeg) / stepa); if (npt < numEval + n) { final double oneOverStepA = ONE / stepa; bMatrix.setEntry(0, nfmm, -oneOverStepA); bMatrix.setEntry(nfm, nfmm, oneOverStepA); bMatrix.setEntry(npt + nfmm, nfmm, -HALF * rhosq); throw new PathIsExploredException(); // XXX } } else if (numEval >= n + 2) { final int ih = nfx * (nfx + 1) / 2 - 1; final double tmp = (f - fbeg) / stepb; final double diff = stepb - stepa; modelSecondDerivativesValues.setEntry(ih, TWO * (tmp - gradientAtTrustRegionCenter.getEntry(nfxm)) / diff); gradientAtTrustRegionCenter.setEntry(nfxm, (gradientAtTrustRegionCenter.getEntry(nfxm) * stepb - tmp * stepa) / diff); if (stepa * stepb < ZERO) { if (f < fAtInterpolationPoints.getEntry(nfm - n)) { fAtInterpolationPoints.setEntry(nfm, fAtInterpolationPoints.getEntry(nfm - n)); fAtInterpolationPoints.setEntry(nfm - n, f); if (trustRegionCenterInterpolationPointIndex == nfm) { trustRegionCenterInterpolationPointIndex = nfm - n; } interpolationPoints.setEntry(nfm - n, nfxm, stepb); interpolationPoints.setEntry(nfm, nfxm, stepa); } } bMatrix.setEntry(0, nfxm, -(stepa + stepb) / (stepa * stepb)); bMatrix.setEntry(nfm, nfxm, -HALF / interpolationPoints.getEntry(nfm - n, nfxm)); bMatrix.setEntry(nfm - n, nfxm, -bMatrix.getEntry(0, nfxm) - bMatrix.getEntry(nfm, nfxm)); zMatrix.setEntry(0, nfxm, Math.sqrt(TWO) / (stepa * stepb)); zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) / rhosq); // zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) * recip); // XXX "testAckley" and "testDiffPow" fail. zMatrix.setEntry(nfm - n, nfxm, -zMatrix.getEntry(0, nfxm) - zMatrix.getEntry(nfm, nfxm)); }  // Set the off-diagonal second derivatives of the Lagrange functions and // the initial quadratic model.  } else { zMatrix.setEntry(0, nfxm, recip); zMatrix.setEntry(nfm, nfxm, recip); zMatrix.setEntry(ipt, nfxm, -recip); zMatrix.setEntry(jpt, nfxm, -recip);  final int ih = ipt * (ipt - 1) / 2 + jpt - 1; final double tmp = interpolationPoints.getEntry(nfm, ipt - 1) * interpolationPoints.getEntry(nfm, jpt - 1); modelSecondDerivativesValues.setEntry(ih, (fbeg - fAtInterpolationPoints.getEntry(ipt) - fAtInterpolationPoints.getEntry(jpt) + f) / tmp); throw new PathIsExploredException(); // XXX } } while (getEvaluations() < npt); } // prelim
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (str.startsWith("0x") || str.startsWith("-0x")) { return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos || expPos > str.length()) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { if (expPos > str.length()) { throw new NumberFormatException(str + " is not a valid number."); } mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { // NOPMD // Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // NOPMD // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // NOPMD // ignore the bad number }  return createBigDecimal(str);  } } }
 public Object answer(InvocationOnMock invocation) throws Throwable { GenericMetadataSupport returnTypeGenericMetadata = actualParameterizedType(invocation.getMock()).resolveGenericReturnType(invocation.getMethod());  Class<?> rawType = returnTypeGenericMetadata.rawType(); if (!mockitoCore.isTypeMockable(rawType)) { return delegate.returnValueFor(rawType); }  return getMock(invocation, returnTypeGenericMetadata); }
 private Object recordDeepStubMock(final Object mock, InvocationContainerImpl container) throws Throwable {  container.addAnswer(new Answer<Object>() { public Object answer(InvocationOnMock invocation) throws Throwable { return mock; } }, false);  return mock; }
 private MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata) { MockSettings mockSettings = returnTypeGenericMetadata.rawExtraInterfaces().length > 0 ? withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces()) : withSettings();  return mockSettings .defaultAnswer(returnsDeepStubsAnswerUsing(returnTypeGenericMetadata)); }
 private MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata) { MockSettings mockSettings = returnTypeGenericMetadata.rawExtraInterfaces().length > 0 ? withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces()) : withSettings();  return mockSettings .defaultAnswer(returnsDeepStubsAnswerUsing(returnTypeGenericMetadata)); }
 public void describeTo(Description description) { description.appendText("same("); appendQuoting(description); description.appendText(wanted.toString()); appendQuoting(description); description.appendText(")"); }
 protected CompilerOptions createOptions() { CompilerOptions options = new CompilerOptions(); options.setCodingConvention(new ClosureCodingConvention()); CompilationLevel level = flags.compilation_level; level.setOptionsForCompilationLevel(options); if (flags.debug) { level.setDebugOptionsForCompilationLevel(options); }  WarningLevel wLevel = flags.warning_level; wLevel.setOptionsForWarningLevel(options); for (FormattingOption formattingOption : flags.formatting) { formattingOption.applyToOptions(options); } if (flags.process_closure_primitives) { options.closurePass = true; }  initOptionsFromFlags(options); return options; }
 void tryFoldStringJoin(NodeTraversal t, Node n, Node left, Node right, Node parent) { if (!NodeUtil.isGetProp(left) || !NodeUtil.isImmutableValue(right)) { return; }  Node arrayNode = left.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return; }  String joinString = NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = new StringBuilder(); int foldedSize = 0; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem)) { if (sb.length() > 0) { sb.append(joinString); } sb.append(NodeUtil.getStringValue(elem)); } else { if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); sb = new StringBuilder(); } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } elem = elem.getNext(); }  if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); parent.replaceChild(n, emptyStringNode); break;  case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString(""), foldedStringNode); foldedStringNode = replacement; } parent.replaceChild(n, foldedStringNode); break;  default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += InlineCostEstimator.getCost(right); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } break; } t.getCompiler().reportCodeChange(); }
 void tryFoldStringJoin(NodeTraversal t, Node n, Node left, Node right, Node parent) { if (!NodeUtil.isGetProp(left) || !NodeUtil.isImmutableValue(right)) { return; }  Node arrayNode = left.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return; }  String joinString = NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = new StringBuilder(); int foldedSize = 0; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem)) { if (sb.length() > 0) { sb.append(joinString); } sb.append(NodeUtil.getStringValue(elem)); } else { if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); sb = new StringBuilder(); } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } elem = elem.getNext(); }  if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); parent.replaceChild(n, emptyStringNode); break;  case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString(""), foldedStringNode); foldedStringNode = replacement; } parent.replaceChild(n, foldedStringNode); break;  default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += InlineCostEstimator.getCost(right); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } break; } t.getCompiler().reportCodeChange(); }
 void tryFoldStringJoin(NodeTraversal t, Node n, Node left, Node right, Node parent) { if (!NodeUtil.isGetProp(left) || !NodeUtil.isImmutableValue(right)) { return; }  Node arrayNode = left.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return; }  String joinString = NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = new StringBuilder(); int foldedSize = 0; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem)) { if (sb.length() > 0) { sb.append(joinString); } sb.append(NodeUtil.getStringValue(elem)); } else { if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); sb = new StringBuilder(); } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } elem = elem.getNext(); }  if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); parent.replaceChild(n, emptyStringNode); break;  case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString(""), foldedStringNode); foldedStringNode = replacement; } parent.replaceChild(n, foldedStringNode); break;  default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += InlineCostEstimator.getCost(right); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } break; } t.getCompiler().reportCodeChange(); }
 void tryFoldStringJoin(NodeTraversal t, Node n, Node left, Node right, Node parent) { if (!NodeUtil.isGetProp(left) || !NodeUtil.isImmutableValue(right)) { return; }  Node arrayNode = left.getFirstChild(); Node functionName = arrayNode.getNext();  if ((arrayNode.getType() != Token.ARRAYLIT) || !functionName.getString().equals("join")) { return; }  String joinString = NodeUtil.getStringValue(right); List<Node> arrayFoldedChildren = Lists.newLinkedList(); StringBuilder sb = new StringBuilder(); int foldedSize = 0; Node elem = arrayNode.getFirstChild(); // Merges adjacent String nodes. while (elem != null) { if (NodeUtil.isImmutableValue(elem)) { if (sb.length() > 0) { sb.append(joinString); } sb.append(NodeUtil.getStringValue(elem)); } else { if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); sb = new StringBuilder(); } foldedSize += InlineCostEstimator.getCost(elem); arrayFoldedChildren.add(elem); } elem = elem.getNext(); }  if (sb.length() > 0) { // + 2 for the quotes. foldedSize += sb.length() + 2; arrayFoldedChildren.add(Node.newString(sb.toString())); } // one for each comma. foldedSize += arrayFoldedChildren.size() - 1;  int originalSize = InlineCostEstimator.getCost(n); switch (arrayFoldedChildren.size()) { case 0: Node emptyStringNode = Node.newString(""); parent.replaceChild(n, emptyStringNode); break;  case 1: Node foldedStringNode = arrayFoldedChildren.remove(0); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); if (foldedStringNode.getType() != Token.STRING) { // If the Node is not a string literal, ensure that // it is coerced to a string. Node replacement = new Node(Token.ADD, Node.newString(""), foldedStringNode); foldedStringNode = replacement; } parent.replaceChild(n, foldedStringNode); break;  default: // No folding could actually be performed. if (arrayFoldedChildren.size() == arrayNode.getChildCount()) { return; } int kJoinOverhead = "[].join()".length(); foldedSize += kJoinOverhead; foldedSize += InlineCostEstimator.getCost(right); if (foldedSize > originalSize) { return; } arrayNode.detachChildren(); for (Node node : arrayFoldedChildren) { arrayNode.addChildToBack(node); } break; } t.getCompiler().reportCodeChange(); }
 public BigDecimal[] operate(BigDecimal[] v) throws IllegalArgumentException { if (v.length != this.getColumnDimension()) { throw new IllegalArgumentException("vector has wrong length"); } final int nRows = this.getRowDimension(); final int nCols = this.getColumnDimension(); final BigDecimal[] out = new BigDecimal[v.length]; for (int row = 0; row < nRows; row++) { BigDecimal sum = ZERO; for (int i = 0; i < nCols; i++) { sum = sum.add(data[row][i].multiply(v[i])); } out[row] = sum; } return out; }
 public double[] operate(double[] v) throws IllegalArgumentException { final int nRows = this.getRowDimension(); final int nCols = this.getColumnDimension(); if (v.length != nCols) { throw new IllegalArgumentException("vector has wrong length"); } final double[] out = new double[v.length]; for (int row = 0; row < nRows; row++) { final double[] dataRow = data[row]; double sum = 0; for (int i = 0; i < nCols; i++) { sum += dataRow[i] * v[i]; } out[row] = sum; } return out; }
 static String strEscape(String s, char quote, String doublequoteEscape, String singlequoteEscape, String backslashEscape, CharsetEncoder outputCharsetEncoder) { StringBuilder sb = new StringBuilder(s.length() + 2); sb.append(quote); for (int i = 0; i < s.length(); i++) { char c = s.charAt(i); switch (c) { case '\n': sb.append("\\n"); break; case '\r': sb.append("\\r"); break; case '\t': sb.append("\\t"); break; case '\\': sb.append(backslashEscape); break; case '\"': sb.append(doublequoteEscape); break; case '\'': sb.append(singlequoteEscape); break; case '>':                       // Break --> into --\> or ]]> into ]]\> if (i >= 2 && ((s.charAt(i - 1) == '-' && s.charAt(i - 2) == '-') || (s.charAt(i - 1) == ']' && s.charAt(i - 2) == ']'))) { sb.append("\\>"); } else { sb.append(c); } break; case '<': // Break </script into <\/script final String END_SCRIPT = "/script";  // Break <!-- into <\!-- final String START_COMMENT = "!--";  if (s.regionMatches(true, i + 1, END_SCRIPT, 0, END_SCRIPT.length())) { sb.append("<\\"); } else if (s.regionMatches(false, i + 1, START_COMMENT, 0, START_COMMENT.length())) { sb.append("<\\"); } else { sb.append(c); } break; default: // If we're given an outputCharsetEncoder, then check if the //  character can be represented in this character set. if (outputCharsetEncoder != null) { if (outputCharsetEncoder.canEncode(c)) { sb.append(c); } else { // Unicode-escape the character. appendHexJavaScriptRepresentation(sb, c); } } else { // No charsetEncoder provided - pass straight latin characters // through, and escape the rest.  Doing the explicit character // check is measurably faster than using the CharsetEncoder. if (c > 0x1f && c <= 0x7f) { sb.append(c); } else { // Other characters can be misinterpreted by some js parsers, // or perhaps mangled by proxies along the way, // so we play it safe and unicode escape them. appendHexJavaScriptRepresentation(sb, c); } } } } sb.append(quote); return sb.toString(); }
 static String strEscape(String s, char quote, String doublequoteEscape, String singlequoteEscape, String backslashEscape, CharsetEncoder outputCharsetEncoder) { StringBuilder sb = new StringBuilder(s.length() + 2); sb.append(quote); for (int i = 0; i < s.length(); i++) { char c = s.charAt(i); switch (c) { case '\n': sb.append("\\n"); break; case '\r': sb.append("\\r"); break; case '\t': sb.append("\\t"); break; case '\\': sb.append(backslashEscape); break; case '\"': sb.append(doublequoteEscape); break; case '\'': sb.append(singlequoteEscape); break; case '>':                       // Break --> into --\> or ]]> into ]]\> if (i >= 2 && ((s.charAt(i - 1) == '-' && s.charAt(i - 2) == '-') || (s.charAt(i - 1) == ']' && s.charAt(i - 2) == ']'))) { sb.append("\\>"); } else { sb.append(c); } break; case '<': // Break </script into <\/script final String END_SCRIPT = "/script";  // Break <!-- into <\!-- final String START_COMMENT = "!--";  if (s.regionMatches(true, i + 1, END_SCRIPT, 0, END_SCRIPT.length())) { sb.append("<\\"); } else if (s.regionMatches(false, i + 1, START_COMMENT, 0, START_COMMENT.length())) { sb.append("<\\"); } else { sb.append(c); } break; default: // If we're given an outputCharsetEncoder, then check if the //  character can be represented in this character set. if (outputCharsetEncoder != null) { if (outputCharsetEncoder.canEncode(c)) { sb.append(c); } else { // Unicode-escape the character. appendHexJavaScriptRepresentation(sb, c); } } else { // No charsetEncoder provided - pass straight latin characters // through, and escape the rest.  Doing the explicit character // check is measurably faster than using the CharsetEncoder. if (c > 0x1f && c <= 0x7f) { sb.append(c); } else { // Other characters can be misinterpreted by some js parsers, // or perhaps mangled by proxies along the way, // so we play it safe and unicode escape them. appendHexJavaScriptRepresentation(sb, c); } } } } sb.append(quote); return sb.toString(); }
 public void process(Node externs, Node root) { NodeTraversal.traverse(compiler, root, this); if (MAKE_LOCAL_NAMES_UNIQUE) { MakeDeclaredNamesUnique renamer = new MakeDeclaredNamesUnique(); NodeTraversal t = new NodeTraversal(compiler, renamer); t.traverseRoots(externs, root); } removeDuplicateDeclarations(root); new PropogateConstantAnnotations(compiler, assertOnChange) .process(externs, root); }
 protected double getInitialDomain(double p) { double ret; double d = getDenominatorDegreesOfFreedom(); // use mean ret = d / (d - 2.0); return ret; }
 protected double getInitialDomain(double p) { double ret; double d = getDenominatorDegreesOfFreedom(); // use mean ret = d / (d - 2.0); return ret; }
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (str.startsWith("0x") || str.startsWith("-0x")) { return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { //Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number }  return createBigDecimal(str);  } } }
 public static Number createNumber(String str) throws NumberFormatException { if (str == null) { return null; } if (StringUtils.isBlank(str)) { throw new NumberFormatException("A blank string is not a valid number"); } if (str.startsWith("--")) { // this is protection for poorness in java.lang.BigDecimal. // it accepts this as a legal value, but it does not appear // to be in specification of class. OS X Java parses it to // a wrong value. return null; } if (str.startsWith("0x") || str.startsWith("-0x")) { return createInteger(str); } char lastChar = str.charAt(str.length() - 1); String mant; String dec; String exp; int decPos = str.indexOf('.'); int expPos = str.indexOf('e') + str.indexOf('E') + 1;  if (decPos > -1) {  if (expPos > -1) { if (expPos < decPos) { throw new NumberFormatException(str + " is not a valid number."); } dec = str.substring(decPos + 1, expPos); } else { dec = str.substring(decPos + 1); } mant = str.substring(0, decPos); } else { if (expPos > -1) { mant = str.substring(0, expPos); } else { mant = str; } dec = null; } if (!Character.isDigit(lastChar) && lastChar != '.') { if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length() - 1); } else { exp = null; } //Requesting a specific type.. String numeric = str.substring(0, str.length() - 1); boolean allZeros = isAllZeros(mant) && isAllZeros(exp); switch (lastChar) { case 'l' : case 'L' : if (dec == null && exp == null && (numeric.charAt(0) == '-' && isDigits(numeric.substring(1)) || isDigits(numeric))) { try { return createLong(numeric); } catch (NumberFormatException nfe) { //Too big for a long } return createBigInteger(numeric);  } throw new NumberFormatException(str + " is not a valid number."); case 'f' : case 'F' : try { Float f = NumberUtils.createFloat(numeric); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { //If it's too big for a float or the float value = 0 and the string //has non-zeros in it, then float does not have the precision we want return f; }  } catch (NumberFormatException nfe) { // ignore the bad number } //$FALL-THROUGH$ case 'd' : case 'D' : try { Double d = NumberUtils.createDouble(numeric); if (!(d.isInfinite() || (d.floatValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number } try { return createBigDecimal(numeric); } catch (NumberFormatException e) { // ignore the bad number } //$FALL-THROUGH$ default : throw new NumberFormatException(str + " is not a valid number.");  } } else { //User doesn't have a preference on the return type, so let's start //small and go from there... if (expPos > -1 && expPos < str.length() - 1) { exp = str.substring(expPos + 1, str.length()); } else { exp = null; } if (dec == null && exp == null) { //Must be an int,long,bigint try { return createInteger(str); } catch (NumberFormatException nfe) { // ignore the bad number } try { return createLong(str); } catch (NumberFormatException nfe) { // ignore the bad number } return createBigInteger(str);  } else { //Must be a float,double,BigDec boolean allZeros = isAllZeros(mant) && isAllZeros(exp); try { Float f = createFloat(str); if (!(f.isInfinite() || (f.floatValue() == 0.0F && !allZeros))) { return f; } } catch (NumberFormatException nfe) { // ignore the bad number } try { Double d = createDouble(str); if (!(d.isInfinite() || (d.doubleValue() == 0.0D && !allZeros))) { return d; } } catch (NumberFormatException nfe) { // ignore the bad number }  return createBigDecimal(str);  } } }
 public void process(Class<?> context, Object testClass) { Field[] fields = context.getDeclaredFields(); for (Field field : fields) { if (field.isAnnotationPresent(Spy.class)) { assertNoAnnotations(Spy.class, field, Mock.class, org.mockito.MockitoAnnotations.Mock.class, Captor.class); boolean wasAccessible = field.isAccessible(); field.setAccessible(true); try { Object instance = field.get(testClass); if (instance == null) { throw new MockitoException("Cannot create a @Spy for '" + field.getName() + "' field because the *instance* is missing\n" + "The instance must be created *before* initMocks();\n" + "Example of correct usage of @Spy:\n" + "   @Spy List mock = new LinkedList();\n" + "   //also, don't forget about MockitoAnnotations.initMocks();");  } if (new MockUtil().isMock(instance)) { // instance has been spied earlier Mockito.reset(instance); } else { field.set(testClass, Mockito.spy(instance)); } } catch (IllegalAccessException e) { throw new MockitoException("Problems initiating spied field " + field.getName(), e); } finally { field.setAccessible(wasAccessible); } } } }
 private void findAliases(NodeTraversal t) { Scope scope = t.getScope(); for (Var v : scope.getVarIterable()) { Node n = v.getNode(); int type = n.getType(); Node parent = n.getParent(); if (parent.isVar()) { if (n.hasChildren() && n.getFirstChild().isQualifiedName()) { String name = n.getString(); Var aliasVar = scope.getVar(name); aliases.put(name, aliasVar);  String qualifiedName = aliasVar.getInitialValue().getQualifiedName(); transformation.addAlias(name, qualifiedName); // Bleeding functions already get a BAD_PARAMETERS error, so just // do nothing. // Parameters of the scope function also get a BAD_PARAMETERS // error. } else { // TODO(robbyw): Support using locals for private variables. report(t, n, GOOG_SCOPE_NON_ALIAS_LOCAL, n.getString()); } } } }
 private void findAliases(NodeTraversal t) { Scope scope = t.getScope(); for (Var v : scope.getVarIterable()) { Node n = v.getNode(); int type = n.getType(); Node parent = n.getParent(); if (parent.isVar()) { if (n.hasChildren() && n.getFirstChild().isQualifiedName()) { String name = n.getString(); Var aliasVar = scope.getVar(name); aliases.put(name, aliasVar);  String qualifiedName = aliasVar.getInitialValue().getQualifiedName(); transformation.addAlias(name, qualifiedName); // Bleeding functions already get a BAD_PARAMETERS error, so just // do nothing. // Parameters of the scope function also get a BAD_PARAMETERS // error. } else { // TODO(robbyw): Support using locals for private variables. report(t, n, GOOG_SCOPE_NON_ALIAS_LOCAL, n.getString()); } } } }
 public void addValue(double value) { sumImpl.increment(value); sumsqImpl.increment(value); minImpl.increment(value); maxImpl.increment(value); sumLogImpl.increment(value); secondMoment.increment(value); // If mean, variance or geomean have been overridden, // need to increment these if (!(meanImpl instanceof Mean)) { meanImpl.increment(value); } if (!(varianceImpl instanceof Variance)) { varianceImpl.increment(value); } if (!(geoMeanImpl instanceof GeometricMean)) { geoMeanImpl.increment(value); } n++; }
 public void addValue(double value) { sumImpl.increment(value); sumsqImpl.increment(value); minImpl.increment(value); maxImpl.increment(value); sumLogImpl.increment(value); secondMoment.increment(value); // If mean, variance or geomean have been overridden, // need to increment these if (!(meanImpl instanceof Mean)) { meanImpl.increment(value); } if (!(varianceImpl instanceof Variance)) { varianceImpl.increment(value); } if (!(geoMeanImpl instanceof GeometricMean)) { geoMeanImpl.increment(value); } n++; }
 public void addValue(double value) { sumImpl.increment(value); sumsqImpl.increment(value); minImpl.increment(value); maxImpl.increment(value); sumLogImpl.increment(value); secondMoment.increment(value); // If mean, variance or geomean have been overridden, // need to increment these if (!(meanImpl instanceof Mean)) { meanImpl.increment(value); } if (!(varianceImpl instanceof Variance)) { varianceImpl.increment(value); } if (!(geoMeanImpl instanceof GeometricMean)) { geoMeanImpl.increment(value); } n++; }
 public Vector2D intersection(final SubLine subLine, final boolean includeEndPoints) {  // retrieve the underlying lines Line line1 = (Line) getHyperplane(); Line line2 = (Line) subLine.getHyperplane();  // compute the intersection on infinite line Vector2D v2D = line1.intersection(line2);  // check location of point with respect to first sub-line Location loc1 = getRemainingRegion().checkPoint(line1.toSubSpace(v2D));  // check location of point with respect to second sub-line Location loc2 = subLine.getRemainingRegion().checkPoint(line2.toSubSpace(v2D));  if (includeEndPoints) { return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v2D : null; } else { return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v2D : null; }  }
 public Vector2D intersection(final SubLine subLine, final boolean includeEndPoints) {  // retrieve the underlying lines Line line1 = (Line) getHyperplane(); Line line2 = (Line) subLine.getHyperplane();  // compute the intersection on infinite line Vector2D v2D = line1.intersection(line2);  // check location of point with respect to first sub-line Location loc1 = getRemainingRegion().checkPoint(line1.toSubSpace(v2D));  // check location of point with respect to second sub-line Location loc2 = subLine.getRemainingRegion().checkPoint(line2.toSubSpace(v2D));  if (includeEndPoints) { return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v2D : null; } else { return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v2D : null; }  }
 public Vector3D intersection(final SubLine subLine, final boolean includeEndPoints) {  // compute the intersection on infinite line Vector3D v1D = line.intersection(subLine.line);  // check location of point with respect to first sub-line Location loc1 = remainingRegion.checkPoint(line.toSubSpace(v1D));  // check location of point with respect to second sub-line Location loc2 = subLine.remainingRegion.checkPoint(subLine.line.toSubSpace(v1D));  if (includeEndPoints) { return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v1D : null; } else { return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v1D : null; }  }
 public Vector3D intersection(final SubLine subLine, final boolean includeEndPoints) {  // compute the intersection on infinite line Vector3D v1D = line.intersection(subLine.line);  // check location of point with respect to first sub-line Location loc1 = remainingRegion.checkPoint(line.toSubSpace(v1D));  // check location of point with respect to second sub-line Location loc2 = subLine.remainingRegion.checkPoint(subLine.line.toSubSpace(v1D));  if (includeEndPoints) { return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v1D : null; } else { return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v1D : null; }  }
 public double[][] getCovariances(EstimationProblem problem) throws EstimationException {  // set up the jacobian updateJacobian();  // compute transpose(J).J, avoiding building big intermediate matrices final int rows = problem.getMeasurements().length; final int cols = problem.getAllParameters().length; final int max  = cols * rows; double[][] jTj = new double[cols][cols]; for (int i = 0; i < cols; ++i) { for (int j = i; j < cols; ++j) { double sum = 0; for (int k = 0; k < max; k += cols) { sum += jacobian[k + i] * jacobian[k + j]; } jTj[i][j] = sum; jTj[j][i] = sum; } }  try { // compute the covariances matrix return new RealMatrixImpl(jTj).inverse().getData(); } catch (InvalidMatrixException ime) { throw new EstimationException("unable to compute covariances: singular problem", new Object[0]); }  }
 public double[] guessParametersErrors(EstimationProblem problem) throws EstimationException { int m = problem.getMeasurements().length; int p = problem.getAllParameters().length; if (m <= p) { throw new EstimationException("no degrees of freedom ({0} measurements, {1} parameters)", new Object[] { new Integer(m), new Integer(p)}); } double[] errors = new double[problem.getAllParameters().length]; final double c = Math.sqrt(getChiSquare(problem) / (m - p)); double[][] covar = getCovariances(problem); for (int i = 0; i < errors.length; ++i) { errors[i] = Math.sqrt(covar[i][i]) * c; } return errors; }
 public double[] guessParametersErrors(EstimationProblem problem) throws EstimationException { int m = problem.getMeasurements().length; int p = problem.getAllParameters().length; if (m <= p) { throw new EstimationException("no degrees of freedom ({0} measurements, {1} parameters)", new Object[] { new Integer(m), new Integer(p)}); } double[] errors = new double[problem.getAllParameters().length]; final double c = Math.sqrt(getChiSquare(problem) / (m - p)); double[][] covar = getCovariances(problem); for (int i = 0; i < errors.length; ++i) { errors[i] = Math.sqrt(covar[i][i]) * c; } return errors; }
 void tryMinimizeExits(Node n, int exitType, String labelName) {  // Just an 'exit'. if (matchingExitNode(n, exitType, labelName)) { NodeUtil.removeChild(n.getParent(), n); compiler.reportCodeChange(); return; }  // Just an 'if'. if (n.isIf()) { Node ifBlock = n.getFirstChild().getNext(); tryMinimizeExits(ifBlock, exitType, labelName); Node elseBlock = ifBlock.getNext(); if (elseBlock != null) { tryMinimizeExits(elseBlock, exitType, labelName); } return; }  // Just a 'try/catch/finally'. if (n.isTry()) { Node tryBlock = n.getFirstChild(); tryMinimizeExits(tryBlock, exitType, labelName); Node allCatchNodes = NodeUtil.getCatchBlock(n); if (NodeUtil.hasCatchHandler(allCatchNodes)) { Preconditions.checkState(allCatchNodes.hasOneChild()); Node catchNode = allCatchNodes.getFirstChild(); Node catchCodeBlock = catchNode.getLastChild(); tryMinimizeExits(catchCodeBlock, exitType, labelName); } /* Don't try to minimize the exits of finally blocks, as this * can cause problems if it changes the completion type of the finally * block. See ECMA 262 Sections 8.9 & 12.14 */ if (NodeUtil.hasFinally(n)) { Node finallyBlock = n.getLastChild(); tryMinimizeExits(finallyBlock, exitType, labelName); } }  // Just a 'label'. if (n.isLabel()) { Node labelBlock = n.getLastChild(); tryMinimizeExits(labelBlock, exitType, labelName); }  // TODO(johnlenz): The last case of SWITCH statement?  // The rest assumes a block with at least one child, bail on anything else. if (!n.isBlock() || n.getLastChild() == null) { return; }  // Multiple if-exits can be converted in a single pass. // Convert "if (blah) break;  if (blah2) break; other_stmt;" to // become "if (blah); else { if (blah2); else { other_stmt; } }" // which will get converted to "if (!blah && !blah2) { other_stmt; }". for (Node c : n.children()) {  // An 'if' block to process below. if (c.isIf()) { Node ifTree = c; Node trueBlock, falseBlock;  // First, the true condition block. trueBlock = ifTree.getFirstChild().getNext(); falseBlock = trueBlock.getNext(); tryMinimizeIfBlockExits(trueBlock, falseBlock, ifTree, exitType, labelName);  // Now the else block. // The if blocks may have changed, get them again. trueBlock = ifTree.getFirstChild().getNext(); falseBlock = trueBlock.getNext(); if (falseBlock != null) { tryMinimizeIfBlockExits(falseBlock, trueBlock, ifTree, exitType, labelName); } }  if (c == n.getLastChild()) { break; } }  // Now try to minimize the exits of the last child, if it is removed // look at what has become the last child. for (Node c = n.getLastChild(); c != null; c = n.getLastChild()) { tryMinimizeExits(c, exitType, labelName); // If the node is still the last child, we are done. if (c == n.getLastChild()) { break; } } }
 public Complex tan() { if (isNaN) { return NaN; }  double real2 = 2.0 * real; double imaginary2 = 2.0 * imaginary; double d = FastMath.cos(real2) + FastMath.cosh(imaginary2);  return createComplex(FastMath.sin(real2) / d, FastMath.sinh(imaginary2) / d); }
 public Complex tan() { if (isNaN) { return NaN; }  double real2 = 2.0 * real; double imaginary2 = 2.0 * imaginary; double d = FastMath.cos(real2) + FastMath.cosh(imaginary2);  return createComplex(FastMath.sin(real2) / d, FastMath.sinh(imaginary2) / d); }
 public Complex tanh() { if (isNaN) { return NaN; } double real2 = 2.0 * real; double imaginary2 = 2.0 * imaginary; double d = FastMath.cosh(real2) + FastMath.cos(imaginary2);  return createComplex(FastMath.sinh(real2) / d, FastMath.sin(imaginary2) / d); }
 public Complex tanh() { if (isNaN) { return NaN; } double real2 = 2.0 * real; double imaginary2 = 2.0 * imaginary; double d = FastMath.cosh(real2) + FastMath.cos(imaginary2);  return createComplex(FastMath.sinh(real2) / d, FastMath.sin(imaginary2) / d); }
 public OngoingInjecter filterCandidate(final Collection<Object> mocks, final Field field, final Object fieldInstance) { if(mocks.size() == 1) { final Object matchingMock = mocks.iterator().next();  return new OngoingInjecter() { public boolean thenInject() { try { new FieldSetter(fieldInstance, field).set(matchingMock); } catch (Exception e) { throw new MockitoException("Problems injecting dependency in " + field.getName(), e); } return true; } }; }  return new OngoingInjecter() { public boolean thenInject() { return false; } };  }
 static boolean evaluatesToLocalValue(Node value, Predicate<Node> locals) { switch (value.getType()) { case Token.ASSIGN: // A result that is aliased by a non-local name, is the effectively the // same as returning a non-local name, but this doesn't matter if the // value is immutable. return NodeUtil.isImmutableValue(value.getLastChild()) || (locals.apply(value) && evaluatesToLocalValue(value.getLastChild(), locals)); case Token.COMMA: return evaluatesToLocalValue(value.getLastChild(), locals); case Token.AND: case Token.OR: return evaluatesToLocalValue(value.getFirstChild(), locals) && evaluatesToLocalValue(value.getLastChild(), locals); case Token.HOOK: return evaluatesToLocalValue(value.getFirstChild().getNext(), locals) && evaluatesToLocalValue(value.getLastChild(), locals); case Token.INC: case Token.DEC: if (value.getBooleanProp(Node.INCRDECR_PROP)) { return evaluatesToLocalValue(value.getFirstChild(), locals); } else { return true; } case Token.THIS: return locals.apply(value); case Token.NAME: return isImmutableValue(value) || locals.apply(value); case Token.GETELEM: case Token.GETPROP: // There is no information about the locality of object properties. return locals.apply(value); case Token.CALL: return callHasLocalResult(value) || isToStringMethodCall(value) || locals.apply(value); case Token.NEW: return newHasLocalResult(value) || locals.apply(value); case Token.FUNCTION: case Token.REGEXP: case Token.ARRAYLIT: case Token.OBJECTLIT: // Literals objects with non-literal children are allowed. return true; case Token.IN: // TODO(johnlenz): should IN operator be included in #isSimpleOperator? return true; default: // Other op force a local value: //  x = '' + g (x is now an local string) //  x -= g (x is now an local number) if (isAssignmentOp(value) || isSimpleOperator(value) || isImmutableValue(value)) { return true; }  throw new IllegalStateException( "Unexpected expression node" + value + "\n parent:" + value.getParent()); } }
 static boolean isBooleanResultHelper(Node n) { switch (n.getType()) { // Primitives case Token.TRUE: case Token.FALSE: // Comparisons case Token.EQ: case Token.NE: case Token.SHEQ: case Token.SHNE: case Token.LT: case Token.GT: case Token.LE: case Token.GE: // Queryies case Token.IN: case Token.INSTANCEOF: // Inversion case Token.NOT: // delete operator returns a boolean. return true; default: return false; } }
 static boolean isBooleanResultHelper(Node n) { switch (n.getType()) { // Primitives case Token.TRUE: case Token.FALSE: // Comparisons case Token.EQ: case Token.NE: case Token.SHEQ: case Token.SHNE: case Token.LT: case Token.GT: case Token.LE: case Token.GE: // Queryies case Token.IN: case Token.INSTANCEOF: // Inversion case Token.NOT: // delete operator returns a boolean. return true; default: return false; } }
 static String strEscape(String s, char quote, String doublequoteEscape, String singlequoteEscape, String backslashEscape, CharsetEncoder outputCharsetEncoder) { StringBuilder sb = new StringBuilder(s.length() + 2); sb.append(quote); for (int i = 0; i < s.length(); i++) { char c = s.charAt(i); switch (c) { case '\0': sb.append("\\0"); break; case '\n': sb.append("\\n"); break; case '\r': sb.append("\\r"); break; case '\t': sb.append("\\t"); break; case '\\': sb.append(backslashEscape); break; case '\"': sb.append(doublequoteEscape); break; case '\'': sb.append(singlequoteEscape); break; case '>':                       // Break --> into --\> or ]]> into ]]\> if (i >= 2 && ((s.charAt(i - 1) == '-' && s.charAt(i - 2) == '-') || (s.charAt(i - 1) == ']' && s.charAt(i - 2) == ']'))) { sb.append("\\>"); } else { sb.append(c); } break; case '<': // Break </script into <\/script final String END_SCRIPT = "/script";  // Break <!-- into <\!-- final String START_COMMENT = "!--";  if (s.regionMatches(true, i + 1, END_SCRIPT, 0, END_SCRIPT.length())) { sb.append("<\\"); } else if (s.regionMatches(false, i + 1, START_COMMENT, 0, START_COMMENT.length())) { sb.append("<\\"); } else { sb.append(c); } break; default: // If we're given an outputCharsetEncoder, then check if the //  character can be represented in this character set. if (outputCharsetEncoder != null) { if (outputCharsetEncoder.canEncode(c)) { sb.append(c); } else { // Unicode-escape the character. appendHexJavaScriptRepresentation(sb, c); } } else { // No charsetEncoder provided - pass straight latin characters // through, and escape the rest.  Doing the explicit character // check is measurably faster than using the CharsetEncoder. if (c > 0x1f && c <= 0x7f) { sb.append(c); } else { // Other characters can be misinterpreted by some js parsers, // or perhaps mangled by proxies along the way, // so we play it safe and unicode escape them. appendHexJavaScriptRepresentation(sb, c); } } } } sb.append(quote); return sb.toString(); }
 private static PeriodFormatter toFormatter(List<Object> elementPairs, boolean notPrinter, boolean notParser) { if (notPrinter && notParser) { throw new IllegalStateException("Builder has created neither a printer nor a parser"); } int size = elementPairs.size(); if (size >= 2 && elementPairs.get(0) instanceof Separator) { Separator sep = (Separator) elementPairs.get(0); PeriodFormatter f = toFormatter(elementPairs.subList(2, size), notPrinter, notParser); sep = sep.finish(f.getPrinter(), f.getParser()); return new PeriodFormatter(sep, sep); } Object[] comp = createComposite(elementPairs); if (notPrinter) { return new PeriodFormatter(null, (PeriodParser) comp[1]); } else if (notParser) { return new PeriodFormatter((PeriodPrinter) comp[0], null); } else { return new PeriodFormatter((PeriodPrinter) comp[0], (PeriodParser) comp[1]); } }
 private JSType getDeclaredType(String sourceName, JSDocInfo info, Node lValue, @Nullable Node rValue) { if (info != null && info.hasType()) { return getDeclaredTypeInAnnotation(sourceName, lValue, info); } else if (rValue != null && rValue.isFunction() && shouldUseFunctionLiteralType( JSType.toMaybeFunctionType(rValue.getJSType()), info, lValue)) { return rValue.getJSType(); } else if (info != null) { if (info.hasEnumParameterType()) { if (rValue != null && rValue.isObjectLit()) { return rValue.getJSType(); } else { return createEnumTypeFromNodes( rValue, lValue.getQualifiedName(), info, lValue); } } else if (info.isConstructor() || info.isInterface()) { return createFunctionTypeFromNodes( rValue, lValue.getQualifiedName(), info, lValue); } else { // Check if this is constant, and if it has a known type. if (info.isConstant()) { JSType knownType = null; if (rValue != null) { if (rValue.getJSType() != null && !rValue.getJSType().isUnknownType()) { // If rValue has a type-cast, we use the type in the type-cast. // If rValue's type was already computed during scope creation, // then we can safely use that. return rValue.getJSType(); } else if (rValue.isOr()) { // Check for a very specific JS idiom: // var x = x || TYPE; // This is used by Closure's base namespace for esoteric // reasons. Node firstClause = rValue.getFirstChild(); Node secondClause = firstClause.getNext(); boolean namesMatch = firstClause.isName() && lValue.isName() && firstClause.getString().equals(lValue.getString()); if (namesMatch && secondClause.getJSType() != null && !secondClause.getJSType().isUnknownType()) { return secondClause.getJSType(); } } } } } }  return getDeclaredTypeInAnnotation(sourceName, lValue, info); }
 public static boolean equal(GeneralPath p1, GeneralPath p2) { if (p1 == null) { return (p2 == null); } if (p2 == null) { return false; } if (p1.getWindingRule() != p2.getWindingRule()) { return false; } PathIterator iterator1 = p1.getPathIterator(null); PathIterator iterator2 = p1.getPathIterator(null); double[] d1 = new double[6]; double[] d2 = new double[6]; boolean done = iterator1.isDone() && iterator2.isDone(); while (!done) { if (iterator1.isDone() != iterator2.isDone()) { return false; } int seg1 = iterator1.currentSegment(d1); int seg2 = iterator2.currentSegment(d2); if (seg1 != seg2) { return false; } if (!Arrays.equals(d1, d2)) { return false; } iterator1.next(); iterator2.next(); done = iterator1.isDone() && iterator2.isDone(); } return true; }
 public boolean isSupportUpperBoundInclusive() { return false; }
 public boolean isSupportLowerBoundInclusive() { return true; }
 private void attachLiteralTypes(NodeTraversal t, Node n) { switch (n.getType()) { case Token.NULL: n.setJSType(getNativeType(NULL_TYPE)); break;  case Token.VOID: n.setJSType(getNativeType(VOID_TYPE)); break;  case Token.STRING: // Defer keys to the Token.OBJECTLIT case if (!NodeUtil.isObjectLitKey(n, n.getParent())) { n.setJSType(getNativeType(STRING_TYPE)); } break;  case Token.NUMBER: n.setJSType(getNativeType(NUMBER_TYPE)); break;  case Token.TRUE: case Token.FALSE: n.setJSType(getNativeType(BOOLEAN_TYPE)); break;  case Token.REGEXP: n.setJSType(getNativeType(REGEXP_TYPE)); break;  case Token.OBJECTLIT: defineObjectLiteral(n); break;  // NOTE(nicksantos): If we ever support Array tuples, // we will need to put ARRAYLIT here as well. } }
 public double cumulativeProbability(double x) throws MathException { return 0.5 * (1.0 + Erf.erf((x - mean) / (standardDeviation * Math.sqrt(2.0)))); }
 public double cumulativeProbability(double x) throws MathException { return 0.5 * (1.0 + Erf.erf((x - mean) / (standardDeviation * Math.sqrt(2.0)))); }
 public RealMatrix getU() throws InvalidMatrixException {  if (cachedU == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[m][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { // compute W = B.E.S^(-1) where E is the eigenvectors matrix final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; }  for (int i = p; i < m; ++i) { wData[i] = new double[p]; } cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(wData)); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, m - 1, 0, p - 1); cachedU = transformer.getU().multiply(e); }  }  // return the cached matrix return cachedU;  }
 public RealMatrix getU() throws InvalidMatrixException {  if (cachedU == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[m][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { // compute W = B.E.S^(-1) where E is the eigenvectors matrix final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; }  for (int i = p; i < m; ++i) { wData[i] = new double[p]; } cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(wData)); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, m - 1, 0, p - 1); cachedU = transformer.getU().multiply(e); }  }  // return the cached matrix return cachedU;  }
 public RealMatrix getU() throws InvalidMatrixException {  if (cachedU == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[m][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { // compute W = B.E.S^(-1) where E is the eigenvectors matrix final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; }  for (int i = p; i < m; ++i) { wData[i] = new double[p]; } cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(wData)); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, m - 1, 0, p - 1); cachedU = transformer.getU().multiply(e); }  }  // return the cached matrix return cachedU;  }
 public RealMatrix getU() throws InvalidMatrixException {  if (cachedU == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[m][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { // compute W = B.E.S^(-1) where E is the eigenvectors matrix final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; }  for (int i = p; i < m; ++i) { wData[i] = new double[p]; } cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(wData)); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, m - 1, 0, p - 1); cachedU = transformer.getU().multiply(e); }  }  // return the cached matrix return cachedU;  }
 public RealMatrix getV() throws InvalidMatrixException {  if (cachedV == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, n - 1, 0, p - 1); cachedV = transformer.getV().multiply(e); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal // compute W = Bt.E.S^(-1) where E is the eigenvectors matrix final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[n][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; } for (int i = p; i < n; ++i) { wData[i] = new double[p]; } cachedV = transformer.getV().multiply(MatrixUtils.createRealMatrix(wData)); }  }  // return the cached matrix return cachedV;  }
 public RealMatrix getV() throws InvalidMatrixException {  if (cachedV == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, n - 1, 0, p - 1); cachedV = transformer.getV().multiply(e); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal // compute W = Bt.E.S^(-1) where E is the eigenvectors matrix final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[n][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; } for (int i = p; i < n; ++i) { wData[i] = new double[p]; } cachedV = transformer.getV().multiply(MatrixUtils.createRealMatrix(wData)); }  }  // return the cached matrix return cachedV;  }
 public RealMatrix getV() throws InvalidMatrixException {  if (cachedV == null) {  final int p = singularValues.length; if (m >= n) { // the tridiagonal matrix is Bt.B, where B is upper bidiagonal final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, n - 1, 0, p - 1); cachedV = transformer.getV().multiply(e); } else { // the tridiagonal matrix is B.Bt, where B is lower bidiagonal // compute W = Bt.E.S^(-1) where E is the eigenvectors matrix final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1); final double[][] eData = e.getData(); final double[][] wData = new double[n][p]; double[] ei1 = eData[0]; for (int i = 0; i < p - 1; ++i) { final double mi = mainBidiagonal[i]; final double[] ei0 = ei1; final double[] wi  = wData[i]; ei1 = eData[i + 1]; final double si = secondaryBidiagonal[i]; for (int j = 0; j < p; ++j) { wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j]; } } for (int j = 0; j < p; ++j) { wData[p - 1][j] = ei1[j] * mainBidiagonal[p - 1] / singularValues[j]; } for (int i = p; i < n; ++i) { wData[i] = new double[p]; } cachedV = transformer.getV().multiply(MatrixUtils.createRealMatrix(wData)); }  }  // return the cached matrix return cachedV;  }
 private String formatMethodCall() { return invocation.getMethod().getName() + "()"; }
 public void smartNullPointerException(Location location) { throw new SmartNullPointerException(join( "You have a NullPointerException here:", new Location(), "Because this method was *not* stubbed correctly:", location, "" )); }
 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { if (new ObjectMethodsGuru().isToString(method)) { return "SmartNull returned by unstubbed " + formatMethodCall()  + " method on mock"; }  new Reporter().smartNullPointerException(location); return null; }
 void addNumber(double x) { // This is not pretty printing. This is to prevent misparsing of x- -4 as // x--4 (which is a syntax error). char prev = getLastChar(); if (x < 0 && prev == '-') { add(" "); }  if ((long) x == x) { long value = (long) x; long mantissa = value; int exp = 0; if (Math.abs(x) >= 100) { while (mantissa / 10 * Math.pow(10, exp + 1) == value) { mantissa /= 10; exp++; } } if (exp > 2) { add(Long.toString(mantissa) + "E" + Integer.toString(exp)); } else { add(Long.toString(value)); } } else { add(String.valueOf(x)); } }
 public Object answer(InvocationOnMock invocation) throws Throwable { GenericMetadataSupport returnTypeGenericMetadata = actualParameterizedType(invocation.getMock()).resolveGenericReturnType(invocation.getMethod());  Class<?> rawType = returnTypeGenericMetadata.rawType(); if (!new MockCreationValidator().isTypeMockable(rawType)) { return delegate.returnValueFor(rawType); }  return getMock(invocation); }
 private Object getMock(InvocationOnMock invocation) throws Throwable { InternalMockHandler<Object> handler = new MockUtil().getMockHandler(invocation.getMock()); InvocationContainerImpl container = (InvocationContainerImpl) handler.getInvocationContainer();  // matches invocation for verification for (StubbedInvocationMatcher stubbedInvocationMatcher : container.getStubbedInvocations()) { if(container.getInvocationForStubbing().matches(stubbedInvocationMatcher.getInvocation())) { return stubbedInvocationMatcher.answer(invocation); } }  // deep stub return recordDeepStubMock(invocation, container); }
 private Object recordDeepStubMock(InvocationOnMock invocation, InvocationContainerImpl container) { Class<?> clz = invocation.getMethod().getReturnType(); final Object mock = org.mockito.Mockito.mock(clz, this);  container.addAnswer(new Answer<Object>() { public Object answer(InvocationOnMock invocation) throws Throwable { return mock; } }, false);  return mock; }
 public static double[] bracket(UnivariateRealFunction function, double initial, double lowerBound, double upperBound, int maximumIterations) throws ConvergenceException, FunctionEvaluationException {  if (function == null) { throw MathRuntimeException.createIllegalArgumentException("function is null"); } if (maximumIterations <= 0)  { throw MathRuntimeException.createIllegalArgumentException( "bad value for maximum iterations number: {0}", maximumIterations); } if (initial < lowerBound || initial > upperBound || lowerBound >= upperBound) { throw MathRuntimeException.createIllegalArgumentException( "invalid bracketing parameters:  lower bound={0},  initial={1}, upper bound={2}", lowerBound, initial, upperBound); } double a = initial; double b = initial; double fa; double fb; int numIterations = 0 ;  do { a = Math.max(a - 1.0, lowerBound); b = Math.min(b + 1.0, upperBound); fa = function.value(a);  fb = function.value(b); numIterations++ ; } while ((fa * fb > 0.0) && (numIterations < maximumIterations) && ((a > lowerBound) || (b < upperBound)));  if (fa * fb >= 0.0 ) { throw new ConvergenceException( "number of iterations={0}, maximum iterations={1}, " + "initial={2}, lower bound={3}, upper bound={4}, final a value={5}, " + "final b value={6}, f(a)={7}, f(b)={8}", numIterations, maximumIterations, initial, lowerBound, upperBound, a, b, fa, fb); }  return new double[]{a, b}; }
 private boolean canBeRedeclared(Node n, Scope s) { if (!NodeUtil.isExprAssign(n)) { return false; } Node assign = n.getFirstChild(); Node lhs = assign.getFirstChild();  if (!lhs.isName()) { return false; }  Var var = s.getVar(lhs.getString()); return var != null && var.getScope() == s && !blacklistedVars.contains(var); }
 private void declareArguments(Node functionNode) { Node astParameters = functionNode.getFirstChild().getNext(); Node body = astParameters.getNext(); FunctionType functionType = (FunctionType) functionNode.getJSType(); if (functionType != null) { Node jsDocParameters = functionType.getParametersNode(); if (jsDocParameters != null) { Node jsDocParameter = jsDocParameters.getFirstChild(); for (Node astParameter : astParameters.children()) { if (jsDocParameter != null) { defineSlot(astParameter, functionNode, jsDocParameter.getJSType(), true); jsDocParameter = jsDocParameter.getNext(); } else { defineSlot(astParameter, functionNode, null, true); } } } } } // end declareArguments
 public static <T> T eq(T value) { return reportMatcher(new Equals(value)).<T>returnNull(); }
 public static <T> T isA(Class<T> clazz) { return reportMatcher(new InstanceOf(clazz)).<T>returnNull(); }
 public static <T> T same(T value) { return reportMatcher(new Same(value)).<T>returnNull(); }
 protected UnivariatePointValuePair doOptimize() { final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final double lo = getMin(); final double mid = getStartValue(); final double hi = getMax();  // Optional additional convergence criteria. final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();  double a; double b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(x); if (!isMinim) { fx = -fx; } double fv = fx; double fw = fx;  UnivariatePointValuePair previous = null; UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx); // Best point encountered so far (which is the initial guess).  int iter = 0; while (true) { final double m = 0.5 * (a + b); final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold; final double tol2 = 2 * tol1;  // Default stopping criterion. final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a); if (!stop) { double p = 0; double q = 0; double r = 0; double u = 0;  if (FastMath.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (FastMath.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(u); if (!isMinim) { fu = -fu; }  // User-defined convergence checker. previous = current; current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);  if (checker != null) { if (checker.converged(iter, previous, current)) { return best(current, previous, isMinim); } }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || Precision.equals(w, x)) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) { v = u; fv = fu; } } } else { // Default termination (Brent's criterion). return best(current, previous, isMinim); } ++iter; } }
 protected UnivariatePointValuePair doOptimize() { final boolean isMinim = getGoalType() == GoalType.MINIMIZE; final double lo = getMin(); final double mid = getStartValue(); final double hi = getMax();  // Optional additional convergence criteria. final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();  double a; double b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(x); if (!isMinim) { fx = -fx; } double fv = fx; double fw = fx;  UnivariatePointValuePair previous = null; UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx); // Best point encountered so far (which is the initial guess).  int iter = 0; while (true) { final double m = 0.5 * (a + b); final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold; final double tol2 = 2 * tol1;  // Default stopping criterion. final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a); if (!stop) { double p = 0; double q = 0; double r = 0; double u = 0;  if (FastMath.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (FastMath.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(u); if (!isMinim) { fu = -fu; }  // User-defined convergence checker. previous = current; current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);  if (checker != null) { if (checker.converged(iter, previous, current)) { return best(current, previous, isMinim); } }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || Precision.equals(w, x)) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) { v = u; fv = fu; } } } else { // Default termination (Brent's criterion). return best(current, previous, isMinim); } ++iter; } }
 public JSType caseObjectType(ObjectType type) { if (value.equals("function")) { JSType ctorType = getNativeType(U2U_CONSTRUCTOR_TYPE); return resultEqualsValue && ctorType.isSubtype(type) ? ctorType : null; // Objects are restricted to "Function", subtypes are left // Only filter out subtypes of "function" } return matchesExpectation("object") ? type : null; }
 public boolean equals(Object other) { boolean ret;  if (this == other) { ret = true; } else if (other == null) { ret = false; } else  { try { Complex rhs = (Complex)other; if (rhs.isNaN()) { ret = this.isNaN(); } else { ret = (Double.doubleToRawLongBits(real) == Double.doubleToRawLongBits(rhs.getReal())) && (Double.doubleToRawLongBits(imaginary) == Double.doubleToRawLongBits(rhs.getImaginary())); } } catch (ClassCastException ex) { // ignore exception ret = false; } }  return ret; }
 private static boolean mayThrowException(Node n) { switch (n.getType()) { case Token.CALL: case Token.GETPROP: case Token.GETELEM: case Token.THROW: case Token.NEW: case Token.ASSIGN: case Token.INC: case Token.DEC: return true; case Token.FUNCTION: return false; } for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(c) && mayThrowException(c)) { return true; } } return false; }
 private static boolean mayThrowException(Node n) { switch (n.getType()) { case Token.CALL: case Token.GETPROP: case Token.GETELEM: case Token.THROW: case Token.NEW: case Token.ASSIGN: case Token.INC: case Token.DEC: return true; case Token.FUNCTION: return false; } for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(c) && mayThrowException(c)) { return true; } } return false; }
 @Override public ObjectType getTypeWithProperty(String field, JSType type) { if (!(type instanceof ObjectType)) { if (type.autoboxesTo() != null) { type = type.autoboxesTo(); } else { return null; } }  // Ignore the prototype itself at all times. if ("prototype".equals(field)) { return null; }  // We look up the prototype chain to find the highest place (if any) that // this appears.  This will make references to overriden properties look // like references to the initial property, so they are renamed alike. ObjectType foundType = null; ObjectType objType = ObjectType.cast(type); while (objType != null && objType.getImplicitPrototype() != objType) { if (objType.hasOwnProperty(field)) { foundType = objType; } objType = objType.getImplicitPrototype(); } // If the property does not exist on the referenced type but the original // type is an object type, see if any subtype has the property. // getGreatestSubtypeWithProperty does not guarantee that the property // is defined on the returned type, it just indicates that it might be, // so we have to double check. return foundType; }
 private void handleObjectLit(NodeTraversal t, Node n) { for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { // Maybe STRING, GET, SET  // We should never see a mix of numbers and strings. String name = child.getString(); T type = typeSystem.getType(getScope(), n, name);  Property prop = getProperty(name); if (!prop.scheduleRenaming(child, processProperty(t, prop, type, null))) { // TODO(user): It doesn't look like the user can do much in this // case right now. if (propertiesToErrorFor.containsKey(name)) { compiler.report(JSError.make( t.getSourceName(), child, propertiesToErrorFor.get(name), Warnings.INVALIDATION, name, (type == null ? "null" : type.toString()), n.toString(), "")); } } } }
 public XYDataItem addOrUpdate(Number x, Number y) { if (x == null) { throw new IllegalArgumentException("Null 'x' argument."); }  // if we get to here, we know that duplicate X values are not permitted XYDataItem overwritten = null; int index = indexOf(x); if (index >= 0 && !this.allowDuplicateXValues) { XYDataItem existing = (XYDataItem) this.data.get(index); try { overwritten = (XYDataItem) existing.clone(); } catch (CloneNotSupportedException e) { throw new SeriesException("Couldn't clone XYDataItem!"); } existing.setY(y); } else { // if the series is sorted, the negative index is a result from // Collections.binarySearch() and tells us where to insert the // new item...otherwise it will be just -1 and we should just // append the value to the list... if (this.autoSort) { this.data.add(-index - 1, new XYDataItem(x, y)); } else { this.data.add(new XYDataItem(x, y)); } // check if this addition will exceed the maximum item count... if (getItemCount() > this.maximumItemCount) { this.data.remove(0); } } fireSeriesChanged(); return overwritten; }
 private void computeGenKill(Node n, BitSet gen, BitSet kill, boolean conditional) {  switch (n.getType()) { case Token.SCRIPT: case Token.BLOCK: case Token.FUNCTION: return;  case Token.WHILE: case Token.DO: case Token.IF: computeGenKill(NodeUtil.getConditionExpression(n), gen, kill, conditional); return;  case Token.FOR: if (!NodeUtil.isForIn(n)) { computeGenKill(NodeUtil.getConditionExpression(n), gen, kill, conditional); } else { // for(x in y) {...} Node lhs = n.getFirstChild(); Node rhs = lhs.getNext(); if (NodeUtil.isVar(lhs)) { // for(var x in y) {...} lhs = lhs.getLastChild(); } addToSetIfLocal(lhs, kill); addToSetIfLocal(lhs, gen); computeGenKill(rhs, gen, kill, conditional); } return;  case Token.VAR: for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { if (c.hasChildren()) { computeGenKill(c.getFirstChild(), gen, kill, conditional); if (!conditional) { addToSetIfLocal(c, kill); } } } return;  case Token.AND: case Token.OR: computeGenKill(n.getFirstChild(), gen, kill, conditional); // May short circuit. computeGenKill(n.getLastChild(), gen, kill, true); return;  case Token.HOOK: computeGenKill(n.getFirstChild(), gen, kill, conditional); // Assume both sides are conditional. computeGenKill(n.getFirstChild().getNext(), gen, kill, true); computeGenKill(n.getLastChild(), gen, kill, true); return;  case Token.NAME: if (isArgumentsName(n)) { markAllParametersEscaped(); } else { addToSetIfLocal(n, gen); } return;  default: if (NodeUtil.isAssignmentOp(n) && NodeUtil.isName(n.getFirstChild())) { Node lhs = n.getFirstChild(); if (!conditional) { addToSetIfLocal(lhs, kill); } if (!NodeUtil.isAssign(n)) { // assignments such as a += 1 reads a. addToSetIfLocal(lhs, gen); } computeGenKill(lhs.getNext(), gen, kill, conditional); } else { for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { computeGenKill(c, gen, kill, conditional); } } return; } }
 private void computeGenKill(Node n, BitSet gen, BitSet kill, boolean conditional) {  switch (n.getType()) { case Token.SCRIPT: case Token.BLOCK: case Token.FUNCTION: return;  case Token.WHILE: case Token.DO: case Token.IF: computeGenKill(NodeUtil.getConditionExpression(n), gen, kill, conditional); return;  case Token.FOR: if (!NodeUtil.isForIn(n)) { computeGenKill(NodeUtil.getConditionExpression(n), gen, kill, conditional); } else { // for(x in y) {...} Node lhs = n.getFirstChild(); Node rhs = lhs.getNext(); if (NodeUtil.isVar(lhs)) { // for(var x in y) {...} lhs = lhs.getLastChild(); } addToSetIfLocal(lhs, kill); addToSetIfLocal(lhs, gen); computeGenKill(rhs, gen, kill, conditional); } return;  case Token.VAR: for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { if (c.hasChildren()) { computeGenKill(c.getFirstChild(), gen, kill, conditional); if (!conditional) { addToSetIfLocal(c, kill); } } } return;  case Token.AND: case Token.OR: computeGenKill(n.getFirstChild(), gen, kill, conditional); // May short circuit. computeGenKill(n.getLastChild(), gen, kill, true); return;  case Token.HOOK: computeGenKill(n.getFirstChild(), gen, kill, conditional); // Assume both sides are conditional. computeGenKill(n.getFirstChild().getNext(), gen, kill, true); computeGenKill(n.getLastChild(), gen, kill, true); return;  case Token.NAME: if (isArgumentsName(n)) { markAllParametersEscaped(); } else { addToSetIfLocal(n, gen); } return;  default: if (NodeUtil.isAssignmentOp(n) && NodeUtil.isName(n.getFirstChild())) { Node lhs = n.getFirstChild(); if (!conditional) { addToSetIfLocal(lhs, kill); } if (!NodeUtil.isAssign(n)) { // assignments such as a += 1 reads a. addToSetIfLocal(lhs, gen); } computeGenKill(lhs.getNext(), gen, kill, conditional); } else { for (Node c = n.getFirstChild(); c != null; c = c.getNext()) { computeGenKill(c, gen, kill, conditional); } } return; } }
 public static String join(Object[] array, char separator, int startIndex, int endIndex) { if (array == null) { return null; } int noOfItems = (endIndex - startIndex); if (noOfItems <= 0) { return EMPTY; }  StringBuilder buf = new StringBuilder((array[startIndex] == null ? 16 : array[startIndex].toString().length()) + 1);  for (int i = startIndex; i < endIndex; i++) { if (i > startIndex) { buf.append(separator); } if (array[i] != null) { buf.append(array[i]); } } return buf.toString(); }
 public static String join(Object[] array, String separator, int startIndex, int endIndex) { if (array == null) { return null; } if (separator == null) { separator = EMPTY; }  // endIndex - startIndex > 0:   Len = NofStrings *(len(firstString) + len(separator)) //           (Assuming that all Strings are roughly equally long) int noOfItems = (endIndex - startIndex); if (noOfItems <= 0) { return EMPTY; }  StringBuilder buf = new StringBuilder((array[startIndex] == null ? 16 : array[startIndex].toString().length()) + separator.length());  for (int i = startIndex; i < endIndex; i++) { if (i > startIndex) { buf.append(separator); } if (array[i] != null) { buf.append(array[i]); } } return buf.toString(); }
 protected void drawHorizontalItem(Graphics2D g2, CategoryItemRendererState state, Rectangle2D dataArea, CategoryPlot plot, CategoryAxis domainAxis, ValueAxis rangeAxis, StatisticalCategoryDataset dataset, int row, int column) {  RectangleEdge xAxisLocation = plot.getDomainAxisEdge();  // BAR Y double rectY = domainAxis.getCategoryStart(column, getColumnCount(), dataArea, xAxisLocation);  int seriesCount = getRowCount(); int categoryCount = getColumnCount(); if (seriesCount > 1) { double seriesGap = dataArea.getHeight() * getItemMargin() / (categoryCount * (seriesCount - 1)); rectY = rectY + row * (state.getBarWidth() + seriesGap); } else { rectY = rectY + row * state.getBarWidth(); }  // BAR X Number meanValue = dataset.getMeanValue(row, column);  double value = meanValue.doubleValue(); double base = 0.0; double lclip = getLowerClip(); double uclip = getUpperClip();  if (uclip <= 0.0) {  // cases 1, 2, 3 and 4 if (value >= uclip) { return; // bar is not visible } base = uclip; if (value <= lclip) { value = lclip; } } else if (lclip <= 0.0) { // cases 5, 6, 7 and 8 if (value >= uclip) { value = uclip; } else { if (value <= lclip) { value = lclip; } } } else { // cases 9, 10, 11 and 12 if (value <= lclip) { return; // bar is not visible } base = getLowerClip(); if (value >= uclip) { value = uclip; } }  RectangleEdge yAxisLocation = plot.getRangeAxisEdge(); double transY1 = rangeAxis.valueToJava2D(base, dataArea, yAxisLocation); double transY2 = rangeAxis.valueToJava2D(value, dataArea, yAxisLocation); double rectX = Math.min(transY2, transY1);  double rectHeight = state.getBarWidth(); double rectWidth = Math.abs(transY2 - transY1);  Rectangle2D bar = new Rectangle2D.Double(rectX, rectY, rectWidth, rectHeight); Paint seriesPaint = getItemPaint(row, column); g2.setPaint(seriesPaint); g2.fill(bar); if (isDrawBarOutline() && state.getBarWidth() > 3) { g2.setStroke(getItemStroke(row, column)); g2.setPaint(getItemOutlinePaint(row, column)); g2.draw(bar); }  // standard deviation lines double valueDelta = dataset.getStdDevValue(row, column).doubleValue(); double highVal = rangeAxis.valueToJava2D(meanValue.doubleValue() + valueDelta, dataArea, yAxisLocation); double lowVal = rangeAxis.valueToJava2D(meanValue.doubleValue() - valueDelta, dataArea, yAxisLocation);  if (this.errorIndicatorStroke != null) { g2.setStroke(this.errorIndicatorStroke); } else { g2.setStroke(getItemOutlineStroke(row, column)); } if (this.errorIndicatorPaint != null) { g2.setPaint(this.errorIndicatorPaint); } else { g2.setPaint(getItemOutlinePaint(row, column)); }  Line2D line = null; line = new Line2D.Double(lowVal, rectY + rectHeight / 2.0d, highVal, rectY + rectHeight / 2.0d); g2.draw(line); line = new Line2D.Double(highVal, rectY + rectHeight * 0.25, highVal, rectY + rectHeight * 0.75); g2.draw(line); line = new Line2D.Double(lowVal, rectY + rectHeight * 0.25, lowVal, rectY + rectHeight * 0.75); g2.draw(line);  CategoryItemLabelGenerator generator = getItemLabelGenerator(row, column); if (generator != null && isItemLabelVisible(row, column)) { drawItemLabel(g2, dataset, row, column, plot, generator, bar, (value < 0.0)); }  // add an item entity, if this information is being collected EntityCollection entities = state.getEntityCollection(); if (entities != null) { addItemEntity(entities, dataset, row, column, bar); }  }
 protected void drawHorizontalItem(Graphics2D g2, CategoryItemRendererState state, Rectangle2D dataArea, CategoryPlot plot, CategoryAxis domainAxis, ValueAxis rangeAxis, StatisticalCategoryDataset dataset, int row, int column) {  RectangleEdge xAxisLocation = plot.getDomainAxisEdge();  // BAR Y double rectY = domainAxis.getCategoryStart(column, getColumnCount(), dataArea, xAxisLocation);  int seriesCount = getRowCount(); int categoryCount = getColumnCount(); if (seriesCount > 1) { double seriesGap = dataArea.getHeight() * getItemMargin() / (categoryCount * (seriesCount - 1)); rectY = rectY + row * (state.getBarWidth() + seriesGap); } else { rectY = rectY + row * state.getBarWidth(); }  // BAR X Number meanValue = dataset.getMeanValue(row, column);  double value = meanValue.doubleValue(); double base = 0.0; double lclip = getLowerClip(); double uclip = getUpperClip();  if (uclip <= 0.0) {  // cases 1, 2, 3 and 4 if (value >= uclip) { return; // bar is not visible } base = uclip; if (value <= lclip) { value = lclip; } } else if (lclip <= 0.0) { // cases 5, 6, 7 and 8 if (value >= uclip) { value = uclip; } else { if (value <= lclip) { value = lclip; } } } else { // cases 9, 10, 11 and 12 if (value <= lclip) { return; // bar is not visible } base = getLowerClip(); if (value >= uclip) { value = uclip; } }  RectangleEdge yAxisLocation = plot.getRangeAxisEdge(); double transY1 = rangeAxis.valueToJava2D(base, dataArea, yAxisLocation); double transY2 = rangeAxis.valueToJava2D(value, dataArea, yAxisLocation); double rectX = Math.min(transY2, transY1);  double rectHeight = state.getBarWidth(); double rectWidth = Math.abs(transY2 - transY1);  Rectangle2D bar = new Rectangle2D.Double(rectX, rectY, rectWidth, rectHeight); Paint seriesPaint = getItemPaint(row, column); g2.setPaint(seriesPaint); g2.fill(bar); if (isDrawBarOutline() && state.getBarWidth() > 3) { g2.setStroke(getItemStroke(row, column)); g2.setPaint(getItemOutlinePaint(row, column)); g2.draw(bar); }  // standard deviation lines double valueDelta = dataset.getStdDevValue(row, column).doubleValue(); double highVal = rangeAxis.valueToJava2D(meanValue.doubleValue() + valueDelta, dataArea, yAxisLocation); double lowVal = rangeAxis.valueToJava2D(meanValue.doubleValue() - valueDelta, dataArea, yAxisLocation);  if (this.errorIndicatorStroke != null) { g2.setStroke(this.errorIndicatorStroke); } else { g2.setStroke(getItemOutlineStroke(row, column)); } if (this.errorIndicatorPaint != null) { g2.setPaint(this.errorIndicatorPaint); } else { g2.setPaint(getItemOutlinePaint(row, column)); }  Line2D line = null; line = new Line2D.Double(lowVal, rectY + rectHeight / 2.0d, highVal, rectY + rectHeight / 2.0d); g2.draw(line); line = new Line2D.Double(highVal, rectY + rectHeight * 0.25, highVal, rectY + rectHeight * 0.75); g2.draw(line); line = new Line2D.Double(lowVal, rectY + rectHeight * 0.25, lowVal, rectY + rectHeight * 0.75); g2.draw(line);  CategoryItemLabelGenerator generator = getItemLabelGenerator(row, column); if (generator != null && isItemLabelVisible(row, column)) { drawItemLabel(g2, dataset, row, column, plot, generator, bar, (value < 0.0)); }  // add an item entity, if this information is being collected EntityCollection entities = state.getEntityCollection(); if (entities != null) { addItemEntity(entities, dataset, row, column, bar); }  }
 protected void drawVerticalItem(Graphics2D g2, CategoryItemRendererState state, Rectangle2D dataArea, CategoryPlot plot, CategoryAxis domainAxis, ValueAxis rangeAxis, StatisticalCategoryDataset dataset, int row, int column) {  RectangleEdge xAxisLocation = plot.getDomainAxisEdge();  // BAR X double rectX = domainAxis.getCategoryStart( column, getColumnCount(), dataArea, xAxisLocation );  int seriesCount = getRowCount(); int categoryCount = getColumnCount(); if (seriesCount > 1) { double seriesGap = dataArea.getWidth() * getItemMargin() / (categoryCount * (seriesCount - 1)); rectX = rectX + row * (state.getBarWidth() + seriesGap); } else { rectX = rectX + row * state.getBarWidth(); }  // BAR Y Number meanValue = dataset.getMeanValue(row, column);  double value = meanValue.doubleValue(); double base = 0.0; double lclip = getLowerClip(); double uclip = getUpperClip();  if (uclip <= 0.0) {  // cases 1, 2, 3 and 4 if (value >= uclip) { return; // bar is not visible } base = uclip; if (value <= lclip) { value = lclip; } } else if (lclip <= 0.0) { // cases 5, 6, 7 and 8 if (value >= uclip) { value = uclip; } else { if (value <= lclip) { value = lclip; } } } else { // cases 9, 10, 11 and 12 if (value <= lclip) { return; // bar is not visible } base = getLowerClip(); if (value >= uclip) { value = uclip; } }  RectangleEdge yAxisLocation = plot.getRangeAxisEdge(); double transY1 = rangeAxis.valueToJava2D(base, dataArea, yAxisLocation); double transY2 = rangeAxis.valueToJava2D(value, dataArea, yAxisLocation); double rectY = Math.min(transY2, transY1);  double rectWidth = state.getBarWidth(); double rectHeight = Math.abs(transY2 - transY1);  Rectangle2D bar = new Rectangle2D.Double(rectX, rectY, rectWidth, rectHeight); Paint seriesPaint = getItemPaint(row, column); g2.setPaint(seriesPaint); g2.fill(bar); if (isDrawBarOutline() && state.getBarWidth() > 3) { g2.setStroke(getItemStroke(row, column)); g2.setPaint(getItemOutlinePaint(row, column)); g2.draw(bar); }  // standard deviation lines double valueDelta = dataset.getStdDevValue(row, column).doubleValue(); double highVal = rangeAxis.valueToJava2D(meanValue.doubleValue() + valueDelta, dataArea, yAxisLocation); double lowVal = rangeAxis.valueToJava2D(meanValue.doubleValue() - valueDelta, dataArea, yAxisLocation);  if (this.errorIndicatorStroke != null) { g2.setStroke(this.errorIndicatorStroke); } else { g2.setStroke(getItemOutlineStroke(row, column)); } if (this.errorIndicatorPaint != null) { g2.setPaint(this.errorIndicatorPaint); } else { g2.setPaint(getItemOutlinePaint(row, column)); } Line2D line = null; line = new Line2D.Double(rectX + rectWidth / 2.0d, lowVal, rectX + rectWidth / 2.0d, highVal); g2.draw(line); line = new Line2D.Double(rectX + rectWidth / 2.0d - 5.0d, highVal, rectX + rectWidth / 2.0d + 5.0d, highVal); g2.draw(line); line = new Line2D.Double(rectX + rectWidth / 2.0d - 5.0d, lowVal, rectX + rectWidth / 2.0d + 5.0d, lowVal); g2.draw(line);  CategoryItemLabelGenerator generator = getItemLabelGenerator(row, column); if (generator != null && isItemLabelVisible(row, column)) { drawItemLabel(g2, dataset, row, column, plot, generator, bar, (value < 0.0)); }  // add an item entity, if this information is being collected EntityCollection entities = state.getEntityCollection(); if (entities != null) { addItemEntity(entities, dataset, row, column, bar); } }
 protected void drawVerticalItem(Graphics2D g2, CategoryItemRendererState state, Rectangle2D dataArea, CategoryPlot plot, CategoryAxis domainAxis, ValueAxis rangeAxis, StatisticalCategoryDataset dataset, int row, int column) {  RectangleEdge xAxisLocation = plot.getDomainAxisEdge();  // BAR X double rectX = domainAxis.getCategoryStart( column, getColumnCount(), dataArea, xAxisLocation );  int seriesCount = getRowCount(); int categoryCount = getColumnCount(); if (seriesCount > 1) { double seriesGap = dataArea.getWidth() * getItemMargin() / (categoryCount * (seriesCount - 1)); rectX = rectX + row * (state.getBarWidth() + seriesGap); } else { rectX = rectX + row * state.getBarWidth(); }  // BAR Y Number meanValue = dataset.getMeanValue(row, column);  double value = meanValue.doubleValue(); double base = 0.0; double lclip = getLowerClip(); double uclip = getUpperClip();  if (uclip <= 0.0) {  // cases 1, 2, 3 and 4 if (value >= uclip) { return; // bar is not visible } base = uclip; if (value <= lclip) { value = lclip; } } else if (lclip <= 0.0) { // cases 5, 6, 7 and 8 if (value >= uclip) { value = uclip; } else { if (value <= lclip) { value = lclip; } } } else { // cases 9, 10, 11 and 12 if (value <= lclip) { return; // bar is not visible } base = getLowerClip(); if (value >= uclip) { value = uclip; } }  RectangleEdge yAxisLocation = plot.getRangeAxisEdge(); double transY1 = rangeAxis.valueToJava2D(base, dataArea, yAxisLocation); double transY2 = rangeAxis.valueToJava2D(value, dataArea, yAxisLocation); double rectY = Math.min(transY2, transY1);  double rectWidth = state.getBarWidth(); double rectHeight = Math.abs(transY2 - transY1);  Rectangle2D bar = new Rectangle2D.Double(rectX, rectY, rectWidth, rectHeight); Paint seriesPaint = getItemPaint(row, column); g2.setPaint(seriesPaint); g2.fill(bar); if (isDrawBarOutline() && state.getBarWidth() > 3) { g2.setStroke(getItemStroke(row, column)); g2.setPaint(getItemOutlinePaint(row, column)); g2.draw(bar); }  // standard deviation lines double valueDelta = dataset.getStdDevValue(row, column).doubleValue(); double highVal = rangeAxis.valueToJava2D(meanValue.doubleValue() + valueDelta, dataArea, yAxisLocation); double lowVal = rangeAxis.valueToJava2D(meanValue.doubleValue() - valueDelta, dataArea, yAxisLocation);  if (this.errorIndicatorStroke != null) { g2.setStroke(this.errorIndicatorStroke); } else { g2.setStroke(getItemOutlineStroke(row, column)); } if (this.errorIndicatorPaint != null) { g2.setPaint(this.errorIndicatorPaint); } else { g2.setPaint(getItemOutlinePaint(row, column)); } Line2D line = null; line = new Line2D.Double(rectX + rectWidth / 2.0d, lowVal, rectX + rectWidth / 2.0d, highVal); g2.draw(line); line = new Line2D.Double(rectX + rectWidth / 2.0d - 5.0d, highVal, rectX + rectWidth / 2.0d + 5.0d, highVal); g2.draw(line); line = new Line2D.Double(rectX + rectWidth / 2.0d - 5.0d, lowVal, rectX + rectWidth / 2.0d + 5.0d, lowVal); g2.draw(line);  CategoryItemLabelGenerator generator = getItemLabelGenerator(row, column); if (generator != null && isItemLabelVisible(row, column)) { drawItemLabel(g2, dataset, row, column, plot, generator, bar, (value < 0.0)); }  // add an item entity, if this information is being collected EntityCollection entities = state.getEntityCollection(); if (entities != null) { addItemEntity(entities, dataset, row, column, bar); } }
 private static Map<TypeVariable<?>, Type> getTypeArguments(Class<?> cls, Class<?> toClass, Map<TypeVariable<?>, Type> subtypeVarAssigns) { // make sure they're assignable if (!isAssignable(cls, toClass)) { return null; }  // can't work with primitives if (cls.isPrimitive()) { // both classes are primitives? if (toClass.isPrimitive()) { // dealing with widening here. No type arguments to be // harvested with these two types. return new HashMap<TypeVariable<?>, Type>(); }  // work with wrapper the wrapper class instead of the primitive cls = ClassUtils.primitiveToWrapper(cls); }  // create a copy of the incoming map, or an empty one if it's null HashMap<TypeVariable<?>, Type> typeVarAssigns = subtypeVarAssigns == null ? new HashMap<TypeVariable<?>, Type>() : new HashMap<TypeVariable<?>, Type>(subtypeVarAssigns);  // has target class been reached? if (cls.getTypeParameters().length > 0 || toClass.equals(cls)) { return typeVarAssigns; }  // walk the inheritance hierarchy until the target class is reached return getTypeArguments(getClosestParentType(cls, toClass), toClass, typeVarAssigns); }
 private static boolean isAssignable(Type type, ParameterizedType toParameterizedType, Map<TypeVariable<?>, Type> typeVarAssigns) { if (type == null) { return true; }  // only a null type can be assigned to null type which // would have cause the previous to return true if (toParameterizedType == null) { return false; }  // all types are assignable to themselves if (toParameterizedType.equals(type)) { return true; }  // get the target type's raw type Class<?> toClass = getRawType(toParameterizedType); // get the subject type's type arguments including owner type arguments // and supertype arguments up to and including the target class. Map<TypeVariable<?>, Type> fromTypeVarAssigns = getTypeArguments(type, toClass, null);  // null means the two types are not compatible if (fromTypeVarAssigns == null) { return false; }  // compatible types, but there's no type arguments. this is equivalent // to comparing Map< ?, ? > to Map, and raw types are always assignable // to parameterized types. if (fromTypeVarAssigns.isEmpty()) { return true; }  // get the target type's type arguments including owner type arguments Map<TypeVariable<?>, Type> toTypeVarAssigns = getTypeArguments(toParameterizedType, toClass, typeVarAssigns);  // now to check each type argument for (Map.Entry<TypeVariable<?>, Type> entry : toTypeVarAssigns.entrySet()) { Type toTypeArg = entry.getValue(); Type fromTypeArg = fromTypeVarAssigns.get(entry.getKey());  // parameters must either be absent from the subject type, within // the bounds of the wildcard type, or be an exact match to the // parameters of the target type. if (fromTypeArg != null && !toTypeArg.equals(fromTypeArg) && !(toTypeArg instanceof WildcardType && isAssignable(fromTypeArg, toTypeArg, typeVarAssigns))) { return false; } }  return true; }
 public Line revert() { final Line reverted = new Line(zero, zero.subtract(direction)); return reverted; }
 private static synchronized String getConvertedId(String id) { Map<String, String> map = cZoneIdConversion; if (map == null) { // Backwards compatibility with TimeZone. map = new HashMap<String, String>(); map.put("GMT", "UTC"); map.put("MIT", "Pacific/Apia"); map.put("HST", "Pacific/Honolulu");  // JDK 1.1 compatible map.put("AST", "America/Anchorage"); map.put("PST", "America/Los_Angeles"); map.put("MST", "America/Denver");  // JDK 1.1 compatible map.put("PNT", "America/Phoenix"); map.put("CST", "America/Chicago"); map.put("EST", "America/New_York");  // JDK 1.1 compatible map.put("IET", "America/Indianapolis"); map.put("PRT", "America/Puerto_Rico"); map.put("CNT", "America/St_Johns"); map.put("AGT", "America/Buenos_Aires"); map.put("BET", "America/Sao_Paulo"); map.put("WET", "Europe/London"); map.put("ECT", "Europe/Paris"); map.put("ART", "Africa/Cairo"); map.put("CAT", "Africa/Harare"); map.put("EET", "Europe/Bucharest"); map.put("EAT", "Africa/Addis_Ababa"); map.put("MET", "Asia/Tehran"); map.put("NET", "Asia/Yerevan"); map.put("PLT", "Asia/Karachi"); map.put("IST", "Asia/Calcutta"); map.put("BST", "Asia/Dhaka"); map.put("VST", "Asia/Saigon"); map.put("CTT", "Asia/Shanghai"); map.put("JST", "Asia/Tokyo"); map.put("ACT", "Australia/Darwin"); map.put("AET", "Australia/Sydney"); map.put("SST", "Pacific/Guadalcanal"); map.put("NST", "Pacific/Auckland"); cZoneIdConversion = map; } return map.get(id); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (hoursOffset < -23 || hoursOffset > 23) { throw new IllegalArgumentException("Hours out of range: " + hoursOffset); } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = hoursOffset * 60; if (hoursInMinutes < 0) { minutesOffset = hoursInMinutes - minutesOffset; } else { minutesOffset = hoursInMinutes + minutesOffset; } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public static DateTimeZone forOffsetHoursMinutes(int hoursOffset, int minutesOffset) throws IllegalArgumentException { if (hoursOffset == 0 && minutesOffset == 0) { return DateTimeZone.UTC; } if (hoursOffset < -23 || hoursOffset > 23) { throw new IllegalArgumentException("Hours out of range: " + hoursOffset); } if (minutesOffset < 0 || minutesOffset > 59) { throw new IllegalArgumentException("Minutes out of range: " + minutesOffset); } int offset = 0; try { int hoursInMinutes = hoursOffset * 60; if (hoursInMinutes < 0) { minutesOffset = hoursInMinutes - minutesOffset; } else { minutesOffset = hoursInMinutes + minutesOffset; } offset = FieldUtils.safeMultiply(minutesOffset, DateTimeConstants.MILLIS_PER_MINUTE); } catch (ArithmeticException ex) { throw new IllegalArgumentException("Offset is too large"); } return forOffsetMillis(offset); }
 public BrentOptimizer() { setMaxEvaluations(Integer.MAX_VALUE); setMaximalIterationCount(100); setAbsoluteAccuracy(1E-10); setRelativeAccuracy(1.0e-14); }
 protected double doOptimize() throws MaxIterationsExceededException, FunctionEvaluationException { throw new UnsupportedOperationException(); }
 private double localMin(boolean isMinim, UnivariateRealFunction f, GoalType goalType, double lo, double mid, double hi, double eps, double t) throws MaxIterationsExceededException, FunctionEvaluationException { if (eps <= 0) { throw new NotStrictlyPositiveException(eps); } if (t <= 0) { throw new NotStrictlyPositiveException(t); } double a, b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(f, x); if (goalType == GoalType.MAXIMIZE) { fx = -fx; } double fv = fx; double fw = fx;  int count = 0; while (count < maximalIterationCount) { double m = 0.5 * (a + b); final double tol1 = eps * Math.abs(x) + t; final double tol2 = 2 * tol1;  // Check stopping criterion. if (Math.abs(x - m) > tol2 - 0.5 * (b - a)) { double p = 0; double q = 0; double r = 0; double u = 0;  if (Math.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && Math.abs(p) < Math.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (Math.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(f, u); if (goalType == GoalType.MAXIMIZE) { fu = -fu; }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || w == x) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || v == x || v == w) { v = u; fv = fu; } } } else { // termination setResult(x, (goalType == GoalType.MAXIMIZE) ? -fx : fx, count); return x; } ++count; } throw new MaxIterationsExceededException(maximalIterationCount); }
 private double localMin(boolean isMinim, UnivariateRealFunction f, GoalType goalType, double lo, double mid, double hi, double eps, double t) throws MaxIterationsExceededException, FunctionEvaluationException { if (eps <= 0) { throw new NotStrictlyPositiveException(eps); } if (t <= 0) { throw new NotStrictlyPositiveException(t); } double a, b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(f, x); if (goalType == GoalType.MAXIMIZE) { fx = -fx; } double fv = fx; double fw = fx;  int count = 0; while (count < maximalIterationCount) { double m = 0.5 * (a + b); final double tol1 = eps * Math.abs(x) + t; final double tol2 = 2 * tol1;  // Check stopping criterion. if (Math.abs(x - m) > tol2 - 0.5 * (b - a)) { double p = 0; double q = 0; double r = 0; double u = 0;  if (Math.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && Math.abs(p) < Math.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (Math.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(f, u); if (goalType == GoalType.MAXIMIZE) { fu = -fu; }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || w == x) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || v == x || v == w) { v = u; fv = fu; } } } else { // termination setResult(x, (goalType == GoalType.MAXIMIZE) ? -fx : fx, count); return x; } ++count; } throw new MaxIterationsExceededException(maximalIterationCount); }
 private double localMin(boolean isMinim, UnivariateRealFunction f, GoalType goalType, double lo, double mid, double hi, double eps, double t) throws MaxIterationsExceededException, FunctionEvaluationException { if (eps <= 0) { throw new NotStrictlyPositiveException(eps); } if (t <= 0) { throw new NotStrictlyPositiveException(t); } double a, b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(f, x); if (goalType == GoalType.MAXIMIZE) { fx = -fx; } double fv = fx; double fw = fx;  int count = 0; while (count < maximalIterationCount) { double m = 0.5 * (a + b); final double tol1 = eps * Math.abs(x) + t; final double tol2 = 2 * tol1;  // Check stopping criterion. if (Math.abs(x - m) > tol2 - 0.5 * (b - a)) { double p = 0; double q = 0; double r = 0; double u = 0;  if (Math.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && Math.abs(p) < Math.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (Math.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(f, u); if (goalType == GoalType.MAXIMIZE) { fu = -fu; }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || w == x) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || v == x || v == w) { v = u; fv = fu; } } } else { // termination setResult(x, (goalType == GoalType.MAXIMIZE) ? -fx : fx, count); return x; } ++count; } throw new MaxIterationsExceededException(maximalIterationCount); }
 private double localMin(boolean isMinim, UnivariateRealFunction f, GoalType goalType, double lo, double mid, double hi, double eps, double t) throws MaxIterationsExceededException, FunctionEvaluationException { if (eps <= 0) { throw new NotStrictlyPositiveException(eps); } if (t <= 0) { throw new NotStrictlyPositiveException(t); } double a, b; if (lo < hi) { a = lo; b = hi; } else { a = hi; b = lo; }  double x = mid; double v = x; double w = x; double d = 0; double e = 0; double fx = computeObjectiveValue(f, x); if (goalType == GoalType.MAXIMIZE) { fx = -fx; } double fv = fx; double fw = fx;  int count = 0; while (count < maximalIterationCount) { double m = 0.5 * (a + b); final double tol1 = eps * Math.abs(x) + t; final double tol2 = 2 * tol1;  // Check stopping criterion. if (Math.abs(x - m) > tol2 - 0.5 * (b - a)) { double p = 0; double q = 0; double r = 0; double u = 0;  if (Math.abs(e) > tol1) { // Fit parabola. r = (x - w) * (fx - fv); q = (x - v) * (fx - fw); p = (x - v) * q - (x - w) * r; q = 2 * (q - r);  if (q > 0) { p = -p; } else { q = -q; }  r = e; e = d;  if (p > q * (a - x) && p < q * (b - x) && Math.abs(p) < Math.abs(0.5 * q * r)) { // Parabolic interpolation step. d = p / q; u = x + d;  // f must not be evaluated too close to a or b. if (u - a < tol2 || b - u < tol2) { if (x <= m) { d = tol1; } else { d = -tol1; } } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; } } else { // Golden section step. if (x < m) { e = b - x; } else { e = a - x; } d = GOLDEN_SECTION * e; }  // Update by at least "tol1". if (Math.abs(d) < tol1) { if (d >= 0) { u = x + tol1; } else { u = x - tol1; } } else { u = x + d; }  double fu = computeObjectiveValue(f, u); if (goalType == GoalType.MAXIMIZE) { fu = -fu; }  // Update a, b, v, w and x. if (fu <= fx) { if (u < x) { b = x; } else { a = x; } v = w; fv = fw; w = x; fw = fx; x = u; fx = fu; } else { if (u < x) { a = u; } else { b = u; } if (fu <= fw || w == x) { v = w; fv = fw; w = u; fw = fu; } else if (fu <= fv || v == x || v == w) { v = u; fv = fu; } } } else { // termination setResult(x, (goalType == GoalType.MAXIMIZE) ? -fx : fx, count); return x; } ++count; } throw new MaxIterationsExceededException(maximalIterationCount); }
 public static Vector3D crossProduct(final Vector3D v1, final Vector3D v2) {   // rescale both vectors without losing precision, // to ensure their norm are the same order of magnitude  // we reduce cancellation errors by preconditioning, // we replace v1 by v3 = v1 - rho v2 with rho chosen in order to compute // v3 without loss of precision. See Kahan lecture // "Computing Cross-Products and Rotations in 2- and 3-Dimensional Euclidean Spaces" // available at http://www.cs.berkeley.edu/~wkahan/MathH110/Cross.pdf  // compute rho as an 8 bits approximation of v1.v2 / v2.v2   // compute cross product from v3 and v2 instead of v1 and v2 return new Vector3D(v1.y * v2.z - v1.z * v2.y, v1.z * v2.x - v1.x * v2.z, v1.x * v2.y - v1.y * v2.x);  }
 private void handleBlockComment(Comment comment) { if (comment.getValue().indexOf("/* @") != -1 || comment.getValue().indexOf("\n * @") != -1) { errorReporter.warning( SUSPICIOUS_COMMENT_WARNING, sourceName, comment.getLineno(), "", 0); } }
 public static long binomialCoefficient(final int n, final int k) { if (n < k) { throw new IllegalArgumentException( "must have n >= k for binomial coefficient (n,k)"); } if (n < 0) { throw new IllegalArgumentException( "must have n >= 0 for binomial coefficient (n,k)"); } if ((n == k) || (k == 0)) { return 1; } if ((k == 1) || (k == n - 1)) { return n; } long result = Math.round(binomialCoefficientDouble(n, k)); if (result == Long.MAX_VALUE) { throw new ArithmeticException( "result too large to represent in a long integer"); } // Use symmetry for large k  // We use the formula // (n choose k) = n! / (n-k)! / k! // (n choose k) == ((n-k+1)*...*n) / (1*...*k) // which could be written // (n choose k) == (n-1 choose k-1) * n / k // For n <= 61, the naive implementation cannot overflow. // For n > 61 but n <= 66, the result cannot overflow, // but we must take care not to overflow intermediate values. // We know that (result * i) is divisible by j, // but (result * i) may overflow, so we split j: // Filter out the gcd, d, so j/d and i/d are integer. // result is divisible by (j/d) because (j/d) // is relative prime to (i/d) and is a divisor of // result * (i/d). // For n > 66, a result overflow might occur, so we check // the multiplication, taking care to not overflow // unnecessary. return result; }
 public static double binomialCoefficientDouble(final int n, final int k) {   return Math.floor(Math.exp(binomialCoefficientLog(n, k)) + 0.5); }
 public static double binomialCoefficientLog(final int n, final int k) { if (n < k) { throw new IllegalArgumentException( "must have n >= k for binomial coefficient (n,k)"); } if (n < 0) { throw new IllegalArgumentException( "must have n >= 0 for binomial coefficient (n,k)"); } if ((n == k) || (k == 0)) { return 0; } if ((k == 1) || (k == n - 1)) { return Math.log((double) n); }  /* * For values small enough to do exact integer computation, * return the log of the exact value */  /* * Return the log of binomialCoefficientDouble for values that will not * overflow binomialCoefficientDouble */  /* * Sum logs for values that could overflow */ double logSum = 0;  // n!/k! for (int i = k + 1; i <= n; i++) { logSum += Math.log((double)i); }  // divide by (n-k)! for (int i = 2; i <= n - k; i++) { logSum -= Math.log((double)i); }  return logSum; }
 private void guessAOmega() { // initialize the sums for the linear model between the two integrals double sx2 = 0; double sy2 = 0; double sxy = 0; double sxz = 0; double syz = 0;  double currentX = observations[0].getX(); double currentY = observations[0].getY(); double f2Integral = 0; double fPrime2Integral = 0; final double startX = currentX; for (int i = 1; i < observations.length; ++i) { // one step forward final double previousX = currentX; final double previousY = currentY; currentX = observations[i].getX(); currentY = observations[i].getY();  // update the integrals of f<sup>2</sup> and f'<sup>2</sup> // considering a linear model for f (and therefore constant f') final double dx = currentX - previousX; final double dy = currentY - previousY; final double f2StepIntegral = dx * (previousY * previousY + previousY * currentY + currentY * currentY) / 3; final double fPrime2StepIntegral = dy * dy / dx;  final double x = currentX - startX; f2Integral += f2StepIntegral; fPrime2Integral += fPrime2StepIntegral;  sx2 += x * x; sy2 += f2Integral * f2Integral; sxy += x * f2Integral; sxz += x * fPrime2Integral; syz += f2Integral * fPrime2Integral; }  // compute the amplitude and pulsation coefficients double c1 = sy2 * sxz - sxy * syz; double c2 = sxy * sxz - sx2 * syz; double c3 = sx2 * sy2 - sxy * sxy; if ((c1 / c2 < 0) || (c2 / c3 < 0)) { final int last = observations.length - 1; // Range of the observations, assuming that the // observations are sorted. final double xRange = observations[last].getX() - observations[0].getX(); if (xRange == 0) { throw new ZeroException(); } omega = 2 * Math.PI / xRange;  double yMin = Double.POSITIVE_INFINITY; double yMax = Double.NEGATIVE_INFINITY; for (int i = 1; i < observations.length; ++i) { final double y = observations[i].getY(); if (y < yMin) { yMin = y; } if (y > yMax) { yMax = y; } } a = 0.5 * (yMax - yMin); } else { // In some ill-conditioned cases (cf. MATH-844), the guesser // procedure cannot produce sensible results.  a = FastMath.sqrt(c1 / c2); omega = FastMath.sqrt(c2 / c3); } }
 public static long safeMultiply(long val1, int val2) { switch (val2) { case -1: return -val1; case 0: return 0L; case 1: return val1; } long total = val1 * val2; if (total / val2 != val1) { throw new ArithmeticException("Multiplication overflows a long: " + val1 + " * " + val2); } return total; }
 public RectangularCholeskyDecomposition(RealMatrix matrix, double small) throws NonPositiveDefiniteMatrixException {  final int order = matrix.getRowDimension(); final double[][] c = matrix.getData(); final double[][] b = new double[order][order];  int[] swap  = new int[order]; int[] index = new int[order]; for (int i = 0; i < order; ++i) { index[i] = i; }  int r = 0; for (boolean loop = true; loop;) {  // find maximal diagonal element swap[r] = r; for (int i = r + 1; i < order; ++i) { int ii  = index[i]; int isi = index[swap[i]]; if (c[ii][ii] > c[isi][isi]) { swap[r] = i; } }   // swap elements if (swap[r] != r) { int tmp = index[r]; index[r] = index[swap[r]]; index[swap[r]] = tmp; }  // check diagonal element int ir = index[r]; if (c[ir][ir] < small) {  if (r == 0) { throw new NonPositiveDefiniteMatrixException(c[ir][ir], ir, small); }  // check remaining diagonal elements for (int i = r; i < order; ++i) { if (c[index[i]][index[i]] < -small) { // there is at least one sufficiently negative diagonal element, // the symmetric positive semidefinite matrix is wrong throw new NonPositiveDefiniteMatrixException(c[index[i]][index[i]], i, small); } }  // all remaining diagonal elements are close to zero, we consider we have // found the rank of the symmetric positive semidefinite matrix ++r; loop = false;  } else {  // transform the matrix final double sqrt = FastMath.sqrt(c[ir][ir]); b[r][r] = sqrt; final double inverse  = 1 / sqrt; for (int i = r + 1; i < order; ++i) { final int ii = index[i]; final double e = inverse * c[ii][ir]; b[i][r] = e; c[ii][ii] -= e * e; for (int j = r + 1; j < i; ++j) { final int ij = index[j]; final double f = c[ii][ij] - e * b[j][r]; c[ii][ij] = f; c[ij][ii] = f; } }  // prepare next iteration loop = ++r < order; } }  // build the root matrix rank = r; root = MatrixUtils.createRealMatrix(order, r); for (int i = 0; i < order; ++i) { for (int j = 0; j < r; ++j) { root.setEntry(index[i], j, b[i][j]); } }  }
 public RectangularCholeskyDecomposition(RealMatrix matrix, double small) throws NonPositiveDefiniteMatrixException {  final int order = matrix.getRowDimension(); final double[][] c = matrix.getData(); final double[][] b = new double[order][order];  int[] swap  = new int[order]; int[] index = new int[order]; for (int i = 0; i < order; ++i) { index[i] = i; }  int r = 0; for (boolean loop = true; loop;) {  // find maximal diagonal element swap[r] = r; for (int i = r + 1; i < order; ++i) { int ii  = index[i]; int isi = index[swap[i]]; if (c[ii][ii] > c[isi][isi]) { swap[r] = i; } }   // swap elements if (swap[r] != r) { int tmp = index[r]; index[r] = index[swap[r]]; index[swap[r]] = tmp; }  // check diagonal element int ir = index[r]; if (c[ir][ir] < small) {  if (r == 0) { throw new NonPositiveDefiniteMatrixException(c[ir][ir], ir, small); }  // check remaining diagonal elements for (int i = r; i < order; ++i) { if (c[index[i]][index[i]] < -small) { // there is at least one sufficiently negative diagonal element, // the symmetric positive semidefinite matrix is wrong throw new NonPositiveDefiniteMatrixException(c[index[i]][index[i]], i, small); } }  // all remaining diagonal elements are close to zero, we consider we have // found the rank of the symmetric positive semidefinite matrix ++r; loop = false;  } else {  // transform the matrix final double sqrt = FastMath.sqrt(c[ir][ir]); b[r][r] = sqrt; final double inverse  = 1 / sqrt; for (int i = r + 1; i < order; ++i) { final int ii = index[i]; final double e = inverse * c[ii][ir]; b[i][r] = e; c[ii][ii] -= e * e; for (int j = r + 1; j < i; ++j) { final int ij = index[j]; final double f = c[ii][ij] - e * b[j][r]; c[ii][ij] = f; c[ij][ii] = f; } }  // prepare next iteration loop = ++r < order; } }  // build the root matrix rank = r; root = MatrixUtils.createRealMatrix(order, r); for (int i = 0; i < order; ++i) { for (int j = 0; j < r; ++j) { root.setEntry(index[i], j, b[i][j]); } }  }
 public long adjustOffset(long instant, boolean earlierOrLater) { // a bit messy, but will work in all non-pathological cases  // evaluate 3 hours before and after to work out if anything is happening long instantBefore = convertUTCToLocal(instant - 3 * DateTimeConstants.MILLIS_PER_HOUR); long instantAfter = convertUTCToLocal(instant + 3 * DateTimeConstants.MILLIS_PER_HOUR); if (instantBefore == instantAfter) { return instant;  // not an overlap (less than is a gap, equal is normal case) }  // work out range of instants that have duplicate local times long local = convertUTCToLocal(instant); return convertLocalToUTC(local, false, earlierOrLater ? instantAfter : instantBefore);  // calculate result // currently in later offset // currently in earlier offset }
 public long adjustOffset(long instant, boolean earlierOrLater) { // a bit messy, but will work in all non-pathological cases  // evaluate 3 hours before and after to work out if anything is happening long instantBefore = convertUTCToLocal(instant - 3 * DateTimeConstants.MILLIS_PER_HOUR); long instantAfter = convertUTCToLocal(instant + 3 * DateTimeConstants.MILLIS_PER_HOUR); if (instantBefore == instantAfter) { return instant;  // not an overlap (less than is a gap, equal is normal case) }  // work out range of instants that have duplicate local times long local = convertUTCToLocal(instant); return convertLocalToUTC(local, false, earlierOrLater ? instantAfter : instantBefore);  // calculate result // currently in later offset // currently in earlier offset }
 private void removeUnreferencedFunctionArgs(Scope fnScope) { // Notice that removing unreferenced function args breaks // Function.prototype.length. In advanced mode, we don't really care // about this: we consider "length" the equivalent of reflecting on // the function's lexical source. // // Rather than create a new option for this, we assume that if the user // is removing globals, then it's OK to remove unused function args. // // See http://code.google.com/p/closure-compiler/issues/detail?id=253  Node function = fnScope.getRootNode();  Preconditions.checkState(function.isFunction()); if (NodeUtil.isGetOrSetKey(function.getParent())) { // The parameters object literal setters can not be removed. return; }  Node argList = getFunctionArgList(function); boolean modifyCallers = modifyCallSites && callSiteOptimizer.canModifyCallers(function); if (!modifyCallers) { // Strip unreferenced args off the end of the function declaration. Node lastArg; while ((lastArg = argList.getLastChild()) != null) { Var var = fnScope.getVar(lastArg.getString()); if (!referenced.contains(var)) { argList.removeChild(lastArg); compiler.reportCodeChange(); } else { break; } } } else { callSiteOptimizer.optimize(fnScope, referenced); } }
 private boolean flipIfWarranted(final int n, final int step) { if (1.5 * work[pingPong] < work[4 * (n - 1) + pingPong]) { // flip array int j = 4 * n - 1; for (int i = 0; i < j; i += 4) { for (int k = 0; k < 4; k += step) { final double tmp = work[i + k]; work[i + k] = work[j - k]; work[j - k] = tmp; } j -= 4; } return true; } return false; }
 public boolean equals(Object obj) {  if (obj == this) { return true; } if (!(obj instanceof ShapeList)) { return false; } return super.equals(obj);  }
 public static Locale toLocale(final String str) { if (str == null) { return null; } final int len = str.length(); if (len < 2) { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch0 = str.charAt(0); if (ch0 == '_') { if (len < 3) { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch1 = str.charAt(1); final char ch2 = str.charAt(2); if (!Character.isUpperCase(ch1) || !Character.isUpperCase(ch2)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 3) { return new Locale("", str.substring(1, 3)); } if (len < 5) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(3) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale("", str.substring(1, 3), str.substring(4)); } else { final char ch1 = str.charAt(1); if (!Character.isLowerCase(ch0) || !Character.isLowerCase(ch1)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 2) { return new Locale(str); } if (len < 5) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(2) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } final char ch3 = str.charAt(3); if (ch3 == '_') { return new Locale(str.substring(0, 2), "", str.substring(4)); } final char ch4 = str.charAt(4); if (!Character.isUpperCase(ch3) || !Character.isUpperCase(ch4)) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (len == 5) { return new Locale(str.substring(0, 2), str.substring(3, 5)); } if (len < 7) { throw new IllegalArgumentException("Invalid locale format: " + str); } if (str.charAt(5) != '_') { throw new IllegalArgumentException("Invalid locale format: " + str); } return new Locale(str.substring(0, 2), str.substring(3, 5), str.substring(6)); } }
 protected void registerTypeVariablesOn(Type classType) { if (!(classType instanceof ParameterizedType)) { return; } ParameterizedType parameterizedType = (ParameterizedType) classType; TypeVariable[] typeParameters = ((Class<?>) parameterizedType.getRawType()).getTypeParameters(); Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for (int i = 0; i < actualTypeArguments.length; i++) { TypeVariable typeParameter = typeParameters[i]; Type actualTypeArgument = actualTypeArguments[i];  if (actualTypeArgument instanceof WildcardType) { contextualActualTypeParameters.put(typeParameter, boundsOf((WildcardType) actualTypeArgument)); } else { contextualActualTypeParameters.put(typeParameter, actualTypeArgument); } // logger.log("For '" + parameterizedType + "' found type variable : { '" + typeParameter + "(" + System.identityHashCode(typeParameter) + ")" + "' : '" + actualTypeArgument + "(" + System.identityHashCode(typeParameter) + ")" + "' }"); } }
 private boolean shouldReportThis(Node n, Node parent) { if (assignLhsChild != null) { // Always report a THIS on the left side of an assign. return true; }  // Also report a THIS with a property access. return false; }
 public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {  if (n.getType() == Token.FUNCTION) { // Don't traverse functions that are constructors or have the @this // annotation. JSDocInfo jsDoc = getFunctionJsDocInfo(n); if (jsDoc != null && (jsDoc.isConstructor() || jsDoc.hasThisType())) { return false; }  // Don't traverse functions unless they would normally // be able to have a @this annotation associated with them. e.g., // var a = function() { }; // or // function a() {} // or // a.x = function() {}; }  if (parent != null && parent.getType() == Token.ASSIGN) { Node lhs = parent.getFirstChild(); Node rhs = lhs.getNext();  if (n == lhs) { // Always traverse the left side of the assignment. To handle // nested assignments properly (e.g., (a = this).property = c;), // assignLhsChild should not be overridden. if (assignLhsChild == null) { assignLhsChild = lhs; } } else { // Only traverse the right side if it's not an assignment to a prototype // property or subproperty. if (lhs.getType() == Token.GETPROP) { if (lhs.getLastChild().getString().equals("prototype")) { return false; } String leftName = lhs.getQualifiedName(); if (leftName != null && leftName.contains(".prototype.")) { return false; } } } }  return true; }
 private void visitParameterList(NodeTraversal t, Node call, FunctionType functionType) { Iterator<Node> arguments = call.children().iterator(); arguments.next(); // skip the function name  Iterator<Node> parameters = functionType.getParameters().iterator(); int ordinal = 0; Node parameter = null; Node argument = null; while (arguments.hasNext() && parameters.hasNext()) { // If there are no parameters left in the list, then the while loop // above implies that this must be a var_args function. parameter = parameters.next(); argument = arguments.next(); ordinal++;  validator.expectArgumentMatchesParameter(t, argument, getJSType(argument), getJSType(parameter), call, ordinal); }  int numArgs = call.getChildCount() - 1; int minArgs = functionType.getMinArguments(); int maxArgs = functionType.getMaxArguments(); if (minArgs > numArgs || maxArgs < numArgs) { report(t, call, WRONG_ARGUMENT_COUNT, validator.getReadableJSTypeName(call.getFirstChild(), false), String.valueOf(numArgs), String.valueOf(minArgs), maxArgs != Integer.MAX_VALUE ? " and no more than " + maxArgs + " argument(s)" : ""); } }
 private void visitParameterList(NodeTraversal t, Node call, FunctionType functionType) { Iterator<Node> arguments = call.children().iterator(); arguments.next(); // skip the function name  Iterator<Node> parameters = functionType.getParameters().iterator(); int ordinal = 0; Node parameter = null; Node argument = null; while (arguments.hasNext() && parameters.hasNext()) { // If there are no parameters left in the list, then the while loop // above implies that this must be a var_args function. parameter = parameters.next(); argument = arguments.next(); ordinal++;  validator.expectArgumentMatchesParameter(t, argument, getJSType(argument), getJSType(parameter), call, ordinal); }  int numArgs = call.getChildCount() - 1; int minArgs = functionType.getMinArguments(); int maxArgs = functionType.getMaxArguments(); if (minArgs > numArgs || maxArgs < numArgs) { report(t, call, WRONG_ARGUMENT_COUNT, validator.getReadableJSTypeName(call.getFirstChild(), false), String.valueOf(numArgs), String.valueOf(minArgs), maxArgs != Integer.MAX_VALUE ? " and no more than " + maxArgs + " argument(s)" : ""); } }
 void add(Node n, Context context) { if (!cc.continueProcessing()) { return; }  int type = n.getType(); String opstr = NodeUtil.opToStr(type); int childCount = n.getChildCount(); Node first = n.getFirstChild(); Node last = n.getLastChild();  // Handle all binary operators if (opstr != null && first != last) { Preconditions.checkState( childCount == 2, "Bad binary operator \"%s\": expected 2 arguments but got %s", opstr, childCount); int p = NodeUtil.precedence(type);  // For right-hand-side of operations, only pass context if it's // the IN_FOR_INIT_CLAUSE one. Context rhsContext = getContextForNoInOperator(context);  // Handle associativity. // e.g. if the parse tree is a * (b * c), // we can simply generate a * b * c. if (last.getType() == type && NodeUtil.isAssociative(type)) { addExpr(first, p, context); cc.addOp(opstr, true); addExpr(last, p, rhsContext); } else if (NodeUtil.isAssignmentOp(n) && NodeUtil.isAssignmentOp(last)) { // Assignments are the only right-associative binary operators addExpr(first, p, context); cc.addOp(opstr, true); addExpr(last, p, rhsContext); } else { unrollBinaryOperator(n, type, opstr, context, rhsContext, p, p + 1); } return; }  cc.startSourceMapping(n);  switch (type) { case Token.TRY: { Preconditions.checkState(first.getNext().isBlock() && !first.getNext().hasMoreThanOneChild()); Preconditions.checkState(childCount >= 2 && childCount <= 3);  add("try"); add(first, Context.PRESERVE_BLOCK);  // second child contains the catch block, or nothing if there // isn't a catch block Node catchblock = first.getNext().getFirstChild(); if (catchblock != null) { add(catchblock); }  if (childCount == 3) { add("finally"); add(last, Context.PRESERVE_BLOCK); } break; }  case Token.CATCH: Preconditions.checkState(childCount == 2); add("catch("); add(first); add(")"); add(last, Context.PRESERVE_BLOCK); break;  case Token.THROW: Preconditions.checkState(childCount == 1); add("throw"); add(first);  // Must have a ';' after a throw statement, otherwise safari can't // parse this. cc.endStatement(true); break;  case Token.RETURN: add("return"); if (childCount == 1) { add(first); } else { Preconditions.checkState(childCount == 0); } cc.endStatement(); break;  case Token.VAR: if (first != null) { add("var "); addList(first, false, getContextForNoInOperator(context)); } break;  case Token.LABEL_NAME: Preconditions.checkState(!n.getString().isEmpty()); addIdentifier(n.getString()); break;  case Token.NAME: if (first == null || first.isEmpty()) { addIdentifier(n.getString()); } else { Preconditions.checkState(childCount == 1); addIdentifier(n.getString()); cc.addOp("=", true); if (first.isComma()) { addExpr(first, NodeUtil.precedence(Token.ASSIGN), Context.OTHER); } else { // Add expression, consider nearby code at lowest level of // precedence. addExpr(first, 0, getContextForNoInOperator(context)); } } break;  case Token.ARRAYLIT: add("["); addArrayList(first); add("]"); break;  case Token.PARAM_LIST: add("("); addList(first); add(")"); break;  case Token.COMMA: Preconditions.checkState(childCount == 2); unrollBinaryOperator(n, Token.COMMA, ",", context, getContextForNoInOperator(context), 0, 0); break;  case Token.NUMBER: Preconditions.checkState(childCount == 0); cc.addNumber(n.getDouble()); break;  case Token.TYPEOF: case Token.VOID: case Token.NOT: case Token.BITNOT: case Token.POS: { // All of these unary operators are right-associative Preconditions.checkState(childCount == 1); cc.addOp(NodeUtil.opToStrNoFail(type), false); addExpr(first, NodeUtil.precedence(type), Context.OTHER); break; }  case Token.NEG: { Preconditions.checkState(childCount == 1);  // It's important to our sanity checker that the code // we print produces the same AST as the code we parse back. // NEG is a weird case because Rhino parses "- -2" as "2". if (n.getFirstChild().isNumber()) { cc.addNumber(-n.getFirstChild().getDouble()); } else { cc.addOp(NodeUtil.opToStrNoFail(type), false); addExpr(first, NodeUtil.precedence(type), Context.OTHER); }  break; }  case Token.HOOK: { Preconditions.checkState(childCount == 3); int p = NodeUtil.precedence(type); Context rhsContext = Context.OTHER; addExpr(first, p + 1, context); cc.addOp("?", true); addExpr(first.getNext(), 1, rhsContext); cc.addOp(":", true); addExpr(last, 1, rhsContext); break; }  case Token.REGEXP: if (!first.isString() || !last.isString()) { throw new Error("Expected children to be strings"); }  String regexp = regexpEscape(first.getString(), outputCharsetEncoder);  // I only use one .add because whitespace matters if (childCount == 2) { add(regexp + last.getString()); } else { Preconditions.checkState(childCount == 1); add(regexp); } break;  case Token.FUNCTION: if (n.getClass() != Node.class) { throw new Error("Unexpected Node subclass."); } Preconditions.checkState(childCount == 3); boolean funcNeedsParens = (context == Context.START_OF_EXPR); if (funcNeedsParens) { add("("); }  add("function"); add(first);  add(first.getNext()); add(last, Context.PRESERVE_BLOCK); cc.endFunction(context == Context.STATEMENT);  if (funcNeedsParens) { add(")"); } break;  case Token.GETTER_DEF: case Token.SETTER_DEF: Preconditions.checkState(n.getParent().isObjectLit()); Preconditions.checkState(childCount == 1); Preconditions.checkState(first.isFunction());  // Get methods are unnamed Preconditions.checkState(first.getFirstChild().getString().isEmpty()); if (type == Token.GETTER_DEF) { // Get methods have no parameters. Preconditions.checkState(!first.getChildAtIndex(1).hasChildren()); add("get "); } else { // Set methods have one parameter. Preconditions.checkState(first.getChildAtIndex(1).hasOneChild()); add("set "); }  // The name is on the GET or SET node. String name = n.getString(); Node fn = first; Node parameters = fn.getChildAtIndex(1); Node body = fn.getLastChild();  // Add the property name. if (!n.isQuotedString() && TokenStream.isJSIdentifier(name) && // do not encode literally any non-literal characters that were // Unicode escaped. NodeUtil.isLatin(name)) { add(name); } else { // Determine if the string is a simple number. double d = getSimpleNumber(name); if (!Double.isNaN(d)) { cc.addNumber(d); } else { addJsString(n); } }  add(parameters); add(body, Context.PRESERVE_BLOCK); break;  case Token.SCRIPT: case Token.BLOCK: { if (n.getClass() != Node.class) { throw new Error("Unexpected Node subclass."); } boolean preserveBlock = context == Context.PRESERVE_BLOCK; if (preserveBlock) { cc.beginBlock(); }  boolean preferLineBreaks = type == Token.SCRIPT || (type == Token.BLOCK && !preserveBlock && n.getParent() != null && n.getParent().isScript()); for (Node c = first; c != null; c = c.getNext()) { add(c, Context.STATEMENT);  // VAR doesn't include ';' since it gets used in expressions if (c.isVar()) { cc.endStatement(); }  if (c.isFunction()) { cc.maybeLineBreak(); }  // Prefer to break lines in between top-level statements // because top-level statements are more homogeneous. if (preferLineBreaks) { cc.notePreferredLineBreak(); } } if (preserveBlock) { cc.endBlock(cc.breakAfterBlockFor(n, context == Context.STATEMENT)); } break; }  case Token.FOR: if (childCount == 4) { add("for("); if (first.isVar()) { add(first, Context.IN_FOR_INIT_CLAUSE); } else { addExpr(first, 0, Context.IN_FOR_INIT_CLAUSE); } add(";"); add(first.getNext()); add(";"); add(first.getNext().getNext()); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } else { Preconditions.checkState(childCount == 3); add("for("); add(first); add("in"); add(first.getNext()); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } break;  case Token.DO: Preconditions.checkState(childCount == 2); add("do"); addNonEmptyStatement(first, Context.OTHER, false); add("while("); add(last); add(")"); cc.endStatement(); break;  case Token.WHILE: Preconditions.checkState(childCount == 2); add("while("); add(first); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); break;  case Token.EMPTY: Preconditions.checkState(childCount == 0); break;  case Token.GETPROP: { Preconditions.checkState( childCount == 2, "Bad GETPROP: expected 2 children, but got %s", childCount); Preconditions.checkState( last.isString(), "Bad GETPROP: RHS should be STRING"); boolean needsParens = (first.isNumber()); if (needsParens) { add("("); } addExpr(first, NodeUtil.precedence(type), context); if (needsParens) { add(")"); } if (this.languageMode == LanguageMode.ECMASCRIPT3 && TokenStream.isKeyword(last.getString())) { // Check for ECMASCRIPT3 keywords. add("["); add(last); add("]"); } else { add("."); addIdentifier(last.getString()); } break; }  case Token.GETELEM: Preconditions.checkState( childCount == 2, "Bad GETELEM: expected 2 children but got %s", childCount); addExpr(first, NodeUtil.precedence(type), context); add("["); add(first.getNext()); add("]"); break;  case Token.WITH: Preconditions.checkState(childCount == 2); add("with("); add(first); add(")"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); break;  case Token.INC: case Token.DEC: { Preconditions.checkState(childCount == 1); String o = type == Token.INC ? "++" : "--"; int postProp = n.getIntProp(Node.INCRDECR_PROP); // A non-zero post-prop value indicates a post inc/dec, default of zero // is a pre-inc/dec. if (postProp != 0) { addExpr(first, NodeUtil.precedence(type), context); cc.addOp(o, false); } else { cc.addOp(o, false); add(first); } break; }  case Token.CALL: // We have two special cases here: // 1) If the left hand side of the call is a direct reference to eval, // then it must have a DIRECT_EVAL annotation. If it does not, then // that means it was originally an indirect call to eval, and that // indirectness must be preserved. // 2) If the left hand side of the call is a property reference, // then the call must not a FREE_CALL annotation. If it does, then // that means it was originally an call without an explicit this and // that must be preserved. if (isIndirectEval(first) || n.getBooleanProp(Node.FREE_CALL) && NodeUtil.isGet(first)) { add("(0,"); addExpr(first, NodeUtil.precedence(Token.COMMA), Context.OTHER); add(")"); } else { addExpr(first, NodeUtil.precedence(type), context); } add("("); addList(first.getNext()); add(")"); break;  case Token.IF: boolean hasElse = childCount == 3; boolean ambiguousElseClause = context == Context.BEFORE_DANGLING_ELSE && !hasElse; if (ambiguousElseClause) { cc.beginBlock(); }  add("if("); add(first); add(")");  if (hasElse) { addNonEmptyStatement( first.getNext(), Context.BEFORE_DANGLING_ELSE, false); add("else"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), false); } else { addNonEmptyStatement(first.getNext(), Context.OTHER, false); Preconditions.checkState(childCount == 2); }  if (ambiguousElseClause) { cc.endBlock(); } break;  case Token.NULL: Preconditions.checkState(childCount == 0); cc.addConstant("null"); break;  case Token.THIS: Preconditions.checkState(childCount == 0); add("this"); break;  case Token.FALSE: Preconditions.checkState(childCount == 0); cc.addConstant("false"); break;  case Token.TRUE: Preconditions.checkState(childCount == 0); cc.addConstant("true"); break;  case Token.CONTINUE: Preconditions.checkState(childCount <= 1); add("continue"); if (childCount == 1) { if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(" "); add(first); } cc.endStatement(); break;  case Token.DEBUGGER: Preconditions.checkState(childCount == 0); add("debugger"); cc.endStatement(); break;  case Token.BREAK: Preconditions.checkState(childCount <= 1); add("break"); if (childCount == 1) { if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(" "); add(first); } cc.endStatement(); break;  case Token.EXPR_RESULT: Preconditions.checkState(childCount == 1); add(first, Context.START_OF_EXPR); cc.endStatement(); break;  case Token.NEW: add("new "); int precedence = NodeUtil.precedence(type);  // If the first child contains a CALL, then claim higher precedence // to force parentheses. Otherwise, when parsed, NEW will bind to the // first viable parentheses (don't traverse into functions). if (NodeUtil.containsType( first, Token.CALL, NodeUtil.MATCH_NOT_FUNCTION)) { precedence = NodeUtil.precedence(first.getType()) + 1; } addExpr(first, precedence, Context.OTHER);  // '()' is optional when no arguments are present Node next = first.getNext(); if (next != null) { add("("); addList(next); add(")"); } break;  case Token.STRING_KEY: Preconditions.checkState( childCount == 1, "Object lit key must have 1 child"); addJsString(n); break;  case Token.STRING: Preconditions.checkState( childCount == 0, "A string may not have children"); addJsString(n); break;  case Token.DELPROP: Preconditions.checkState(childCount == 1); add("delete "); add(first); break;  case Token.OBJECTLIT: { boolean needsParens = (context == Context.START_OF_EXPR); if (needsParens) { add("("); } add("{"); for (Node c = first; c != null; c = c.getNext()) { if (c != first) { cc.listSeparator(); }  if (c.isGetterDef() || c.isSetterDef()) { add(c); } else { Preconditions.checkState(c.isStringKey()); String key = c.getString(); // Object literal property names don't have to be quoted if they // are not JavaScript keywords if (!c.isQuotedString() && !(languageMode == LanguageMode.ECMASCRIPT3 && TokenStream.isKeyword(key)) && TokenStream.isJSIdentifier(key) // do not encode literally any non-literal characters that // were Unicode escaped. && NodeUtil.isLatin(key)) { add(key); } else { // Determine if the string is a simple number. double d = getSimpleNumber(key); if (!Double.isNaN(d)) { cc.addNumber(d); } else { addExpr(c, 1, Context.OTHER); } } add(":"); addExpr(c.getFirstChild(), 1, Context.OTHER); } } add("}"); if (needsParens) { add(")"); } break; }  case Token.SWITCH: add("switch("); add(first); add(")"); cc.beginBlock(); addAllSiblings(first.getNext()); cc.endBlock(context == Context.STATEMENT); break;  case Token.CASE: Preconditions.checkState(childCount == 2); add("case "); add(first); addCaseBody(last); break;  case Token.DEFAULT_CASE: Preconditions.checkState(childCount == 1); add("default"); addCaseBody(first); break;  case Token.LABEL: Preconditions.checkState(childCount == 2); if (!first.isLabelName()) { throw new Error("Unexpected token type. Should be LABEL_NAME."); } add(first); add(":"); addNonEmptyStatement( last, getContextForNonEmptyExpression(context), true); break;  case Token.CAST: add("("); add(first); add(")"); break;  default: throw new Error("Unknown type " + type + "\n" + n.toStringTree()); }  cc.endSourceMapping(n); }
 JSType resolveInternal(ErrorReporter t, StaticScope<JSType> enclosing) { // TODO(user): Investigate whether it is really necessary to keep two // different mechanisms for resolving named types, and if so, which order // makes more sense. Now, resolution via registry is first in order to // avoid triggering the warnings built into the resolution via properties. boolean resolved = resolveViaRegistry(t, enclosing); if (detectImplicitPrototypeCycle()) { handleTypeCycle(t); }  if (resolved) { super.resolveInternal(t, enclosing); finishPropertyContinuations(); return registry.isLastGeneration() ? getReferencedType() : this; }  resolveViaProperties(t, enclosing); if (detectImplicitPrototypeCycle()) { handleTypeCycle(t); }  super.resolveInternal(t, enclosing); if (isResolved()) { finishPropertyContinuations(); } return registry.isLastGeneration() ? getReferencedType() : this; }
 JSType resolveInternal(ErrorReporter t, StaticScope<JSType> enclosing) { // TODO(user): Investigate whether it is really necessary to keep two // different mechanisms for resolving named types, and if so, which order // makes more sense. Now, resolution via registry is first in order to // avoid triggering the warnings built into the resolution via properties. boolean resolved = resolveViaRegistry(t, enclosing); if (detectImplicitPrototypeCycle()) { handleTypeCycle(t); }  if (resolved) { super.resolveInternal(t, enclosing); finishPropertyContinuations(); return registry.isLastGeneration() ? getReferencedType() : this; }  resolveViaProperties(t, enclosing); if (detectImplicitPrototypeCycle()) { handleTypeCycle(t); }  super.resolveInternal(t, enclosing); if (isResolved()) { finishPropertyContinuations(); } return registry.isLastGeneration() ? getReferencedType() : this; }
 private void init() { thisYear= Calendar.getInstance(timeZone, locale).get(Calendar.YEAR);  nameValues= new ConcurrentHashMap<Integer, KeyValue[]>();  StringBuilder regex= new StringBuilder(); List<Strategy> collector = new ArrayList<Strategy>();  Matcher patternMatcher= formatPattern.matcher(pattern); if(!patternMatcher.lookingAt()) { throw new IllegalArgumentException("Invalid pattern"); }  currentFormatField= patternMatcher.group(); Strategy currentStrategy= getStrategy(currentFormatField); for(;;) { patternMatcher.region(patternMatcher.end(), patternMatcher.regionEnd()); if(!patternMatcher.lookingAt()) { nextStrategy = null; break; } String nextFormatField= patternMatcher.group(); nextStrategy = getStrategy(nextFormatField); if(currentStrategy.addRegex(this, regex)) { collector.add(currentStrategy); } currentFormatField= nextFormatField; currentStrategy= nextStrategy; } if(currentStrategy.addRegex(this, regex)) { collector.add(currentStrategy); } currentFormatField= null; strategies= collector.toArray(new Strategy[collector.size()]); parsePattern= Pattern.compile(regex.toString()); }
 private void recordAssignment(NodeTraversal t, Node n, Node recordNode) { Node nameNode = n.getFirstChild(); Node parent = n.getParent(); NameInformation ns = createNameInformation(t, nameNode); if (ns != null) { if (parent.isFor() && !NodeUtil.isForIn(parent)) { // Patch for assignments that appear in the init, // condition or iteration part of a FOR loop.  Without // this change, all 3 of those parts try to claim the for // loop as their dependency scope.  The last assignment in // those three fields wins, which can result in incorrect // reference edges between referenced and assigned variables. // // TODO(user) revisit the dependency scope calculation // logic. if (parent.getFirstChild().getNext() != n) { recordDepScope(recordNode, ns); } else { recordDepScope(nameNode, ns); } } else { // The rhs of the assignment is the caller, so it's used by the // context. Don't associate it w/ the lhs. // FYI: this fixes only the specific case where the assignment is the // caller expression, but it could be nested deeper in the caller and // we would still get a bug. // See testAssignWithCall2 for an example of this. recordDepScope(recordNode, ns); } } }
 public Fraction parse(String source, ParsePosition pos) { // try to parse improper fraction Fraction ret = super.parse(source, pos); if (ret != null) { return ret; }  int initialIndex = pos.getIndex();  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse whole Number whole = getWholeFormat().parse(source, pos); if (whole == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse numerator Number num = getNumeratorFormat().parse(source, pos); if (num == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // minus signs should be leading, invalid expression  // parse '/' int startIndex = pos.getIndex(); char c = parseNextCharacter(source, pos); switch (c) { case 0 : // no '/' // return num as a fraction return new Fraction(num.intValue(), 1); case '/' : // found '/', continue parsing denominator break; default : // invalid '/' // set index back to initial, error index should be the last // character examined. pos.setIndex(initialIndex); pos.setErrorIndex(startIndex); return null; }  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse denominator Number den = getDenominatorFormat().parse(source, pos); if (den == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // minus signs must be leading, invalid  int w = whole.intValue(); int n = num.intValue(); int d = den.intValue(); return new Fraction(((Math.abs(w) * d) + n) * MathUtils.sign(w), d); }
 public Fraction parse(String source, ParsePosition pos) { // try to parse improper fraction Fraction ret = super.parse(source, pos); if (ret != null) { return ret; }  int initialIndex = pos.getIndex();  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse whole Number whole = getWholeFormat().parse(source, pos); if (whole == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse numerator Number num = getNumeratorFormat().parse(source, pos); if (num == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // minus signs should be leading, invalid expression  // parse '/' int startIndex = pos.getIndex(); char c = parseNextCharacter(source, pos); switch (c) { case 0 : // no '/' // return num as a fraction return new Fraction(num.intValue(), 1); case '/' : // found '/', continue parsing denominator break; default : // invalid '/' // set index back to initial, error index should be the last // character examined. pos.setIndex(initialIndex); pos.setErrorIndex(startIndex); return null; }  // parse whitespace parseAndIgnoreWhitespace(source, pos);  // parse denominator Number den = getDenominatorFormat().parse(source, pos); if (den == null) { // invalid integer number // set index back to initial, error index should already be set // character examined. pos.setIndex(initialIndex); return null; }  // minus signs must be leading, invalid  int w = whole.intValue(); int n = num.intValue(); int d = den.intValue(); return new Fraction(((Math.abs(w) * d) + n) * MathUtils.sign(w), d); }
 private void traverseFunction(Node n, Node parent) { Preconditions.checkState(n.getChildCount() == 3); Preconditions.checkState(n.isFunction());  final Node fnName = n.getFirstChild();  boolean isFunctionExpression = (parent != null) && NodeUtil.isFunctionExpression(n);  if (!isFunctionExpression) { // Functions declarations are in the scope containing the declaration. traverseBranch(fnName, n); }  curNode = n; pushScope(n);  if (isFunctionExpression) { // Function expression names are only accessible within the function // scope. traverseBranch(fnName, n); }  final Node args = fnName.getNext(); final Node body = args.getNext();  // Args traverseBranch(args, n);  // Body Preconditions.checkState(body.getNext() == null && body.isBlock()); traverseBranch(body, n);  popScope(); }
 private void traverseFunction(Node n, Node parent) { Preconditions.checkState(n.getChildCount() == 3); Preconditions.checkState(n.isFunction());  final Node fnName = n.getFirstChild();  boolean isFunctionExpression = (parent != null) && NodeUtil.isFunctionExpression(n);  if (!isFunctionExpression) { // Functions declarations are in the scope containing the declaration. traverseBranch(fnName, n); }  curNode = n; pushScope(n);  if (isFunctionExpression) { // Function expression names are only accessible within the function // scope. traverseBranch(fnName, n); }  final Node args = fnName.getNext(); final Node body = args.getNext();  // Args traverseBranch(args, n);  // Body Preconditions.checkState(body.getNext() == null && body.isBlock()); traverseBranch(body, n);  popScope(); }
 Node processFunctionNode(FunctionNode functionNode) { Name name = functionNode.getFunctionName(); Boolean isUnnamedFunction = false; if (name == null) { int functionType = functionNode.getFunctionType(); if (functionType != FunctionNode.FUNCTION_EXPRESSION) { errorReporter.error( "unnamed function statement", sourceName, functionNode.getLineno(), "", 0);  // Return the bare minimum to put the AST in a valid state. return newNode(Token.EXPR_RESULT, Node.newNumber(0)); } name = new Name(); name.setIdentifier(""); isUnnamedFunction = true; } Node node = newNode(Token.FUNCTION); Node newName = transform(name); if (isUnnamedFunction) { // Old Rhino tagged the empty name node with the line number of the // declaration. newName.setLineno(functionNode.getLineno()); // TODO(bowdidge) Mark line number of paren correctly. // Same problem as below - the left paren might not be on the // same line as the function keyword. int lpColumn = functionNode.getAbsolutePosition() + functionNode.getLp(); newName.setCharno(position2charno(lpColumn)); maybeSetLengthFrom(newName, name); }  node.addChildToBack(newName); Node lp = newNode(Token.PARAM_LIST); // The left paren's complicated because it's not represented by an // AstNode, so there's nothing that has the actual line number that it // appeared on.  We know the paren has to appear on the same line as the // function name (or else a semicolon will be inserted.)  If there's no // function name, assume the paren was on the same line as the function. // TODO(bowdidge): Mark line number of paren correctly. Name fnName = functionNode.getFunctionName(); if (fnName != null) { lp.setLineno(fnName.getLineno()); } else { lp.setLineno(functionNode.getLineno()); } int lparenCharno = functionNode.getLp() + functionNode.getAbsolutePosition();  lp.setCharno(position2charno(lparenCharno)); for (AstNode param : functionNode.getParams()) { lp.addChildToBack(transform(param)); } node.addChildToBack(lp);  Node bodyNode = transform(functionNode.getBody()); // When in ideMode Rhino tries to parse some constructs the compiler // doesn't support, repair it here. see Rhino's // Parser#parseFunctionBodyExpr. parseDirectives(bodyNode); node.addChildToBack(bodyNode); return node; }
 public void initOptions(CompilerOptions options) { this.options = options; if (errorManager == null) { if (outStream == null) { setErrorManager( new LoggerErrorManager(createMessageFormatter(), logger)); } else { PrintStreamErrorManager printer = new PrintStreamErrorManager(createMessageFormatter(), outStream); printer.setSummaryDetailLevel(options.summaryDetailLevel); setErrorManager(printer); } }  // DiagnosticGroups override the plain checkTypes option. if (options.enables(DiagnosticGroups.CHECK_TYPES)) { options.checkTypes = true; } else if (options.disables(DiagnosticGroups.CHECK_TYPES)) { options.checkTypes = false; } else if (!options.checkTypes) { // If DiagnosticGroups did not override the plain checkTypes // option, and checkTypes is enabled, then turn off the // parser type warnings. options.setWarningLevel( DiagnosticGroup.forType( RhinoErrorReporter.TYPE_PARSE_ERROR), CheckLevel.OFF); }  if (options.checkGlobalThisLevel.isOn()) { options.setWarningLevel( DiagnosticGroups.GLOBAL_THIS, options.checkGlobalThisLevel); }  if (options.getLanguageIn() == LanguageMode.ECMASCRIPT5_STRICT) { options.setWarningLevel( DiagnosticGroups.ES5_STRICT, CheckLevel.ERROR); }  // Initialize the warnings guard. List<WarningsGuard> guards = Lists.newArrayList(); guards.add( new SuppressDocWarningsGuard( getDiagnosticGroups().getRegisteredGroups())); guards.add(options.getWarningsGuard());  ComposeWarningsGuard composedGuards = new ComposeWarningsGuard(guards);  // All passes must run the variable check. This synthesizes // variables later so that the compiler doesn't crash. It also // checks the externs file for validity. If you don't want to warn // about missing variable declarations, we shut that specific // error off. if (!options.checkSymbols && !composedGuards.enables(DiagnosticGroups.CHECK_VARIABLES)) { composedGuards.addGuard(new DiagnosticGroupWarningsGuard( DiagnosticGroups.CHECK_VARIABLES, CheckLevel.OFF)); }  this.warningsGuard = composedGuards; }
 private Fraction(double value, double epsilon, int maxDenominator, int maxIterations) throws FractionConversionException { long overflow = Integer.MAX_VALUE; double r0 = value; long a0 = (long)FastMath.floor(r0); if (FastMath.abs(a0) > overflow) { throw new FractionConversionException(value, a0, 1l); }  // check for (almost) integer arguments, which should not go to iterations. if (FastMath.abs(a0 - value) < epsilon) { this.numerator = (int) a0; this.denominator = 1; return; }  long p0 = 1; long q0 = 0; long p1 = a0; long q1 = 1;  long p2 = 0; long q2 = 1;  int n = 0; boolean stop = false; do { ++n; double r1 = 1.0 / (r0 - a0); long a1 = (long)FastMath.floor(r1); p2 = (a1 * p1) + p0; q2 = (a1 * q1) + q0;  if ((FastMath.abs(p2) > overflow) || (FastMath.abs(q2) > overflow)) { // in maxDenominator mode, if the last fraction was very close to the actual value // q2 may overflow in the next iteration; in this case return the last one. throw new FractionConversionException(value, p2, q2); }  double convergent = (double)p2 / (double)q2; if (n < maxIterations && FastMath.abs(convergent - value) > epsilon && q2 < maxDenominator) { p0 = p1; p1 = p2; q0 = q1; q1 = q2; a0 = a1; r0 = r1; } else { stop = true; } } while (!stop);  if (n >= maxIterations) { throw new FractionConversionException(value, maxIterations); }  if (q2 < maxDenominator) { this.numerator = (int) p2; this.denominator = (int) q2; } else { this.numerator = (int) p1; this.denominator = (int) q1; }  }
 private BigFraction(final double value, final double epsilon, final int maxDenominator, int maxIterations) throws FractionConversionException { long overflow = Integer.MAX_VALUE; double r0 = value; long a0 = (long) FastMath.floor(r0); if (a0 > overflow) { throw new FractionConversionException(value, a0, 1l); }  // check for (almost) integer arguments, which should not go // to iterations. if (FastMath.abs(a0 - value) < epsilon) { numerator = BigInteger.valueOf(a0); denominator = BigInteger.ONE; return; }  long p0 = 1; long q0 = 0; long p1 = a0; long q1 = 1;  long p2 = 0; long q2 = 1;  int n = 0; boolean stop = false; do { ++n; final double r1 = 1.0 / (r0 - a0); final long a1 = (long) FastMath.floor(r1); p2 = (a1 * p1) + p0; q2 = (a1 * q1) + q0; if ((p2 > overflow) || (q2 > overflow)) { // in maxDenominator mode, if the last fraction was very close to the actual value // q2 may overflow in the next iteration; in this case return the last one. throw new FractionConversionException(value, p2, q2); }  final double convergent = (double) p2 / (double) q2; if ((n < maxIterations) && (FastMath.abs(convergent - value) > epsilon) && (q2 < maxDenominator)) { p0 = p1; p1 = p2; q0 = q1; q1 = q2; a0 = a1; r0 = r1; } else { stop = true; } } while (!stop);  if (n >= maxIterations) { throw new FractionConversionException(value, maxIterations); }  if (q2 < maxDenominator) { numerator   = BigInteger.valueOf(p2); denominator = BigInteger.valueOf(q2); } else { numerator   = BigInteger.valueOf(p1); denominator = BigInteger.valueOf(q1); } }
 private String getRemainingJSDocLine() { String result = stream.getRemainingJSDocLine(); return result; }
 private String getRemainingJSDocLine() { String result = stream.getRemainingJSDocLine(); return result; }
 public void addValue(Object v) { addValue((Comparable<?>) v); }
 public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {  sanityChecks(equations, t0, y0, t, y); setEquations(equations); resetEvaluations(); final boolean forward = t > t0;  // create some internal working arrays final int stages = c.length + 1; if (y != y0) { System.arraycopy(y0, 0, y, 0, y0.length); } final double[][] yDotK = new double[stages][y0.length]; final double[] yTmp = new double[y0.length];  // set up an interpolator sharing the integrator arrays AbstractStepInterpolator interpolator; if (requiresDenseOutput() || (! eventsHandlersManager.isEmpty())) { final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy(); rki.reinitialize(this, yTmp, yDotK, forward); interpolator = rki; } else { interpolator = new DummyStepInterpolator(yTmp, forward); } interpolator.storeTime(t0);  // set up integration control objects stepStart         = t0; double  hNew      = 0; boolean firstTime = true; for (StepHandler handler : stepHandlers) { handler.reset(); } CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager); boolean lastStep = false;  // main integration loop while (!lastStep) {  interpolator.shift();  double error = 0; for (boolean loop = true; loop;) {  if (firstTime || !fsal) { // first stage computeDerivatives(stepStart, y, yDotK[0]); }  if (firstTime) { final double[] scale; if (vecAbsoluteTolerance == null) { scale = new double[y0.length]; java.util.Arrays.fill(scale, scalAbsoluteTolerance); } else { scale = vecAbsoluteTolerance; } hNew = initializeStep(equations, forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]); firstTime = false; }  stepSize = hNew;  // next stages for (int k = 1; k < stages; ++k) {  for (int j = 0; j < y0.length; ++j) { double sum = a[k-1][0] * yDotK[0][j]; for (int l = 1; l < k; ++l) { sum += a[k-1][l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  computeDerivatives(stepStart + c[k-1] * stepSize, yTmp, yDotK[k]);  }  // estimate the state at the end of the step for (int j = 0; j < y0.length; ++j) { double sum    = b[0] * yDotK[0][j]; for (int l = 1; l < stages; ++l) { sum    += b[l] * yDotK[l][j]; } yTmp[j] = y[j] + stepSize * sum; }  // estimate the error at the end of the step error = estimateError(yDotK, y, yTmp, stepSize); if (error <= 1.0) {  // discrete events handling interpolator.storeTime(stepStart + stepSize); if (manager.evaluateStep(interpolator)) { final double dt = manager.getEventTime() - stepStart; if (Math.abs(dt) <= Math.ulp(stepStart)) { // rejecting the step would lead to a too small next step, we accept it loop = false; } else { // reject the step to match exactly the next switch time hNew = dt; } } else { // accept the step loop = false; }  } else { // reject the step and attempt to reduce error by stepsize control final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp))); hNew = filterStep(stepSize * factor, forward, false); }  }  // the step has been accepted final double nextStep = stepStart + stepSize; System.arraycopy(yTmp, 0, y, 0, y0.length); manager.stepAccepted(nextStep, y); lastStep = manager.stop();  // provide the step data to the step handler interpolator.storeTime(nextStep); for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, lastStep); } stepStart = nextStep;  if (fsal) { // save the last evaluation for the next step System.arraycopy(yDotK[stages - 1], 0, yDotK[0], 0, y0.length); }  if (manager.reset(stepStart, y) && ! lastStep) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them computeDerivatives(stepStart, y, yDotK[0]); }  if (! lastStep) { // in some rare cases we may get here with stepSize = 0, for example // when an event occurs at integration start, reducing the first step // to zero; we have to reset the step to some safe non zero value stepSize = filterStep(stepSize, forward, true);  // stepsize control for next step final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp))); final double  scaledH    = stepSize * factor; final double  nextT      = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast); }  }  final double stopTime = stepStart; resetInternalState(); return stopTime;  }
 public Fraction reduce() { int gcd = greatestCommonDivisor(Math.abs(numerator), denominator); if (gcd == 1) { return this; } return Fraction.getFraction(numerator / gcd, denominator / gcd); }
 public void matchConstraint(ObjectType constraintObj) { // We only want to match contraints on anonymous types.  // Handle the case where the constraint object is a record type. // // param constraintObj {{prop: (number|undefined)}} // function f(constraintObj) {} // f({}); // // We want to modify the object literal to match the constraint, by // taking any each property on the record and trying to match // properties on this object. if (constraintObj.isRecordType()) { for (String prop : constraintObj.getOwnPropertyNames()) { JSType propType = constraintObj.getPropertyType(prop); if (!isPropertyTypeDeclared(prop)) { JSType typeToInfer = propType; if (!hasProperty(prop)) { typeToInfer = getNativeType(JSTypeNative.VOID_TYPE) .getLeastSupertype(propType); } defineInferredProperty(prop, typeToInfer, null); } } } }
 public RealMatrix getCorrelationPValues() throws MathException { TDistribution tDistribution = new TDistributionImpl(nObs - 2); int nVars = correlationMatrix.getColumnDimension(); double[][] out = new double[nVars][nVars]; for (int i = 0; i < nVars; i++) { for (int j = 0; j < nVars; j++) { if (i == j) { out[i][j] = 0d; } else { double r = correlationMatrix.getEntry(i, j); double t = Math.abs(r * Math.sqrt((nObs - 2)/(1 - r * r))); out[i][j] = 2 * (1 - tDistribution.cumulativeProbability(t)); } } } return new BlockRealMatrix(out); }
 public Object clone() throws CloneNotSupportedException { Object clone = createCopy(0, getItemCount() - 1); return clone; }
 public void toSource(final CodeBuilder cb, final int inputSeqNum, final Node root) { runInCompilerThread(new Callable<Void>() { public Void call() throws Exception { if (options.printInputDelimiter) { if ((cb.getLength() > 0) && !cb.endsWith("\n")) { cb.append("\n");  // Make sure that the label starts on a new line } Preconditions.checkState(root.getType() == Token.SCRIPT);  String delimiter = options.inputDelimiter;  String sourceName = (String)root.getProp(Node.SOURCENAME_PROP); Preconditions.checkState(sourceName != null); Preconditions.checkState(!sourceName.isEmpty());  delimiter = delimiter.replaceAll("%name%", sourceName) .replaceAll("%num%", String.valueOf(inputSeqNum));  cb.append(delimiter) .append("\n"); } if (root.getJSDocInfo() != null && root.getJSDocInfo().getLicense() != null) { cb.append("/*\n") .append(root.getJSDocInfo().getLicense()) .append("*/\n"); }  // If there is a valid source map, then indicate to it that the current // root node's mappings are offset by the given string builder buffer. if (options.sourceMapOutputPath != null) { sourceMap.setStartingPosition( cb.getLineIndex(), cb.getColumnIndex()); }  // if LanguageMode is ECMASCRIPT5_STRICT, only print 'use strict' // for the first input file String code = toSource(root, sourceMap); if (!code.isEmpty()) { cb.append(code);  // In order to avoid parse ambiguity when files are concatenated // together, all files should end in a semi-colon. Do a quick // heuristic check if there's an obvious semi-colon already there. int length = code.length(); char lastChar = code.charAt(length - 1); char secondLastChar = length >= 2 ? code.charAt(length - 2) : '\0'; boolean hasSemiColon = lastChar == ';' || (lastChar == '\n' && secondLastChar == ';'); if (!hasSemiColon) { cb.append(";"); } } return null; } }); }
 private String toSource(Node n, SourceMap sourceMap) { CodePrinter.Builder builder = new CodePrinter.Builder(n); builder.setPrettyPrint(options.prettyPrint); builder.setLineBreak(options.lineBreak); builder.setSourceMap(sourceMap); builder.setSourceMapDetailLevel(options.sourceMapDetailLevel); builder.setTagAsStrict( options.getLanguageOut() == LanguageMode.ECMASCRIPT5_STRICT); builder.setLineLengthThreshold(options.lineLengthThreshold);  Charset charset = options.outputCharset != null ? Charset.forName(options.outputCharset) : null; builder.setOutputCharset(charset);  return builder.build(); }
 private VariableLiveness isVariableReadBeforeKill( Node n, String variable) { if (NodeUtil.isName(n) && variable.equals(n.getString())) { if (NodeUtil.isLhs(n, n.getParent())) { // The expression to which the assignment is made is evaluated before // the RHS is evaluated (normal left to right evaluation) but the KILL // occurs after the RHS is evaluated. return VariableLiveness.KILL; } else { return VariableLiveness.READ; } }  // Expressions are evaluated left-right, depth first. for (Node child = n.getFirstChild(); child != null; child = child.getNext()) { if (!ControlFlowGraph.isEnteringNewCfgNode(child)) { // Not a FUNCTION VariableLiveness state = isVariableReadBeforeKill(child, variable); if (state != VariableLiveness.MAYBE_LIVE) { return state; } } } return VariableLiveness.MAYBE_LIVE; }
 protected AxisState drawLabel(String label, Graphics2D g2, Rectangle2D plotArea, Rectangle2D dataArea, RectangleEdge edge, AxisState state, PlotRenderingInfo plotState) {  // it is unlikely that 'state' will be null, but check anyway... if (state == null) { throw new IllegalArgumentException("Null 'state' argument."); }  if ((label == null) || (label.equals(""))) { return state; }  Font font = getLabelFont(); RectangleInsets insets = getLabelInsets(); g2.setFont(font); g2.setPaint(getLabelPaint()); FontMetrics fm = g2.getFontMetrics(); Rectangle2D labelBounds = TextUtilities.getTextBounds(label, g2, fm); Shape hotspot = null;  if (edge == RectangleEdge.TOP) { AffineTransform t = AffineTransform.getRotateInstance( getLabelAngle(), labelBounds.getCenterX(), labelBounds.getCenterY()); Shape rotatedLabelBounds = t.createTransformedShape(labelBounds); labelBounds = rotatedLabelBounds.getBounds2D(); float w = (float) labelBounds.getWidth(); float h = (float) labelBounds.getHeight(); float labelx = (float) dataArea.getCenterX(); float labely = (float) (state.getCursor() - insets.getBottom() - h / 2.0); TextUtilities.drawRotatedString(label, g2, labelx, labely, TextAnchor.CENTER, getLabelAngle(), TextAnchor.CENTER); hotspot = new Rectangle2D.Float(labelx - w / 2.0f, labely - h / 2.0f, w, h); state.cursorUp(insets.getTop() + labelBounds.getHeight() + insets.getBottom()); } else if (edge == RectangleEdge.BOTTOM) { AffineTransform t = AffineTransform.getRotateInstance( getLabelAngle(), labelBounds.getCenterX(), labelBounds.getCenterY()); Shape rotatedLabelBounds = t.createTransformedShape(labelBounds); labelBounds = rotatedLabelBounds.getBounds2D(); float w = (float) labelBounds.getWidth(); float h = (float) labelBounds.getHeight(); float labelx = (float) dataArea.getCenterX(); float labely = (float) (state.getCursor() + insets.getTop() + h / 2.0); TextUtilities.drawRotatedString(label, g2, labelx, labely, TextAnchor.CENTER, getLabelAngle(), TextAnchor.CENTER); hotspot = new Rectangle2D.Float(labelx - w / 2.0f, labely - h / 2.0f, w, h); state.cursorDown(insets.getTop() + labelBounds.getHeight() + insets.getBottom()); } else if (edge == RectangleEdge.LEFT) { AffineTransform t = AffineTransform.getRotateInstance( getLabelAngle() - Math.PI / 2.0, labelBounds.getCenterX(), labelBounds.getCenterY()); Shape rotatedLabelBounds = t.createTransformedShape(labelBounds); labelBounds = rotatedLabelBounds.getBounds2D(); float w = (float) labelBounds.getWidth(); float h = (float) labelBounds.getHeight(); float labelx = (float) (state.getCursor() - insets.getRight() - w / 2.0); float labely = (float) dataArea.getCenterY(); TextUtilities.drawRotatedString(label, g2, labelx, labely, TextAnchor.CENTER, getLabelAngle() - Math.PI / 2.0, TextAnchor.CENTER); hotspot = new Rectangle2D.Float(labelx - w / 2.0f, labely - h / 2.0f, w, h); state.cursorLeft(insets.getLeft() + labelBounds.getWidth() + insets.getRight()); } else if (edge == RectangleEdge.RIGHT) {  AffineTransform t = AffineTransform.getRotateInstance( getLabelAngle() + Math.PI / 2.0, labelBounds.getCenterX(), labelBounds.getCenterY()); Shape rotatedLabelBounds = t.createTransformedShape(labelBounds); labelBounds = rotatedLabelBounds.getBounds2D(); float w = (float) labelBounds.getWidth(); float h = (float) labelBounds.getHeight(); float labelx = (float) (state.getCursor() + insets.getLeft() + w / 2.0); float labely = (float) (dataArea.getY() + dataArea.getHeight() / 2.0); TextUtilities.drawRotatedString(label, g2, labelx, labely, TextAnchor.CENTER, getLabelAngle() + Math.PI / 2.0, TextAnchor.CENTER); hotspot = new Rectangle2D.Float(labelx - w / 2.0f, labely - h / 2.0f, w, h); state.cursorRight(insets.getLeft() + labelBounds.getWidth() + insets.getRight());  } if (plotState != null && hotspot != null) { ChartRenderingInfo owner = plotState.getOwner(); EntityCollection entities = owner.getEntityCollection(); if (entities != null) { entities.add(new AxisLabelEntity(this, hotspot, this.labelToolTip, this.labelURL)); } } return state;  }
 private void processRequireCall(NodeTraversal t, Node n, Node parent) { Node left = n.getFirstChild(); Node arg = left.getNext(); if (verifyLastArgumentIsString(t, left, arg)) { String ns = arg.getString(); ProvidedName provided = providedNames.get(ns); if (provided == null || !provided.isExplicitlyProvided()) { unrecognizedRequires.add( new UnrecognizedRequire(n, ns, t.getSourceName())); } else { JSModule providedModule = provided.explicitModule;  // This must be non-null, because there was an explicit provide. Preconditions.checkNotNull(providedModule);  JSModule module = t.getModule(); if (moduleGraph != null && module != providedModule && !moduleGraph.dependsOn(module, providedModule)) { compiler.report( t.makeError(n, XMODULE_REQUIRE_ERROR, ns, providedModule.getName(), module.getName())); } }  maybeAddToSymbolTable(left); maybeAddStringNodeToSymbolTable(arg);  // Requires should be removed before further processing. // Some clients run closure pass multiple times, first with // the checks for broken requires turned off. In these cases, we // allow broken requires to be preserved by the first run to // let them be caught in the subsequent run. if (provided != null) { parent.detachFromParent(); compiler.reportCodeChange(); } } }
 private boolean isPrototypePropertyAssign(Node assign) { Node n = assign.getFirstChild(); if (n != null && NodeUtil.isVarOrSimpleAssignLhs(n, assign) && n.getType() == Token.GETPROP ) { // We want to exclude the assignment itself from the usage list boolean isChainedProperty = n.getFirstChild().getType() == Token.GETPROP;  if (isChainedProperty) { Node child = n.getFirstChild().getFirstChild().getNext();  if (child.getType() == Token.STRING && child.getString().equals("prototype")) { return true; } } }  return false; }
 public long getDateTimeMillis(int year, int monthOfYear, int dayOfMonth, int hourOfDay, int minuteOfHour, int secondOfMinute, int millisOfSecond) throws IllegalArgumentException { Chronology base; if ((base = getBase()) != null) { return base.getDateTimeMillis (year, monthOfYear, dayOfMonth, hourOfDay, minuteOfHour, secondOfMinute, millisOfSecond); }  // Assume date is Gregorian. long instant; instant = iGregorianChronology.getDateTimeMillis (year, monthOfYear, dayOfMonth, hourOfDay, minuteOfHour, secondOfMinute, millisOfSecond); if (instant < iCutoverMillis) { // Maybe it's Julian. instant = iJulianChronology.getDateTimeMillis (year, monthOfYear, dayOfMonth, hourOfDay, minuteOfHour, secondOfMinute, millisOfSecond); if (instant >= iCutoverMillis) { // Okay, it's in the illegal cutover gap. throw new IllegalArgumentException("Specified date does not exist"); } } return instant; }
 public int parseInto(ReadWritableInstant instant, String text, int position) { DateTimeParser parser = requireParser(); if (instant == null) { throw new IllegalArgumentException("Instant must not be null"); }  long instantMillis = instant.getMillis(); Chronology chrono = instant.getChronology(); long instantLocal = instantMillis + chrono.getZone().getOffset(instantMillis); chrono = selectChronology(chrono); int defaultYear = chrono.year().get(instantLocal);  DateTimeParserBucket bucket = new DateTimeParserBucket( instantLocal, chrono, iLocale, iPivotYear, defaultYear); int newPos = parser.parseInto(bucket, text, position); instant.setMillis(bucket.computeMillis(false, text)); if (iOffsetParsed && bucket.getOffsetInteger() != null) { int parsedOffset = bucket.getOffsetInteger(); DateTimeZone parsedZone = DateTimeZone.forOffsetMillis(parsedOffset); chrono = chrono.withZone(parsedZone); } else if (bucket.getZone() != null) { chrono = chrono.withZone(bucket.getZone()); } instant.setChronology(chrono); if (iZone != null) { instant.setZone(iZone); } return newPos; }
 public double density(final double[] vals) throws DimensionMismatchException { final int dim = getDimension(); if (vals.length != dim) { throw new DimensionMismatchException(vals.length, dim); }  return FastMath.pow(2 * FastMath.PI, -dim / 2) * FastMath.pow(covarianceMatrixDeterminant, -0.5) * getExponentTerm(vals); }
 public final void translate(CharSequence input, Writer out) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (input == null) { return; } int pos = 0; int len = input.length(); while (pos < len) { int consumed = translate(input, pos, out); if (consumed == 0) { char[] c = Character.toChars(Character.codePointAt(input, pos)); out.write(c); pos+= c.length; continue; } //          // contract with translators is that they have to understand codepoints //          // and they just took care of a surrogate pair for (int pt = 0; pt < consumed; pt++) { pos += Character.charCount(Character.codePointAt(input, pos)); } } }
 private static void escapeJavaStyleString(Writer out, String str, boolean escapeSingleQuote) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (str == null) { return; } int sz; sz = str.length(); for (int i = 0; i < sz; i++) { char ch = str.charAt(i);  // handle unicode if (ch > 0xfff) { out.write("\\u" + hex(ch)); } else if (ch > 0xff) { out.write("\\u0" + hex(ch)); } else if (ch > 0x7f) { out.write("\\u00" + hex(ch)); } else if (ch < 32) { switch (ch) { case '\b': out.write('\\'); out.write('b'); break; case '\n': out.write('\\'); out.write('n'); break; case '\t': out.write('\\'); out.write('t'); break; case '\f': out.write('\\'); out.write('f'); break; case '\r': out.write('\\'); out.write('r'); break; default : if (ch > 0xf) { out.write("\\u00" + hex(ch)); } else { out.write("\\u000" + hex(ch)); } break; } } else { switch (ch) { case '\'': if (escapeSingleQuote) { out.write('\\'); } out.write('\''); break; case '"': out.write('\\'); out.write('"'); break; case '\\': out.write('\\'); out.write('\\'); break; default : out.write(ch); break; } } } }
 private static void escapeJavaStyleString(Writer out, String str, boolean escapeSingleQuote) throws IOException { if (out == null) { throw new IllegalArgumentException("The Writer must not be null"); } if (str == null) { return; } int sz; sz = str.length(); for (int i = 0; i < sz; i++) { char ch = str.charAt(i);  // handle unicode if (ch > 0xfff) { out.write("\\u" + hex(ch)); } else if (ch > 0xff) { out.write("\\u0" + hex(ch)); } else if (ch > 0x7f) { out.write("\\u00" + hex(ch)); } else if (ch < 32) { switch (ch) { case '\b': out.write('\\'); out.write('b'); break; case '\n': out.write('\\'); out.write('n'); break; case '\t': out.write('\\'); out.write('t'); break; case '\f': out.write('\\'); out.write('f'); break; case '\r': out.write('\\'); out.write('r'); break; default : if (ch > 0xf) { out.write("\\u00" + hex(ch)); } else { out.write("\\u000" + hex(ch)); } break; } } else { switch (ch) { case '\'': if (escapeSingleQuote) { out.write('\\'); } out.write('\''); break; case '"': out.write('\\'); out.write('"'); break; case '\\': out.write('\\'); out.write('\\'); break; default : out.write(ch); break; } } } }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MathIllegalStateException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime(); resetOccurred = false;  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // trigger the event interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState(); currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); return eventT; }  if (currentEvent.reset(eventT, eventY)) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MathIllegalStateException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime(); resetOccurred = false;  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // trigger the event interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState(); currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); return eventT; }  if (currentEvent.reset(eventT, eventY)) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MathIllegalStateException {  double previousT = interpolator.getGlobalPreviousTime(); final double currentT = interpolator.getGlobalCurrentTime(); resetOccurred = false;  // initialize the events states if needed if (! statesInitialized) { for (EventState state : eventsStates) { state.reinitializeBegin(interpolator); } statesInitialized = true; }  // search for next events that may occur during the step final int orderingSign = interpolator.isForward() ? +1 : -1; SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {  /** {@inheritDoc} */ public int compare(EventState es0, EventState es1) { return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime()); }  });  for (final EventState state : eventsStates) { if (state.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(state); } }  while (!occuringEvents.isEmpty()) {  // handle the chronologically first event final Iterator<EventState> iterator = occuringEvents.iterator(); final EventState currentEvent = iterator.next(); iterator.remove();  // restrict the interpolator to the first part of the step, up to the event final double eventT = currentEvent.getEventTime(); interpolator.setSoftPreviousTime(previousT); interpolator.setSoftCurrentTime(eventT);  // trigger the event interpolator.setInterpolatedTime(eventT); final double[] eventY = interpolator.getInterpolatedState(); currentEvent.stepAccepted(eventT, eventY); isLastStep = currentEvent.stop();  // handle the first part of the step, up to the event for (final StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  if (isLastStep) { // the event asked to stop integration System.arraycopy(eventY, 0, y, 0, y.length); return eventT; }  if (currentEvent.reset(eventT, eventY)) { // some event handler has triggered changes that // invalidate the derivatives, we need to recompute them System.arraycopy(eventY, 0, y, 0, y.length); computeDerivatives(eventT, y, yDot); resetOccurred = true; return eventT; }  // prepare handling of the remaining part of the step previousT = eventT; interpolator.setSoftPreviousTime(eventT); interpolator.setSoftCurrentTime(currentT);  // check if the same event occurs again in the remaining part of the step if (currentEvent.evaluateStep(interpolator)) { // the event occurs during the current step occuringEvents.add(currentEvent); }  }  interpolator.setInterpolatedTime(currentT); final double[] currentY = interpolator.getInterpolatedState(); for (final EventState state : eventsStates) { state.stepAccepted(currentT, currentY); isLastStep = isLastStep || state.stop(); } isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);  // handle the remaining part of the step, after all events if any for (StepHandler handler : stepHandlers) { handler.handleStep(interpolator, isLastStep); }  return currentT;  }
 public Complex divide(Complex divisor) throws NullArgumentException { MathUtils.checkNotNull(divisor); if (isNaN || divisor.isNaN) { return NaN; }  if (divisor.isZero) { // return isZero ? NaN : INF; // See MATH-657 return isZero ? NaN : INF; }  if (divisor.isInfinite() && !isInfinite()) { return ZERO; }  final double c = divisor.getReal(); final double d = divisor.getImaginary();  if (FastMath.abs(c) < FastMath.abs(d)) { double q = c / d; double denominator = c * q + d; return createComplex((real * q + imaginary) / denominator, (imaginary * q - real) / denominator); } else { double q = d / c; double denominator = d * q + c; return createComplex((imaginary * q + real) / denominator, (imaginary - real * q) / denominator); } }
 public Complex divide(double divisor) { if (isNaN || Double.isNaN(divisor)) { return NaN; } if (divisor == 0d) { // return isZero ? NaN : INF; // See MATH-657 return isZero ? NaN : INF; } if (Double.isInfinite(divisor)) { return !isInfinite() ? ZERO : NaN; } return createComplex(real / divisor, imaginary  / divisor); }
 public double evaluate(final double[] values, final double[] weights, final double mean, final int begin, final int length) {  double var = Double.NaN;  if (test(values, weights, begin, length)) { if (length == 1) { var = 0.0; } else if (length > 1) { double accum = 0.0; double dev = 0.0; double accum2 = 0.0; for (int i = begin; i < begin + length; i++) { dev = values[i] - mean; accum += weights[i] * (dev * dev); accum2 += weights[i] * dev; }  double sumWts = 0; for (int i = 0; i < weights.length; i++) { sumWts += weights[i]; }  if (isBiasCorrected) { var = (accum - (accum2 * accum2 / sumWts)) / (sumWts - 1.0); } else { var = (accum - (accum2 * accum2 / sumWts)) / sumWts; } } } return var; }
 public void addValue(Object v) {  /** * Adds 1 to the frequency count for v. * <p> * If other objects have already been added to this Frequency, v must * be comparable to those that have already been added. * </p> * * @param v the value to add. * @throws IllegalArgumentException if <code>v</code> is not comparable with previous entries */ Object obj = v; if (v instanceof Integer) { obj = Long.valueOf(((Integer) v).longValue()); } try { Long count = (Long) freqTable.get(obj); if (count == null) { freqTable.put(obj, Long.valueOf(1)); } else { freqTable.put(obj, Long.valueOf(count.longValue() + 1)); } } catch (ClassCastException ex) { //TreeMap will throw ClassCastException if v is not comparable throw new IllegalArgumentException("Value not comparable to existing values."); } }
 public void verify(VerificationData data) { AssertionError error = null;  timer.start(); while (timer.isCounting()) { try { delegate.verify(data);  if (returnOnSuccess) { return; } else { error = null; } } catch (MockitoAssertionError e) { error = handleVerifyException(e); } catch (org.mockito.exceptions.verification.junit.ArgumentsAreDifferent e) { error = handleVerifyException(e); } }  if (error != null) { throw error; } }
 public int compareTo(Fraction object) { double nOd = doubleValue(); double dOn = object.doubleValue(); return (nOd < dOn) ? -1 : ((nOd > dOn) ? +1 : 0); }
 public int compareTo(Fraction object) { double nOd = doubleValue(); double dOn = object.doubleValue(); return (nOd < dOn) ? -1 : ((nOd > dOn) ? +1 : 0); }
 private void computeShiftIncrement(final int start, final int end, final int deflated) {  final double cnst1 = 0.563; final double cnst2 = 1.010; final double cnst3 = 1.05;  // a negative dMin forces the shift to take that absolute value // tType records the type of shift. if (dMin <= 0.0) { tau = -dMin; tType = -1; return; }  int nn = 4 * end + pingPong - 1; switch (deflated) {  case 0 : // no realEigenvalues deflated. if (dMin == dN || dMin == dN1) {  double b1 = Math.sqrt(work[nn - 3]) * Math.sqrt(work[nn - 5]); double b2 = Math.sqrt(work[nn - 7]) * Math.sqrt(work[nn - 9]); double a2 = work[nn - 7] + work[nn - 5];  if (dMin == dN && dMin1 == dN1) { // cases 2 and 3. final double gap2 = dMin2 - a2 - dMin2 * 0.25; final double gap1 = a2 - dN - ((gap2 > 0.0 && gap2 > b2) ? (b2 / gap2) * b2 : (b1 + b2)); if (gap1 > 0.0 && gap1 > b1) { tau   = Math.max(dN - (b1 / gap1) * b1, 0.5 * dMin); tType = -2; } else { double s = 0.0; if (dN > b1) { s = dN - b1; } if (a2 > (b1 + b2)) { s = Math.min(s, a2 - (b1 + b2)); } tau   = Math.max(s, 0.333 * dMin); tType = -3; } } else { // case 4. tType = -4; double s = 0.25 * dMin; double gam; int np; if (dMin == dN) { gam = dN; a2 = 0.0; if (work[nn - 5]  >  work[nn - 7]) { return; } b2 = work[nn - 5] / work[nn - 7]; np = nn - 9; } else { np = nn - 2 * pingPong; b2 = work[np - 2]; gam = dN1; if (work[np - 4]  >  work[np - 2]) { return; } a2 = work[np - 4] / work[np - 2]; if (work[nn - 9]  >  work[nn - 11]) { return; } b2 = work[nn - 9] / work[nn - 11]; np = nn - 13; }  // approximate contribution to norm squared from i < nn-1. a2 = a2 + b2; for (int i4 = np; i4 >= 4 * start + 2 + pingPong; i4 -= 4) { if(b2 == 0.0) { break; } b1 = b2; if (work[i4]  >  work[i4 - 2]) { return; } b2 = b2 * (work[i4] / work[i4 - 2]); a2 = a2 + b2; if (100 * Math.max(b2, b1) < a2 || cnst1 < a2) { break; } } a2 = cnst3 * a2;  // rayleigh quotient residual bound. if (a2 < cnst1) { s = gam * (1 - Math.sqrt(a2)) / (1 + a2); } tau = s;  } } else if (dMin == dN2) {  // case 5. tType = -5; double s = 0.25 * dMin;  // compute contribution to norm squared from i > nn-2. final int np = nn - 2 * pingPong; double b1 = work[np - 2]; double b2 = work[np - 6]; final double gam = dN2; if (work[np - 8] > b2 || work[np - 4] > b1) { return; } double a2 = (work[np - 8] / b2) * (1 + work[np - 4] / b1);  // approximate contribution to norm squared from i < nn-2. if (end - start > 2) { b2 = work[nn - 13] / work[nn - 15]; a2 = a2 + b2; for (int i4 = nn - 17; i4 >= 4 * start + 2 + pingPong; i4 -= 4) { if (b2 == 0.0) { break; } b1 = b2; if (work[i4]  >  work[i4 - 2]) { return; } b2 = b2 * (work[i4] / work[i4 - 2]); a2 = a2 + b2; if (100 * Math.max(b2, b1) < a2 || cnst1 < a2)  { break; } } a2 = cnst3 * a2; }  if (a2 < cnst1) { tau = gam * (1 - Math.sqrt(a2)) / (1 + a2); } else { tau = s; }  } else {  // case 6, no information to guide us. if (tType == -6) { g += 0.333 * (1 - g); } else if (tType == -18) { g = 0.25 * 0.333; } else { g = 0.25; } tau   = g * dMin; tType = -6;  } break;  case 1 : // one eigenvalue just deflated. use dMin1, dN1 for dMin and dN. if (dMin1 == dN1 && dMin2 == dN2) {  // cases 7 and 8. tType = -7; double s = 0.333 * dMin1; if (work[nn - 5] > work[nn - 7]) { return; } double b1 = work[nn - 5] / work[nn - 7]; double b2 = b1; if (b2 != 0.0) { for (int i4 = 4 * end - 10 + pingPong; i4 >= 4 * start + 2 + pingPong; i4 -= 4) { final double oldB1 = b1; if (work[i4] > work[i4 - 2]) { return; } b1 = b1 * (work[i4] / work[i4 - 2]); b2 = b2 + b1; if (100 * Math.max(b1, oldB1) < b2) { break; } } } b2 = Math.sqrt(cnst3 * b2); final double a2 = dMin1 / (1 + b2 * b2); final double gap2 = 0.5 * dMin2 - a2; if (gap2 > 0.0 && gap2 > b2 * a2) { tau = Math.max(s, a2 * (1 - cnst2 * a2 * (b2 / gap2) * b2)); } else { tau = Math.max(s, a2 * (1 - cnst2 * b2)); tType = -8; } } else {  // case 9. tau = 0.25 * dMin1; if (dMin1 == dN1) { tau = 0.5 * dMin1; } tType = -9; } break;  case 2 : // two realEigenvalues deflated. use dMin2, dN2 for dMin and dN.  // cases 10 and 11. if (dMin2 == dN2 && 2 * work[nn - 5] < work[nn - 7]) { tType = -10; final double s = 0.333 * dMin2; if (work[nn - 5] > work[nn - 7]) { return; } double b1 = work[nn - 5] / work[nn - 7]; double b2 = b1; if (b2 != 0.0){ for (int i4 = 4 * end - 9 + pingPong; i4 >= 4 * start + 2 + pingPong; i4 -= 4) { if (work[i4] > work[i4 - 2]) { return; } b1 *= work[i4] / work[i4 - 2]; b2 += b1; if (100 * b1 < b2) { break; } } } b2 = Math.sqrt(cnst3 * b2); final double a2 = dMin2 / (1 + b2 * b2); final double gap2 = work[nn - 7] + work[nn - 9] - Math.sqrt(work[nn - 11]) * Math.sqrt(work[nn - 9]) - a2; if (gap2 > 0.0 && gap2 > b2 * a2) { tau = Math.max(s, a2 * (1 - cnst2 * a2 * (b2 / gap2) * b2)); } else { tau = Math.max(s, a2 * (1 - cnst2 * b2)); } } else { tau   = 0.25 * dMin2; tType = -11; } break;  default : // case 12, more than two realEigenvalues deflated. no information. tau   = 0.0; tType = -12; }  }
 private void processGeneralBlock(final int n) throws InvalidMatrixException {  // check decomposed matrix data range double sumOffDiag = 0; for (int i = 0; i < n - 1; ++i) { final int fourI = 4 * i; final double ei = work[fourI + 2]; sumOffDiag += ei; }  if (sumOffDiag == 0) { // matrix is already diagonal return; }  // initial checks for splits (see Parlett & Marques section 3.3) flipIfWarranted(n, 2);  // two iterations with Li's test for initial splits initialSplits(n);  // initialize parameters used by goodStep tType = 0; dMin1 = 0; dMin2 = 0; dN    = 0; dN1   = 0; dN2   = 0; tau   = 0;  // process split segments int i0 = 0; int n0 = n; while (n0 > 0) {  // retrieve shift that was temporarily stored as a negative off-diagonal element sigma    = (n0 == n) ? 0 : -work[4 * n0 - 2]; sigmaLow = 0;  // find start of a new split segment to process double offDiagMin = (i0 == n0) ? 0 : work[4 * n0 - 6]; double offDiagMax = 0; double diagMax    = work[4 * n0 - 4]; double diagMin    = diagMax; i0 = 0; for (int i = 4 * (n0 - 2); i >= 0; i -= 4) { if (work[i + 2] <= 0) { i0 = 1 + i / 4; break; } if (diagMin >= 4 * offDiagMax) { diagMin    = Math.min(diagMin, work[i + 4]); offDiagMax = Math.max(offDiagMax, work[i + 2]); } diagMax    = Math.max(diagMax, work[i] + work[i + 2]); offDiagMin = Math.min(offDiagMin, work[i + 2]); } work[4 * n0 - 2] = offDiagMin;  // lower bound of Gershgorin disk dMin = -Math.max(0, diagMin - 2 * Math.sqrt(diagMin * offDiagMax));  pingPong = 0; int maxIter = 30 * (n0 - i0); for (int k = 0; i0 < n0; ++k) { if (k >= maxIter) { throw new InvalidMatrixException(new MaxIterationsExceededException(maxIter)); }  // perform one step n0 = goodStep(i0, n0); pingPong = 1 - pingPong;  // check for new splits after "ping" steps // when the last elements of qd array are very small if ((pingPong == 0) && (n0 - i0 > 3) && (work[4 * n0 - 1] <= TOLERANCE_2 * diagMax) && (work[4 * n0 - 2] <= TOLERANCE_2 * sigma)) { int split  = i0 - 1; diagMax    = work[4 * i0]; offDiagMin = work[4 * i0 + 2]; double previousEMin = work[4 * i0 + 3]; for (int i = 4 * i0; i < 4 * n0 - 11; i += 4) { if ((work[i + 3] <= TOLERANCE_2 * work[i]) && (work[i + 2] <= TOLERANCE_2 * sigma)) { // insert a split work[i + 2]  = -sigma; split        = i / 4; diagMax      = 0; offDiagMin   = work[i + 6]; previousEMin = work[i + 7]; } else { diagMax      = Math.max(diagMax, work[i + 4]); offDiagMin   = Math.min(offDiagMin, work[i + 2]); previousEMin = Math.min(previousEMin, work[i + 3]); } } work[4 * n0 - 2] = offDiagMin; work[4 * n0 - 1] = previousEMin; i0 = split + 1; } }  }  }
 private void processGeneralBlock(final int n) throws InvalidMatrixException {  // check decomposed matrix data range double sumOffDiag = 0; for (int i = 0; i < n - 1; ++i) { final int fourI = 4 * i; final double ei = work[fourI + 2]; sumOffDiag += ei; }  if (sumOffDiag == 0) { // matrix is already diagonal return; }  // initial checks for splits (see Parlett & Marques section 3.3) flipIfWarranted(n, 2);  // two iterations with Li's test for initial splits initialSplits(n);  // initialize parameters used by goodStep tType = 0; dMin1 = 0; dMin2 = 0; dN    = 0; dN1   = 0; dN2   = 0; tau   = 0;  // process split segments int i0 = 0; int n0 = n; while (n0 > 0) {  // retrieve shift that was temporarily stored as a negative off-diagonal element sigma    = (n0 == n) ? 0 : -work[4 * n0 - 2]; sigmaLow = 0;  // find start of a new split segment to process double offDiagMin = (i0 == n0) ? 0 : work[4 * n0 - 6]; double offDiagMax = 0; double diagMax    = work[4 * n0 - 4]; double diagMin    = diagMax; i0 = 0; for (int i = 4 * (n0 - 2); i >= 0; i -= 4) { if (work[i + 2] <= 0) { i0 = 1 + i / 4; break; } if (diagMin >= 4 * offDiagMax) { diagMin    = Math.min(diagMin, work[i + 4]); offDiagMax = Math.max(offDiagMax, work[i + 2]); } diagMax    = Math.max(diagMax, work[i] + work[i + 2]); offDiagMin = Math.min(offDiagMin, work[i + 2]); } work[4 * n0 - 2] = offDiagMin;  // lower bound of Gershgorin disk dMin = -Math.max(0, diagMin - 2 * Math.sqrt(diagMin * offDiagMax));  pingPong = 0; int maxIter = 30 * (n0 - i0); for (int k = 0; i0 < n0; ++k) { if (k >= maxIter) { throw new InvalidMatrixException(new MaxIterationsExceededException(maxIter)); }  // perform one step n0 = goodStep(i0, n0); pingPong = 1 - pingPong;  // check for new splits after "ping" steps // when the last elements of qd array are very small if ((pingPong == 0) && (n0 - i0 > 3) && (work[4 * n0 - 1] <= TOLERANCE_2 * diagMax) && (work[4 * n0 - 2] <= TOLERANCE_2 * sigma)) { int split  = i0 - 1; diagMax    = work[4 * i0]; offDiagMin = work[4 * i0 + 2]; double previousEMin = work[4 * i0 + 3]; for (int i = 4 * i0; i < 4 * n0 - 11; i += 4) { if ((work[i + 3] <= TOLERANCE_2 * work[i]) && (work[i + 2] <= TOLERANCE_2 * sigma)) { // insert a split work[i + 2]  = -sigma; split        = i / 4; diagMax      = 0; offDiagMin   = work[i + 6]; previousEMin = work[i + 7]; } else { diagMax      = Math.max(diagMax, work[i + 4]); offDiagMin   = Math.min(offDiagMin, work[i + 2]); previousEMin = Math.min(previousEMin, work[i + 3]); } } work[4 * n0 - 2] = offDiagMin; work[4 * n0 - 1] = previousEMin; i0 = split + 1; } }  }  }
 public Complex reciprocal() { if (isNaN) { return NaN; }  if (real == 0.0 && imaginary == 0.0) { return NaN; }  if (isInfinite) { return ZERO; }  if (FastMath.abs(real) < FastMath.abs(imaginary)) { double q = real / imaginary; double scale = 1. / (real * q + imaginary); return createComplex(scale * q, -scale); } else { double q = imaginary / real; double scale = 1. / (imaginary * q + real); return createComplex(scale, -scale * q); } }
 private static StringBuilder escapeRegex(StringBuilder regex, String value, boolean unquote) { boolean wasWhite= false; for(int i= 0; i<value.length(); ++i) { char c= value.charAt(i); if(Character.isWhitespace(c)) { if(!wasWhite) { wasWhite= true; regex.append("\\s*+"); } continue; } wasWhite= false; switch(c) { case '\'': if(unquote) { if(++i==value.length()) { return regex; } c= value.charAt(i); } break; case '?': case '[': case ']': case '(': case ')': case '{': case '}': case '\\': case '|': case '*': case '+': case '^': case '$': case '.': regex.append('\\'); } regex.append(c); } return regex; }
 private static StringBuilder escapeRegex(StringBuilder regex, String value, boolean unquote) { boolean wasWhite= false; for(int i= 0; i<value.length(); ++i) { char c= value.charAt(i); if(Character.isWhitespace(c)) { if(!wasWhite) { wasWhite= true; regex.append("\\s*+"); } continue; } wasWhite= false; switch(c) { case '\'': if(unquote) { if(++i==value.length()) { return regex; } c= value.charAt(i); } break; case '?': case '[': case ']': case '(': case ')': case '{': case '}': case '\\': case '|': case '*': case '+': case '^': case '$': case '.': regex.append('\\'); } regex.append(c); } return regex; }
 private boolean canInline( Reference declaration, Reference initialization, Reference reference) { if (!isValidDeclaration(declaration) || !isValidInitialization(initialization) || !isValidReference(reference)) { return false; }  // If the value is read more than once, skip it. // VAR declarations and EXPR_RESULT don't need the value, but other // ASSIGN expressions parents do. if (declaration != initialization && !initialization.getGrandparent().isExprResult()) { return false; }  // Be very conservative and do no cross control structures or // scope boundaries if (declaration.getBasicBlock() != initialization.getBasicBlock() || declaration.getBasicBlock() != reference.getBasicBlock()) { return false; }  // Do not inline into a call node. This would change // the context in which it was being called. For example, //   var a = b.c; //   a(); // should not be inlined, because it calls a in the context of b // rather than the context of the window. //   var a = b.c; //   f(a) // is ok. Node value = initialization.getAssignedValue(); Preconditions.checkState(value != null); if (value.isGetProp() && reference.getParent().isCall() && reference.getParent().getFirstChild() == reference.getNode()) { return false; }  if (value.isFunction()) { Node callNode = reference.getParent(); if (reference.getParent().isCall()) { CodingConvention convention = compiler.getCodingConvention(); // Bug 2388531: Don't inline subclass definitions into class defining // calls as this confused class removing logic. SubclassRelationship relationship = convention.getClassesDefinedByCall(callNode); if (relationship != null) { return false; }  // issue 668: Don't inline singleton getter methods // calls as this confused class removing logic. } }  return canMoveAggressively(value) || canMoveModerately(initialization, reference); }
 public int parseInto(DateTimeParserBucket bucket, String text, int position) { String str = text.substring(position); for (String id : ALL_IDS) { if (str.startsWith(id)) { bucket.setZone(DateTimeZone.forID(id)); return position + id.length(); } } return ~position; }
 public int parseInto(DateTimeParserBucket bucket, String text, int position) { String str = text.substring(position); for (String id : ALL_IDS) { if (str.startsWith(id)) { bucket.setZone(DateTimeZone.forID(id)); return position + id.length(); } } return ~position; }
 public OpenMapRealVector ebeDivide(RealVector v) { checkVectorDimensions(v.getDimension()); OpenMapRealVector res = new OpenMapRealVector(this); Iterator iter = res.entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() / v.getEntry(iter.key())); } return res; }
 public OpenMapRealVector ebeDivide(double[] v) { checkVectorDimensions(v.length); OpenMapRealVector res = new OpenMapRealVector(this); Iterator iter = res.entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() / v[iter.key()]); } return res; }
 public OpenMapRealVector ebeMultiply(RealVector v) { checkVectorDimensions(v.getDimension()); OpenMapRealVector res = new OpenMapRealVector(this); Iterator iter = res.entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() * v.getEntry(iter.key())); } return res; }
 public OpenMapRealVector ebeMultiply(double[] v) { checkVectorDimensions(v.length); OpenMapRealVector res = new OpenMapRealVector(this); Iterator iter = res.entries.iterator(); while (iter.hasNext()) { iter.advance(); res.setEntry(iter.key(), iter.value() * v[iter.key()]); } return res; }
 public void validate(Answer<?> answer, Invocation invocation) { if (answer instanceof ThrowsException) { validateException((ThrowsException) answer, invocation); }  if (answer instanceof Returns) { validateReturnValue((Returns) answer, invocation); }  if (answer instanceof DoesNothing) { validateDoNothing((DoesNothing) answer, invocation); }  }
 public int calculatePrintedLength(ReadablePeriod period, Locale locale) { long valueLong = getFieldValue(period); if (valueLong == Long.MAX_VALUE) { return 0; }  int sum = Math.max(FormatUtils.calculateDigitCount(valueLong), iMinPrintedDigits); if (iFieldType >= SECONDS_MILLIS) { // valueLong contains the seconds and millis fields // the minimum output is 0.000, which is 4 or 5 digits with a negative sum = Math.max(sum, 4); // plus one for the decimal point sum++; if (iFieldType == SECONDS_OPTIONAL_MILLIS && (Math.abs(valueLong) % DateTimeConstants.MILLIS_PER_SECOND) == 0) { sum -= 4; // remove three digits and decimal point } // reset valueLong to refer to the seconds part for the prefic/suffix calculation valueLong = valueLong / DateTimeConstants.MILLIS_PER_SECOND; } int value = (int) valueLong;  if (iPrefix != null) { sum += iPrefix.calculatePrintedLength(value); } if (iSuffix != null) { sum += iSuffix.calculatePrintedLength(value); }  return sum; }
 public void printTo(StringBuffer buf, ReadablePeriod period, Locale locale) { long valueLong = getFieldValue(period); if (valueLong == Long.MAX_VALUE) { return; } int value = (int) valueLong; if (iFieldType >= SECONDS_MILLIS) { value = (int) (valueLong / DateTimeConstants.MILLIS_PER_SECOND); }  if (iPrefix != null) { iPrefix.printTo(buf, value); } int minDigits = iMinPrintedDigits; if (minDigits <= 1) { FormatUtils.appendUnpaddedInteger(buf, value); } else { FormatUtils.appendPaddedInteger(buf, value, minDigits); } if (iFieldType >= SECONDS_MILLIS) { int dp = (int) (Math.abs(valueLong) % DateTimeConstants.MILLIS_PER_SECOND); if (iFieldType == SECONDS_MILLIS || dp > 0) { buf.append('.'); FormatUtils.appendPaddedInteger(buf, dp, 3); } } if (iSuffix != null) { iSuffix.printTo(buf, value); } }
 public Complex add(Complex rhs) throws NullArgumentException { MathUtils.checkNotNull(rhs); return createComplex(real + rhs.getReal(), imaginary + rhs.getImaginary()); }
 public double solve(final UnivariateRealFunction f, double min, double max, double initial) throws MaxIterationsExceededException, FunctionEvaluationException { return solve(min, max); }
 public void enterScope(NodeTraversal t) { Node declarationRoot = t.getScopeRoot(); Renamer renamer; if (nameStack.isEmpty()) { // If the contextual renamer is being used the starting context can not // be a function. Preconditions.checkState( declarationRoot.getType() != Token.FUNCTION || !(rootRenamer instanceof ContextualRenamer)); Preconditions.checkState(t.inGlobalScope()); renamer = rootRenamer; } else { renamer = nameStack.peek().forChildScope(); }  if (declarationRoot.getType() == Token.FUNCTION) { for (Node c = declarationRoot.getFirstChild().getNext().getFirstChild(); c != null; c = c.getNext()) { String name = c.getString(); renamer.addDeclaredName(name); } Node functionBody = declarationRoot.getLastChild(); findDeclaredNames(functionBody, null, renamer); }  else if (declarationRoot.getType() != Token.FUNCTION) { // Add the block declarations findDeclaredNames(declarationRoot, null, renamer); } nameStack.push(renamer); }
 public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {  switch (n.getType()) { case Token.FUNCTION: { // Add recursive function name, if needed. // NOTE: "enterScope" is called after we need to pick up this name. Renamer renamer = nameStack.peek().forChildScope();  // If needed, add the function recursive name. String name = n.getFirstChild().getString(); if (name != null && !name.isEmpty() && parent != null && !NodeUtil.isFunctionDeclaration(n)) { renamer.addDeclaredName(name); }    // Add the function parameters  // Add the function body declarations  nameStack.push(renamer); } break;  case Token.CATCH: { Renamer renamer = nameStack.peek().forChildScope();  String name = n.getFirstChild().getString(); renamer.addDeclaredName(name);  nameStack.push(renamer); } break; }  return true; }
 private void checkParameters() { final double[] init = getStartPoint(); final double[] lB = getLowerBound(); final double[] uB = getUpperBound();  // Checks whether there is at least one finite bound value. boolean hasFiniteBounds = false; for (int i = 0; i < lB.length; i++) { if (!Double.isInfinite(lB[i]) || !Double.isInfinite(uB[i])) { hasFiniteBounds = true; break; } } // Checks whether there is at least one infinite bound value. boolean hasInfiniteBounds = false; if (hasFiniteBounds) { for (int i = 0; i < lB.length; i++) { if (Double.isInfinite(lB[i]) || Double.isInfinite(uB[i])) { hasInfiniteBounds = true; break; } }  if (hasInfiniteBounds) { // If there is at least one finite bound, none can be infinite, // because mixed cases are not supported by the current code. throw new MathUnsupportedOperationException(); } else { // Convert API to internal handling of boundaries. boundaries = new double[2][]; boundaries[0] = lB; boundaries[1] = uB;  // Abort early if the normalization will overflow (cf. "encode" method). } } else { // Convert API to internal handling of boundaries. boundaries = null; }  if (inputSigma != null) { if (inputSigma.length != init.length) { throw new DimensionMismatchException(inputSigma.length, init.length); } for (int i = 0; i < init.length; i++) { if (inputSigma[i] < 0) { throw new NotPositiveException(inputSigma[i]); } if (boundaries != null) { if (inputSigma[i] > boundaries[1][i] - boundaries[0][i]) { throw new OutOfRangeException(inputSigma[i], 0, boundaries[1][i] - boundaries[0][i]); } } } } }
 public double evaluate(double x, double epsilon, int maxIterations) { final double small = 1e-50; double hPrev = getA(0, x);  // use the value of small as epsilon criteria for zero checks if (Precision.equals(hPrev, 0.0, small)) { hPrev = small; }  int n = 1; double dPrev = 0.0; double p0 = 1.0; double q1 = 1.0; double cPrev = hPrev; double hN = hPrev;  while (n < maxIterations) { final double a = getA(n, x); final double b = getB(n, x);  double cN = a * hPrev + b * p0; double q2 = a * q1 + b * dPrev; if (Double.isInfinite(cN) || Double.isInfinite(q2)) { double scaleFactor = 1d; double lastScaleFactor = 1d; final int maxPower = 5; final double scale = FastMath.max(a,b); if (scale <= 0) {  // Can't scale throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x); } for (int i = 0; i < maxPower; i++) { lastScaleFactor = scaleFactor; scaleFactor *= scale; if (a != 0.0 && a > b) { cN = hPrev / lastScaleFactor + (b / scaleFactor * p0); q2 = q1 / lastScaleFactor + (b / scaleFactor * dPrev); } else if (b != 0) { cN = (a / scaleFactor * hPrev) + p0 / lastScaleFactor; q2 = (a / scaleFactor * q1) + dPrev / lastScaleFactor; } if (!(Double.isInfinite(cN) || Double.isInfinite(q2))) { break; } } }  final double deltaN = cN / q2 / cPrev; hN = cPrev * deltaN;  if (Double.isInfinite(hN)) { throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x); } if (Double.isNaN(hN)) { throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_NAN_DIVERGENCE, x); }  if (FastMath.abs(deltaN - 1.0) < epsilon) { break; }  dPrev = q1; cPrev = cN / q2; p0 = hPrev; hPrev = cN; q1 = q2; n++; }  if (n >= maxIterations) { throw new MaxCountExceededException(LocalizedFormats.NON_CONVERGENT_CONTINUED_FRACTION, maxIterations, x); }  return hN; }
 public double evaluate(double x, double epsilon, int maxIterations) { final double small = 1e-50; double hPrev = getA(0, x);  // use the value of small as epsilon criteria for zero checks if (Precision.equals(hPrev, 0.0, small)) { hPrev = small; }  int n = 1; double dPrev = 0.0; double p0 = 1.0; double q1 = 1.0; double cPrev = hPrev; double hN = hPrev;  while (n < maxIterations) { final double a = getA(n, x); final double b = getB(n, x);  double cN = a * hPrev + b * p0; double q2 = a * q1 + b * dPrev; if (Double.isInfinite(cN) || Double.isInfinite(q2)) { double scaleFactor = 1d; double lastScaleFactor = 1d; final int maxPower = 5; final double scale = FastMath.max(a,b); if (scale <= 0) {  // Can't scale throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x); } for (int i = 0; i < maxPower; i++) { lastScaleFactor = scaleFactor; scaleFactor *= scale; if (a != 0.0 && a > b) { cN = hPrev / lastScaleFactor + (b / scaleFactor * p0); q2 = q1 / lastScaleFactor + (b / scaleFactor * dPrev); } else if (b != 0) { cN = (a / scaleFactor * hPrev) + p0 / lastScaleFactor; q2 = (a / scaleFactor * q1) + dPrev / lastScaleFactor; } if (!(Double.isInfinite(cN) || Double.isInfinite(q2))) { break; } } }  final double deltaN = cN / q2 / cPrev; hN = cPrev * deltaN;  if (Double.isInfinite(hN)) { throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x); } if (Double.isNaN(hN)) { throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_NAN_DIVERGENCE, x); }  if (FastMath.abs(deltaN - 1.0) < epsilon) { break; }  dPrev = q1; cPrev = cN / q2; p0 = hPrev; hPrev = cN; q1 = q2; n++; }  if (n >= maxIterations) { throw new MaxCountExceededException(LocalizedFormats.NON_CONVERGENT_CONTINUED_FRACTION, maxIterations, x); }  return hN; }
 public LookupTranslator(final CharSequence[]... lookup) { lookupMap = new HashMap<CharSequence, CharSequence>(); int _shortest = Integer.MAX_VALUE; int _longest = 0; if (lookup != null) { for (final CharSequence[] seq : lookup) { this.lookupMap.put(seq[0], seq[1]); final int sz = seq[0].length(); if (sz < _shortest) { _shortest = sz; } if (sz > _longest) { _longest = sz; } } } shortest = _shortest; longest = _longest; }
 public int translate(final CharSequence input, final int index, final Writer out) throws IOException { int max = longest; if (index + longest > input.length()) { max = input.length() - index; } // descend so as to get a greedy algorithm for (int i = max; i >= shortest; i--) { final CharSequence subSeq = input.subSequence(index, index + i); final CharSequence result = lookupMap.get(subSeq); if (result != null) { out.write(result.toString()); return i; } } return 0; }
 protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException { String name = desc.getName(); try { return Class.forName(name, false, classLoader); } catch (ClassNotFoundException ex) { return Class.forName(name, false, Thread.currentThread().getContextClassLoader()); } }
 public int compareTo(Object other) { return iValue - ((ValuedEnum) other).iValue; }
 public MultiplePiePlot(CategoryDataset dataset) { super(); this.dataset = dataset; PiePlot piePlot = new PiePlot(null); this.pieChart = new JFreeChart(piePlot); this.pieChart.removeLegend(); this.dataExtractOrder = TableOrder.BY_COLUMN; this.pieChart.setBackgroundPaint(null); TextTitle seriesTitle = new TextTitle("Series Title", new Font("SansSerif", Font.BOLD, 12)); seriesTitle.setPosition(RectangleEdge.BOTTOM); this.pieChart.setTitle(seriesTitle); this.aggregatedItemsKey = "Other"; this.aggregatedItemsPaint = Color.lightGray; this.sectionPaints = new HashMap(); }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; while (true) {  incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals);  // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return new VectorialPointValuePair(point, objective); }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm);  // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost();  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm); } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; }  // tests for convergence. // we use the vectorial convergence checker // we use the Levenberg-Marquardt specific convergence parameters if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return new VectorialPointValuePair(point, objective); }  // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException("cost relative tolerance is too small ({0})," + " no further reduction in the" + " sum of squares is possible", costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException("parameters relative tolerance is too small" + " ({0}), no further improvement in" + " the approximate solution is possible", parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException("orthogonality tolerance is too small ({0})," + " solution is orthogonal to the jacobian", orthoTolerance); }  }  }  }
 protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {  // arrays shared with the other private methods solvedCols  = Math.min(rows, cols); diagR       = new double[cols]; jacNorm     = new double[cols]; beta        = new double[cols]; permutation = new int[cols]; lmDir       = new double[cols];  // local point double   delta   = 0; double   xNorm   = 0; double[] diag    = new double[cols]; double[] oldX    = new double[cols]; double[] oldRes  = new double[rows]; double[] work1   = new double[cols]; double[] work2   = new double[cols]; double[] work3   = new double[cols];  // evaluate the function at the starting point and calculate its norm updateResidualsAndCost();  // outer loop lmPar = 0; boolean firstIteration = true; while (true) {  incrementIterationsCounter();  // compute the Q.R. decomposition of the jacobian matrix updateJacobian(); qrDecomposition();  // compute Qt.res qTy(residuals);  // now we don't need Q anymore, // so let jacobian contain the R matrix with its diagonal elements for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; }  if (firstIteration) {  // scale the point according to the norms of the columns // of the initial jacobian xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm  += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm);  // initialize the step bound delta delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);  }  // check orthogonality between function vector and jacobian columns double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int    pj = permutation[j]; double s  = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { // convergence has been reached return new VectorialPointValuePair(point, objective); }  // rescale if necessary for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); }  // inner loop for (double ratio = 0; ratio < 1.0e-4;) {  // save the state for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes    = tmpVec;  // determine the Levenberg-Marquardt parameter determineLMParameter(oldRes, delta, diag, work1, work2, work3);  // compute the new point and the norm of the evolution direction double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm  += s * s; } lmNorm = Math.sqrt(lmNorm);  // on the first iteration, adjust the initial step bound. if (firstIteration) { delta = Math.min(delta, lmNorm); }  // evaluate the function at x + p and calculate its norm updateResidualsAndCost();  // compute the scaled actual reduction double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; }  // compute the scaled predicted reduction // and the scaled directional derivative for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2);  // ratio of the actual to the predicted reduction ratio = (preRed == 0) ? 0 : (actRed / preRed);  // update the step bound if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; }  // test for successful iteration. if (ratio >= 1.0e-4) { // successful iteration, update the norm firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm    += xK * xK; } xNorm = Math.sqrt(xNorm); } else { // failed iteration, reset the previous values cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec    = residuals; residuals = oldRes; oldRes    = tmpVec; }  // tests for convergence. // we use the vectorial convergence checker // we use the Levenberg-Marquardt specific convergence parameters if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return new VectorialPointValuePair(point, objective); }  // tests for termination and stringent tolerances // (2.2204e-16 is the machine epsilon for IEEE754) if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException("cost relative tolerance is too small ({0})," + " no further reduction in the" + " sum of squares is possible", costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException("parameters relative tolerance is too small" + " ({0}), no further improvement in" + " the approximate solution is possible", parRelativeTolerance); } else if (maxCosine <= 2.2204e-16)  { throw new OptimizationException("orthogonality tolerance is too small ({0})," + " solution is orthogonal to the jacobian", orthoTolerance); }  }  }  }
 protected Dfp(final DfpField field, double x) {  // initialize as if 0 mant = new int[field.getRadixDigits()]; sign = 1; exp = 0; nans = FINITE; this.field = field;  long bits = Double.doubleToLongBits(x); long mantissa = bits & 0x000fffffffffffffL; int exponent = (int) ((bits & 0x7ff0000000000000L) >> 52) - 1023;  if (exponent == -1023) { // Zero or sub-normal if (x == 0) { // make sure 0 has the right sign return; }  exponent++;  // Normalize the subnormal number while ( (mantissa & 0x0010000000000000L) == 0) { exponent--; mantissa <<= 1; } mantissa &= 0x000fffffffffffffL; }  if (exponent == 1024) { // infinity or NAN if (x != x) { sign = (byte) 1; nans = QNAN; } else if (x < 0) { sign = (byte) -1; nans = INFINITE; } else { sign = (byte) 1; nans = INFINITE; } return; }  Dfp xdfp = new Dfp(field, mantissa); xdfp = xdfp.divide(new Dfp(field, 4503599627370496l)).add(field.getOne());  // Divide by 2^52, then add one xdfp = xdfp.multiply(DfpMath.pow(field.getTwo(), exponent));  if ((bits & 0x8000000000000000L) != 0) { xdfp = xdfp.negate(); }  System.arraycopy(xdfp.mant, 0, mant, 0, mant.length); sign = xdfp.sign; exp  = xdfp.exp; nans = xdfp.nans;  }
 public double toDouble() {  if (isInfinite()) { if (lessThan(getZero())) { return Double.NEGATIVE_INFINITY; } else { return Double.POSITIVE_INFINITY; } }  if (isNaN()) { return Double.NaN; }  Dfp y = this; boolean negate = false; if (lessThan(getZero())) { y = negate(); negate = true; }  /* Find the exponent, first estimate by integer log10, then adjust. Should be faster than doing a natural logarithm.  */ int exponent = (int)(y.log10() * 3.32); if (exponent < 0) { exponent--; }  Dfp tempDfp = DfpMath.pow(getTwo(), exponent); while (tempDfp.lessThan(y) || tempDfp.equals(y)) { tempDfp = tempDfp.multiply(2); exponent++; } exponent--;  /* We have the exponent, now work on the mantissa */  y = y.divide(DfpMath.pow(getTwo(), exponent)); if (exponent > -1023) { y = y.subtract(getOne()); }  if (exponent < -1074) { return 0; }  if (exponent > 1023) { return negate ? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY; }   y = y.multiply(newInstance(4503599627370496l)).rint(); String str = y.toString(); str = str.substring(0, str.length()-1); long mantissa = Long.parseLong(str);  if (mantissa == 4503599627370496L) { // Handle special case where we round up to next power of two mantissa = 0; exponent++; }  /* Its going to be subnormal, so make adjustments */ if (exponent <= -1023) { exponent--; }  while (exponent < -1023) { exponent++; mantissa >>>= 1; }  long bits = mantissa | ((exponent + 1023L) << 52); double x = Double.longBitsToDouble(bits);  if (negate) { x = -x; }  return x;  }
 void add(String newcode) { maybeEndStatement();  if (newcode.length() == 0) { return; }  char c = newcode.charAt(0); if ((isWordChar(c) || c == '\\') && isWordChar(getLastChar())) { // need space to separate. This is not pretty printing. // For example: "return foo;" append(" "); // Do not allow a forward slash to appear after a DIV. // For example, // REGEXP DIV REGEXP // is valid and should print like // / // / / }  append(newcode); }
 public double chiSquare(double[] expected, long[] observed) throws IllegalArgumentException { if ((expected.length < 2) || (expected.length != observed.length)) { throw new IllegalArgumentException( "observed, expected array lengths incorrect"); } if (!isPositive(expected) || !isNonNegative(observed)) { throw new IllegalArgumentException( "observed counts must be non-negative and expected counts must be postive"); } double sumSq = 0.0d; double dev = 0.0d; for (int i = 0; i < observed.length; i++) { dev = ((double) observed[i] - expected[i]); sumSq += dev * dev / expected[i]; } return sumSq; }
 public void visit(NodeTraversal t, Node n, Node parent) { // VOID nodes appear when there are extra semicolons at the BLOCK level. // I've been unable to think of any cases where this indicates a bug, // and apparently some people like keeping these semicolons around, // so we'll allow it. if (n.isEmpty() || n.isComma()) { return; }  if (parent == null) { return; }  // Do not try to remove a block or an expr result. We already handle // these cases when we visit the child, and the peephole passes will // fix up the tree in more clever ways when these are removed. if (parent.getType() == Token.COMMA) { Node gramps = parent.getParent(); if (gramps.isCall() && parent == gramps.getFirstChild()) { if (n == parent.getFirstChild() && parent.getChildCount() == 2 && n.getNext().isName() && "eval".equals(n.getNext().getString())) { return; } }  // This no-op statement was there so that JSDoc information could // be attached to the name. This check should not complain about it. if (n == parent.getLastChild()) { for (Node an : parent.getAncestors()) { int ancestorType = an.getType(); if (ancestorType == Token.COMMA) continue; if (ancestorType != Token.EXPR_RESULT && ancestorType != Token.BLOCK) return; else break; } } } else if (parent.getType() != Token.EXPR_RESULT && parent.getType() != Token.BLOCK) { if (parent.getType() == Token.FOR && parent.getChildCount() == 4 && (n == parent.getFirstChild() || n == parent.getFirstChild().getNext().getNext())) { } else { return; } }  boolean isResultUsed = NodeUtil.isExpressionResultUsed(n); boolean isSimpleOp = NodeUtil.isSimpleOperatorType(n.getType()); if (!isResultUsed && (isSimpleOp || !NodeUtil.mayHaveSideEffects(n, t.getCompiler()))) { if (n.isQualifiedName() && n.getJSDocInfo() != null) { return; } else if (n.isExprResult()) { return; } String msg = "This code lacks side-effects. Is there a bug?"; if (n.isString()) { msg = "Is there a missing '+' on the previous line?"; } else if (isSimpleOp) { msg = "The result of the '" + Token.name(n.getType()).toLowerCase() + "' operator is not being used."; }  t.getCompiler().report( t.makeError(n, level, USELESS_CODE_ERROR, msg)); // TODO(johnlenz): determine if it is necessary to // try to protect side-effect free statements as well. if (!NodeUtil.isStatement(n)) { problemNodes.add(n); } } }
 public void visit(NodeTraversal t, Node n, Node parent) { // VOID nodes appear when there are extra semicolons at the BLOCK level. // I've been unable to think of any cases where this indicates a bug, // and apparently some people like keeping these semicolons around, // so we'll allow it. if (n.isEmpty() || n.isComma()) { return; }  if (parent == null) { return; }  // Do not try to remove a block or an expr result. We already handle // these cases when we visit the child, and the peephole passes will // fix up the tree in more clever ways when these are removed. if (parent.getType() == Token.COMMA) { Node gramps = parent.getParent(); if (gramps.isCall() && parent == gramps.getFirstChild()) { if (n == parent.getFirstChild() && parent.getChildCount() == 2 && n.getNext().isName() && "eval".equals(n.getNext().getString())) { return; } }  // This no-op statement was there so that JSDoc information could // be attached to the name. This check should not complain about it. if (n == parent.getLastChild()) { for (Node an : parent.getAncestors()) { int ancestorType = an.getType(); if (ancestorType == Token.COMMA) continue; if (ancestorType != Token.EXPR_RESULT && ancestorType != Token.BLOCK) return; else break; } } } else if (parent.getType() != Token.EXPR_RESULT && parent.getType() != Token.BLOCK) { if (parent.getType() == Token.FOR && parent.getChildCount() == 4 && (n == parent.getFirstChild() || n == parent.getFirstChild().getNext().getNext())) { } else { return; } }  boolean isResultUsed = NodeUtil.isExpressionResultUsed(n); boolean isSimpleOp = NodeUtil.isSimpleOperatorType(n.getType()); if (!isResultUsed && (isSimpleOp || !NodeUtil.mayHaveSideEffects(n, t.getCompiler()))) { if (n.isQualifiedName() && n.getJSDocInfo() != null) { return; } else if (n.isExprResult()) { return; } String msg = "This code lacks side-effects. Is there a bug?"; if (n.isString()) { msg = "Is there a missing '+' on the previous line?"; } else if (isSimpleOp) { msg = "The result of the '" + Token.name(n.getType()).toLowerCase() + "' operator is not being used."; }  t.getCompiler().report( t.makeError(n, level, USELESS_CODE_ERROR, msg)); // TODO(johnlenz): determine if it is necessary to // try to protect side-effect free statements as well. if (!NodeUtil.isStatement(n)) { problemNodes.add(n); } } }
 public void visit(NodeTraversal t, Node n, Node parent) { // VOID nodes appear when there are extra semicolons at the BLOCK level. // I've been unable to think of any cases where this indicates a bug, // and apparently some people like keeping these semicolons around, // so we'll allow it. if (n.isEmpty() || n.isComma()) { return; }  if (parent == null) { return; }  // Do not try to remove a block or an expr result. We already handle // these cases when we visit the child, and the peephole passes will // fix up the tree in more clever ways when these are removed. if (parent.getType() == Token.COMMA) { Node gramps = parent.getParent(); if (gramps.isCall() && parent == gramps.getFirstChild()) { if (n == parent.getFirstChild() && parent.getChildCount() == 2 && n.getNext().isName() && "eval".equals(n.getNext().getString())) { return; } }  // This no-op statement was there so that JSDoc information could // be attached to the name. This check should not complain about it. if (n == parent.getLastChild()) { for (Node an : parent.getAncestors()) { int ancestorType = an.getType(); if (ancestorType == Token.COMMA) continue; if (ancestorType != Token.EXPR_RESULT && ancestorType != Token.BLOCK) return; else break; } } } else if (parent.getType() != Token.EXPR_RESULT && parent.getType() != Token.BLOCK) { if (parent.getType() == Token.FOR && parent.getChildCount() == 4 && (n == parent.getFirstChild() || n == parent.getFirstChild().getNext().getNext())) { } else { return; } }  boolean isResultUsed = NodeUtil.isExpressionResultUsed(n); boolean isSimpleOp = NodeUtil.isSimpleOperatorType(n.getType()); if (!isResultUsed && (isSimpleOp || !NodeUtil.mayHaveSideEffects(n, t.getCompiler()))) { if (n.isQualifiedName() && n.getJSDocInfo() != null) { return; } else if (n.isExprResult()) { return; } String msg = "This code lacks side-effects. Is there a bug?"; if (n.isString()) { msg = "Is there a missing '+' on the previous line?"; } else if (isSimpleOp) { msg = "The result of the '" + Token.name(n.getType()).toLowerCase() + "' operator is not being used."; }  t.getCompiler().report( t.makeError(n, level, USELESS_CODE_ERROR, msg)); // TODO(johnlenz): determine if it is necessary to // try to protect side-effect free statements as well. if (!NodeUtil.isStatement(n)) { problemNodes.add(n); } } }
 public static boolean toBoolean(String str) { // Previously used equalsIgnoreCase, which was fast for interned 'true'. // Non interned 'true' matched 15 times slower. // // Optimisation provides same performance as before for interned 'true'. // Similar performance for null, 'false', and other strings not length 2/3/4. // 'true'/'TRUE' match 4 times slower, 'tRUE'/'True' 7 times slower. if (str == "true") { return true; } if (str == null) { return false; } switch (str.length()) { case 2: { char ch0 = str.charAt(0); char ch1 = str.charAt(1); return (ch0 == 'o' || ch0 == 'O') && (ch1 == 'n' || ch1 == 'N'); } case 3: { char ch = str.charAt(0); if (ch == 'y') { return (str.charAt(1) == 'e' || str.charAt(1) == 'E') && (str.charAt(2) == 's' || str.charAt(2) == 'S'); } if (ch == 'Y') { return (str.charAt(1) == 'E' || str.charAt(1) == 'e') && (str.charAt(2) == 'S' || str.charAt(2) == 's'); } } case 4: { char ch = str.charAt(0); if (ch == 't') { return (str.charAt(1) == 'r' || str.charAt(1) == 'R') && (str.charAt(2) == 'u' || str.charAt(2) == 'U') && (str.charAt(3) == 'e' || str.charAt(3) == 'E'); } if (ch == 'T') { return (str.charAt(1) == 'R' || str.charAt(1) == 'r') && (str.charAt(2) == 'U' || str.charAt(2) == 'u') && (str.charAt(3) == 'E' || str.charAt(3) == 'e'); } } } return false; }
 public static boolean toBoolean(String str) { // Previously used equalsIgnoreCase, which was fast for interned 'true'. // Non interned 'true' matched 15 times slower. // // Optimisation provides same performance as before for interned 'true'. // Similar performance for null, 'false', and other strings not length 2/3/4. // 'true'/'TRUE' match 4 times slower, 'tRUE'/'True' 7 times slower. if (str == "true") { return true; } if (str == null) { return false; } switch (str.length()) { case 2: { char ch0 = str.charAt(0); char ch1 = str.charAt(1); return (ch0 == 'o' || ch0 == 'O') && (ch1 == 'n' || ch1 == 'N'); } case 3: { char ch = str.charAt(0); if (ch == 'y') { return (str.charAt(1) == 'e' || str.charAt(1) == 'E') && (str.charAt(2) == 's' || str.charAt(2) == 'S'); } if (ch == 'Y') { return (str.charAt(1) == 'E' || str.charAt(1) == 'e') && (str.charAt(2) == 'S' || str.charAt(2) == 's'); } } case 4: { char ch = str.charAt(0); if (ch == 't') { return (str.charAt(1) == 'r' || str.charAt(1) == 'R') && (str.charAt(2) == 'u' || str.charAt(2) == 'U') && (str.charAt(3) == 'e' || str.charAt(3) == 'E'); } if (ch == 'T') { return (str.charAt(1) == 'R' || str.charAt(1) == 'r') && (str.charAt(2) == 'U' || str.charAt(2) == 'u') && (str.charAt(3) == 'E' || str.charAt(3) == 'e'); } } } return false; }
 public static Node tryCatch(Node tryBody, Node catchNode) { Preconditions.checkState(tryBody.isBlock()); Preconditions.checkState(catchNode.isCatch()); Node catchBody = block(catchNode).copyInformationFrom(catchNode); return new Node(Token.TRY, tryBody, catchBody); }
 public static Node tryFinally(Node tryBody, Node finallyBody) { Preconditions.checkState(tryBody.isLabelName()); Preconditions.checkState(finallyBody.isLabelName()); Node catchBody = block().copyInformationFrom(tryBody); return new Node(Token.TRY, tryBody, catchBody, finallyBody); }
 private CanInlineResult canInlineReferenceDirectly( Node callNode, Node fnNode) { if (!isDirectCallNodeReplacementPossible(fnNode)) { return CanInlineResult.NO; }  Node block = fnNode.getLastChild();   // CALL NODE: [ NAME, ARG1, ARG2, ... ] Node cArg = callNode.getFirstChild().getNext();  // Functions called via 'call' and 'apply' have a this-object as // the first parameter, but this is not part of the called function's // parameter list. if (!callNode.getFirstChild().isName()) { if (NodeUtil.isFunctionObjectCall(callNode)) { // TODO(johnlenz): Support replace this with a value. if (cArg == null || !cArg.isThis()) { return CanInlineResult.NO; } cArg = cArg.getNext(); } else { // ".apply" call should be filtered before this. Preconditions.checkState(!NodeUtil.isFunctionObjectApply(callNode)); } }  // FUNCTION NODE -> LP NODE: [ ARG1, ARG2, ... ] Node fnParam = NodeUtil.getFunctionParameters(fnNode).getFirstChild(); while (cArg != null || fnParam != null) { // For each named parameter check if a mutable argument use more than one. if (fnParam != null) { if (cArg != null) {  // Check for arguments that are evaluated more than once. // Note: Unlike block inlining, there it is not possible that a // parameter reference will be in a loop. if (NodeUtil.mayEffectMutableState(cArg, compiler) && NodeUtil.getNameReferenceCount( block, fnParam.getString()) > 1) { return CanInlineResult.NO; } }  // Move to the next name. fnParam = fnParam.getNext(); }  // For every call argument check for side-effects, even if there // isn't a named parameter to match. if (cArg != null) { if (NodeUtil.mayHaveSideEffects(cArg, compiler)) { return CanInlineResult.NO; } cArg = cArg.getNext(); } }  return CanInlineResult.YES; }
 private CanInlineResult canInlineReferenceDirectly( Node callNode, Node fnNode) { if (!isDirectCallNodeReplacementPossible(fnNode)) { return CanInlineResult.NO; }  Node block = fnNode.getLastChild();   // CALL NODE: [ NAME, ARG1, ARG2, ... ] Node cArg = callNode.getFirstChild().getNext();  // Functions called via 'call' and 'apply' have a this-object as // the first parameter, but this is not part of the called function's // parameter list. if (!callNode.getFirstChild().isName()) { if (NodeUtil.isFunctionObjectCall(callNode)) { // TODO(johnlenz): Support replace this with a value. if (cArg == null || !cArg.isThis()) { return CanInlineResult.NO; } cArg = cArg.getNext(); } else { // ".apply" call should be filtered before this. Preconditions.checkState(!NodeUtil.isFunctionObjectApply(callNode)); } }  // FUNCTION NODE -> LP NODE: [ ARG1, ARG2, ... ] Node fnParam = NodeUtil.getFunctionParameters(fnNode).getFirstChild(); while (cArg != null || fnParam != null) { // For each named parameter check if a mutable argument use more than one. if (fnParam != null) { if (cArg != null) {  // Check for arguments that are evaluated more than once. // Note: Unlike block inlining, there it is not possible that a // parameter reference will be in a loop. if (NodeUtil.mayEffectMutableState(cArg, compiler) && NodeUtil.getNameReferenceCount( block, fnParam.getString()) > 1) { return CanInlineResult.NO; } }  // Move to the next name. fnParam = fnParam.getNext(); }  // For every call argument check for side-effects, even if there // isn't a named parameter to match. if (cArg != null) { if (NodeUtil.mayHaveSideEffects(cArg, compiler)) { return CanInlineResult.NO; } cArg = cArg.getNext(); } }  return CanInlineResult.YES; }
 void defineSlot(Node n, Node parent, JSType type, boolean inferred) { Preconditions.checkArgument(inferred || type != null);  // Only allow declarations of NAMEs and qualfied names. boolean shouldDeclareOnGlobalThis = false; if (n.getType() == Token.NAME) { Preconditions.checkArgument( parent.getType() == Token.FUNCTION || parent.getType() == Token.VAR || parent.getType() == Token.LP || parent.getType() == Token.CATCH); shouldDeclareOnGlobalThis = scope.isGlobal() && (parent.getType() == Token.VAR || parent.getType() == Token.FUNCTION); } else { Preconditions.checkArgument( n.getType() == Token.GETPROP && (parent.getType() == Token.ASSIGN || parent.getType() == Token.EXPR_RESULT)); } String variableName = n.getQualifiedName(); Preconditions.checkArgument(!variableName.isEmpty());  // If n is a property, then we should really declare it in the // scope where the root object appears. This helps out people // who declare "global" names in an anonymous namespace. Scope scopeToDeclareIn = scope;  // don't try to declare in the global scope if there's // already a symbol there with this name.  // declared in closest scope? if (scopeToDeclareIn.isDeclared(variableName, false)) { Var oldVar = scopeToDeclareIn.getVar(variableName); validator.expectUndeclaredVariable( sourceName, n, parent, oldVar, variableName, type); } else { if (!inferred) { setDeferredType(n, type); } CompilerInput input = compiler.getInput(sourceName); scopeToDeclareIn.declare(variableName, n, type, input, inferred);  if (shouldDeclareOnGlobalThis) { ObjectType globalThis = typeRegistry.getNativeObjectType(JSTypeNative.GLOBAL_THIS); boolean isExtern = input.isExtern(); if (inferred) { globalThis.defineInferredProperty(variableName, type == null ? getNativeType(JSTypeNative.NO_TYPE) : type, isExtern); } else { globalThis.defineDeclaredProperty(variableName, type, isExtern); } }  // If we're in the global scope, also declare var.prototype // in the scope chain. if (scopeToDeclareIn.isGlobal() && type instanceof FunctionType) { FunctionType fnType = (FunctionType) type; if (fnType.isConstructor() || fnType.isInterface()) { FunctionType superClassCtor = fnType.getSuperClassConstructor(); scopeToDeclareIn.declare(variableName + ".prototype", n, fnType.getPrototype(), compiler.getInput(sourceName), /* declared iff there's an explicit supertype */ superClassCtor == null || superClassCtor.getInstanceType().equals( getNativeType(OBJECT_TYPE))); } } } }
 public static int gcd(final int p, final int q) { int u = p; int v = q; if ((u == 0) || (v == 0)) { return (Math.abs(u) + Math.abs(v)); } // keep u and v negative, as negative integers range down to // -2^31, while positive numbers can only be as large as 2^31-1 // (i.e. we can't necessarily negate a negative number without // overflow) /* assert u!=0 && v!=0; */ if (u > 0) { u = -u; } // make u negative if (v > 0) { v = -v; } // make v negative // B1. [Find power of 2] int k = 0; while ((u & 1) == 0 && (v & 1) == 0 && k < 31) { // while u and v are // both even... u /= 2; v /= 2; k++; // cast out twos. } if (k == 31) { throw MathRuntimeException.createArithmeticException( "overflow: gcd({0}, {1}) is 2^31", new Object[] { p, q }); } // B2. Initialize: u and v have been divided by 2^k and at least // one is odd. int t = ((u & 1) == 1) ? v : -(u / 2)/* B3 */; // t negative: u was odd, v may be even (t replaces v) // t positive: u was even, v is odd (t replaces u) do { /* assert u<0 && v<0; */ // B4/B3: cast out twos from t. while ((t & 1) == 0) { // while t is even.. t /= 2; // cast out twos } // B5 [reset max(u,v)] if (t > 0) { u = -t; } else { v = t; } // B6/B3. at this point both u and v should be odd. t = (v - u) / 2; // |u| larger: t positive (replace u) // |v| larger: t negative (replace v) } while (t != 0); return -u * (1 << k); // gcd is u*2^k }
 public static int lcm(int a, int b) { if (a==0 || b==0){ return 0; } int lcm = Math.abs(mulAndCheck(a / gcd(a, b), b)); return lcm; }
 public static String abbreviate(String str, int lower, int upper, String appendToEnd) { // initial parameter checks if (str == null) { return null; } if (str.length() == 0) { return StringUtils.EMPTY; }  // if the lower value is greater than the length of the string, // set to the length of the string // if the upper value is -1 (i.e. no limit) or is greater // than the length of the string, set to the length of the string if (upper == -1 || upper > str.length()) { upper = str.length(); } // if upper is less than lower, raise it to lower if (upper < lower) { upper = lower; }  StringBuffer result = new StringBuffer(); int index = StringUtils.indexOf(str, " ", lower); if (index == -1) { result.append(str.substring(0, upper)); // only if abbreviation has occured do we append the appendToEnd value if (upper != str.length()) { result.append(StringUtils.defaultString(appendToEnd)); } } else if (index > upper) { result.append(str.substring(0, upper)); result.append(StringUtils.defaultString(appendToEnd)); } else { result.append(str.substring(0, index)); result.append(StringUtils.defaultString(appendToEnd)); } return result.toString(); }
 private double calculateAsymptoticPValue(final double Umin, final int n1, final int n2) throws ConvergenceException, MaxCountExceededException {  final int n1n2prod = n1 * n2;  // http://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U#Normal_approximation final double EU = n1n2prod / 2.0; final double VarU = n1n2prod * (n1 + n2 + 1) / 12.0;  final double z = (Umin - EU) / FastMath.sqrt(VarU);  final NormalDistribution standardNormal = new NormalDistribution(0, 1);  return 2 * standardNormal.cumulativeProbability(z); }
 public <T> T newInstance(Class<T> cls) { if (outerClassInstance == null) { return noArgConstructor(cls); } return withOuterClass(cls); }
 private <T> T withOuterClass(Class<T> cls) { try { //this is kind of overengineered because we don't need to support more params //however, I know we will be needing it :) Constructor<T> c = cls.getDeclaredConstructor(outerClassInstance.getClass()); return c.newInstance(outerClassInstance); } catch (Exception e) { throw paramsException(cls, e); } }
 private <T> T withOuterClass(Class<T> cls) { try { //this is kind of overengineered because we don't need to support more params //however, I know we will be needing it :) Constructor<T> c = cls.getDeclaredConstructor(outerClassInstance.getClass()); return c.newInstance(outerClassInstance); } catch (Exception e) { throw paramsException(cls, e); } }
 private void annotateCalls(Node n) { Preconditions.checkState(n.isCall());  // Keep track of of the "this" context of a call.  A call without an // explicit "this" is a free call. Node first = n.getFirstChild();  // ignore cast nodes.  if (!NodeUtil.isGet(first)) { n.putBooleanProp(Node.FREE_CALL, true); }  // Keep track of the context in which eval is called. It is important // to distinguish between "(0, eval)()" and "eval()". if (first.isName() && "eval".equals(first.getString())) { first.putBooleanProp(Node.DIRECT_EVAL, true); } }
 private boolean inferTemplatedTypesForCall( Node n, FunctionType fnType) { final ImmutableList<TemplateType> keys = fnType.getTemplateTypeMap() .getTemplateKeys(); if (keys.isEmpty()) { return false; }  // Try to infer the template types Map<TemplateType, JSType> inferred = inferTemplateTypesFromParameters(fnType, n);   // Replace all template types. If we couldn't find a replacement, we // replace it with UNKNOWN. TemplateTypeReplacer replacer = new TemplateTypeReplacer( registry, inferred); Node callTarget = n.getFirstChild();  FunctionType replacementFnType = fnType.visit(replacer) .toMaybeFunctionType(); Preconditions.checkNotNull(replacementFnType);  callTarget.setJSType(replacementFnType); n.setJSType(replacementFnType.getReturnType());  return replacer.madeChanges; }
 public boolean hasSameMethod(Invocation candidate) { //not using method.equals() for 1 good reason: //sometimes java generates forwarding methods when generics are in play see JavaGenericsForwardingMethodsTest Method m1 = invocation.getMethod(); Method m2 = candidate.getMethod();  /* Avoid unnecessary cloning */ return m1.equals(m2); }
 private boolean isFoldableExpressBlock(Node n) { if (n.getType() == Token.BLOCK) { if (n.hasOneChild()) { Node maybeExpr = n.getFirstChild(); // IE has a bug where event handlers behave differently when // their return value is used vs. when their return value is in // an EXPR_RESULT. It's pretty freaking weird. See: // http://code.google.com/p/closure-compiler/issues/detail?id=291 // We try to detect this case, and not fold EXPR_RESULTs // into other expressions.  // We only have to worry about methods with an implicit 'this' // param, or this doesn't happen.  return NodeUtil.isExpressionNode(maybeExpr); } }  return false; }
 Node processFunctionNode(FunctionNode functionNode) { Name name = functionNode.getFunctionName(); Boolean isUnnamedFunction = false; if (name == null) { name = new Name(); name.setIdentifier(""); isUnnamedFunction = true; } Node node = newNode(Token.FUNCTION); Node newName = transform(name); if (isUnnamedFunction) { // Old Rhino tagged the empty name node with the line number of the // declaration. newName.setLineno(functionNode.getLineno()); // TODO(bowdidge) Mark line number of paren correctly. // Same problem as below - the left paren might not be on the // same line as the function keyword. int lpColumn = functionNode.getAbsolutePosition() + functionNode.getLp(); newName.setCharno(position2charno(lpColumn)); }  node.addChildToBack(newName); Node lp = newNode(Token.LP); // The left paren's complicated because it's not represented by an // AstNode, so there's nothing that has the actual line number that it // appeared on.  We know the paren has to appear on the same line as the // function name (or else a semicolon will be inserted.)  If there's no // function name, assume the paren was on the same line as the function. // TODO(bowdidge): Mark line number of paren correctly. Name fnName = functionNode.getFunctionName(); if (fnName != null) { lp.setLineno(fnName.getLineno()); } else { lp.setLineno(functionNode.getLineno()); } int lparenCharno = functionNode.getLp() + functionNode.getAbsolutePosition();  lp.setCharno(position2charno(lparenCharno)); for (AstNode param : functionNode.getParams()) { lp.addChildToBack(transform(param)); } node.addChildToBack(lp);  Node bodyNode = transform(functionNode.getBody()); parseDirectives(bodyNode); node.addChildToBack(bodyNode); return node; }
 public double getPct(Object v) { return getCumPct((Comparable<?>) v); }
 public double getSumSquaredErrors() { return sumYY - sumXY * sumXY / sumXX; }
 private void traverse(Node node) { // The goal here is to avoid retraversing // the entire AST to catch newly created opportunities. // So we track whether a "unit of code" has changed, // and revisit immediately. if (!shouldVisit(node)) { return; }  int visits = 0; do { Node c = node.getFirstChild(); while(c != null) { traverse(c); Node next = c.getNext(); c = next; }  visit(node); visits++;  Preconditions.checkState(visits < 10000, "too many interations"); } while (shouldRetraverse(node));  exitNode(node); }
 public static int gcd(int u, int v) { if (u * v == 0) { return (Math.abs(u) + Math.abs(v)); } // keep u and v negative, as negative integers range down to // -2^31, while positive numbers can only be as large as 2^31-1 // (i.e. we can't necessarily negate a negative number without // overflow) /* assert u!=0 && v!=0; */ if (u > 0) { u = -u; } // make u negative if (v > 0) { v = -v; } // make v negative // B1. [Find power of 2] int k = 0; while ((u & 1) == 0 && (v & 1) == 0 && k < 31) { // while u and v are // both even... u /= 2; v /= 2; k++; // cast out twos. } if (k == 31) { throw new ArithmeticException("overflow: gcd is 2^31"); } // B2. Initialize: u and v have been divided by 2^k and at least // one is odd. int t = ((u & 1) == 1) ? v : -(u / 2)/* B3 */; // t negative: u was odd, v may be even (t replaces v) // t positive: u was even, v is odd (t replaces u) do { /* assert u<0 && v<0; */ // B4/B3: cast out twos from t. while ((t & 1) == 0) { // while t is even.. t /= 2; // cast out twos } // B5 [reset max(u,v)] if (t > 0) { u = -t; } else { v = t; } // B6/B3. at this point both u and v should be odd. t = (v - u) / 2; // |u| larger: t positive (replace u) // |v| larger: t negative (replace v) } while (t != 0); return -u * (1 << k); // gcd is u*2^k }
 public void applyAlias() { typeReference.setString(aliasName); }
 private void fixTypeNode(Node typeNode) { if (typeNode.isString()) { String name = typeNode.getString(); int endIndex = name.indexOf('.'); if (endIndex == -1) { endIndex = name.length(); } String baseName = name.substring(0, endIndex); Var aliasVar = aliases.get(baseName); if (aliasVar != null) { Node aliasedNode = aliasVar.getInitialValue(); aliasUsages.add(new AliasedTypeNode(typeNode, aliasedNode.getQualifiedName() + name.substring(endIndex))); } }  for (Node child = typeNode.getFirstChild(); child != null; child = child.getNext()) { fixTypeNode(child); } }
 private Node tryFoldSimpleFunctionCall(Node n) { Preconditions.checkState(n.isCall()); Node callTarget = n.getFirstChild(); if (callTarget != null && callTarget.isName() && callTarget.getString().equals("String")) { // Fold String(a) to '' + (a) on immutable literals, // which allows further optimizations // // We can't do this in the general case, because String(a) has // slightly different semantics than '' + (a). See // http://code.google.com/p/closure-compiler/issues/detail?id=759 Node value = callTarget.getNext(); if (value != null) { Node addition = IR.add( IR.string("").srcref(callTarget), value.detachFromParent()); n.getParent().replaceChild(n, addition); reportCodeChange(); return addition; } } return n; }
